{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import xml.etree.ElementTree as ET\n",
    "import glob, os\n",
    "import numpy as np\n",
    "from comet_ml import Experiment, Optimizer\n",
    "import pickle\n",
    "import logging\n",
    "import sys\n",
    "from sklearn.utils import class_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['TF_KERAS'] = '1'\n",
    "from tensorflow.keras.preprocessing import sequence\n",
    "from tensorflow.keras.models import Sequential, Model, load_model\n",
    "from tensorflow.keras.layers import Dense, Dropout, Embedding, LSTM, Lambda, BatchNormalization, \\\n",
    "    CuDNNLSTM, Bidirectional, Input, concatenate, Flatten, RepeatVector, Activation, Multiply, Permute\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras import callbacks, optimizers\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.utils import plot_model, Sequence\n",
    "\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\n",
    "# only reserve 1 GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tf.enable_eager_execution()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger = logging.getLogger('training')\n",
    "logger.addHandler(logging.StreamHandler(sys.stdout))\n",
    "logger.setLevel(logging.DEBUG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_subject_writings(subject_file):\n",
    "    writings = []\n",
    "    with open(subject_file) as sf:\n",
    "        contents = sf.read()\n",
    "        root = ET.fromstring(contents)\n",
    "        try:\n",
    "            subject = root.findall('ID')[0].text.strip()\n",
    "        except Exception:\n",
    "            print('Cannot extract ID', contents[:500], '\\n-------\\n')        \n",
    "        for w in root.iter('WRITING'):\n",
    "            subject_writings = {'subject': subject}\n",
    "            for title in w.findall('TITLE'):\n",
    "                subject_writings['title'] = title.text\n",
    "            for text in w.findall('TEXT'):\n",
    "                subject_writings['text'] = text.text\n",
    "            for date in w.findall('DATE'):\n",
    "                subject_writings['date'] = date.text\n",
    "            writings.append(subject_writings)\n",
    "    return writings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# root_dir = '/home/anasab/' \n",
    "root_dir = '/home/ana/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### eRisk 2020 T1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "datadir_T1 = root_dir + '/eRisk/data/eRisk2020_T1_train/eRISK2020_T1_training_data/eRISK2020_training_data/data/'\n",
    "labels_file_T1 = root_dir + '/eRisk/data//eRisk2020_T1_train/eRISK2020_T1_training_data/eRISK2020_training_data/golden_truth.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_texts_2020(datadir_T1, labels_file_T1):\n",
    "    writings = []\n",
    "    for subject_file in os.listdir(datadir_T1):\n",
    "        print(subject_file)\n",
    "        writings.extend(read_subject_writings(os.path.join(datadir_T1, subject_file)))\n",
    "    writings_df = pd.DataFrame(writings)\n",
    "\n",
    "    labels_T1 = pd.read_csv(labels_file_T1, delimiter=' ', names=['subject', 'label'])\n",
    "    labels_T1 = labels_T1.set_index('subject')\n",
    "\n",
    "    writings_df['label'] = writings_df['subject'].apply(\n",
    "    lambda s: labels_T1.loc[s, 'label'])\n",
    "    \n",
    "    return writings_df\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### eRisk 2019 T1 (Anorexia)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "datadirs_T1_2019 = {\n",
    "    'train': ['2018 test/', '2018 train/positive_examples/', '2018 train/negative_examples/'],\n",
    "    'test': ['data/']\n",
    "}\n",
    "datadir_root_T1_2019 = {\n",
    "    'train': root_dir + '/eRisk/data/past/eRisk2019_T1/training data - t1/',\n",
    "    'test': root_dir + '/eRisk/data/past/eRisk2019_T1/test data - T1/'\n",
    "}\n",
    "    \n",
    "labels_files_T1_2019 = {\n",
    "    'train': ['2018 train/risk_golden_truth.txt', '2018 test/risk-golden-truth-test.txt'],\n",
    "    'test': ['T1_erisk_golden_truth.txt']\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_texts_2019(datadir_root_T1_2019,\n",
    "                   datadirs_T1_2019,\n",
    "                   labels_files_T1_2019,\n",
    "                   test_suffix='0000'):\n",
    "    writings = {'train': [], 'test': []}\n",
    "    writings_df = pd.DataFrame()\n",
    "    labels_df = pd.DataFrame()\n",
    "\n",
    "    for subset in ('train', 'test'):\n",
    "        for subdir in [os.path.join(datadir_root_T1_2019[subset], subp) for subp in datadirs_T1_2019[subset]]:\n",
    "            if subset=='train':\n",
    "                chunkdirs = [os.path.join(datadir_root_T1_2019[subset], subdir, chunkdir) \n",
    "                             for chunkdir in os.listdir(subdir)]\n",
    "            else:\n",
    "                chunkdirs = [os.path.join(datadir_root_T1_2019[subset], subdir)]\n",
    "                \n",
    "            for chunkdir in chunkdirs:\n",
    "                if not os.path.isdir(chunkdir):\n",
    "                    continue\n",
    "                for subject_file in os.listdir(chunkdir):\n",
    "                    writings[subset].extend(read_subject_writings(os.path.join(chunkdir, subject_file)))\n",
    "        writings_df_part = pd.DataFrame(writings[subset])\n",
    "        # add a suffix for users in the test -- the numbers are duplicated with the ones in train\n",
    "        if subset=='test':\n",
    "            writings_df_part['subject'] = writings_df_part['subject'].apply(lambda s: s+test_suffix)\n",
    "            print(subset, writings_df_part.subject)\n",
    "        writings_df_part['subset'] = subset\n",
    "        writings_df = pd.concat([writings_df, writings_df_part])\n",
    "        writings_df.reindex()\n",
    "\n",
    "        for label_file in labels_files_T1_2019[subset]:\n",
    "            labels = pd.read_csv(os.path.join(datadir_root_T1_2019[subset], label_file), \n",
    "                                 delimiter='\\s+', names=['subject', 'label'])\n",
    "            # add a suffix for users in the test -- the numbers are duplicated with the ones in train\n",
    "            if subset=='test':\n",
    "                labels['subject'] = labels['subject'].apply(lambda s: s+test_suffix)\n",
    "            labels_df = pd.concat([labels_df, labels])\n",
    "    labels_df = labels_df.drop_duplicates()\n",
    "    labels_df = labels_df.set_index('subject')\n",
    "\n",
    "    writings_df = writings_df.drop_duplicates()\n",
    "    \n",
    "    writings_df = writings_df.join(labels_df, on='subject')\n",
    "    \n",
    "    return writings_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# writings_df = read_texts_2020(datadir_T1, labels_file_T1)\n",
    "# writings_df = read_texts_2019(datadir_root_T1_2019,\n",
    "#                    datadirs_T1_2019,\n",
    "#                    labels_files_T1_2019)\n",
    "writings_df = pickle.load(open('writings_df_selfharm_liwc', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f81c8aacb10>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "writings_df.label.hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subject</th>\n",
       "      <th>title</th>\n",
       "      <th>date</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>tokenized_title</th>\n",
       "      <th>title_len</th>\n",
       "      <th>tokenized_text</th>\n",
       "      <th>text_len</th>\n",
       "      <th>all_tokens</th>\n",
       "      <th>...</th>\n",
       "      <th>feel</th>\n",
       "      <th>excl</th>\n",
       "      <th>future</th>\n",
       "      <th>nonfl</th>\n",
       "      <th>ppron</th>\n",
       "      <th>shehe</th>\n",
       "      <th>i</th>\n",
       "      <th>we</th>\n",
       "      <th>you</th>\n",
       "      <th>they</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>subject8292</td>\n",
       "      <td>If anyone could help with which sub to put thi...</td>\n",
       "      <td>2016-08-02 09:22:12</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>[if, anyone, could, help, with, which, sub, to...</td>\n",
       "      <td>11.0</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[if, anyone, could, help, with, which, sub, to...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>subject8292</td>\n",
       "      <td>I'm literally never gonna stop waiting...</td>\n",
       "      <td>2016-08-05 09:35:55</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>[i, m, literally, never, gonna, stop, waiting]</td>\n",
       "      <td>7.0</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[i, m, literally, never, gonna, stop, waiting]</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>subject8292</td>\n",
       "      <td>This is a really interesting study! Makes sens...</td>\n",
       "      <td>2016-08-05 21:36:24</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>[this, is, a, really, interesting, study, make...</td>\n",
       "      <td>9.0</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[this, is, a, really, interesting, study, make...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>subject8292</td>\n",
       "      <td>The only thing Frank is building ...</td>\n",
       "      <td>2016-08-07 23:35:23</td>\n",
       "      <td>... Is hype. Think about it, every time he wor...</td>\n",
       "      <td>0</td>\n",
       "      <td>[the, only, thing, frank, is, building]</td>\n",
       "      <td>6.0</td>\n",
       "      <td>[is, hype, think, about, it, every, time, he, ...</td>\n",
       "      <td>26.0</td>\n",
       "      <td>[is, hype, think, about, it, every, time, he, ...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.062500</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.062500</td>\n",
       "      <td>0.03125</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.03125</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>subject8292</td>\n",
       "      <td>Mostly always me during this whole charade</td>\n",
       "      <td>2016-08-09 08:39:41</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>[mostly, always, me, during, this, whole, char...</td>\n",
       "      <td>7.0</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[mostly, always, me, during, this, whole, char...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 74 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       subject                                              title  \\\n",
       "0  subject8292  If anyone could help with which sub to put thi...   \n",
       "1  subject8292          I'm literally never gonna stop waiting...   \n",
       "2  subject8292  This is a really interesting study! Makes sens...   \n",
       "3  subject8292               The only thing Frank is building ...   \n",
       "4  subject8292         Mostly always me during this whole charade   \n",
       "\n",
       "                  date                                               text  \\\n",
       "0  2016-08-02 09:22:12                                                NaN   \n",
       "1  2016-08-05 09:35:55                                                NaN   \n",
       "2  2016-08-05 21:36:24                                                NaN   \n",
       "3  2016-08-07 23:35:23  ... Is hype. Think about it, every time he wor...   \n",
       "4  2016-08-09 08:39:41                                                NaN   \n",
       "\n",
       "   label                                    tokenized_title  title_len  \\\n",
       "0      0  [if, anyone, could, help, with, which, sub, to...       11.0   \n",
       "1      0     [i, m, literally, never, gonna, stop, waiting]        7.0   \n",
       "2      0  [this, is, a, really, interesting, study, make...        9.0   \n",
       "3      0            [the, only, thing, frank, is, building]        6.0   \n",
       "4      0  [mostly, always, me, during, this, whole, char...        7.0   \n",
       "\n",
       "                                      tokenized_text  text_len  \\\n",
       "0                                               None       NaN   \n",
       "1                                               None       NaN   \n",
       "2                                               None       NaN   \n",
       "3  [is, hype, think, about, it, every, time, he, ...      26.0   \n",
       "4                                               None       NaN   \n",
       "\n",
       "                                          all_tokens  ...  feel      excl  \\\n",
       "0  [if, anyone, could, help, with, which, sub, to...  ...   0.0  0.090909   \n",
       "1     [i, m, literally, never, gonna, stop, waiting]  ...   0.0  0.000000   \n",
       "2  [this, is, a, really, interesting, study, make...  ...   0.0  0.111111   \n",
       "3  [is, hype, think, about, it, every, time, he, ...  ...   0.0  0.000000   \n",
       "4  [mostly, always, me, during, this, whole, char...  ...   0.0  0.000000   \n",
       "\n",
       "     future  nonfl     ppron    shehe         i       we  you  they  \n",
       "0  0.090909    0.0  0.000000  0.00000  0.000000  0.00000  0.0   0.0  \n",
       "1  0.285714    0.0  0.142857  0.00000  0.142857  0.00000  0.0   0.0  \n",
       "2  0.000000    0.0  0.000000  0.00000  0.000000  0.00000  0.0   0.0  \n",
       "3  0.062500    0.0  0.062500  0.03125  0.000000  0.03125  0.0   0.0  \n",
       "4  0.000000    0.0  0.142857  0.00000  0.142857  0.00000  0.0   0.0  \n",
       "\n",
       "[5 rows x 74 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "writings_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = RegexpTokenizer(r'\\w+')\n",
    "\n",
    "def tokenize(t):\n",
    "    return tokenizer.tokenize(t.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_fields(writings_df):\n",
    "    writings_df['tokenized_title'] = writings_df['title'].apply(lambda t: tokenize(t) \n",
    "                                                                if type(t)==str and t else None)\n",
    "    writings_df['title_len'] = writings_df['tokenized_title'].apply(lambda t: len(t) \n",
    "                                                                    if type(t)==list and t else None)\n",
    "    writings_df['tokenized_text'] = writings_df['text'].apply(lambda t: tokenize(t) \n",
    "                                                              if type(t)==str and t else None)\n",
    "    writings_df['text_len'] = writings_df['tokenized_text'].apply(lambda t: len(t) \n",
    "                                                                  if type(t)==list and t else None)\n",
    "    return writings_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    127941.000000\n",
       "mean         32.268929\n",
       "std          82.590713\n",
       "min           0.000000\n",
       "25%           6.000000\n",
       "50%          13.000000\n",
       "75%          31.000000\n",
       "max        7201.000000\n",
       "Name: text_len, dtype: float64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "writings_df.text_len.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    49762.000000\n",
       "mean        10.699771\n",
       "std          9.282454\n",
       "min          0.000000\n",
       "25%          4.000000\n",
       "50%          8.000000\n",
       "75%         14.000000\n",
       "max        149.000000\n",
       "Name: title_len, dtype: float64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "writings_df.title_len.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>title_len</th>\n",
       "      <th>text_len</th>\n",
       "      <th>funct</th>\n",
       "      <th>article</th>\n",
       "      <th>affect</th>\n",
       "      <th>negemo</th>\n",
       "      <th>sad</th>\n",
       "      <th>cogmech</th>\n",
       "      <th>inhib</th>\n",
       "      <th>...</th>\n",
       "      <th>feel</th>\n",
       "      <th>excl</th>\n",
       "      <th>future</th>\n",
       "      <th>nonfl</th>\n",
       "      <th>ppron</th>\n",
       "      <th>shehe</th>\n",
       "      <th>i</th>\n",
       "      <th>we</th>\n",
       "      <th>you</th>\n",
       "      <th>they</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>340.000000</td>\n",
       "      <td>336.000000</td>\n",
       "      <td>340.000000</td>\n",
       "      <td>340.000000</td>\n",
       "      <td>340.000000</td>\n",
       "      <td>340.000000</td>\n",
       "      <td>340.000000</td>\n",
       "      <td>340.000000</td>\n",
       "      <td>340.000000</td>\n",
       "      <td>340.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>340.000000</td>\n",
       "      <td>340.000000</td>\n",
       "      <td>340.000000</td>\n",
       "      <td>340.000000</td>\n",
       "      <td>340.000000</td>\n",
       "      <td>340.000000</td>\n",
       "      <td>340.000000</td>\n",
       "      <td>340.000000</td>\n",
       "      <td>340.000000</td>\n",
       "      <td>340.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.120588</td>\n",
       "      <td>9.514427</td>\n",
       "      <td>33.122855</td>\n",
       "      <td>0.425434</td>\n",
       "      <td>0.049284</td>\n",
       "      <td>0.080990</td>\n",
       "      <td>0.023242</td>\n",
       "      <td>0.003515</td>\n",
       "      <td>0.125608</td>\n",
       "      <td>0.004730</td>\n",
       "      <td>...</td>\n",
       "      <td>0.005483</td>\n",
       "      <td>0.022510</td>\n",
       "      <td>0.089113</td>\n",
       "      <td>0.002740</td>\n",
       "      <td>0.079820</td>\n",
       "      <td>0.008573</td>\n",
       "      <td>0.040263</td>\n",
       "      <td>0.004642</td>\n",
       "      <td>0.020469</td>\n",
       "      <td>0.005873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.326128</td>\n",
       "      <td>4.714271</td>\n",
       "      <td>31.874155</td>\n",
       "      <td>0.085804</td>\n",
       "      <td>0.013413</td>\n",
       "      <td>0.032889</td>\n",
       "      <td>0.011015</td>\n",
       "      <td>0.002891</td>\n",
       "      <td>0.031706</td>\n",
       "      <td>0.002874</td>\n",
       "      <td>...</td>\n",
       "      <td>0.004131</td>\n",
       "      <td>0.009740</td>\n",
       "      <td>0.028436</td>\n",
       "      <td>0.004729</td>\n",
       "      <td>0.027475</td>\n",
       "      <td>0.007100</td>\n",
       "      <td>0.020218</td>\n",
       "      <td>0.004367</td>\n",
       "      <td>0.012310</td>\n",
       "      <td>0.004040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.018182</td>\n",
       "      <td>0.005237</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.601190</td>\n",
       "      <td>14.402079</td>\n",
       "      <td>0.379003</td>\n",
       "      <td>0.042321</td>\n",
       "      <td>0.063090</td>\n",
       "      <td>0.016110</td>\n",
       "      <td>0.001949</td>\n",
       "      <td>0.109709</td>\n",
       "      <td>0.002829</td>\n",
       "      <td>...</td>\n",
       "      <td>0.003234</td>\n",
       "      <td>0.016795</td>\n",
       "      <td>0.073775</td>\n",
       "      <td>0.000669</td>\n",
       "      <td>0.064952</td>\n",
       "      <td>0.004052</td>\n",
       "      <td>0.027496</td>\n",
       "      <td>0.002302</td>\n",
       "      <td>0.013474</td>\n",
       "      <td>0.003566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>8.660264</td>\n",
       "      <td>24.212121</td>\n",
       "      <td>0.439643</td>\n",
       "      <td>0.049415</td>\n",
       "      <td>0.074207</td>\n",
       "      <td>0.022189</td>\n",
       "      <td>0.002867</td>\n",
       "      <td>0.127451</td>\n",
       "      <td>0.004594</td>\n",
       "      <td>...</td>\n",
       "      <td>0.004879</td>\n",
       "      <td>0.022203</td>\n",
       "      <td>0.088307</td>\n",
       "      <td>0.001581</td>\n",
       "      <td>0.077149</td>\n",
       "      <td>0.006945</td>\n",
       "      <td>0.037420</td>\n",
       "      <td>0.003735</td>\n",
       "      <td>0.018725</td>\n",
       "      <td>0.005123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>11.526931</td>\n",
       "      <td>37.878342</td>\n",
       "      <td>0.478550</td>\n",
       "      <td>0.057188</td>\n",
       "      <td>0.090063</td>\n",
       "      <td>0.028348</td>\n",
       "      <td>0.004319</td>\n",
       "      <td>0.145710</td>\n",
       "      <td>0.006224</td>\n",
       "      <td>...</td>\n",
       "      <td>0.006712</td>\n",
       "      <td>0.027300</td>\n",
       "      <td>0.105534</td>\n",
       "      <td>0.002902</td>\n",
       "      <td>0.093965</td>\n",
       "      <td>0.011430</td>\n",
       "      <td>0.049840</td>\n",
       "      <td>0.005544</td>\n",
       "      <td>0.025045</td>\n",
       "      <td>0.007488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>32.166667</td>\n",
       "      <td>266.446446</td>\n",
       "      <td>0.646948</td>\n",
       "      <td>0.095561</td>\n",
       "      <td>0.270520</td>\n",
       "      <td>0.073699</td>\n",
       "      <td>0.020833</td>\n",
       "      <td>0.251136</td>\n",
       "      <td>0.022180</td>\n",
       "      <td>...</td>\n",
       "      <td>0.042094</td>\n",
       "      <td>0.090475</td>\n",
       "      <td>0.202499</td>\n",
       "      <td>0.045799</td>\n",
       "      <td>0.213871</td>\n",
       "      <td>0.069447</td>\n",
       "      <td>0.133143</td>\n",
       "      <td>0.037712</td>\n",
       "      <td>0.099026</td>\n",
       "      <td>0.041093</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 67 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            label   title_len    text_len       funct     article      affect  \\\n",
       "count  340.000000  336.000000  340.000000  340.000000  340.000000  340.000000   \n",
       "mean     0.120588    9.514427   33.122855    0.425434    0.049284    0.080990   \n",
       "std      0.326128    4.714271   31.874155    0.085804    0.013413    0.032889   \n",
       "min      0.000000    1.000000    1.000000    0.018182    0.005237    0.000000   \n",
       "25%      0.000000    6.601190   14.402079    0.379003    0.042321    0.063090   \n",
       "50%      0.000000    8.660264   24.212121    0.439643    0.049415    0.074207   \n",
       "75%      0.000000   11.526931   37.878342    0.478550    0.057188    0.090063   \n",
       "max      1.000000   32.166667  266.446446    0.646948    0.095561    0.270520   \n",
       "\n",
       "           negemo         sad     cogmech       inhib  ...        feel  \\\n",
       "count  340.000000  340.000000  340.000000  340.000000  ...  340.000000   \n",
       "mean     0.023242    0.003515    0.125608    0.004730  ...    0.005483   \n",
       "std      0.011015    0.002891    0.031706    0.002874  ...    0.004131   \n",
       "min      0.000000    0.000000    0.000000    0.000000  ...    0.000000   \n",
       "25%      0.016110    0.001949    0.109709    0.002829  ...    0.003234   \n",
       "50%      0.022189    0.002867    0.127451    0.004594  ...    0.004879   \n",
       "75%      0.028348    0.004319    0.145710    0.006224  ...    0.006712   \n",
       "max      0.073699    0.020833    0.251136    0.022180  ...    0.042094   \n",
       "\n",
       "             excl      future       nonfl       ppron       shehe           i  \\\n",
       "count  340.000000  340.000000  340.000000  340.000000  340.000000  340.000000   \n",
       "mean     0.022510    0.089113    0.002740    0.079820    0.008573    0.040263   \n",
       "std      0.009740    0.028436    0.004729    0.027475    0.007100    0.020218   \n",
       "min      0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "25%      0.016795    0.073775    0.000669    0.064952    0.004052    0.027496   \n",
       "50%      0.022203    0.088307    0.001581    0.077149    0.006945    0.037420   \n",
       "75%      0.027300    0.105534    0.002902    0.093965    0.011430    0.049840   \n",
       "max      0.090475    0.202499    0.045799    0.213871    0.069447    0.133143   \n",
       "\n",
       "               we         you        they  \n",
       "count  340.000000  340.000000  340.000000  \n",
       "mean     0.004642    0.020469    0.005873  \n",
       "std      0.004367    0.012310    0.004040  \n",
       "min      0.000000    0.000000    0.000000  \n",
       "25%      0.002302    0.013474    0.003566  \n",
       "50%      0.003735    0.018725    0.005123  \n",
       "75%      0.005544    0.025045    0.007488  \n",
       "max      0.037712    0.099026    0.041093  \n",
       "\n",
       "[8 rows x 67 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "writings_df.groupby('subject').mean().describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>title_len</th>\n",
       "      <th>text_len</th>\n",
       "      <th>all_tokens</th>\n",
       "      <th>funct</th>\n",
       "      <th>article</th>\n",
       "      <th>affect</th>\n",
       "      <th>negemo</th>\n",
       "      <th>sad</th>\n",
       "      <th>cogmech</th>\n",
       "      <th>...</th>\n",
       "      <th>feel</th>\n",
       "      <th>excl</th>\n",
       "      <th>future</th>\n",
       "      <th>nonfl</th>\n",
       "      <th>ppron</th>\n",
       "      <th>shehe</th>\n",
       "      <th>i</th>\n",
       "      <th>we</th>\n",
       "      <th>you</th>\n",
       "      <th>they</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>label</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>299</td>\n",
       "      <td>296</td>\n",
       "      <td>299</td>\n",
       "      <td>299</td>\n",
       "      <td>299</td>\n",
       "      <td>299</td>\n",
       "      <td>299</td>\n",
       "      <td>299</td>\n",
       "      <td>299</td>\n",
       "      <td>299</td>\n",
       "      <td>...</td>\n",
       "      <td>299</td>\n",
       "      <td>299</td>\n",
       "      <td>299</td>\n",
       "      <td>299</td>\n",
       "      <td>299</td>\n",
       "      <td>299</td>\n",
       "      <td>299</td>\n",
       "      <td>299</td>\n",
       "      <td>299</td>\n",
       "      <td>299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>41</td>\n",
       "      <td>40</td>\n",
       "      <td>41</td>\n",
       "      <td>41</td>\n",
       "      <td>41</td>\n",
       "      <td>41</td>\n",
       "      <td>41</td>\n",
       "      <td>41</td>\n",
       "      <td>41</td>\n",
       "      <td>41</td>\n",
       "      <td>...</td>\n",
       "      <td>41</td>\n",
       "      <td>41</td>\n",
       "      <td>41</td>\n",
       "      <td>41</td>\n",
       "      <td>41</td>\n",
       "      <td>41</td>\n",
       "      <td>41</td>\n",
       "      <td>41</td>\n",
       "      <td>41</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 68 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       date  title_len  text_len  all_tokens  funct  article  affect  negemo  \\\n",
       "label                                                                          \n",
       "0       299        296       299         299    299      299     299     299   \n",
       "1        41         40        41          41     41       41      41      41   \n",
       "\n",
       "       sad  cogmech  ...  feel  excl  future  nonfl  ppron  shehe    i   we  \\\n",
       "label                ...                                                      \n",
       "0      299      299  ...   299   299     299    299    299    299  299  299   \n",
       "1       41       41  ...    41    41      41     41     41     41   41   41   \n",
       "\n",
       "       you  they  \n",
       "label             \n",
       "0      299   299  \n",
       "1       41    41  \n",
       "\n",
       "[2 rows x 68 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "writings_df.groupby('subject').max().groupby('label').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average number of posts per user 146.35882352941175\n",
      "Average number of comments per user 376.2970588235294\n"
     ]
    }
   ],
   "source": [
    "print(\"Average number of posts per user\", writings_df.groupby('subject').count().title.mean())\n",
    "print(\"Average number of comments per user\", writings_df.groupby('subject').count().text.mean())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    340.000000\n",
       "mean     146.358824\n",
       "std      240.998992\n",
       "min        0.000000\n",
       "25%       13.000000\n",
       "50%       42.500000\n",
       "75%      148.500000\n",
       "max      998.000000\n",
       "Name: title, dtype: float64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "writings_df.groupby('subject').count().title.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count     340.000000\n",
       "mean      376.297059\n",
       "std       379.091730\n",
       "min         1.000000\n",
       "25%        54.000000\n",
       "50%       214.500000\n",
       "75%       646.000000\n",
       "max      1350.000000\n",
       "Name: text, dtype: float64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "writings_df.groupby('subject').count().text.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recurrent NN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract features and encode data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparams_features = {\n",
    "    \"max_features\": 40000,\n",
    "    # cut texts after this number of words\n",
    "    # (among top max_features most common words)\n",
    "    \"maxlen\": 500,\n",
    "    \"embedding_dim\": 100,\n",
    "    \"user_level\": True,\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Emotions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_NRC(nrc_path):\n",
    "    word_emotions = {}\n",
    "    emotion_words = {}\n",
    "    with open(nrc_path) as in_f:\n",
    "        for line in in_f:\n",
    "            line = line.strip()\n",
    "            if not line:\n",
    "                continue\n",
    "            word, emotion, label = line.split()\n",
    "            if word not in word_emotions:\n",
    "                word_emotions[word] = set()\n",
    "            if emotion not in emotion_words:\n",
    "                emotion_words[emotion] = set()\n",
    "            label = int(label)\n",
    "            if label:\n",
    "                word_emotions[word].add(emotion)\n",
    "                emotion_words[emotion].add(word)\n",
    "    return emotion_words\n",
    "\n",
    "nrc_lexicon_path = root_dir + '/resources/NRC-Emotion-Lexicon-Wordlevel-v0.92.txt'\n",
    "nrc_lexicon = load_NRC(nrc_lexicon_path)\n",
    "emotions = list(nrc_lexicon.keys())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_emotions(tokens, emotion_lexicon, emotions, relative=True):\n",
    "    text_len = len(tokens)\n",
    "    encoded_emotions = [0 for e in emotions]\n",
    "    for i, emotion in enumerate(emotions):\n",
    "        try:\n",
    "            emotion_words = [t for t in tokens if t in emotion_lexicon[emotion]]\n",
    "            if relative:\n",
    "                encoded_emotions[i] = len(emotion_words) / len(tokens)\n",
    "            else:\n",
    "                encoded_emotions[i] = len(emotion_words)\n",
    "        except ValueError:\n",
    "            print(\"Emotion not found.\")\n",
    "    return encoded_emotions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from liwc_readDict import readDict\n",
    "\n",
    "liwc = readDict(root_dir + '/resources/liwc.dic')\n",
    "\n",
    "categories = set([c for (w,c) in liwc])\n",
    "len(categories)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Style features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Char n-grams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_ngrams(tokens):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Personal pronouns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_person_pronouns = {\"i\", \"me\", \"my\", \"mine\", \"myself\"}\n",
    "def encode_pronouns(tokens, pronouns={\"i\", \"me\", \"my\", \"mine\", \"myself\"}, relative=True):\n",
    "    if not tokens:\n",
    "        return np.nan\n",
    "    text_len = len(tokens)\n",
    "    nr_pronouns = len([t for t in tokens if t in pronouns])\n",
    "    if relative:\n",
    "        return nr_pronouns/text_len\n",
    "    else:\n",
    "        return nr_pronouns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopword_list = stopwords.words(\"english\")\n",
    "def encode_stopwords(tokens, stopwords=stopword_list):\n",
    "    encoded_stopwords = [0 for s in stopword_list]\n",
    "    if not tokens:\n",
    "        return encoded_stopwords\n",
    "    for i, stopword in enumerate(stopwords):\n",
    "        if stopword in tokens:\n",
    "            encoded_stopwords[i] += 1\n",
    "    return encoded_stopwords"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Topics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encode data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "def load_erisk_data(writings_df, voc_size, emotion_lexicon, seq_len, emotions =  \n",
    "                    ['anger', 'anticipation', 'disgust', 'fear', 'joy', \n",
    "                     'negative', 'positive', 'sadness', 'surprise', 'trust'],\n",
    "                    liwc_categories = categories,\n",
    "                    pronouns = [\"i\", \"me\", \"my\", \"mine\", \"myself\"],\n",
    "                    train_prop=0.7, valid_prop=0.3, test_slice=2,\n",
    "                    nr_slices=5,\n",
    "                    min_post_len=3, min_word_len=1, \n",
    "                    user_level=True, vocabulary=None,\n",
    "                   logger=logger):\n",
    "    logger.debug(\"Loading data...\\n\")\n",
    "    if not vocabulary:\n",
    "        vocabulary = {}\n",
    "        word_freqs = Counter()\n",
    "        for words in writings_df.tokenized_text:\n",
    "            word_freqs.update(words)\n",
    "        for words in writings_df.tokenized_title:\n",
    "            word_freqs.update(words)\n",
    "        i = 1\n",
    "        for w, f in word_freqs.most_common(voc_size-2): # keeping voc_size-1 for unk\n",
    "            if len(w) < min_word_len:\n",
    "                continue\n",
    "            vocabulary[w] = i\n",
    "            i += 1\n",
    "    tokens_data_train = []\n",
    "    categ_data_train = []\n",
    "    sparse_data_train = []\n",
    "    tokens_data_valid = []\n",
    "    categ_data_valid = []\n",
    "    sparse_data_valid = []\n",
    "    tokens_data_test = []\n",
    "    categ_data_test = []\n",
    "    sparse_data_test = []\n",
    "    labels_train = []\n",
    "    users_train = []\n",
    "    labels_valid = []\n",
    "    users_valid = []\n",
    "    users_test = []\n",
    "    labels_test = []\n",
    "    if 'subset' in writings_df.columns:\n",
    "        training_subjects = list(set(writings_df[writings_df['subset']=='train'].subject))\n",
    "        test_subjects = list(set(writings_df[writings_df['subset']=='test'].subject))\n",
    "    else:\n",
    "        all_subjects = sorted(list(set(writings_df.subject)))\n",
    "        training_subjects_size = int(len(all_subjects) * train_prop)\n",
    "        test_subjects_size = len(all_subjects) - training_subjects_size\n",
    "        # Cross-validation, with fixed slice as input\n",
    "        test_prop = 1-train_prop\n",
    "        test_slice = min(test_slice, nr_slices)\n",
    "        logger.debug(\"start index: %f, from %f\\n\" % (\n",
    "            len(all_subjects)*(1/nr_slices)*test_slice, test_prop*test_slice))\n",
    "        start_slice = int(len(all_subjects)*(1/nr_slices)*test_slice)\n",
    "        test_subjects = all_subjects[start_slice: start_slice+test_subjects_size]\n",
    "        training_subjects = [s for s in all_subjects if s not in test_subjects]\n",
    "    training_subjects = sorted(training_subjects) # ensuring reproducibility\n",
    "    valid_subjects_size = int(len(training_subjects) * valid_prop)\n",
    "    valid_subjects = training_subjects[:valid_subjects_size]\n",
    "    training_subjects = training_subjects[valid_subjects_size:]\n",
    "    categories = [c for c in liwc_categories if c in writings_df.columns]\n",
    "    logger.debug(\"%d training users, %d validation users, %d test users.\" % (\n",
    "        len(training_subjects), \n",
    "          len(valid_subjects),\n",
    "          len(test_subjects)))\n",
    "    subjects_split = {'train': training_subjects, \n",
    "                      'valid': valid_subjects, \n",
    "                      'test': test_subjects}\n",
    "\n",
    "    user_level_texts = {}\n",
    "    for row in writings_df.sort_values(by='date').itertuples():\n",
    "        words = []\n",
    "        if row.tokenized_title:\n",
    "            words.extend(row.tokenized_title)\n",
    "        if row.tokenized_text:\n",
    "            words.extend(row.tokenized_text)\n",
    "        if not words or len(words)<min_post_len:\n",
    "            continue\n",
    "        label = row.label\n",
    "        liwc_categs = [getattr(row, categ) for categ in categories]\n",
    "        if row.subject not in user_level_texts.keys():\n",
    "            user_level_texts[row.subject] = {}\n",
    "            user_level_texts[row.subject]['texts'] = [words]\n",
    "            user_level_texts[row.subject]['label'] = label\n",
    "            user_level_texts[row.subject]['liwc'] = [liwc_categs]\n",
    "        else:\n",
    "            user_level_texts[row.subject]['texts'].append(words)\n",
    "            user_level_texts[row.subject]['liwc'].append(liwc_categs)\n",
    "    return user_level_texts, subjects_split, vocabulary\n",
    "\n",
    "#     for subject in user_level_texts.keys():\n",
    "#         texts = user_level_texts[subject]['texts']\n",
    "#         label = user_level_texts[subject]['label']\n",
    "#         if user_level:\n",
    "#             all_words = [sum(texts, [])] # merge all texts in one list\n",
    "#             liwc_aggreg = [np.array(user_level_texts[subject]['liwc']).mean(axis=0).tolist()]\n",
    "#         else:\n",
    "#             all_words = texts\n",
    "#             liwc_aggreg = user_level_texts[subject]['liwc']\n",
    "#         for i, words in enumerate(all_words):\n",
    "#             encoded_tokens, encoded_emotions, encoded_pronouns, encoded_stopwords = encode_text(words)\n",
    "#             subject_id = int(subject.split('t')[1])\n",
    "#             if subject in training_subjects:\n",
    "#                 tokens_data_train.append(encoded_tokens)\n",
    "#                 categ_data_train.append(encoded_emotions + [encoded_pronouns] + liwc_aggreg[i])\n",
    "#                 sparse_data_train.append(encoded_stopwords)\n",
    "#                 labels_train.append(label)\n",
    "#                 users_train.append(subject_id)\n",
    "#             elif subject in valid_subjects:\n",
    "#                 tokens_data_valid.append(encoded_tokens)\n",
    "#                 categ_data_valid.append(encoded_emotions + [encoded_pronouns]  + liwc_aggreg[i])\n",
    "#                 sparse_data_valid.append(encoded_stopwords)\n",
    "#                 labels_valid.append(label)\n",
    "#                 users_valid.append(subject_id)\n",
    "#             else:\n",
    "#                 tokens_data_test.append(encoded_tokens)\n",
    "#                 categ_data_test.append(encoded_emotions + [encoded_pronouns] + liwc_aggreg[i])\n",
    "#                 sparse_data_test.append(encoded_stopwords)\n",
    "#                 labels_test.append(label)\n",
    "#                 users_test.append(subject_id)\n",
    "        \n",
    "#     # using zeros for padding\n",
    "#     tokens_data_train_padded = sequence.pad_sequences(tokens_data_train, maxlen=seq_len)\n",
    "#     tokens_data_valid_padded = sequence.pad_sequences(tokens_data_valid, maxlen=seq_len)\n",
    "#     tokens_data_test_padded = sequence.pad_sequences(tokens_data_test, maxlen=seq_len)\n",
    "        \n",
    "#     return ([np.array(tokens_data_train_padded), np.array(categ_data_train), np.array(sparse_data_train),\n",
    "#             np.array(users_train)],\n",
    "#             np.array(labels_train)), \\\n",
    "#             ([np.array(tokens_data_valid_padded),\n",
    "#               np.array(categ_data_valid), np.array(sparse_data_valid),\n",
    "#             np.array(users_valid)],\n",
    "#             np.array(labels_valid)), \\\n",
    "#             ([np.array(tokens_data_test_padded), np.array(categ_data_test), np.array(sparse_data_test),\n",
    "#              np.array(users_test)],\n",
    "#              np.array(labels_test)), vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "\n",
      "start index: 136.000000, from 0.600000\n",
      "\n",
      "166 training users, 71 validation users, 103 test users.\n"
     ]
    }
   ],
   "source": [
    "user_level_data, subjects_split, vocabulary = load_erisk_data(writings_df, \n",
    "                                                            seq_len=hyperparams_features['maxlen'],\n",
    "                                                            voc_size=hyperparams_features['max_features'],\n",
    "                                                           emotion_lexicon=nrc_lexicon,\n",
    "                                                           emotions=emotions,\n",
    "                                                           user_level=hyperparams_features['user_level'],\n",
    "                                                                                logger=logger\n",
    "#                                                            vocabulary=pickle.load(open('vocabulary20K_selfharm.pkl', 'rb'))\n",
    "                                                                               )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataGenerator(Sequence):\n",
    "    'Generates data for Keras'\n",
    "    def __init__(self, user_level_data, subjects_split, set_type='train',\n",
    "                 batch_size=32, seq_len=500, voc_size=40000, emotion_lexicon=nrc_lexicon,\n",
    "                 emotions=emotions, pronouns=[\"i\", \"me\", \"my\", \"mine\", \"myself\"], max_posts_per_user=10,\n",
    "                 shuffle=True):\n",
    "        'Initialization'\n",
    "        self.seq_len = seq_len\n",
    "        self.subjects_split = subjects_split\n",
    "        self.set = set_type\n",
    "        self.emotion_lexicon = emotion_lexicon\n",
    "        self.batch_size = batch_size\n",
    "        self.data = user_level_data\n",
    "        self.emotions = emotions\n",
    "        self.pronouns = pronouns\n",
    "        self.shuffle = shuffle\n",
    "        self.voc_size = voc_size\n",
    "        self.max_posts_per_user = max_posts_per_user\n",
    "        self.on_epoch_end()\n",
    "\n",
    "    def __encode_text(self, tokens):\n",
    "        # Using voc_size-1 value for OOV token\n",
    "        encoded_tokens = [vocabulary.get(w, self.voc_size-1) for w in tokens]\n",
    "        encoded_emotions = encode_emotions(tokens, self.emotion_lexicon, self.emotions)\n",
    "        encoded_pronouns = encode_pronouns(tokens, self.pronouns)\n",
    "        encoded_stopwords = encode_stopwords(tokens)\n",
    "        return (encoded_tokens, encoded_emotions, encoded_pronouns, encoded_stopwords)\n",
    "        \n",
    "    def __len__(self):\n",
    "        'Denotes the number of batches per epoch'\n",
    "        return int(np.floor(len(self.subjects_split[self.set]) / self.batch_size))\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        'Generate one batch of data'\n",
    "        # Generate indexes of the batch\n",
    "        user_indexes = self.indexes[index*self.batch_size:(index+1)*self.batch_size]\n",
    "        # Find users\n",
    "        users = [self.subjects_split[self.set][i] for i in user_indexes]\n",
    "\n",
    "        post_indexes = {}\n",
    "        # Sample post ids\n",
    "        for subject in users:\n",
    "            posts_len = len(self.data[subject])\n",
    "            posts_index_sample = sorted(np.random.choice(posts_len, \n",
    "                                                         min(self.max_posts_per_user, posts_len),\n",
    "                                                         replace=False))\n",
    "            post_indexes[subject] = posts_index_sample\n",
    "        # Generate data\n",
    "        X, y = self.__data_generation(users, post_indexes)\n",
    "\n",
    "        return X, y\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        'Updates indexes after each epoch'\n",
    "        self.indexes = np.arange(len(self.subjects_split[self.set]))\n",
    "        if self.shuffle == True:\n",
    "            np.random.shuffle(self.indexes)\n",
    "\n",
    "    def __data_generation(self, users, post_indexes):\n",
    "        'Generates data containing batch_size samples' # X : (n_samples, *dim, n_channels)\n",
    "        tokens_data = []\n",
    "        categ_data = []\n",
    "        sparse_data = []\n",
    "        subjects = []\n",
    "        labels = []\n",
    "        for subject in users:\n",
    "            texts = self.data[subject]['texts']\n",
    "            label = self.data[subject]['label']\n",
    "            \n",
    "            # Sample\n",
    "            texts = [texts[i] for i in post_indexes[subject]]\n",
    "            all_words = [sum(texts, [])] # merge all texts in one list\n",
    "            liwc_aggreg = [np.array(self.data[subject]['liwc']).mean(axis=0).tolist()]\n",
    "\n",
    "            for i, words in enumerate(all_words):\n",
    "                encoded_tokens, encoded_emotions, encoded_pronouns, encoded_stopwords = self.__encode_text(words)\n",
    "                subject_id = int(subject.split('t')[1])\n",
    "                tokens_data.append(encoded_tokens)\n",
    "                categ_data.append(encoded_emotions + [encoded_pronouns] + liwc_aggreg[i])\n",
    "                sparse_data.append(encoded_stopwords)\n",
    "                labels.append(label)\n",
    "                subjects.append(subject_id)\n",
    "\n",
    "        \n",
    "        # using zeros for padding\n",
    "        tokens_data_padded = sequence.pad_sequences(tokens_data, maxlen=self.seq_len)\n",
    "\n",
    "        return ([np.array(tokens_data_padded), np.array(categ_data), np.array(sparse_data),\n",
    "                np.array(subjects)],\n",
    "                np.array(labels))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26 train positive examples\n",
      "\n",
      "5 valid positive examples\n",
      "\n",
      "9 test positive examples\n",
      "\n"
     ]
    }
   ],
   "source": [
    "logger.setLevel(logging.DEBUG)\n",
    "\n",
    "# TODO: it is skipping the last batch\n",
    "\n",
    "for set_type in ['train', 'valid', 'test']:\n",
    "    total_positive = 0\n",
    "    for x, y in DataGenerator(user_level_data, subjects_split, \n",
    "                                          set_type=set_type):\n",
    "        total_positive += pd.Series(y_train).sum()\n",
    "    logger.info(\"%d %s positive examples\\n\" % (total_positive, set_type))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32, 179)"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "item[0][2].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.57142857, 4.        ])"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_weights = class_weight.compute_class_weight('balanced',\n",
    "                                                 np.unique(y_train),\n",
    "                                                 y_train)\n",
    "class_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total 40000 word vectors.\n"
     ]
    }
   ],
   "source": [
    "def load_embeddings(path, embedding_dim, voc):\n",
    "    # random matrix with mean value = 0\n",
    "    embedding_matrix = np.random.random((len(voc)+2, embedding_dim)) - 0.5 # voc + unk + pad value(0)\n",
    "\n",
    "    f = open(path)\n",
    "    for line in f:\n",
    "        values = line.split()\n",
    "        word = values[0]\n",
    "        coefs = np.asarray(values[1:], dtype='float32')\n",
    "        word_i = voc.get(word)\n",
    "        if word_i is not None:\n",
    "            embedding_matrix[word_i] = coefs\n",
    "    f.close()\n",
    "\n",
    "    print('Total %s word vectors.' % len(embedding_matrix))\n",
    "\n",
    " \n",
    "    return embedding_matrix\n",
    "\n",
    "pretrained_embeddings_path = root_dir + '/resources/glove.twitter.27B/glove.twitter.27B.%dd.txt' % hyperparams_features['embedding_dim']\n",
    "embedding_matrix = load_embeddings(pretrained_embeddings_path, hyperparams_features['embedding_dim'], voc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(166,)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train[3].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparams = {\n",
    "    'lstm_units': 256,\n",
    "    'dense_bow_units': 5,\n",
    "    'dropout': 0.0,\n",
    "    'l2_dense': 0.0000011,\n",
    "    'l2_embeddings': 0.000001,\n",
    "    'optimizer': 'adam',\n",
    "    'decay': 0.0001,\n",
    "    'lr': 0.001,\n",
    "    \"batch_size\": 32,\n",
    "    \"trainable_embeddings\": True,\n",
    "    \"reduce_lr_factor\": 0.0002,\n",
    "    \"reduce_lr_patience\": 50,\n",
    "    \"freeze_patience\": 500,\n",
    "    'threshold': 0.5,\n",
    "    'ignore_layer': [],\n",
    "    'norm_momentum': 0.3,\n",
    "\n",
    "}\n",
    "if not hyperparams['optimizer']:\n",
    "    hyperparams['optimizer'] = optimizers.Adam(lr=hyperparams['lr'], #beta_1=0.9, beta_2=0.999, epsilon=0.0001,\n",
    "                                   decay=hyperparams['decay'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Metrics():\n",
    "    def __init__(self, threshold=0.5):\n",
    "        self.threshold=threshold\n",
    "        \n",
    "    def recall_m(self, y_true, y_pred):\n",
    "            y_labels = y_true\n",
    "            y_pred = K.cast(K.greater(K.clip(y_pred, 0, 1), self.threshold), K.floatx())        \n",
    "            possible_positives = K.sum(K.round(K.clip(y_labels, 0, 1)))\n",
    "            true_positives = K.sum(K.round(K.clip(y_labels * y_pred, 0, 1)))\n",
    "            recall = true_positives / (possible_positives + K.epsilon())\n",
    "            return recall\n",
    "\n",
    "    def precision_m(self, y_true, y_pred):\n",
    "            y_labels = y_true\n",
    "            y_pred = K.cast(K.greater(K.clip(y_pred, 0, 1), self.threshold), K.floatx())        \n",
    "            true_positives = K.sum(K.round(K.clip(y_labels * y_pred, 0, 1)))\n",
    "            predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "            precision = true_positives / (predicted_positives + K.epsilon())\n",
    "            return precision\n",
    "\n",
    "    def f1_m(self, y_true, y_pred):\n",
    "        precision = self.precision_m(y_true, y_pred)\n",
    "        recall = self.recall_m(y_true, y_pred)\n",
    "        return 2*((precision*recall)/(precision+recall+K.epsilon()))\n",
    "\n",
    "def binary_crossentropy_custom(y_true, y_pred):\n",
    "    y_labels = y_true\n",
    "    return K.binary_crossentropy(y_labels, \n",
    "                                 y_pred)\n",
    "\n",
    "metrics_class = Metrics(threshold=hyperparams['threshold'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(hyperparams, hyperparams_features, embedding_matrix, emotions, stopwords_list,\n",
    "                liwc_categories,\n",
    "               ignore_layer=[]):\n",
    "\n",
    "    tokens_features = Input(shape=(hyperparams_features['maxlen'],), name='word_seq')\n",
    "    embedding_layer = Embedding(hyperparams_features['max_features'], \n",
    "                                hyperparams_features['embedding_dim'], \n",
    "                                input_length=hyperparams_features['maxlen'],\n",
    "                                embeddings_regularizer=regularizers.l2(hyperparams['l2_embeddings']),\n",
    "                                weights=[embedding_matrix], \n",
    "                                trainable=hyperparams['trainable_embeddings'],\n",
    "                               name='embeddings_layer')(\n",
    "        tokens_features)\n",
    "    if 'batchnorm' not in ignore_layer:\n",
    "        embedding_layer_norm = BatchNormalization(axis=1, momentum=hyperparams['norm_momentum'],\n",
    "                                                     name='embeddings_layer_norm')(embedding_layer)\n",
    "#     lstm_layers = Bidirectional(LSTM(hyperparams['lstm_units']))(embedding_layer)\n",
    "\n",
    "    if tf.test.is_gpu_available():\n",
    "        lstm_layers = CuDNNLSTM(hyperparams['lstm_units'], \n",
    "                                return_sequences='attention' not in ignore_layer, # only True if using attention\n",
    "                      name='LSTM_layer')(embedding_layer)\n",
    "    else:\n",
    "        lstm_layers = LSTM(hyperparams['lstm_units'], \n",
    "                           return_sequences='attention' not in ignore_layer,\n",
    "                      name='LSTM_layer')(embedding_layer)\n",
    "    \n",
    "    # Attention\n",
    "    if 'attention' not in ignore_layer:\n",
    "        attention = Dense(1, activation='tanh', name='attention')(lstm_layers)\n",
    "        attention = Flatten()(attention)\n",
    "        attention = Activation('softmax')(attention)\n",
    "        attention = RepeatVector(hyperparams['lstm_units'])(attention)\n",
    "        attention = Permute([2, 1])(attention)\n",
    "\n",
    "        sent_representation = Multiply()([lstm_layers, attention])\n",
    "        sent_representation = Lambda(lambda xin: K.sum(xin, axis=1), \n",
    "                                     output_shape=(hyperparams['lstm_units'],)\n",
    "                                    )(sent_representation)\n",
    "\n",
    "        \n",
    "    else:\n",
    "        sent_representation = lstm_layers\n",
    "        \n",
    "    \n",
    "    sent_representation = Dropout(hyperparams['dropout'], name='lstm_att_dropout')(sent_representation)\n",
    "    numerical_features = Input(shape=(len(emotions) + 1 + len(liwc_categories),), name='numeric_input') # emotions and pronouns\n",
    "    dense_layer = Dense(units=1,\n",
    "                        kernel_regularizer=regularizers.l2(hyperparams['l2_dense']),\n",
    "                        name='numerical_dense_layer',\n",
    "                       )(numerical_features)\n",
    "    sparse_features = Input(shape=(len(stopwords_list),), name='sparse_input') # stopwords\n",
    "\n",
    "    dense_layer_sparse = Dense(units=hyperparams['dense_bow_units'],\n",
    "                              name='sparse_feat_dense_layer',\n",
    "                                kernel_regularizer=regularizers.l2(hyperparams['l2_dense']),\n",
    "                              )(sparse_features)\n",
    "    \n",
    "    if 'batchnorm' not in ignore_layer:\n",
    "        numerical_features_norm = BatchNormalization(axis=1, momentum=hyperparams['norm_momentum'],\n",
    "                                                     name='numerical_features_norm')(numerical_features)\n",
    "        sent_representation_norm = BatchNormalization(axis=1, momentum=hyperparams['norm_momentum'],\n",
    "                                                      name='sent_repr_norm')(sent_representation)\n",
    "        dense_layer_sparse_norm = BatchNormalization(axis=1, momentum=hyperparams['norm_momentum'],\n",
    "                                                     name='sparse_features_norm')(dense_layer_sparse)\n",
    "        \n",
    "    subjects = Input(shape=(1,), name='subjects')\n",
    "    \n",
    "\n",
    "    all_layers = {\n",
    "        'lstm_layers': sent_representation,\n",
    "        'numerical_dense_layer': numerical_features,\n",
    "        'sparse_feat_dense_layer': dense_layer_sparse\n",
    "    }\n",
    "    if 'batchnorm' not in ignore_layer:\n",
    "        all_layers = {\n",
    "            'lstm_layers': sent_representation_norm,\n",
    "            'numerical_dense_layer': numerical_features_norm,\n",
    "            'sparse_feat_dense_layer': dense_layer_sparse_norm\n",
    "        }\n",
    "    layers_to_merge = []\n",
    "    for n, l in all_layers.items():\n",
    "        if n in ignore_layer:\n",
    "            continue\n",
    "        layers_to_merge.append(l)\n",
    "        \n",
    "    if len(layers_to_merge) == 1:\n",
    "        merged_layers = layers_to_merge[0]\n",
    "    else:\n",
    "        merged_layers = concatenate(layers_to_merge)\n",
    "    output_layer = Dense(1, activation='sigmoid',\n",
    "                         name='output_layer',\n",
    "                        kernel_regularizer=regularizers.l2(hyperparams['l2_dense']))(merged_layers)\n",
    "\n",
    "    # Compile model\n",
    "    model = Model(inputs=[tokens_features, numerical_features, sparse_features, subjects], \n",
    "                  outputs=output_layer)\n",
    "\n",
    "    model.compile(hyperparams['optimizer'], binary_crossentropy_custom,\n",
    "                  metrics=[metrics_class.f1_m, metrics_class.precision_m, metrics_class.recall_m])\n",
    "    return model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/ana/anaconda3/envs/tf/lib/python3.7/site-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /home/ana/anaconda3/envs/tf/lib/python3.7/site-packages/tensorflow/python/keras/layers/core.py:143: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "word_seq (InputLayer)           (None, 500)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embeddings_layer (Embedding)    (None, 500, 100)     4000000     word_seq[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "LSTM_layer (LSTM)               (None, 500, 256)     365568      embeddings_layer[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "attention (Dense)               (None, 500, 1)       257         LSTM_layer[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 500)          0           attention[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation (Activation)         (None, 500)          0           flatten[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "repeat_vector (RepeatVector)    (None, 256, 500)     0           activation[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "permute (Permute)               (None, 500, 256)     0           repeat_vector[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "multiply (Multiply)             (None, 500, 256)     0           LSTM_layer[0][0]                 \n",
      "                                                                 permute[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda (Lambda)                 (None, 256)          0           multiply[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "sparse_input (InputLayer)       (None, 179)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lstm_att_dropout (Dropout)      (None, 256)          0           lambda[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "numeric_input (InputLayer)      (None, 75)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "sparse_feat_dense_layer (Dense) (None, 5)            900         sparse_input[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "sent_repr_norm (BatchNormalizat (None, 256)          1024        lstm_att_dropout[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "numerical_features_norm (BatchN (None, 75)           300         numeric_input[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "sparse_features_norm (BatchNorm (None, 5)            20          sparse_feat_dense_layer[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 336)          0           sent_repr_norm[0][0]             \n",
      "                                                                 numerical_features_norm[0][0]    \n",
      "                                                                 sparse_features_norm[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "output_layer (Dense)            (None, 1)            337         concatenate[0][0]                \n",
      "==================================================================================================\n",
      "Total params: 4,368,406\n",
      "Trainable params: 4,367,734\n",
      "Non-trainable params: 672\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = build_model(hyperparams, hyperparams_features, embedding_matrix, emotions, stopword_list,\n",
    "                    liwc_categories=[c for c in categories if c in writings_df.columns]\n",
    ",\n",
    "                   ignore_layer=hyperparams['ignore_layer'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot_model(model, 'models/lstm_plus_attention.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "COMET INFO: old comet version (3.0.2) detected. current: 3.1.0 please update your comet lib with command: `pip install --no-cache-dir --upgrade comet_ml`\n",
      "COMET INFO: Experiment is live on comet.ml https://www.comet.ml/ananana/mental/63067179a5f349be819ce476a2d64b36\n",
      "\n"
     ]
    }
   ],
   "source": [
    "experiment = Experiment(api_key=\"eoBdVyznAhfg3bK9pZ58ZSXfv\",\n",
    "                        project_name=\"mental\", workspace=\"ananana\")\n",
    "\n",
    "experiment.log_parameters(hyperparams_features)\n",
    "\n",
    "experiment.log_parameter('emotion_lexicon', nrc_lexicon_path)\n",
    "experiment.log_parameter('emotions', emotions)\n",
    "experiment.log_parameter('embeddings_path', pretrained_embeddings_path)\n",
    "if 'subset' in writings_df.columns:\n",
    "    experiment.add_tag('anorexia')\n",
    "\n",
    "experiment.log_parameters(hyperparams)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WeightsHistory(callbacks.Callback):\n",
    "    def on_train_begin(self, logs={}):\n",
    "        self.log_weights(0)\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        self.log_weights(epoch)\n",
    "        \n",
    "    def log_weights(self, step):\n",
    "        for layer in model.layers:\n",
    "            try:\n",
    "                experiment.log_histogram_3d(layer.get_weights()[0], \n",
    "                                            name=layer.name, step=step)\n",
    "            except Exception as e:\n",
    "                logger.debug(\"Logging weights error: \" + str(e) + \"\\n\")\n",
    "                # Layer probably does not exist\n",
    "                pass\n",
    "\n",
    "\n",
    "class FreezeLayer(callbacks.Callback):\n",
    "    def __init__(self, logs={}, patience=5, layer='embeddings_layer', verbose=1, set_to=False):\n",
    "        super(FreezeLayer, self).__init__()\n",
    "        self.freeze_epoch = patience\n",
    "        self.freeze_layer = layer\n",
    "        self.verbose = verbose\n",
    "        self.set_to = set_to\n",
    "\n",
    "    def on_epoch_begin(self, epoch, logs={}):\n",
    "        logging.debug(\"Trainable embeddings\", model.get_layer(self.freeze_layer).trainable)\n",
    "        if epoch == self.freeze_epoch:\n",
    "            try:\n",
    "                layer = model.get_layer(self.freeze_layer)\n",
    "                old_value = layer.trainable\n",
    "                layer.trainable = self.set_to\n",
    "                # TODO: does this reset the optimizer?\n",
    "                model.compile(hyperparams['optimizer'], binary_crossentropy_custom,\n",
    "                  metrics=[metrics_class.f1_m, metrics_class.precision_m, metrics_class.recall_m])\n",
    "                if self.verbose:\n",
    "                    logging.debug(\"Setting %s layer from %s to trainable=%s...\\n\" % (layer.name, old_value,\n",
    "                                                                   model.get_layer(self.freeze_layer).trainable))\n",
    "            except Exception as e:\n",
    "                # layer probably does not exist\n",
    "                pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping_patience=50\n",
    "def train_model(model, \n",
    "                data_generator_train, data_generator_valid,\n",
    "                batch_size, epochs, class_weight, start_epoch=0, workers=4,\n",
    "                callback_list = [],\n",
    "                model_path='/tmp/model',\n",
    "               verbose=1):\n",
    "    logging.info('Train...')\n",
    "    experiment.log_parameter('class_weight', class_weight.values())\n",
    "    experiment.log_parameter('callbacks', callbacks)\n",
    "\n",
    "    history = model.fit_generator(data_generator_train,\n",
    "#               batch_size=batch_size,\n",
    "                steps_per_epoch=100,\n",
    "              epochs=epochs, initial_epoch=start_epoch, \n",
    "              class_weight=class_weight,\n",
    "              validation_data=data_generator_valid,\n",
    "                        verbose=verbose,\n",
    "#               validation_split=0.3,\n",
    "                       workers=workers,\n",
    "            callbacks = [\n",
    "                callbacks.ModelCheckpoint(filepath='%s_best' % model_path, verbose=1, \n",
    "                                          save_best_only=True),\n",
    "                callbacks.EarlyStopping(patience=early_stopping_patience), *callback_list\n",
    "            ])\n",
    "    model.save(model_path)\n",
    "    experiment.log_parameter('model_path', model_path)\n",
    "    return model, history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/ana/anaconda3/envs/tf/lib/python3.7/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/ana/anaconda3/envs/tf/lib/python3.7/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logging weights error: list index out of range\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:training:Logging weights error: list index out of range\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logging weights error: list index out of range\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:training:Logging weights error: list index out of range\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logging weights error: list index out of range\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:training:Logging weights error: list index out of range\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logging weights error: list index out of range\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:training:Logging weights error: list index out of range\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logging weights error: list index out of range\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:training:Logging weights error: list index out of range\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logging weights error: list index out of range\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:training:Logging weights error: list index out of range\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logging weights error: list index out of range\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:training:Logging weights error: list index out of range\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logging weights error: list index out of range\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:training:Logging weights error: list index out of range\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logging weights error: list index out of range\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:training:Logging weights error: list index out of range\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logging weights error: list index out of range\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:training:Logging weights error: list index out of range\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logging weights error: list index out of range\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:training:Logging weights error: list index out of range\n",
      "\n",
      "COMET INFO: Ignoring automatic log_parameter('verbose') because 'keras:verbose' is in COMET_LOGGING_PARAMETERS_IGNORE\n",
      "COMET INFO: Ignoring automatic log_parameter('do_validation') because 'keras:do_validation' is in COMET_LOGGING_PARAMETERS_IGNORE\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "freeze_layer = FreezeLayer(patience=hyperparams['freeze_patience'], set_to=not hyperparams['trainable_embeddings'])\n",
    "weights_history = WeightsHistory()\n",
    "reduce_lr = callbacks.ReduceLROnPlateau(monitor='val_loss', factor=hyperparams['reduce_lr_factor'],\n",
    "                          patience=hyperparams['reduce_lr_patience'], min_lr=0.000001, verbose=1)\n",
    "data_generator_train = DataGenerator(user_level_data, subjects_split, set_type='train')\n",
    "data_generator_valid = DataGenerator(user_level_data, subjects_split, set_type='valid')\n",
    "model, history = train_model(model, data_generator_train, data_generator_valid,\n",
    "           epochs=50, batch_size=hyperparams['batch_size'],\n",
    "                      class_weight={0:0.5, 1:5}, start_epoch=0,\n",
    "                      callback_list = [freeze_layer, weights_history, reduce_lr],\n",
    "                      model_path='models/lstm_user_selfharm_att', workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "103/103 [==============================] - 1s 10ms/sample - loss: 0.9224 - f1_m: 0.4902 - precision_m: 0.3849 - recall_m: 0.6875\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.9223724927717042, 0.49020976, 0.38492063, 0.6875]"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "dependencies = {\n",
    "    'f1_m': metrics_class.f1_m,\n",
    "    'precision_m': metrics_class.precision_m,\n",
    "    'recall_m': metrics_class.recall_m,\n",
    "    'binary_crossentropy_custom': binary_crossentropy_custom\n",
    "}\n",
    "model = load_model(model_path, custom_objects=dependencies)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f5025e55e10>"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYsAAAD4CAYAAAAdIcpQAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAgAElEQVR4nOy9eZhldX3n//rcfat96+qN7qa7gYYGxBYQBWMQRDSCMzpB/UV0dIiJZp3E0ZmYOCbxiTETZpzBPOOOJiMiE0eMGIKIUVGBRva1q/fqrfaqu6/f3x/nfE/dun23qrq3lnu/r+epp2+de+6537p97nmfzy5KKQwGg8FgqIZrtRdgMBgMhrWPEQuDwWAw1MSIhcFgMBhqYsTCYDAYDDUxYmEwGAyGmnhWewGNpL+/X23btm21l2EwGAzriscff3xCKTVQbZ+WEott27axf//+1V6GwWAwrCtE5GitfYwbymAwGAw1MWJhMBgMhpoYsTAYDAZDTYxYGAwGg6EmRiwMBoPBUBMjFgaDwWCoiRELg8FgMNSkpeosDAaDod0Zi6b4ycsT+L0u3nLxxoYdtyGWhYjcICIviciIiHy0zPN+Efmm/fwjIrLN3n6diDwuIs/Y//5q0WteaW8fEZHPiog0Yq0Gg8HQytz2tcf5j996it/5xhNkcoWGHXfZYiEibuAO4E3AHuCdIrKnZLf3A9NKqZ3A7cCn7e0TwK8ppfYCtwJfL3rN3wG3AbvsnxuWu1aDwWBodU7NJgFQCmaSmYYdtxGWxeXAiFLqkFIqA9wF3FSyz03Anfbje4BrRUSUUk8opU7a258DArYVMgx0KqV+rqxRfl8Dbm7AWg0Gg6FlUUoxnciyqTsIwHQ827BjN0IsNgHHi34ftbeV3UcplQNmgb6Sff4t8IRSKm3vP1rjmACIyG0isl9E9o+Pjy/5jzAYDIb1TipbIJMrsL0/DMB0wrIskpk8xyYTyzp2I8SiXCyhdLB31X1E5EIs19RvLuKY1kalPq+U2qeU2jcwULVposFgMLQ0Why0WMwkMiil+MDXHuPav/0R//ry0m+oGyEWo8CWot83Aycr7SMiHqALmLJ/3wx8G3iPUupg0f6baxzTYDAYDEXMJCy3kxaLqXiWf3jkGA+PTNIZ8PKbX9/PiZnkko7dCLF4DNglIttFxAfcAtxbss+9WAFsgLcDP1RKKRHpBr4HfEwp9bDeWSl1CoiKyJV2FtR7gO80YK0Gg8HQssxoy2Jg3g31dz86yOXbe/ncuy8jlS0wMhZb0rGXLRZ2DOLDwP3AC8DdSqnnROSTIvJWe7cvAX0iMgL8IaDTaz8M7AQ+LiJP2j+D9nO/BXwRGAEOAt9f7loNBoOhlZm2LYvhrgBBr5vxaJqTs0levaOPzqAXgGQmt6RjN6QoTyl1H3BfybY/LXqcAt5R5nV/AfxFhWPuBy5qxPoMBoOhHdCpst1BHz0hL8+fmkMp2NQdJOyzLvfxdH5JxzbtPgwGg6FF0DGL7pCXnrCPF07OAbCxO0jQ5wYgsUTLwoiFwWAwtAgziQwBr4uA101PyEc0bQnDxu4AYb8lFvHM0iwL0xvKYDAYWoTpRJaekA+wrAvNxu4gPrcLEUgYsTAYDIb2ZiaRpdsWi96w9W9/xEfAa1kVIa+bRNq4oQwGg6GtmUlk6LaznrRobLRbfwAEfZ4lu6GMWBgMBkOLMJ3I0BO2xKLXdkNt7JoXi7DfbQLcBoPB0O7MJrN0BS2Losd2Q23qmReLkM+z5JiFEQuDwWBoAZRSzCSy9NgWRU8ZN1TYZywLg8FgaGti6Ry5gjpLJHbYrT8Agj73kovyTDaUwWAwtAC6IK/Ltix2Dkb4/u9dzfkbOpx9wj4PY3PpJR3fiIXBYDC0ALo9ubYsAC4Y7lywT8jvJr6avaEMBoPBsLpoy6KnqBivlLAd4J6KZ/jZwQlcIrzpog11Hd+IhcFgMLQA2rLoriIWIZ+beDrHX33/Be7ebw0jve93r67r+CbAbTAYDC3AbFI3EfRV3Cfk85DOFTg6mUDseaTjsfpiGEYsDAaDoQWYjtsB7mAVN5TdTPDIZJzzhjrs12XqOr4RC4PBYGgBphMZOvwevO7Kl/WQPdPizFzayZKaMmJhaDZ3PDTCu7/4i9VehsFgwHJDdYcrWxVgxSw0u4Y6cEn9YmEC3IYlMZvI8rmHRsjkCyilEO0ANRgMq8J0IkN3sHK8AhaKxVBngJ6Qj6mEsSwMTeTvHzlKPJMnm1dL7mJpMBgah9WevLplEfbP2wdDnX56wz4TszA0j1y+wFd/dgSf7Rut92QzGAzNYyaRqZoJBWUsi7DPxCwMzeMnIxOMR9O89dKNwHwxkMFgWD1mktmqBXkwH+AGGOoI0BvyOfUZtTBiYVg03/7lCbqCXv7NKzYBlq/0E/c+x7f2H1/xtcylssyljFgZ2pt8QVkB7jotC7/HRWfQs/KWhYjcICIviciIiHy0zPN+Efmm/fwjIrLN3t4nIg+JSExE/lfJa35kH/NJ+2ewEWs1LI9YOse/PH+at1w8zGCnH4DxaJqv/uwIf3zP0/z3H7y8ouv5g7ue5I+/9dSKvqfBsNaYS2ZRCmdKXiV0zGKw04+I0Bv2Ml2nZ2DZYiEibuAO4E3AHuCdIrKnZLf3A9NKqZ3A7cCn7e0p4OPAH1U4/LuVUpfaP2PLXath+Tx6eJJUtsCb9w47dzEvnYkCsKU3yH//wQG+8eixFVvP0akEJ2aSK/Z+BsNaZMau3u6pM3V2qCMAQG/YT76g6nqPRlgWlwMjSqlDSqkMcBdwU8k+NwF32o/vAa4VEVFKxZVSP8USDcM64Mnjs7gELtnS7dzFvHBqDoD/+tYLed3uAT7+/55lbG5l/kun4xliqaV10TQYWgWnL1SN1Fm/x4VLrOA2QG8NcSmmEWKxCSh2Vo/a28ruo5TKAbNAXx3H/ortgvq4VEjkF5HbRGS/iOwfHx9f/OoNi+LJ4zPsHuog7PfgcbvoCHh48bRlWWzsDnLrVeeQKyhOzjZfLAoFxXQiQ9SIhaHNmU3ovlDVL/4iwnBX0BmI1FMjxlFMI8Si3EW81K6pZ59S3q2U2gtcbf/8RrmdlFKfV0rtU0rtGxgYqLlYw9JRSvHU8Rku3dLtbOsJ+RiPWo3INnQGiPitk3Ul7vbnUlkKCqJpIxaG9qbcLItKfPtDV/Gh1+8EoDe8smIxCmwp+n0zcLLSPiLiAbqAqWoHVUqdsP+NAv8Hy91lWEWOTiaYTWa5ZIFYWOLg97joCnqJ2AG0WLr5GUo6MJfJFUjnTGGgoX1xpuTVCHADDHYECHit2MVKi8VjwC4R2S4iPuAW4N6Sfe4FbrUfvx34oVKqomUhIh4R6bcfe4G3AM82YK2GZfDk8RkALtk8LxY6yL2hK4CIFIlF8y/exSl/Jm5haGe0K7YjsLgOTosRi2X3hlJK5UTkw8D9gBv4slLqORH5JLBfKXUv8CXg6yIygmVR3KJfLyJHgE7AJyI3A9cDR4H7baFwAz8AvrDctRqWx08OTBDxe9g9FHG2actCB8wi9skaW4Hah+LK8Vg6R1/E3/T3NBjWIvFMjoDXhadKx9lyBL1uLt/ey9E69m1II0Gl1H3AfSXb/rTocQp4R4XXbqtw2Fc2Ym2GxhBL57jvmVPc/IqNC05Ix7KwxUL3y1+JflHFDdBMkNvQzsTSOceqXwwiwt2/+Wrkg7X3NRXchrr43tMnSWbzvGPflgXbe4rcUAB+jxuf27UiF+9iy8KIhaGdiadzC5oENgPTotxQlUQmx/u+8hjPnJjl3IEwrygKbsN8EZB2Q4HlilrJADdA1LT8MLQx8SVaFovBWBaGqhyZSPDI4Sn2bevlU2/be9bcilI3FFiuqPgKBLhLYxYGQ6tzajZJNl84a3s01XzLwoiFoSr6jv22q3dwxY6z6yi394URgV1FQe+I37sibqGpRIbBDr+9TiMWhtYmX1Bc/7c/5nMPHQSsm6Vbv/wojx+dIp4xloVhlamVkrd3cxe//JPr2G0Pfwfo8K+QGyqeYWtvCDCWhaH1mUtmiaZzPPDCaZRS/NG3nuJfXx7nF4emiKfzxrIwrC5R+6LfWaXYp6ckV3vF3FCJDEOdAXweF3OpLD89MEEqa4rzDK2JbsX/7Ik5Pvejgzz4otVbdSaRWXI21GIwYmGoylxy8cU+kYB3Re70pxNZesJeOgMenj4+y//3pUe4/7nTTX9fg2E1mE3OW+t/8y8v8Yqt3WzoDDCdyBJL5Yj43VVevXyMWBiqomMWixILv7vpMYR8QTGTyNAb8hHxe5zqcjO1z9Cq6Bs3AKXgP91wvjO8KJltvhvKpM4aqhJN5fB5XPg99d+1RPwe4k22LI5OxikoGOjwEwl4ODKZAKxKVoOhFdGWxVsv2UjI5+bKHX10B72cmLbmuTTbDWXEwlCVuVSOzkX2m4n4vSSzeXL5wqLbD9TLNx49hsclXH/hBu57Zt711GyRMhhWCx2z+NiN5zPcFQSsOqenRy2r2sQsDKtKNJWlI1D/gBRofsuPZCbP3ftHeeOFGxjqDDj9qIAVCawbDKuBtiyKO8t2BX3O98xkQxlWlWgqt+hOlnr/ZgW5f/jiGLPJLO++cuuC9wOr4txgaEXmklk8LiHonXcJ9xQNOzKWhWFVsSyLxbuhoHltw8ei1hS+CzZ0AlZdh2YlGhgaDKvBbDJLV9C7oItC8WQ8Y1kYVpVoKkfnEt1QzbIsdFxCfzm0m0zExCwMrctcKndWvVN30WQ8Y1kYmsJnHzzAB7/+eM395pZgWTTbDRVL5/G5Xfg81unbE/YhAucOREiYmIWhRZlNZs8Six4jFoZm89iRKX58YJwqAwsBHbNYrGWhByA1z7IIFxUgvWPfZv7+/VdwTm/IpM6uI6bjGX7lMw/x7InZ1V7KumAumT0rM3GhG8oU5RmawFQ8QyKTZ7Koc2spuXyBRCa/hJiFtX+zXELxdI6Qb35NnQEvr9nZT9jvIWFiFuuGl89EOTKZ4Ck79dNQnbmylsXKxSxMnUWbMhmzROL4VIL+CuNItRtpsZZFhx3gjjbNDVW+D07Y7zYNBdcRp+esRIXpKjcsBrjzZ0d46vgMc6nsgrRZsFJnAbxuwe9p7r2/sSzaEKUUk/E0AMft6s9yLHUIvBPgbpYbKpMra3KHfB4SRizWDadnLbGYipsWLdX4yYFx/t+TJ5hOZM9KNtFuqLDfc9asmUZjxKINmUvlyOatWMXxqUSV/eyOs4sUC4/bRcDralr8IFahHXPY5yaRzVMoVI/DGNYGjmWRMJZFNabiGQrK6odWall43S4ifg9hX/OdREYs2pDJWNp5PDpdWSzmLYvFuaGgcQOQfvTSGF99+PCCbZVGSIb9HpSCVM7ELdYDZ+a0ZZHhl8em+R8/OLDKK1qbTBW56TqDZ5/33SFv0zOhwIhFW1J88h2rYlnoi/1i6yzA6jzbiAD33fuP8/kfH1qwrdJw+pC/uSm7hsai3VDTiQz3PD7K7T942cwjKUNxEkqpZQFW+mxkkdb/UmiIWIjIDSLykoiMiMhHyzzvF5Fv2s8/IiLb7O19IvKQiMRE5H+VvOaVIvKM/ZrPSrMdcm3EhB3cPncgzKHxOH/4zSd5/Oj0WfvNJRffnlwTCXgactGeS+ZI5RbOHK4Y4PZZcQxTa7E+0GIxGctwasaKnZ2ytxksMrnCAgu93I3bu67Yyr/bt7npa1m2WIiIG7gDeBOwB3iniOwp2e39wLRSaidwO/Bpe3sK+DjwR2UO/XfAbcAu++eG5a7VYKGD25du6eHUbIp/fOIE9zx+fME+P355nH98YhRYmliEfZ6GBLhnk1mSRemwSqmz6iw0Op3W1FqsfQoFxVjUOg+nExlHJE5USbhoR3Q8Z+egNeO+3MTKd16+lV9/1damr6URlsXlwIhS6pBSKgPcBdxUss9NwJ3243uAa0VElFJxpdRPsUTDQUSGgU6l1M+VVTX2NeDmBqzVwHza7KVbupxtpXGJT933Ar84NMX5GzrKmr616GiUZZHKkszmneLBVLZAQZXPKdfWhqm1WPtMxNPkCoqhTj+JTJ6j9jySkzNGLIrR39X3XrWND7x2O3uGO1dtLY0Qi01A8W3pqL2t7D5KqRwwC/TVOOZojWMCICK3ich+Edk/Pj6+yKW3J5OxNJ0BDzfuHeb3rt1FwOta0K1VKcXxqQTvefU5/PPvX7OkmRQRf6PcUJYrLG27ovQxy7mhQk3uSWVoHGdmLaviAvvil7RjFSeMWCxAxxd3DUb4k7fscVrcrAaNeOdysYTS3MV69lnS/kqpzyul9iml9g0MDFQ5pEEzGc/QH/HTF/HzB9ftpi/sX3A3PhXPEM/k2dITWvJ7hBsgFkop5mxXlnZFaVErlyqot5mYxdpHp81eUHKnbCyLhWiXcV/EV2PP5tMIsRgFthT9vhk4WWkfEfEAXcBUjWMWR2zKHdOwRCZjmQUnX9DnXhAX0BlSW3uXLhaNCHAnMnnyds2EvvOMlXScLSbk00OXjGWx1jk9a4lCsVh43WIsixK0ZdEbLt9lYSVphFg8BuwSke0i4gNuAe4t2ede4Fb78duBH6oqHeyUUqeAqIhcaWdBvQf4TgPWasC6W+krOvlCPvcCy0JXdW/tW7pYdPg9ZHIF0kuoeRidTnDzHQ9zYCzmbNMplXoSXjk3lBOzMG6oNc94LIOI5V7R7N3UZSyLEqbiGVwC3UuIGzaaZYuFHYP4MHA/8AJwt1LqORH5pIi81d7tS0CfiIwAfwg46bUicgT4W+C9IjJalEn1W8AXgRHgIPD95a7VYDEZy9BbbFl4F1oWuqp7c09wye8RdpoJLl4sfnpggiePz/CTl+djUElHLLRlUSYbqsnjXA2NYzqeoSvoZaDDumlxCbxiaw8nZ1OmAr+IyXiGnpAPl2v1KwcaUsmhlLoPuK9k258WPU4B76jw2m0Vtu8HLmrE+gzzZPMFphKZBc0DQz4340VV3ccmreaCoWW0ECjuPNsbXpy/9cXTUYCylkW1ALfP7cLjEjMAaR0wlcjQG/I5d8yDHQG29obI5ApMxjOOiLQ7U7HMor8/zcJUcLcZY9E0SsHGroCzLeTzlLihEmzpXbpVAfMX86W0/HipjFgkMwV++OIZJ55SLmYhIme51Axrk5lEhu6QF4/bRVfQy3B3gI3d1jl3/e3/yldKWry0K1NxIxaGVUIHFoeKxKJcgHs5wW3AaT+w2GCzUoqXzlhicXB8Xixmk1k+cOd+Pvug1T+oUu/+iN/Dsydm+d7Tp5aybMMKMRXPOhfBrb0hdg1GuHRLN3s3dZHOFXjsSLX8l/ZhMp5eE5lQYOZZtB26UnZ4gWXhdmIC2XyBU7Op5YvFEqfljcfSTgZIpqjNx3g0RUHN11vo1h6lhP0e9h+d5pfHpnnjhW9aUo2IoflMxzNctNHKhPrq+16F3+sm4vfw3d95Le/8/C84M5eucYTWxxolYCwLwyqh+/EMd867mYJFrpupeIZ8QTHYGSj7+npx3FCLjB9oF1RpW/TimErA66ooAv/5xgt4wwWDFJQJdK9VlFJMJzL02BfBvoh/QQxqqNPPWNT0iDo6mWAmkWX3UMdqLwUwYtF2nJ5NEfS6F7Q6DnmtNNd8QTnuqEp37vXiuKGWKBav3dW/YPtY0Z1mtXbMrz9/kOv2DC3pvQ0rQzKbJ50r0BMqf8c82BlgbC5dcz58q/OTkQkAXruzv8aeK4MRizbj1FyKDV2BBVO1dDFbIpNzLIzQcsViiW6og+NxesM+LthguSj0JDDddA5qzxoOm1bla5r5QrPytQODHX7SuYJTvd+uPHxggk3dQbb3h1d7KYARi7bjzGyKDSUupqAtDMlM3oldBLzLEwvdemOxbqjTs0mGuwIM2WsctFMox22x6A55axYoRYxYrDmm4xnu3n8cpRQzCavfV3cFy0KnzY7Nta8rKl9Q/OzgBK/d2d/0can1YsSizTg1m1oQ3IZiyyLvuKGCyxQLl0sI++ofgDRjt2I+PZdmuCvAYKd1wegO+fB5XI5l8T/f+Qo+845Lqh5rqVaNofGMRVPk8gW+9fhxPnLP0xwcjxdZFhXcUB0B+7XtG+R+9sQsc6kcr9m1NlxQYMSirSgUFGfmUgvSZqFELLLaDbX8RLmw30M0lXXGZ1bi2GSCy/78AR49PGWtr3PesugMeAl63UzZDdUu3NhVM+C31HiJYfE8enhqQT+ndG6+nXwyk+f1n/kR//DIMY7YLcifOznrzGioHLOwLYs2DnK/eHoOgEs2d9XYc+UwYtFG6BkCpZZF0BaGZDbniEXQt/xTIxLwcPf+UV7zVz9cMMq1lJOzSQoK9h+dYiqeYUOxWAQ9BL1udAeIemYNL9UFZlg8v/0Pv+RzD40AVpbT6/76R3z8O88CVr1OPJPn6dFZjtli8fypOabjWiwqxyxgYVJDu3FwPI7P42LzMjo/NxpTZ9FG6BkCpTGLhW4o6wIbbIBloZNZcgXFWDRV0e2gXV+PHLIKsYa6AvSEvAS8LnpDPiem4ve46urnryf7GTdU85lNZpwBPWPRNKfnUvz9L47xqm29jivz4HjMuVl4/uQcfo8bkfLzpMG6IQj53G3thhoZi7GjP4x7DfSE0hjLoo0Yj1lmfWnfHf2lbmTMAuDwRNx5PGsHNcuhM7B01e6GTitb68vvfRUfuHqHE2wvneZXibDfuKFWgnQuTzavmElaQqCn3XX4PfztAy87rVlGxmKOq+r5k3NOE8FKtTIiwmCHv6b7spUZGYtxblFH3rWAEYs2QvdpKr3oFmdDJbKNE4u/+jd7ueHCDQBV0yB1SxAtGtpNdtW5/WzoChD0WqdpaaFeJbxuF36Py2RDNRndUVhnNx2dtG4Obtw7zNHJBM+emAWsrLR8QXHhxk4m4xlePD1Hb4V4hWawI9C2lkUqm+f4dIJzB4xYGFYJffHsKLnoFruhUhmdOrv8U+OWy7fysRvPB6zeTpVIllRalwbgtZiVrrsajZoBbqiMtty0WBybSuB2iVMU+eCLYxRnfd64dxiAJ47NOPUzlRjo9HN0Ms7odKIJK1/bHJ6IoxTsNJaFYbXQPvzSIHHIaw8NylgB7qDX3bDcbu2XriYWxV1iQz43HSXr01ZOZBFi0Yixrobq6M9XZzcdnUywsTvAxVusDJ5oKsclm7ud/W/cO8xFmzoJ+txcvr2v6rHfeOEGJmMZ3vC3/9p20/N0A82da8yyMAHuNiKWziFydnX2AjdUJu/83gi0y6u6ZTF/UdfximL8Ombhr39aWMTvMTGLJqM/33SuQCqb5+hUgnN6wwx2BBjo8DMeTXPF9l5ePhMlV1Cc0xvin37n6rqO/dZLNtIT8vIbX3qUl89E2dS9vJb564mRsRgisGNgbVRua4xl0UZEUzkifs9ZF2OfxxoalMzmHcuiUbhdQoffw1wVsYhn8k7Wx4ausxsYBr2Ld0NZNR5GLJpJseU2nchwbDLujOK90O4ou7UvxLkDEbb0BBc97W2LnTY6Faucdt2KnJlL0xf2LbuLQqMxlkUbEUvnznLxaHTn2WSDLQuAzqC3qlgkMnl6Qj5Eyo9yXYobqsPv4XQbZ9OsBMUjc49PJZlOZDmnd14sfvTSOOf0hvm9a3c5reUXg+5Kq91c7UIsnaurnmilWXsrMjSNWCpX8YIbsgcgJbP5ZTcRLKUr6K3phgr53Hzu3ZctGPeqmQ9w1++GChs3VNMp/nyfHp0B4Bzbsrh61wBf+/lRztvQseQRqZ0BDx6XVC3obEXi6crf09Vk7a3I0DSq3bGEfB4SWcuyaLT5W0ssEhlLoC7aVL61gV5PvamzYFkhJsDdXIo/3yeOa7Gw/OxX7ujjmU+8cVnHFxF6wr62E4tYOud0IVhLmJhFGxFN54hUuDsPet0ki7KhGklX0MtcqrpYVHN9OW6oRZjmEZMN1XSKLYv9R6YQoeHttHtD7ScW8TXqhjJi0UbEUtmKMYtQUcyi0W6ozqCnhmVR/U5KF+Utxg0V8XtIZQvk8ov3lRvqI5bJoWPWZ+bSbOkJNdwq7W1Xy6JVxUJEbhCRl0RkREQ+WuZ5v4h8037+ERHZVvTcx+ztL4nIG4u2HxGRZ0TkSRHZ34h1tjtV3VB+D/FM47OhoD43VFXLYglFeRGn5YcZrdos4ukc3SEffrtfVzOKyHrDPqbaLMC9VmMWyxYLEXEDdwBvAvYA7xSRPSW7vR+YVkrtBG4HPm2/dg9wC3AhcAPwOft4mtcrpS5VSu1b7joN1QPcfWEfk7F0U7KhuoJeUtkC6Vz5C3eihjUTWELq7PwM8MoiZVgeibT1/6ZbjTdNLNrQsmhVN9TlwIhS6pBSKgPcBdxUss9NwJ3243uAa8VK9r8JuEsplVZKHQZG7OMZGky+oIhn8hUvuIOdfsbm0tZdfhMsC4C5ZPkYgiUWlb8cF23q4qJNnezor/9ipEXRxC2ah76o6dYdzag47gn7mE1m28admMsXSGULLRvg3gQcL/p91N5Wdh+lVA6YBfpqvFYB/yIij4vIbZXeXERuE5H9IrJ/fHx8WX9IK6Ob9VW6Y9nQGSCTL1huqCbUWUDlKm6dOluJcwci/NPvXE1XjX5CxZjOs80nnrF861osmtEltS/sQymYqeLGbCW02zTsX1sFedAYsShXlqnq3Kfaa1+jlLoMy731IRG5ptybK6U+r5Tap5TaNzAwUO+a245YqnwTQc1Q0YyLZorFU8dn+ONvPUXBnmaklCLRhNoOxw1lqribRiydt8QiaLuhmmRZAM7ApFYnlqn+PV1NGiEWo8CWot83Aycr7SMiHqALmKr2WqWU/ncM+DbGPbUstDsmUqG/0lDnfOFU89xQWb771Em+9fioU5WbyhZQqvECpaetnZ41VdzNwkrxdHNOX4htfaFFWX710meLxWSbiIW2hFs1G+oxYJeIbBcRH1bA+t6Sfe4FbrUfvx34obIG9d4L3GJnS20HdgGPikhYRDoARCQMXA8824C1ti1Ru86hUoB7sGPesmhGBTfAXCrLgbGY/VjPsLC/HA320W7sDuL3uBix38/QeOJ28dgfXLebb//2a5ryHjp43jaWxRoWi8YfWOgAACAASURBVGWvSCmVE5EPA/cDbuDLSqnnROSTwH6l1L3Al4Cvi8gIlkVxi/3a50TkbuB5IAd8SCmVF5Eh4Nt2wzsP8H+UUv+83LW2M9EK7ck1g0WWRaNz5fUXfjyadi7euleUbk/eaMvC7RJ2DEScds+GxqPrAQJed9Oa3vW2mWXhuItbUSwAlFL3AfeVbPvToscp4B0VXvuXwF+WbDsEXNKItbUzxyYTvPWOn3LXbVdWHHyk8Xvc9IS8TCeyDXdD9YS8DHcFeHhkwplNoIPdSXsyX6OtGYBzB8I8PTrb8OMarFjTSlQa94Qtq7RdLItWd0MZ1ii/ODzJTMIKKlcafFSMDnJXS2NdCiLC5dt7+deX57PVdPsP/eVojlhEOD6dIJU1hXnL4fvPnOIt//MnZIvSV1PZAgXV/Iua3+OmM+BpmxGr87FFIxaGFeSFU3MAnJhOzp+EVbIstFgEfY0/LS7f3kuhKEdO11zokaqNFiiwisSUssZUGpbOzw5O8uyJOV46HXW2zV/Ump/iubE7yKk2SVQwloVhVXj+pCUWozNJJ2ZRLZCsM6KC3safqJdv6wVweglpyyKRaaYbykrlNHGL5XHcnoP9xLFpwLqgPXvCcu+txEVtQ1eAU7PLH606k8is+XNhPsDdmnUWhjWIUuosyyLsczsT6coxb1k0/kTdORihN+xje38Yr1ucALcuFmyGWOwYCCOCyYhaAtl8gY/c8xQjYzFGp60LtW5DfsdDI7zvq48BKyMWw12NsSz++w8O8O4vPNKAFTWPWDqPz+3C7zFiYWgS/+eRY1zz1w+Rt309J2dTzKVyuF3Cydkkp2aT9JUZLFTMOX1h3C5xUl0biYjwW687l/e8ehudgfmW5UknG6rxF52A182uwQj3PnXSxC2qcGg8xge//jhniiYLvngqyt37R7n3qZOM2pbFk7ZYvHBqjojfQ3/Ez64mVG2XsrErwFQ8s+z/wxMzSc5EU853ZC0ST+fWpFUBRixahrxSHJtKMBmzAoHaBfWqbT2cmknx1PFZ9lYYLqS5+dKN3Pe7Vzvpio3mP1yzg1uv2kZn0MtsUtdZ2O0NmmBZAPyXN+/h0Hiczz54oCnHbwV+fmiSf37uNO/7ymOOG+TAmBWf+PHL46SyBTZ0Bjg0Hmc2keXwRJzX7R5g/5+8gR1NqNouZbjbGrW7XOtiMpZGqbU9pnWtticHIxYtg65Y1lkjz52cRQSuPX+IXEFxYibJ3s3VxcLjdnHeho6mr7Uz4HHcUDp1thmuL4DX7R7gLRcP89WfHXFajBgWotNSXzg9xxd+fAjAKZ7U1sRbLh4G4LEjUxyfTjZ8yFE1NnZZ7tFTM8uLW0zErL9zLXexXasdZ8GIRcug4w3alfCzg5NcuLGTnUPzd34X1xCLlaKzaHLembkUQa8bn7t5p+KVO/pIZPKcmmuPjJrFMhnP0OH3cMX2Xu575hRwdpznLZdsxO0S/vGJUfIFxY6BlROLRlkWE7bVPRlbfbFIZvK8/6uPMTIWXbB9rU7JAyMWLUOxZRFL5/jl0Wmu3jXAZvuLBtR0Q60UnUGvY1k8eniKfdt6sKv1m4K+sB0eNym05ZiOZ+gJ+7hx7zAHxmIcOBNlZCzmdJMF2D0U4aJNXTzw/Bmg8eNTqzGsLYtlZEQlMjnH5TkZX/2ajRdPz/Hgi2P84tDUgu1x44YyNJsBWyzOzKX4+cFJcgXF1bv62dRjicWOgfCixpI2EyvAnWM6nuHF01Gu3NHX1PfTKbSHJkxWVDmmEll6wj7eeOEGROD/PXmCo5NxbtxruZ76Iz5CPsvyyOYtV95KikXA66Y37OPwRIKfHZxY0jGKrYm14IbSVpLuZFAoKO7ef5yTs6k1OSUPjFi0DF63i/6Ij7Fomp8cGCfkc/PKc3oI+TwMdvh5xZae1V6ig57J/chh667qiu29TX2/wQ4/YZ+bQ8ayKMtUPE1f2MdQZ4BXbevlSz89TEHBq3f0MdDhZ3NPCJivlekN++gONScJohLDXQH+7y9HedcXHuHIEoostQsKyruhoqnsimZJnbTjLzpe9OToDB+552nGo2k2FXkD1hJGLFqIgY4AY3MpHh6Z4IrtvU6u9tfefzkfu/H8VV7dPJ0BL5lcgR8fGCfgdXHx5u6mvp+IsH0gzCFTyV2W6XjWafb4qbdd5MSPdg1F+ODrzuXdV2wF4FXbehGBHStoVWg2Fl1AlzKTe6KKZZHM5Hntpx/irseOLX2Bi0T3SNNDnY5PWenJ//CBK/hPN6yd72oxa9PeMSyJoU4/h8bjHJqIc/Ol88MKz9/QuYqrOhtdx/Evz53hlef04PM0/55lR3+EX9oVyIaFTMbT9NoN+3YOdvDFW1/FXY8dY+dAZMG50xXyct0FQ1y0CrGv37t2F7sGI3zuRwedPmeLQaeUh3zus8TimROzzCazC9qZNBttWcwkLLHQhY+v2NpdtXB2NTFi0UIMdvj50UtWs75aabKriZ6cNxFL81vnn7si77m9P8x3n7aK85rVTns9kszkSWUL9IbnCzYv397L5RVcg59/z76VWtoCLtrUhdft4nM/Orik6YfaDbVzMHJWgPvJ49ZNxEr2n5qPWVjCNTqdpDfsa0qPtEZh3FAtRPFo1LWS+VSOzqIA3g0XbViR99wxEEYpODJpXFHFaJeOtizWMrq9fiy9+HncE7EMHQEPw3Y1eDG6lmQlpyqWWhYnZpJs7lmbsQqNEYsWQqfPbuoO1mztsZpoy+KSzV0rFszTX0QzZnUhU7Yvv2eFA9ZLQWcJLdWy6I/46Q37zxaLY5ZYrJRlkcrmnRiKjlmMTifWbGBbY8SihRi0LYu1UnxXiV77wnTDRcMr9p46e0enKhostGXRF1n7YqE7JuuWJIvBEgsffWEf04msU80/Npfi5GyKnpCXiViaTK5Q40jLR9+wDHb4mU1kUUpxciZpxMKwcmg31FqOVwBs6w9zx7su471XbVux9+wOttfEtXqZsv3368GycLuEsM9dd4D74ZEJ/vCbTxJP55iIZWzLwke+oJybhqfsSYpvuGAIgLFo860L7YLas7GTTL7A8akkqWzBuKEMK8f5Gzp4895h3rx35e7Yl8qbLx5uWj+ocugMrBljWSxgKm59Hs1qHtloIgFP3W6oH7xwhn984gTX3/5jRsZinLehw7Gg9ExvPd/imt0DwMq4KXXa7J5hK9Ps2ZOWYG2y61nWKkYsWoiA180d776Mc/pWPg9+reNxu+gIeJyAosFiOp7B7RI610h1fy06At663VDRVA6f28VYNMVt1+zgw6/f6VhQuvPskYk4vWGf00CznrhFOpfnL/7peae/2WI5NpXA7RLOt8XiOS0Wa9wNtXbztAyGBtMT8jGzhttTrwaT8Qw9IS+uNZrbX0rE7yFap1jMJbNs7w9z7++8xilQ1Ram7k12ZDLOtr4QG+z+U/VYFs+emOWLPz3MK8/p4U1LsOJfPhPlnL6Qk5Dy7AlrnMAm44YyGNYG3SEv08ayWMB4NEVfeO1mzpXSEfAQq/OOPprK0RHwLJg611GSUXVkIsG2/jAdfg8hn7suyyKezi84xmI5cCbG7sEOp1Hj/iNTDHX6mzJ0rJE0RCxE5AYReUlERkTko2We94vIN+3nHxGRbUXPfcze/pKIvLHeYxoMi6U75DMxixIOjMU4d3D9uC0j/vpjFtF01knT1ujf51JZkpk8p+dSbO8LIyJs6AosmBZYiYQ9CngpbqhUNs+RyTi7hyJ0By2XWDyT5/LtzW2m2QiWLRYi4gbuAN4E7AHeKSJ7SnZ7PzCtlNoJ3A582n7tHuAW4ELgBuBzIuKu85gGw6LoDnrrckP9528/wyfufW4FVrS6JDN5jk0l2D3U/IFXjaIj4Kk7ZjGXzDmWRPHrreeyHJ2yCjS32b2uhrsCdbVB15bF3BIsi0PjcQoKdg11LGgBX6lifi3RCMvicmBEKXVIKZUB7gJuKtnnJuBO+/E9wLViDTC4CbhLKZVWSh0GRuzj1XNMg2FR9IS8NQPcqWyef/zlKE/YVb2tzMHxGEqxrsQi4vfWnTobTWXPCtz7PW78HhfRVM7pXrvNTgjpj/idLKlqaMsiugTLQo+r3T3UQcDrJuC1LsFXtolYbAKOF/0+am8ru49SKgfMAn1VXlvPMQEQkdtEZL+I7B8fH1/Gn2FodbpCPuZqtKLef2SaVLZAMrM0f/R6QjfO2z3U/DnajSIS8BDL5GqOyFVKMZc627KA+UmNhyesTq/b+q2U1Z6Qz6lor0bcHqI0l1z8OfLymSgelzjzQLqDPnrDPnYOrv3/g0aIRbk0itL/yUr7LHb72RuV+rxSap9Sat/AwEDVhRram+6gF6XmM2HK8eMD1g2HnqrWyrw8FsXndq2rVOsOvwelIF5DzJPZPPmCKjvwqzPgYS6V4+hknP6Iz9mnL+wjms6RzlX/v0+kl2ZZZHIFHjs8zbb+sNNp+Zy+EL+ye6CpkyIbRSNSZ0eBLUW/bwZOVthnVEQ8QBcwVeO1tY5pMCyKHrtZ3nTCGiNajh+/bIlFssFi8eALZ8gXFNdfuDKNE+vhwJkYOwbCeJs4/7zRRALzLT+qTX7Ud/2dwbMvcR0Ba6xvLJVbMCej1y7Ym45n2dBVuWDUsSwWIRaFguI3vvQIjx6Z4mNvmp9X8dX3Xc460AmgMZbFY8AuEdkuIj6sgPW9JfvcC9xqP3478EOllLK332JnS20HdgGP1nlMg2FR6OyTShlR0VSWF09bboJGWxaf/eEIf/695xt6zOXy0unouopXQFHn2RpxC33XX9ayCFpjfcejaQaKGm72hXV198IW5tl8gT/7zrNODYaTDbUIN9RYNM0jh6f43Wt38Zuvm2/LH/S5103L/GWLhR2D+DBwP/ACcLdS6jkR+aSIvNXe7UtAn4iMAH8IfNR+7XPA3cDzwD8DH1JK5Ssdc7lrNbQ3OvukUkaU7hc02OEnmc3X9IsvhvG5FMenkmum6202X+DETHJFZ2k3gojfrpOokRGlM5U6y8UsAh6iqSzjsbQzux5wZnqUdqU9MhHnzp8fdVyUTp3FIlql67bq6yE2UYmGVHArpe4D7ivZ9qdFj1PAOyq89i+Bv6znmAbDctCdZytlROmUzIEOPydnU6Ry+YYMo1FKMW4P33n0yBRvvWTjso+5XHRDxeKL5XqguKhu/5EpPv3PL/L1919x1t35XBXLoiNgZcXNJDIlYmGdH2eNXc1a4qBjFUuxLGK2wET868OKKMf6cVYaDMukJ6RjFuXFIu6IhdX6oVGuqNlklmzeslIeOzzVkGMuFy1e/eugNXkxEb/1fxhL5bjn8VEeOzJdtupaF+51lYlZdAY9TMUzFNRCsXTcULGzZ3TDfKxivoLbai9eD9ptpte/HjFiYWgbOgJeRGC2ghtKX2D0BaRRQe7xqHVhdgk8dmRtiIW+IK7lIVnlKJ6W99ORCaD8jBKd8VY+G2p+W3HMoivoxSWVLYt4iWVRUPMCUgvthtJutPXI+l25wbBIdHfVSgFufceoG7w1yrLQYnHF9j5+cXiSeDpHeAkXjWjKslAa0U5cB3H715lY6GyoJ4/PMDptVVuXEwst/GXrLIq2FVsWLpfQE/I5hXmfuu8FOvwedtlJAIkSC8N6n2xdAlBtPesFY1kY2oqOKvMQ9N2fvoDUyuWvF+3yuXhLF0qdfedaL//1u8/zH762vyFrmoiunwl5xXT4PVy4sZNvPDpfs1suYSGayuJxCcEymUbF/aJKYza9YR9T8TTRVJavPnyEHx8YJ1VqWaRzhOxZLPXGLXQ8bD1bFkYsDG2F1YiuUoB7oWXRaDfUzgErE2apo13PzKWcKWvLZSKexudx0bHOLl4iwv+45VKCXjdh54Jdxg2VytIR8JQtdit2Q5VaVr1hH9PxLD98cYxMvkAik593Q9k3D/FM3mlpXm9hno5ZLMWiXCsYsTC0FZ0Bb8UGcLGSmEUj3VA+j4vN9iS0ahXk1Yinc0t+bSmTsQz9Yd+6qBwuZedgB194zz5u//VLgcpuqNKOsxrtCgr73GddvPsiPibjab7/zGnAumFIlgS2E5kcw7ZY1FuYF8vk8HtcTuX2emT9ypzBsAQ6Ah5OVqh1iGdyBLwuJyiaaJQbyi7+0vMKlmpZJDJ54pk8uXwBzzKrridi6XUX3C7mtbv6AQh63RUD3JXiA1pEyqUN94Z9nJlLO6NP45ncfOpsJkcmVyCbV868+7rdUKncunZBgbEsDG1GR6CyGyqayhHxex1/dMPcUHbxV1dofpbCUog73U6XL2KTscy6S5stR1ewfCfhaCpXcVSs3l5eLPzE0jkKBbjq3D4SmTxpWyxi6bxzAzG8WDdUOucE59crRiwMbUVHwFvxYhtP54j43Y5YNNINNdDRAMsivfieRJVY75aFpivoLW9ZpCpbFnp7ObEYsAX0Izecx6Vbuklk8s55kMjknEyoDdqyqFO4jWVhMKwz9PCccsVU+u4vqC2LbGPFIuxz43bJksUivoTK4XIopZiMZdZdJlQ5KonFWDRdsTo95HPjccmCGgvNr12ykb95xyX8+9dsJ+z3kC8oR5zj6bxTxd0d8uH3uOoW7mh6/YvF+l69wbBIOgJe8gVFMnt2K49YOkfY58HnduF2SUNiFtl8galEhoGIHxGhM+BZkljkC4pUtgAs37KIpnNk8oWyF8v1RlfIy/GpxIJtyUyemUSW4a5g2deICH/1by/m0i1dZz3XHfLx9lduBnDSbnWqczw9b1mE/W67e21950g8PR8UX68Yy8LQVhT3FiolZg/LERFCXndD3FBT8QyqqK2EdSe8eBEqtnKWmxE1YafytoplUfp56NGo1S7Ob3/lZnYOVu+4q92Rukgvmc07MYqQz0PnIka8xlrAsjBiYWgr5sXi7AtuPDNfWR30uZ0YwXIYm7MuzAvFYvEX+0TRRWm5loWu++gLt4BlETy7Il/3iqpkWdRLyD4XiosodZuUsM9DpEqyRCmxlAlwGwzrCp0JUy4wWRyEDPncJBoQsxiPWRcuXejXWeZOuB4WtphYuntsKp7hE999Hp/Hxa51NE61El1BL4lMnmy+4GybF4vluX1CthuquLGgFtqQ303E76l/HvgSW7ysJYxYGNqKqm6odLFYeBoyh1tfXAaWKxbFlsUy3FCfffAAB8difPE9+5Z9570W0DNKiq2107YbasNyxcJuJ17sahqLWkIU9nmcZIlaZHIFMrnCuquWL8WIhaGt0AV3pe6DbL5AOldYaFk0IGahxUK3lViyG6poLfWma5bj2FSCnYMRrtndGvPqy6Ujn5xN0Rv2LXsCXXEChMsudF9oWVROwy4m3gJ9ocCIhaHNqGRZ6C/0gphFg8SiM+BxLlxaLOqdg+CsL9MYy2Iylm6JwLams4xYnJ5NNSTzSAe4YX6Knm4KGfK6qxZ4FuM0EawyM3w9YMTC0FZUCnBr8dBByJDPXbGC+6njM4xOJ8o+V0rp6M6uoJdcQS1aiHSw3eeuP7e/HBOxTEukzGocy6KoivvkTLLhYqGr3Q+Px+kKevG4XVVrdopxzi1jWRgM64ewz4NIGcsis/ALHfJ5SGTLuxg+/I1f8j8fHKnr/cZLisPmA+yLu+Dr9Q11+ZdclKfHu/avs1Gq1eguZ1nMpRoSjyl2Q2k34snZlDNHO+L3UFC1K/21ZbGeZ1mAEQtDm+Fyid2mfOEFN1Zy9xesYllMx7NE0/Vd7C2xmL/LXWrLD506O9wZXLJlEU1bjfBaoSeUpr/Dj0vg4HgMmC/IW25wGxZaFsWuO91qPuJM7asu3q0wJQ+MWBjaEKtN+cILbqwkZlGpKC9fUMTSubqbDOqOs5pybpN6cHoSdQWWHLOYiK7P6XjV6Ax4uXJHH997+hRKKb788GEAzukLLfvYfo/LCWwX16Roy6JSskQpek6KSZ01GNYZZS2LEldByOcmmc1TKCz0R2sLpJ6+Ubo9RGnMApZgWWRyuF1Cf8S/6Gyoo5NxXveZh9h/dBpYf3O3a/Frl2zk0ESc3/nGE3zm/pd4y8XDXL9nw7KPKyKOK2qBZaHFwl85DbsYnUHVE2rjALeI9IrIAyJywP63p8J+t9r7HBCRW4u2v1JEnhGRERH5rNiTWETkEyJyQkSetH9uXM46DYZiOgJnF1OVzkgO+jwoBancQlHQFonu01SNidjCGguAzqB1/MWKRTydJ+Rz0xX0EkvnyOVrv7/mgefPcHQywXefOgnQUm4ogBsu3IDHJfzT06f49X1b+Owtr2jYkCHtiuoIeJxjOjGLOt1QL56aoz/iX/civdxP9KPAg0qpXcCD9u8LEJFe4M+AK4DLgT8rEpW/A24Ddtk/NxS99Hal1KX2z33LXKfB4NAR8JwVc9Aumt6wdSHd0GV9sU9MLxxjqkUlVYdlUVqQB/NB03peX0wik3MKwaD2BaqYnx2cBOCxI1PWetb5RauUnrCP9161jXddsZVP/Zu9uFyNm/6nxSLgtSq2A14Xm7qt4Hm1As9iXjg9xwXD1ftQrQeWKxY3AXfaj+8Ebi6zzxuBB5RSU0qpaeAB4AYRGQY6lVI/V1bu2dcqvN5gaCidZQbmTMSsegi/x7o4XDDcCcDzp+Y4PBF3mtNp/3Q9bihHLIouzottf66U4thkgngmT8jvdsTs4Hi8rtdn8wUeOWSJRSpbQGReEFuJP3nLHj71tr24GygUMC/uQa8152RHf8QRIx2wrtbyI5sv8PLpGHvs82k9s1yxGFJKnQKw/x0ss88m4HjR76P2tk3249Ltmg+LyNMi8uVK7i0AEblNRPaLyP7x8fGl/h2GNuLcgQgnZpIL7s5LU0p39EfwuoUXTkV571ce5ZPffR5YpGVhu6EGO+ePG7BdGclMfW6kux47zjWfeYhfHp0m7PPwqxcM0hX0csdD9aXuPnNilngm7wS1e0K+ZY9kbSeKLYsLN3ZytT3OFaDDbwe4K1h5L56e44VTc2TyBefmYz1T86wRkR+IyLNlfm6q8z3KSb2qsh0s99S5wKXAKeC/VTq4UurzSql9Sql9AwOt0cLA0Fwu3NiJUvDCqTln20Q0syBLyOdxce5AhH957jRHJxNOczrtvqonG2psLo3bJfSE5u/kPW4XPrerLssimsryN/e/BFjN8UI+N50BL7/5uh388MUxHrcD1tX4ue2CevcVWwHoa0GroploSzDodfO/f2MfH7vxAue5SJUOxtl8gZv+18P8+68+BtAeYqGUeoNS6qIyP98BztjuJOx/x8ocYhTYUvT7ZuCkvX1zme0opc4opfJKqQLwBaxYh8HQEC7aZA29efbErLNtIpY+y5d/wXAnhyYsd49uUz1vWdS2DMajafrCvrNcIwGvqy7L5CsPH2EynnHubnXq5Xuv2obXLfzghTM1jzE6naQ/4uPV5/YBrZU2uxKEtRvKd/al0u0SQj53WTfUXDJLOldgIpbB53axYyDc9LU2m+Xao/cCOrvpVuA7Zfa5H7heRHpsd9L1wP222yoqIlfaWVDv0a/XAmTzNuDZZa7TYHAY7PDTH/Hz7Il5y2I8lj4rS+j8DfNByVKxyOQL5AvV2zyUtvrQWB1ta4vFsydm2T0U4bU7++3XuZ3X7+iP8PLpaM1jTMcz9IR8zt/SStXbK0GxG6ocEX/5zrM6vdnrFvZu7sLbAq6/5f4FfwVcJyIHgOvs3xGRfSLyRQCl1BTw58Bj9s8n7W0AvwV8ERgBDgLft7f/tZ1S+zTweuAPlrlOg8FBRLhoUyfPnbQsi1Q2TzSVO+uuW7sOXGJlH6Vz+QXFfLWsg9JWH5qgXcORyRU4M5eq+Poz0TRDnQEu3doNLKwo3r2hgxfrEYtEhp6wj+6Qj1dt6+Ey+1iG+tBtyoMVxMJqJljesgD4m3dcwpdu3de8Ba4gyyopVEpNAteW2b4f+EDR718Gvlxhv4vKbP+N5azLYKjFRRu7+MmBCVLZvDM2s/TCfsnmbrb0Brl0Sw/ffeqk1eaj6MKQzOarVuWOR9MLrBNNwGuJxd//4ii3/+Blnvj4dWWDzuNzKXYO9HPpFi0W8+913lCE7z51kmgq61QSl2M6kWFHv1UX8K0PXlVxP0N59Gde0bIIeMsGuPV5srE7SHeoNeJE6982MhiWwPnDHeQLikPj8YptMLpCXn7ykV/lzXutauDJeHqBWFSzLAoFZcVBylkWdszi1GySaCpX9s60UFCMRdMMdvq5eHM3XvfCQPl5Gyyr58BYrOrfOZ3I0hNe35XDq4m2KCpaFn4PsTIBbm2BrvfmgcUYsTC0Jb32hXc2mXUqrSv58/VF2rIs6nNDzSSz5Aqqshsqk3d6BpWr5p5OZMgVFEMdfiJ+D9/64FXcetU5zvPnDVkWS7W4hVLKiVkYlsbuoQ42dQcrzs+u5YbqXOczLIppHdkzGBZBcRO46YTlhqrUBkP3BSq1LIprJXL5Agrwul0opZzxm+UtCzcziawTGC1taqhjKQBDnVb3VO2K0mzuCRLyuavGLWLpHLmCMmKxDN588TBvvni44vMRv4czcyl+NjLBq8/tw+5Y5Pyf6uFMrYARC0NbUtyqoXT0aSl6StpUPGPFCPweouncgr5Rf33/Szx6eIpv//ZVXPOZh5yK3XKtNXTMQk/nK7Ysnjo+w013PMxt1+wAFhb0FeNyCbsGIxwYqywW03HruD2mtqJpvGZnP999+iTv+uIjvO812zgyEcfjdnHeUAcugbBveaNd1xJGLAxtSfHEvIlYhg6/p2IQsyvoRUSLRY6BDj/Rkjblvzg0yfGpBMlsnuNTSY5PWe1BKlkWqUx+3rIoGmZ02s6O+v6zpwAY7Kg8l2GoM8DRycoT+6Zsi2m9dztdy9z8ik3ccNEG/vJ7L/CVh48AVhxjY1eAjoDXsTRaAROzMLQl826oXM3pcboKu1gsYL6/U76geOl0lHg6Tzy9FOqgEQAADN9JREFUMI4x2Hn2xV6nzpazLPTjamKj6Qn5HBcawNhcyqkHAZznjGXRXAJeN5+86UI+9ba9vPWSjUTTOU7PpZwOw62CEQtDW+LzuAh4XUTTOaZimZptMHrDPiZiaWLpnCMAOsB9ZDJOOlcgky8wm5y/WAe97rJuiGCJG6o4ZlE82Kg75K1o7QB0h73MJLPODOgPf+MJ/su3n3Gen45ry8KIRbMREd51xVZet9tqOTQyFmup4DYYsTC0MR0BL3PJrFO4Vo3ekI9j+m7fjkNosXjx1HzcYGwu7Twe6PCXdUMEvG5S2YLjhipnWYBVaV6N7qCPTK7gWDjj0TQjRam003Zn3V4jFiuGTkg4MploObFoLTvJYFgEOu1xKp7hks3VK5t7wz6etbOUhuygs45ZvHh6vm3ImB0sf/srN3PhxvLN43RzOu0yKhaIYstiqIwLqxgdi5hOZAn5PMTTOWLpHEopRITpeAaXtFau/1pHJyTkC6rlPvfW+msMhkWgZ3FPJzL01pge1xvxOTO5h+3hN0enEtx8x8PMFMUNdPuOd12xlcu2lu+srwu8dGupuRLLoi/sYzKeqRrcBpzK4Ol4hk3dQRKZPIlMnplElp6wFc/oCfkaOgzIUJ2hov+zVkqbBSMWhjamI+Dh1GyKbF7VdNVs7LIuAr92yUau3zMEwM9GJnnpjOWC6gx4mEvlHMsi7Kv81SqtBi51Q23sDvKuK7Zy+fbeqmvSlsVMwopbxDOWW+vETNIRi26TCbWidAY9+D0u0rmCcUMZDK1CZ8DLI4etnpa1Yhbvfc12XrtrwCmOC3hdHJm02pd/8HXn0h/x8Rffe2FeLPyVA9OBkqD3XFGh32wyS2fQw3+8/rya69eWxUwyQzKbx45zMzqd5KJNXUzFMy05FW8tIyIMdQY4NpUw2VAGQ6vQEfCQyVlV2L01+idF/J4FVdQBr5t0roDP4+I/3XCeMy9izHZDRao0GCy2LFyy0A01l8rRVaf7ojhmUZyye2LGCsTPJLIt08RuPaETE6o1eFyPGLEwtC3FPuXFppfqC/6GzgAi4oiDrgYP1emG2tAZOMsNVa9YOJZFPEMiM2+djE4nUEpxcibpBOMNK4dOTOhssQC3EQtD29JRdPffF17cRbVYLGBeHMaiaXxuFz5P5a9W8dS1TT1B5opqJSw3VH1i4fO4CPvcZ1sW00mmE1nmUjm29a3/CW3rDZ0R1WoBbiMWhralOLVxsW28/bZYDNmBb21ZxNK5qvEKWDgbYbgrSK6gSGTypOyBSIsJjHaHfMwkMk5w2+dxcWImyeEJq95ie78Ri5Vm3rJoLbFoLTvJYFgE2qfsdUvVGEM5gl7rPmvYFouA14VLrHTYai4o67XzYrHRTsN94PkzbLCPVa8bCqwq75lk1qkGP3cgYouF1TPKiMXKo63Nxfw/rgeMWBjaFu0m6An5Ft3wTRfW6btIESHss7rR1hKeoK9YLKzX//43n3Qu7Iu5yOj+ULoG5KKNnbxwao5HDk3idglbekP1/1GGhvDGCzfwqbft5YLhs6ckrmeMG8rQtmg31FLSSwMe64KvLQvAGbFayw21wLLoCjqPD09YqbiLtiwS85bFdXYNyL1PnWRzTxBvmXGthuYS9Ll51xVbW6rjLBixMLQxyxKLEssCIGSLRLW53DAfs3AJjuupOGtpMYHR7pCX6UTGEYvLzumhP+InnSsYF5ShoRixMLQtOgC5lBbeTjZUkWWh3U/VqrcB/B4XIpao7Bnu5FNv28vt/+5S5/nFuqFmk1lngl/E7+HqXf0AJhPK0FCMWBjaFseyWELhWsBrXfCLO8OGfPVZFiJC0Osm4vfgclmtrfdt68Vnu4wWKxZKwcnZFB6X4Pe4uGa3JRbGsjA0kmWJhYj0isgDInLA/rds5zQRudXe54CI3Fq0/S9F5LiIxEr294vIN0VkREQeEZFty1mnwVCOjoCXsM/Npp5g7Z1L+JXdg7z7iq0LYgKROmMWYM+6KBIVn8fFHrtL7WKKuXRO/5GJOCGfGxHhV88b4lfOG3BmKxgMjWC5lsVHgQeVUruAB+3fFyAivcCfAVcAlwN/ViQq37W3lfJ+YFoptRO4Hfj0MtdpMJyF2yV873ev5r1XbVv0a9+wZ4i/uHnvgm06ZbaWZQFW3KJ0vyt29DLU6ceziKC0TtM8OB5zjtcV8vLV913ONmNZGBrIcsXiJuBO+/GdwM1l9nkj8IBSakopNQ08ANwAoJT6hVLqVI3j3gNcK62WWmBYE2zrD1edRrcY9MW6npqNoM+9oIIc4A/esJvvfOi1i3pPHTMZi6YdN5jB0AyWW2cxpC/2SqlTIjJYZp9NwPGi30ftbdVwXqOUyonILNAHTJTuKCK3AbcBbN26ddF/gMHQKCK2+6mei/Y1uwbo71gYKwl43WzoWtwFv3jmxWILCw2GxVDz7BKRHwAbyjz1X+p8j3IWgWrUa5RSnwc+D7Bv375axzUYmsZi3FB/+mt7GvKePo+L/oiPiVimZuW4wbAcap5dSqk3VHpORM6IyLBtVQwDY2V2GwV+pej3zcCParztKLAFGBURD9AFTNVaq8GwmkQW4YZqJBu6AkzEMnUF1g2GpbLcmMW9gM5uuhX4Tpl97geuF5EeO7B9vb2t3uO+Hfih0m05DYY1SmgRbqhGUtr51mBoBssVi78CrhORA8B19u+IyD4R+SKAUmoK+HPgMfvnk/Y2ROSvRWQUCInIqIh8wj7ul4A+ERkB/pAyWVYGw1pjtSwLXUVej/vLYFgqyzq7lFKTwLVltu8HPlD0+5eBL5fZ7yPAR8psTwHvWM7aDIaV5rwNHQx3BThnhSundX+qsMmGMjQRcytiMDSI8zd08vOPnXXv1HS0ZREyloWhiZh2HwbDOmeDM4DJWBaG5mHEwmBY52g3VNAEuA1NxIiFwbDO2d4f4cOv38l1Fwyt9lIMLYy5FTEY1jlul/BHbzxvtZdhaHGMZWEwGAyGmhixMBgMBkNNjFgYDAaDoSZGLAwGg8FQEyMWBoPBYKiJEQuDwWAw1MSIhcFgMBhqYsTCYDAYDDWRVhoTISJR4KXVXscaoJ8yI2jbDPMZWJjPwcJ8DtU/g3OUUgPVXtxqFdwvKaX2rfYiVhsR2d/un4P5DCzM52BhPoflfwbGDWUwGAyGmhixMBgMBkNNWk0sPr/aC1gjmM/BfAYa8zlYmM9hmZ9BSwW4DQaDwdAcWs2yMBgMBkMTMGJhMBgMhpq0hFiIyA0i8pKIjIjIR1d7PSuJiBwRkWdE5EkR2W9v6xWRB0TkgP1vz2qvs9GIyJdFZExEni3aVvbvFovP2ufH0yJy2eqtvLFU+Bw+ISIn7HPiSRG5sei5j9mfw0si8sbVWXVjEZEtIvKQiLwgIs+JyO/Z29vmfKjyGTTuXFBKresfwA0cBHYAPuApYM9qr2sF//4jQH/Jtr8GPmo//ijw6dVeZxP+7muAy4Bna/3dwI3A9wEBrgQeWe31N/lz+ATwR2X23WN/P/zAdvt7417tv6EBn8EwcJn9uAN42f5b2+Z8qPIZNOxcaAXL4nJgRCl1SCmVAe4CblrlNa02NwF32o/vBG5exbU0BaXUj4Gpks2V/u6bgK8pi18A3SIyvDIrbS4VPodK3ATcpZRKK6UOAyNY3591jVLqlFLql/bjKPACsIk2Oh+qfAaVWPS50ApisQk4XvT7KNU/pFZDAf8iIo+LyG32tiGl1CmwTiJgcNVWt7JU+rvb8Rz5sO1i+XKRG7LlPwcR2Qa8AniENj0fSj4DaNC50ApiIWW2tVM+8GuUUpcBbwI+JCLXrPaC1iDtdo78HXAucClwCvhv9vaW/hxEJAL8X+D3lVJz1XYts60lPocyn0HDzoVWEItRYEvR75uBk6u0lhVHKXXS/ncM+DaWKXlGm9X2v2Ort8IVpdLf3VbniFLqjFIqr5QqAF9g3r3Qsp+DiHixLpL/oJT6R3tzW50P5T6DRp4LrSAWjwG7RGS7iPiAW4B7V3lNK4KIhEWkQz8Grgeexfr7b7V3uxX4zuqscMWp9HffC7zHzoK5EpjV7olWpMT//jascwKsz+H/b+fucRMGggAKv6noSUUJEjdIyQXCCehzDO5AR5kqRU6RC1AlIIRQlJOkMMVuJBrYZs1K8D7JcmEXM6ORxz8rLyJiEBFjYApsbh1fbRERwBtw6LpudXboYfrhUg2q9kLrr/iVVgLMSV//f4Fl63humPeEtKLhG9j/5w48AZ/AT94PW8faQ+4fpMfqP9Jd0uulvEmP3OvcHzvguXX8PdfhPee5zReF0dn5y1yHI/DSOv5KNZiRXqFsga+8zR+pH67UoFov+LsPSVLRPbyGkiT1zGEhSSpyWEiSihwWkqQih4UkqchhIUkqclhIkopOfPHZq24YSdMAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pd.Series([v for v in model.get_layer('attention').get_weights()[0].flatten()]).rolling(50).mean().plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f5025a1bed0>"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pd.Series([abs(v) for v in model.get_layer('output_layer').get_weights()[0].flatten()]).plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "179 179\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(('himself', 'stopword'), -0.7284296154975891),\n",
       " (('against', 'stopword'), -0.677932858467102),\n",
       " (('themselves', 'stopword'), -0.6269885897636414),\n",
       " (('myself', 'stopword'), 0.5944074988365173),\n",
       " (('me', 'stopword'), 0.5808129906654358),\n",
       " (('which', 'stopword'), -0.5802603363990784),\n",
       " (('y', 'stopword'), -0.4890809953212738),\n",
       " (('yours', 'stopword'), -0.45802047848701477),\n",
       " (('shouldn', 'stopword'), -0.44473156332969666),\n",
       " (('herself', 'stopword'), -0.44048914313316345),\n",
       " (('ain', 'stopword'), 0.43934911489486694),\n",
       " (('as', 'stopword'), -0.42869824171066284),\n",
       " (('or', 'stopword'), 0.42340654134750366),\n",
       " (('by', 'stopword'), -0.4231763184070587),\n",
       " (('hasn', 'stopword'), -0.4093189239501953),\n",
       " (('from', 'stopword'), -0.40467941761016846),\n",
       " (('during', 'stopword'), -0.40312299132347107),\n",
       " (('no', 'stopword'), 0.39973184466362),\n",
       " (('am', 'stopword'), 0.39801648259162903),\n",
       " (('re', 'stopword'), -0.39346882700920105),\n",
       " (('once', 'stopword'), -0.3780168890953064),\n",
       " (('below', 'stopword'), -0.3677508234977722),\n",
       " (('i', 'stopword'), 0.36311987042427063),\n",
       " (('don', 'stopword'), 0.3617483377456665),\n",
       " (('haven', 'stopword'), 0.3546900451183319),\n",
       " (('my', 'stopword'), 0.33312052488327026),\n",
       " (('itself', 'stopword'), -0.32148054242134094),\n",
       " (('ma', 'stopword'), -0.3166116774082184),\n",
       " (('where', 'stopword'), -0.3089277744293213),\n",
       " (('isn', 'stopword'), 0.2894366383552551),\n",
       " (('our', 'stopword'), -0.27598702907562256),\n",
       " (('but', 'stopword'), 0.2721453905105591),\n",
       " (('their', 'stopword'), -0.2711140513420105),\n",
       " (('will', 'stopword'), -0.267701119184494),\n",
       " (('couldn', 'stopword'), -0.26473215222358704),\n",
       " (('above', 'stopword'), -0.26369601488113403),\n",
       " (('has', 'stopword'), -0.26124489307403564),\n",
       " (('too', 'stopword'), 0.26051756739616394),\n",
       " (('he', 'stopword'), -0.2553723156452179),\n",
       " (('doesn', 'stopword'), -0.24496737122535706),\n",
       " (('being', 'stopword'), 0.2437523603439331),\n",
       " (('those', 'stopword'), -0.23140552639961243),\n",
       " (('had', 'stopword'), 0.2304789274930954),\n",
       " (('few', 'stopword'), 0.22835423052310944),\n",
       " (('in', 'stopword'), -0.22744475305080414),\n",
       " (('such', 'stopword'), 0.22520944476127625),\n",
       " (('been', 'stopword'), 0.21875424683094025),\n",
       " (('having', 'stopword'), 0.21869756281375885),\n",
       " (('wouldn', 'stopword'), -0.21862567961215973),\n",
       " (('before', 'stopword'), 0.21012906730175018),\n",
       " (('we', 'stopword'), -0.20108430087566376),\n",
       " (('ourselves', 'stopword'), -0.19850486516952515),\n",
       " (('there', 'stopword'), -0.19686132669448853),\n",
       " (('other', 'stopword'), 0.19673803448677063),\n",
       " (('some', 'stopword'), 0.18504102528095245),\n",
       " (('so', 'stopword'), 0.18480679392814636),\n",
       " (('here', 'stopword'), -0.18447595834732056),\n",
       " (('what', 'stopword'), -0.1844455450773239),\n",
       " (('does', 'stopword'), 0.17731575667858124),\n",
       " (('do', 'stopword'), 0.17503418028354645),\n",
       " (('won', 'stopword'), 0.17335145175457),\n",
       " (('whom', 'stopword'), -0.1720760464668274),\n",
       " (('are', 'stopword'), -0.16836398839950562),\n",
       " (('that', 'stopword'), -0.1671752631664276),\n",
       " (('to', 'stopword'), -0.16634982824325562),\n",
       " (('how', 'stopword'), -0.16420386731624603),\n",
       " (('out', 'stopword'), 0.16412632167339325),\n",
       " (('theirs', 'stopword'), -0.16323165595531464),\n",
       " (('s', 'stopword'), -0.16315224766731262),\n",
       " (('both', 'stopword'), -0.16060587763786316),\n",
       " (('who', 'stopword'), -0.1551540493965149),\n",
       " (('and', 'stopword'), 0.15454809367656708),\n",
       " (('not', 'stopword'), -0.14919698238372803),\n",
       " (('same', 'stopword'), 0.1489904373884201),\n",
       " (('him', 'stopword'), 0.14691443741321564),\n",
       " (('weren', 'stopword'), -0.14680826663970947),\n",
       " (('an', 'stopword'), -0.14651371538639069),\n",
       " (('have', 'stopword'), 0.14613273739814758),\n",
       " (('between', 'stopword'), -0.14189879596233368),\n",
       " (('on', 'stopword'), -0.13969027996063232),\n",
       " (('yourself', 'stopword'), 0.13830257952213287),\n",
       " (('didn', 'stopword'), -0.13764648139476776),\n",
       " (('ll', 'stopword'), 0.1372218132019043),\n",
       " (('they', 'stopword'), 0.13642309606075287),\n",
       " (('because', 'stopword'), 0.13503842055797577),\n",
       " (('hers', 'stopword'), -0.13339081406593323),\n",
       " (('into', 'stopword'), 0.12987807393074036),\n",
       " (('very', 'stopword'), 0.12931254506111145),\n",
       " (('m', 'stopword'), 0.12383969873189926),\n",
       " (('you', 'stopword'), -0.1210186555981636),\n",
       " (('them', 'stopword'), 0.11946829408407211),\n",
       " (('each', 'stopword'), -0.11706925928592682),\n",
       " (('just', 'stopword'), 0.1131720021367073),\n",
       " (('this', 'stopword'), -0.11145927011966705),\n",
       " (('the', 'stopword'), -0.10931143164634705),\n",
       " (('more', 'stopword'), -0.10882273316383362),\n",
       " (('over', 'stopword'), -0.10315610468387604),\n",
       " (('should', 'stopword'), 0.10081365704536438),\n",
       " (('yourselves', 'stopword'), -0.0988498404622078),\n",
       " (('doing', 'stopword'), -0.09709588438272476),\n",
       " (('she', 'stopword'), -0.0968303382396698),\n",
       " (('ours', 'stopword'), -0.09657665342092514),\n",
       " (('only', 'stopword'), 0.09469287842512131),\n",
       " (('now', 'stopword'), 0.08953463286161423),\n",
       " (('nor', 'stopword'), -0.08595557510852814),\n",
       " (('hadn', 'stopword'), 0.08587336540222168),\n",
       " (('through', 'stopword'), -0.08433729410171509),\n",
       " (('under', 'stopword'), -0.08411584794521332),\n",
       " (('aren', 'stopword'), 0.08257634937763214),\n",
       " (('own', 'stopword'), -0.07760537415742874),\n",
       " (('was', 'stopword'), -0.07583646476268768),\n",
       " (('at', 'stopword'), -0.07479090988636017),\n",
       " (('these', 'stopword'), -0.07382287830114365),\n",
       " (('most', 'stopword'), -0.07372624427080154),\n",
       " (('than', 'stopword'), 0.0693732500076294),\n",
       " (('why', 'stopword'), 0.06750459969043732),\n",
       " (('it', 'stopword'), 0.06707317382097244),\n",
       " (('ve', 'stopword'), 0.06469342112541199),\n",
       " (('wasn', 'stopword'), -0.06450213491916656),\n",
       " (('while', 'stopword'), 0.06333070993423462),\n",
       " (('can', 'stopword'), 0.058743420988321304),\n",
       " (('until', 'stopword'), -0.058417029678821564),\n",
       " (('o', 'stopword'), 0.05738965421915054),\n",
       " (('of', 'stopword'), -0.05538037419319153),\n",
       " (('further', 'stopword'), -0.051090940833091736),\n",
       " (('t', 'stopword'), 0.04609139263629913),\n",
       " (('its', 'stopword'), -0.042768996208906174),\n",
       " (('your', 'stopword'), 0.03739121928811073),\n",
       " (('his', 'stopword'), -0.034853242337703705),\n",
       " (('down', 'stopword'), 0.03455885127186775),\n",
       " (('did', 'stopword'), 0.03330613672733307),\n",
       " (('is', 'stopword'), 0.032258592545986176),\n",
       " (('about', 'stopword'), 0.02921261638402939),\n",
       " (('if', 'stopword'), -0.028307614848017693),\n",
       " (('again', 'stopword'), -0.022284070029854774),\n",
       " (('d', 'stopword'), -0.022185973823070526),\n",
       " (('then', 'stopword'), 0.021076273173093796),\n",
       " (('when', 'stopword'), 0.02044433355331421),\n",
       " (('up', 'stopword'), -0.019743449985980988),\n",
       " (('after', 'stopword'), -0.019444486126303673),\n",
       " (('be', 'stopword'), 0.01701318472623825),\n",
       " (('with', 'stopword'), 0.013119727373123169),\n",
       " (('were', 'stopword'), 0.012461096048355103),\n",
       " (('all', 'stopword'), -0.01203831098973751),\n",
       " (('needn', 'stopword'), -0.008970396593213081),\n",
       " (('her', 'stopword'), 0.0054072244092822075),\n",
       " (('any', 'stopword'), -0.002541568363085389),\n",
       " (('a', 'stopword'), -0.002423858502879739),\n",
       " (('off', 'stopword'), -0.001514786621555686),\n",
       " (('shan', 'stopword'), -0.0011344060767441988),\n",
       " (('for', 'stopword'), 0.00031475667492486537),\n",
       " ((\"wouldn't\", 'stopword'), 5.176468636734443e-32),\n",
       " ((\"shan't\", 'stopword'), -5.095613433307483e-32),\n",
       " ((\"should've\", 'stopword'), -4.964383594970385e-32),\n",
       " ((\"weren't\", 'stopword'), 4.772837965998244e-32),\n",
       " ((\"won't\", 'stopword'), -4.63614354829776e-32),\n",
       " ((\"that'll\", 'stopword'), 4.584724780530504e-32),\n",
       " ((\"it's\", 'stopword'), -4.3887857414221647e-32),\n",
       " ((\"you'd\", 'stopword'), -4.3158663003576057e-32),\n",
       " ((\"couldn't\", 'stopword'), -4.2802335401011297e-32),\n",
       " ((\"hasn't\", 'stopword'), -4.041534424613691e-32),\n",
       " (('mightn', 'stopword'), 3.896663855956063e-32),\n",
       " ((\"hadn't\", 'stopword'), 3.5740990960092086e-32),\n",
       " ((\"don't\", 'stopword'), -3.12946688844274e-32),\n",
       " ((\"didn't\", 'stopword'), 3.1185759332823714e-32),\n",
       " ((\"shouldn't\", 'stopword'), -3.057398799161764e-32),\n",
       " ((\"wasn't\", 'stopword'), 3.0061598820301835e-32),\n",
       " ((\"mightn't\", 'stopword'), 2.937466930904006e-32),\n",
       " ((\"mustn't\", 'stopword'), 2.8985042890252383e-32),\n",
       " ((\"doesn't\", 'stopword'), 2.7697121320981575e-32),\n",
       " ((\"you're\", 'stopword'), 2.1849133903924637e-32),\n",
       " ((\"needn't\", 'stopword'), 1.6041142682154428e-32),\n",
       " ((\"you've\", 'stopword'), -1.4975576154917225e-32),\n",
       " ((\"you'll\", 'stopword'), 1.1830921585588274e-32),\n",
       " ((\"aren't\", 'stopword'), 1.0727144879793623e-32),\n",
       " ((\"isn't\", 'stopword'), 5.661518013502029e-33),\n",
       " (('mustn', 'stopword'), -3.381039136439621e-33),\n",
       " ((\"haven't\", 'stopword'), 1.1777872994903602e-33),\n",
       " ((\"she's\", 'stopword'), -2.1108939804891228e-35)]"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features = [\n",
    "    (e, 'nrc') for e in emotions] + ['pers_pronouns'] + [\n",
    "    (c, 'liwc') for c in list(categories) if c in writings_df.columns] + [\n",
    "(st, 'stopword') for st in stopword_list]\n",
    "weights = model.get_layer('output_layer').get_weights()[0].tolist()[-(len(features)):]\n",
    "\n",
    "print(len(weights), len(features))\n",
    "feature_importance = {}\n",
    "for (i, f) in enumerate(features):\n",
    "    feature_importance[f] = weights[i][0]\n",
    "\n",
    "sorted(feature_importance.items(), key=lambda t: abs(t[1]), reverse=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate per user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_for_point(subject, voc, hyperparams_features=hyperparams_features, nrc_lexicon=nrc_lexicon,\n",
    "                      emotions=emotions):\n",
    "    eval_writings_df = writings_df[writings_df['subject']==subject]\n",
    "    correct_label = eval_writings_df.label.values[0]\n",
    "    (x_train, y_train), (x_valid, y_valid), (x_test, y_test), voc = load_erisk_data(eval_writings_df,\n",
    "                        seq_len=hyperparams_features['maxlen'],\n",
    "                        voc_size=hyperparams_features['max_features'],\n",
    "                        emotion_lexicon=nrc_lexicon,\n",
    "                        emotions=emotions, user_level=False,\n",
    "                        train_prop=0.0, vocabulary=voc)\n",
    "    return x_test, y_test, correct_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_per_user(writings_df, majority_prop=0.2, train_prop=0.7, majority_nr=0, validate=False, voc=None,\n",
    "                    random=False, nr_slices=5, test_slice=2):\n",
    "    all_predictions = []\n",
    "    all_labels = []\n",
    "    tp = 0\n",
    "    tn = 0\n",
    "    fp = 0\n",
    "    fn = 0\n",
    "    thresh=0.5\n",
    "    majority_proportion=majority_prop\n",
    "    valid_prop = 0.3\n",
    "    \n",
    "    if 'subset' in writings_df.columns:\n",
    "        training_subjects = list(set(writings_df[writings_df['subset']=='train'].subject))\n",
    "        test_subjects = list(set(writings_df[writings_df['subset']=='test'].subject))\n",
    "    else:\n",
    "        all_subjects = sorted(list(set(writings_df.subject)))\n",
    "        training_subjects_size = int(len(all_subjects) * train_prop)\n",
    "        test_subjects_size = len(all_subjects) - training_subjects_size\n",
    "        # Cross-validation, with fixed slice as input\n",
    "        test_prop = 1-train_prop\n",
    "        test_slice = min(test_slice, nr_slices)\n",
    "        logger.debug(\"start index: %f, from %f\\n\" % (\n",
    "            len(all_subjects)*(1/nr_slices)*test_slice, test_prop*test_slice))\n",
    "        start_slice = int(len(all_subjects)*(1/nr_slices)*test_slice)\n",
    "        test_subjects = all_subjects[start_slice: start_slice+test_subjects_size]\n",
    "        training_subjects = [s for s in all_subjects if s not in test_subjects]\n",
    "    training_subjects = sorted(training_subjects) # ensuring reproducibility\n",
    "    valid_subjects_size = int(len(training_subjects) * valid_prop)\n",
    "    valid_subjects = training_subjects[:valid_subjects_size]\n",
    "    training_subjects = training_subjects[valid_subjects_size:]\n",
    "    \n",
    "    if validate:\n",
    "        subjects = valid_subjects\n",
    "    else:\n",
    "        subjects = test_subjects\n",
    "    for subject in subjects:\n",
    "        x_test_user, y_test_user, label = get_data_for_point(subject, voc=voc)\n",
    "        outputs = model.predict(x_test_user)\n",
    "        if random:\n",
    "            sigma = np.std(outputs)\n",
    "            mu = np.mean(outputs)\n",
    "            print(\"generating random outputs with sigma\", sigma, \"and mu\", mu)\n",
    "            outputs = sigma*np.random.randn(len(outputs))+mu\n",
    "        positive_pred = sum(outputs>=thresh)\n",
    "        negative_pred = sum(outputs<thresh)\n",
    "        majority_pred = 0\n",
    "        if majority_proportion and positive_pred >= majority_proportion*negative_pred:\n",
    "            majority_pred = 1\n",
    "        if majority_nr and positive_pred>=majority_nr:\n",
    "            majority_pred = 1\n",
    "        if label == 1:\n",
    "            if majority_pred == 1:\n",
    "                tp+=1\n",
    "            else:\n",
    "                fn+=1\n",
    "        else:\n",
    "            if majority_pred == 0:\n",
    "                tn+=1\n",
    "            else:\n",
    "                fp+=1\n",
    "        print(negative_pred, positive_pred, majority_pred)\n",
    "        all_predictions.append(majority_pred)\n",
    "        all_labels.append(label)\n",
    "    def prec_recall_f1(tp, fp, tn, fn):\n",
    "        recall = tp/(tp+fn+0.0000001)\n",
    "        precision = tp/(tp+fp+0.0000001)\n",
    "        f1 = 2*precision*recall/(precision+recall+0.0000001)\n",
    "        print(\"Recall\", recall, \"Precision\", precision, \"F1\", f1)\n",
    "    if majority_prop:\n",
    "        print(\"Vote proportion\", majority_prop)\n",
    "    if majority_nr:\n",
    "        print(\"Vote points\", majority_nr)\n",
    "    prec_recall_f1(tp, fp, tn, fn)\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "0 training users,  0 validation users,  1  test users.\n",
      "[417] [22] 0\n",
      "Loading data...\n",
      "0 training users,  0 validation users,  1  test users.\n",
      "[78] [7] 0\n",
      "Loading data...\n",
      "0 training users,  0 validation users,  1  test users.\n",
      "[496] [7] 0\n",
      "Loading data...\n",
      "0 training users,  0 validation users,  1  test users.\n",
      "[1285] [62] 0\n",
      "Loading data...\n",
      "0 training users,  0 validation users,  1  test users.\n",
      "[172] [14] 0\n",
      "Loading data...\n",
      "0 training users,  0 validation users,  1  test users.\n",
      "[112] [0] 0\n",
      "Loading data...\n",
      "0 training users,  0 validation users,  1  test users.\n",
      "[1231] [27] 0\n",
      "Loading data...\n",
      "0 training users,  0 validation users,  1  test users.\n",
      "[1866] [10] 0\n",
      "Loading data...\n",
      "0 training users,  0 validation users,  1  test users.\n",
      "[282] [10] 0\n",
      "Loading data...\n",
      "0 training users,  0 validation users,  1  test users.\n",
      "[113] [1] 0\n",
      "Loading data...\n",
      "0 training users,  0 validation users,  1  test users.\n",
      "[478] [2] 0\n",
      "Loading data...\n",
      "0 training users,  0 validation users,  1  test users.\n",
      "[9] [0] 0\n",
      "Loading data...\n",
      "0 training users,  0 validation users,  1  test users.\n",
      "[155] [3] 0\n",
      "Loading data...\n",
      "0 training users,  0 validation users,  1  test users.\n",
      "[197] [2] 0\n",
      "Loading data...\n",
      "0 training users,  0 validation users,  1  test users.\n",
      "[989] [33] 0\n",
      "Loading data...\n",
      "0 training users,  0 validation users,  1  test users.\n",
      "[872] [12] 0\n",
      "Loading data...\n",
      "0 training users,  0 validation users,  1  test users.\n",
      "[105] [2] 0\n",
      "Loading data...\n",
      "0 training users,  0 validation users,  1  test users.\n",
      "[70] [0] 0\n",
      "Loading data...\n",
      "0 training users,  0 validation users,  1  test users.\n",
      "[42] [1] 0\n",
      "Loading data...\n",
      "0 training users,  0 validation users,  1  test users.\n",
      "[688] [37] 0\n",
      "Loading data...\n",
      "0 training users,  0 validation users,  1  test users.\n",
      "[965] [14] 0\n",
      "Loading data...\n",
      "0 training users,  0 validation users,  1  test users.\n",
      "[168] [4] 0\n",
      "Loading data...\n",
      "0 training users,  0 validation users,  1  test users.\n",
      "[321] [7] 0\n",
      "Loading data...\n",
      "0 training users,  0 validation users,  1  test users.\n",
      "[100] [1] 0\n",
      "Loading data...\n",
      "0 training users,  0 validation users,  1  test users.\n",
      "[379] [21] 0\n",
      "Loading data...\n",
      "0 training users,  0 validation users,  1  test users.\n",
      "[31] [1] 0\n",
      "Loading data...\n",
      "0 training users,  0 validation users,  1  test users.\n",
      "[1099] [16] 0\n",
      "Loading data...\n",
      "0 training users,  0 validation users,  1  test users.\n",
      "[363] [3] 0\n",
      "Loading data...\n",
      "0 training users,  0 validation users,  1  test users.\n",
      "[87] [9] 0\n",
      "Loading data...\n",
      "0 training users,  0 validation users,  1  test users.\n",
      "[19] [0] 0\n",
      "Loading data...\n",
      "0 training users,  0 validation users,  1  test users.\n",
      "[160] [0] 0\n",
      "Loading data...\n",
      "0 training users,  0 validation users,  1  test users.\n",
      "[62] [0] 0\n",
      "Loading data...\n",
      "0 training users,  0 validation users,  1  test users.\n",
      "[1181] [5] 0\n",
      "Loading data...\n",
      "0 training users,  0 validation users,  1  test users.\n",
      "[25] [2] 0\n",
      "Loading data...\n",
      "0 training users,  0 validation users,  1  test users.\n",
      "[160] [6] 0\n",
      "Loading data...\n",
      "0 training users,  0 validation users,  1  test users.\n",
      "[562] [23] 0\n",
      "Loading data...\n",
      "0 training users,  0 validation users,  1  test users.\n",
      "[1188] [50] 0\n",
      "Loading data...\n",
      "0 training users,  0 validation users,  1  test users.\n",
      "[285] [1] 0\n",
      "Loading data...\n",
      "0 training users,  0 validation users,  1  test users.\n",
      "[14] [2] 0\n",
      "Loading data...\n",
      "0 training users,  0 validation users,  1  test users.\n",
      "[962] [8] 0\n",
      "Loading data...\n",
      "0 training users,  0 validation users,  1  test users.\n",
      "[935] [13] 0\n",
      "Loading data...\n",
      "0 training users,  0 validation users,  1  test users.\n",
      "[391] [3] 0\n",
      "Loading data...\n",
      "0 training users,  0 validation users,  1  test users.\n",
      "[22] [0] 0\n",
      "Loading data...\n",
      "0 training users,  0 validation users,  1  test users.\n",
      "[848] [42] 0\n",
      "Loading data...\n",
      "0 training users,  0 validation users,  1  test users.\n",
      "[1356] [24] 0\n",
      "Loading data...\n",
      "0 training users,  0 validation users,  1  test users.\n",
      "[1165] [7] 0\n",
      "Loading data...\n",
      "0 training users,  0 validation users,  1  test users.\n",
      "[25] [4] 0\n",
      "Loading data...\n",
      "0 training users,  0 validation users,  1  test users.\n",
      "[19] [0] 0\n",
      "Loading data...\n",
      "0 training users,  0 validation users,  1  test users.\n",
      "[46] [0] 0\n",
      "Loading data...\n",
      "0 training users,  0 validation users,  1  test users.\n",
      "[14] [2] 0\n",
      "Loading data...\n",
      "0 training users,  0 validation users,  1  test users.\n",
      "[52] [4] 0\n",
      "Loading data...\n",
      "0 training users,  0 validation users,  1  test users.\n",
      "[1124] [29] 0\n",
      "Loading data...\n",
      "0 training users,  0 validation users,  1  test users.\n",
      "[289] [20] 0\n",
      "Loading data...\n",
      "0 training users,  0 validation users,  1  test users.\n",
      "[119] [0] 0\n",
      "Loading data...\n",
      "0 training users,  0 validation users,  1  test users.\n",
      "[237] [41] 0\n",
      "Loading data...\n",
      "0 training users,  0 validation users,  1  test users.\n",
      "[261] [7] 0\n",
      "Loading data...\n",
      "0 training users,  0 validation users,  1  test users.\n",
      "[41] [14] 1\n",
      "Loading data...\n",
      "0 training users,  0 validation users,  1  test users.\n",
      "[27] [1] 0\n",
      "Loading data...\n",
      "0 training users,  0 validation users,  1  test users.\n",
      "[1132] [16] 0\n",
      "Loading data...\n",
      "0 training users,  0 validation users,  1  test users.\n",
      "[569] [13] 0\n",
      "Loading data...\n",
      "0 training users,  0 validation users,  1  test users.\n",
      "[440] [31] 0\n",
      "Loading data...\n",
      "0 training users,  0 validation users,  1  test users.\n",
      "[48] [1] 0\n",
      "Loading data...\n",
      "0 training users,  0 validation users,  1  test users.\n",
      "[51] [1] 0\n",
      "Loading data...\n",
      "0 training users,  0 validation users,  1  test users.\n",
      "[97] [0] 0\n",
      "Loading data...\n",
      "0 training users,  0 validation users,  1  test users.\n",
      "[1079] [12] 0\n",
      "Loading data...\n",
      "0 training users,  0 validation users,  1  test users.\n",
      "[239] [5] 0\n",
      "Loading data...\n",
      "0 training users,  0 validation users,  1  test users.\n",
      "[33] [1] 0\n",
      "Loading data...\n",
      "0 training users,  0 validation users,  1  test users.\n",
      "[314] [2] 0\n",
      "Loading data...\n",
      "0 training users,  0 validation users,  1  test users.\n",
      "[918] [7] 0\n",
      "Loading data...\n",
      "0 training users,  0 validation users,  1  test users.\n",
      "[1375] [31] 0\n",
      "Loading data...\n",
      "0 training users,  0 validation users,  1  test users.\n",
      "[322] [9] 0\n",
      "Loading data...\n",
      "0 training users,  0 validation users,  1  test users.\n",
      "[1586] [13] 0\n",
      "Loading data...\n",
      "0 training users,  0 validation users,  1  test users.\n",
      "[25] [4] 0\n",
      "Loading data...\n",
      "0 training users,  0 validation users,  1  test users.\n",
      "[59] [46] 1\n",
      "Loading data...\n",
      "0 training users,  0 validation users,  1  test users.\n",
      "[407] [13] 0\n",
      "Loading data...\n",
      "0 training users,  0 validation users,  1  test users.\n",
      "[51] [1] 0\n",
      "Loading data...\n",
      "0 training users,  0 validation users,  1  test users.\n",
      "[481] [8] 0\n",
      "Loading data...\n",
      "0 training users,  0 validation users,  1  test users.\n",
      "[36] [0] 0\n",
      "Loading data...\n",
      "0 training users,  0 validation users,  1  test users.\n",
      "[131] [4] 0\n",
      "Loading data...\n",
      "0 training users,  0 validation users,  1  test users.\n",
      "[143] [1] 0\n",
      "Loading data...\n",
      "0 training users,  0 validation users,  1  test users.\n",
      "[34] [1] 0\n",
      "Loading data...\n",
      "0 training users,  0 validation users,  1  test users.\n",
      "[37] [2] 0\n",
      "Loading data...\n",
      "0 training users,  0 validation users,  1  test users.\n",
      "[491] [39] 0\n",
      "Loading data...\n",
      "0 training users,  0 validation users,  1  test users.\n",
      "[1539] [23] 0\n",
      "Loading data...\n",
      "0 training users,  0 validation users,  1  test users.\n",
      "[32] [1] 0\n",
      "Loading data...\n",
      "0 training users,  0 validation users,  1  test users.\n",
      "[22] [0] 0\n",
      "Loading data...\n",
      "0 training users,  0 validation users,  1  test users.\n",
      "[93] [2] 0\n",
      "Loading data...\n",
      "0 training users,  0 validation users,  1  test users.\n",
      "[34] [12] 1\n",
      "Loading data...\n",
      "0 training users,  0 validation users,  1  test users.\n",
      "[139] [2] 0\n",
      "Loading data...\n",
      "0 training users,  0 validation users,  1  test users.\n",
      "[12] [0] 0\n",
      "Loading data...\n",
      "0 training users,  0 validation users,  1  test users.\n",
      "[53] [2] 0\n",
      "Loading data...\n",
      "0 training users,  0 validation users,  1  test users.\n",
      "[35] [0] 0\n",
      "Loading data...\n",
      "0 training users,  0 validation users,  1  test users.\n",
      "[120] [7] 0\n",
      "Loading data...\n",
      "0 training users,  0 validation users,  1  test users.\n",
      "[800] [18] 0\n",
      "Loading data...\n",
      "0 training users,  0 validation users,  1  test users.\n",
      "[98] [0] 0\n",
      "Loading data...\n",
      "0 training users,  0 validation users,  1  test users.\n",
      "[243] [7] 0\n",
      "Loading data...\n",
      "0 training users,  0 validation users,  1  test users.\n",
      "[122] [0] 0\n",
      "Loading data...\n",
      "0 training users,  0 validation users,  1  test users.\n",
      "[90] [4] 0\n",
      "Loading data...\n",
      "0 training users,  0 validation users,  1  test users.\n",
      "[72] [76] 1\n",
      "Loading data...\n",
      "0 training users,  0 validation users,  1  test users.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[282] [7] 0\n",
      "Loading data...\n",
      "0 training users,  0 validation users,  1  test users.\n",
      "[1039] [24] 0\n",
      "Loading data...\n",
      "0 training users,  0 validation users,  1  test users.\n",
      "[587] [4] 0\n",
      "Loading data...\n",
      "0 training users,  0 validation users,  1  test users.\n",
      "[95] [5] 0\n",
      "Vote proportion 0.2\n",
      "Recall 0.23529411626297578 Precision 0.9999999750000006 F1 0.3809523464852629\n"
     ]
    }
   ],
   "source": [
    "predict_per_user(writings_df=writings_df, voc=voc, majority_prop=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_per_slice = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train...\n",
      "103/103 [==============================] - 0s 48us/sample - loss: 0.4739 - f1_m: 0.3333 - precision_m: 0.3000 - recall_m: 0.5000     \n",
      "Results for slice 0: [0.47392676351139845, 0.33333328, 0.29999998, 0.49999994]\n",
      "\n",
      "Train...\n",
      "103/103 [==============================] - 0s 54us/sample - loss: 0.4942 - f1_m: 0.3576 - precision_m: 0.3806 - recall_m: 0.5250     \n",
      "Results for slice 1: [0.49420061707496643, 0.3575757, 0.3805555, 0.525]\n",
      "\n",
      "Train...\n",
      "103/103 [==============================] - 0s 216us/sample - loss: 0.4024 - f1_m: 0.6373 - precision_m: 0.5214 - recall_m: 0.9500\n",
      "Results for slice 2: [0.4023708821211046, 0.6373015, 0.5214286, 0.9499999]\n",
      "\n",
      "Train...\n",
      "103/103 [==============================] - 0s 148us/sample - loss: 0.3093 - f1_m: 0.8264 - precision_m: 0.7250 - recall_m: 1.0000\n",
      "Results for slice 3: [0.3093455121355149, 0.82638884, 0.725, 1.0]\n",
      "\n",
      "Train...\n",
      "68/68 [==============================] - 0s 130us/sample - loss: 0.3460 - f1_m: 0.8611 - precision_m: 0.7714 - recall_m: 1.0000\n",
      "Results for slice 4: [0.34599672871477466, 0.8611111, 0.7714286, 1.0]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "nr_slices=5\n",
    "logger.setLevel(logging.INFO)\n",
    "for tslice in range(nr_slices): \n",
    "    (x_train, y_train), (x_valid, y_valid), (x_test, y_test), voc = load_erisk_data(writings_df, \n",
    "                                                                seq_len=hyperparams_features['maxlen'],\n",
    "                                                                voc_size=hyperparams_features['max_features'],\n",
    "                                                               emotion_lexicon=nrc_lexicon,\n",
    "                                                               emotions=emotions,\n",
    "                                                               user_level=hyperparams_features['user_level'],\n",
    "                                                                                    test_slice=tslice,\n",
    "                                                                                    nr_slices=nr_slices,\n",
    "    #                                                            vocabulary=pickle.load(open('vocabulary20K_selfharm.pkl', 'rb'))\n",
    "                                                                                   logger=logger)\n",
    "    model, history = train_model(model, x_train, y_train, x_valid, y_valid,\n",
    "           epochs=200, batch_size=hyperparams['batch_size'],\n",
    "                      class_weight={0:0.5, 1:5}, start_epoch=0,\n",
    "                      callback_list = [freeze_layer, weights_history, reduce_lr],\n",
    "                      workers=2, verbose=0)\n",
    "    results_per_slice[tslice] = model.evaluate(x_test, y_test)\n",
    "    logger.info(\"Results for slice %d: %s\\n\" % (tslice, results_per_slice[tslice]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average F1 score:  0.60314214 all F1 scores:  {0: 0.33333328, 1: 0.3575757, 2: 0.6373015, 3: 0.82638884, 4: 0.8611111}\n"
     ]
    }
   ],
   "source": [
    "print(\"Average F1 score: \", np.array([results_per_slice[s][1] for s in results_per_slice.keys()]).mean(),\n",
    "     \"all F1 scores: \", {s: v[1] for (s,v) in results_per_slice.items()} )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extra analysis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_tokens(row):\n",
    "    tokens = []\n",
    "    if row.tokenized_text:\n",
    "        tokens += row.tokenized_text\n",
    "    if row.tokenized_title:\n",
    "        tokens += row.tokenized_title\n",
    "    return tokens\n",
    "writings_df['all_tokens'] = writings_df.apply (lambda row: merge_tokens(row), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: include the title\n",
    "def extract_emotions(tokens, emotion, relative=True):\n",
    "    if not tokens:\n",
    "        return None\n",
    "    emotion_words = [t for t in tokens \n",
    "                     if t in nrc_lexicon[emotion]]\n",
    "    if relative:\n",
    "        return len(emotion_words) / len(tokens)\n",
    "    else:\n",
    "        return len(emotion_words)\n",
    "    \n",
    "    return encoded_emotions\n",
    "\n",
    "from functools import partial\n",
    "for emotion in emotions:\n",
    "    writings_df[emotion] = writings_df['all_tokens'].apply(partial(extract_emotions, emotion=emotion, \n",
    "                                                                   relative=True))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "writings_df['pronouns'] = writings_df['all_tokens'].apply(partial(encode_pronouns, relative=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>pronouns</th>\n",
       "      <th>text_len</th>\n",
       "      <th>anger</th>\n",
       "      <th>anticipation</th>\n",
       "      <th>disgust</th>\n",
       "      <th>fear</th>\n",
       "      <th>joy</th>\n",
       "      <th>negative</th>\n",
       "      <th>positive</th>\n",
       "      <th>sadness</th>\n",
       "      <th>surprise</th>\n",
       "      <th>trust</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>label</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.104269</td>\n",
       "      <td>0.011986</td>\n",
       "      <td>0.020197</td>\n",
       "      <td>0.031982</td>\n",
       "      <td>0.031271</td>\n",
       "      <td>0.019335</td>\n",
       "      <td>0.040782</td>\n",
       "      <td>0.023853</td>\n",
       "      <td>0.023621</td>\n",
       "      <td>0.032969</td>\n",
       "      <td>0.020421</td>\n",
       "      <td>0.023590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pronouns</th>\n",
       "      <td>0.104269</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.636745</td>\n",
       "      <td>0.449384</td>\n",
       "      <td>0.567496</td>\n",
       "      <td>0.452098</td>\n",
       "      <td>0.464899</td>\n",
       "      <td>0.548570</td>\n",
       "      <td>0.513029</td>\n",
       "      <td>0.571303</td>\n",
       "      <td>0.524614</td>\n",
       "      <td>0.461328</td>\n",
       "      <td>0.538335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>text_len</th>\n",
       "      <td>0.011986</td>\n",
       "      <td>0.636745</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.708853</td>\n",
       "      <td>0.791715</td>\n",
       "      <td>0.642980</td>\n",
       "      <td>0.738146</td>\n",
       "      <td>0.728836</td>\n",
       "      <td>0.823974</td>\n",
       "      <td>0.867609</td>\n",
       "      <td>0.723653</td>\n",
       "      <td>0.650420</td>\n",
       "      <td>0.834939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>anger</th>\n",
       "      <td>0.020197</td>\n",
       "      <td>0.449384</td>\n",
       "      <td>0.708853</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.643459</td>\n",
       "      <td>0.762591</td>\n",
       "      <td>0.858442</td>\n",
       "      <td>0.564162</td>\n",
       "      <td>0.835345</td>\n",
       "      <td>0.681573</td>\n",
       "      <td>0.774846</td>\n",
       "      <td>0.583704</td>\n",
       "      <td>0.671042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>anticipation</th>\n",
       "      <td>0.031982</td>\n",
       "      <td>0.567496</td>\n",
       "      <td>0.791715</td>\n",
       "      <td>0.643459</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.573916</td>\n",
       "      <td>0.668326</td>\n",
       "      <td>0.834784</td>\n",
       "      <td>0.684882</td>\n",
       "      <td>0.849864</td>\n",
       "      <td>0.668269</td>\n",
       "      <td>0.727331</td>\n",
       "      <td>0.818885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>disgust</th>\n",
       "      <td>0.031271</td>\n",
       "      <td>0.452098</td>\n",
       "      <td>0.642980</td>\n",
       "      <td>0.762591</td>\n",
       "      <td>0.573916</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.729799</td>\n",
       "      <td>0.526733</td>\n",
       "      <td>0.765865</td>\n",
       "      <td>0.603013</td>\n",
       "      <td>0.737717</td>\n",
       "      <td>0.540439</td>\n",
       "      <td>0.589641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fear</th>\n",
       "      <td>0.019335</td>\n",
       "      <td>0.464899</td>\n",
       "      <td>0.738146</td>\n",
       "      <td>0.858442</td>\n",
       "      <td>0.668326</td>\n",
       "      <td>0.729799</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.570632</td>\n",
       "      <td>0.862778</td>\n",
       "      <td>0.706676</td>\n",
       "      <td>0.824782</td>\n",
       "      <td>0.569688</td>\n",
       "      <td>0.687232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>joy</th>\n",
       "      <td>0.040782</td>\n",
       "      <td>0.548570</td>\n",
       "      <td>0.728836</td>\n",
       "      <td>0.564162</td>\n",
       "      <td>0.834784</td>\n",
       "      <td>0.526733</td>\n",
       "      <td>0.570632</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.604964</td>\n",
       "      <td>0.850961</td>\n",
       "      <td>0.603296</td>\n",
       "      <td>0.722710</td>\n",
       "      <td>0.811529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>negative</th>\n",
       "      <td>0.023853</td>\n",
       "      <td>0.513029</td>\n",
       "      <td>0.823974</td>\n",
       "      <td>0.835345</td>\n",
       "      <td>0.684882</td>\n",
       "      <td>0.765865</td>\n",
       "      <td>0.862778</td>\n",
       "      <td>0.604964</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.735431</td>\n",
       "      <td>0.840379</td>\n",
       "      <td>0.597634</td>\n",
       "      <td>0.706808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>positive</th>\n",
       "      <td>0.023621</td>\n",
       "      <td>0.571303</td>\n",
       "      <td>0.867609</td>\n",
       "      <td>0.681573</td>\n",
       "      <td>0.849864</td>\n",
       "      <td>0.603013</td>\n",
       "      <td>0.706676</td>\n",
       "      <td>0.850961</td>\n",
       "      <td>0.735431</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.702751</td>\n",
       "      <td>0.678778</td>\n",
       "      <td>0.916526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sadness</th>\n",
       "      <td>0.032969</td>\n",
       "      <td>0.524614</td>\n",
       "      <td>0.723653</td>\n",
       "      <td>0.774846</td>\n",
       "      <td>0.668269</td>\n",
       "      <td>0.737717</td>\n",
       "      <td>0.824782</td>\n",
       "      <td>0.603296</td>\n",
       "      <td>0.840379</td>\n",
       "      <td>0.702751</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.584816</td>\n",
       "      <td>0.665750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>surprise</th>\n",
       "      <td>0.020421</td>\n",
       "      <td>0.461328</td>\n",
       "      <td>0.650420</td>\n",
       "      <td>0.583704</td>\n",
       "      <td>0.727331</td>\n",
       "      <td>0.540439</td>\n",
       "      <td>0.569688</td>\n",
       "      <td>0.722710</td>\n",
       "      <td>0.597634</td>\n",
       "      <td>0.678778</td>\n",
       "      <td>0.584816</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.660681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>trust</th>\n",
       "      <td>0.023590</td>\n",
       "      <td>0.538335</td>\n",
       "      <td>0.834939</td>\n",
       "      <td>0.671042</td>\n",
       "      <td>0.818885</td>\n",
       "      <td>0.589641</td>\n",
       "      <td>0.687232</td>\n",
       "      <td>0.811529</td>\n",
       "      <td>0.706808</td>\n",
       "      <td>0.916526</td>\n",
       "      <td>0.665750</td>\n",
       "      <td>0.660681</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 label  pronouns  text_len     anger  anticipation   disgust  \\\n",
       "label         1.000000  0.104269  0.011986  0.020197      0.031982  0.031271   \n",
       "pronouns      0.104269  1.000000  0.636745  0.449384      0.567496  0.452098   \n",
       "text_len      0.011986  0.636745  1.000000  0.708853      0.791715  0.642980   \n",
       "anger         0.020197  0.449384  0.708853  1.000000      0.643459  0.762591   \n",
       "anticipation  0.031982  0.567496  0.791715  0.643459      1.000000  0.573916   \n",
       "disgust       0.031271  0.452098  0.642980  0.762591      0.573916  1.000000   \n",
       "fear          0.019335  0.464899  0.738146  0.858442      0.668326  0.729799   \n",
       "joy           0.040782  0.548570  0.728836  0.564162      0.834784  0.526733   \n",
       "negative      0.023853  0.513029  0.823974  0.835345      0.684882  0.765865   \n",
       "positive      0.023621  0.571303  0.867609  0.681573      0.849864  0.603013   \n",
       "sadness       0.032969  0.524614  0.723653  0.774846      0.668269  0.737717   \n",
       "surprise      0.020421  0.461328  0.650420  0.583704      0.727331  0.540439   \n",
       "trust         0.023590  0.538335  0.834939  0.671042      0.818885  0.589641   \n",
       "\n",
       "                  fear       joy  negative  positive   sadness  surprise  \\\n",
       "label         0.019335  0.040782  0.023853  0.023621  0.032969  0.020421   \n",
       "pronouns      0.464899  0.548570  0.513029  0.571303  0.524614  0.461328   \n",
       "text_len      0.738146  0.728836  0.823974  0.867609  0.723653  0.650420   \n",
       "anger         0.858442  0.564162  0.835345  0.681573  0.774846  0.583704   \n",
       "anticipation  0.668326  0.834784  0.684882  0.849864  0.668269  0.727331   \n",
       "disgust       0.729799  0.526733  0.765865  0.603013  0.737717  0.540439   \n",
       "fear          1.000000  0.570632  0.862778  0.706676  0.824782  0.569688   \n",
       "joy           0.570632  1.000000  0.604964  0.850961  0.603296  0.722710   \n",
       "negative      0.862778  0.604964  1.000000  0.735431  0.840379  0.597634   \n",
       "positive      0.706676  0.850961  0.735431  1.000000  0.702751  0.678778   \n",
       "sadness       0.824782  0.603296  0.840379  0.702751  1.000000  0.584816   \n",
       "surprise      0.569688  0.722710  0.597634  0.678778  0.584816  1.000000   \n",
       "trust         0.687232  0.811529  0.706808  0.916526  0.665750  0.660681   \n",
       "\n",
       "                 trust  \n",
       "label         0.023590  \n",
       "pronouns      0.538335  \n",
       "text_len      0.834939  \n",
       "anger         0.671042  \n",
       "anticipation  0.818885  \n",
       "disgust       0.589641  \n",
       "fear          0.687232  \n",
       "joy           0.811529  \n",
       "negative      0.706808  \n",
       "positive      0.916526  \n",
       "sadness       0.665750  \n",
       "surprise      0.660681  \n",
       "trust         1.000000  "
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "writings_df[['text', 'label', 'pronouns', 'text_len'] + emotions].corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pronouns</th>\n",
       "      <th>text_len</th>\n",
       "      <th>anger</th>\n",
       "      <th>anticipation</th>\n",
       "      <th>disgust</th>\n",
       "      <th>fear</th>\n",
       "      <th>joy</th>\n",
       "      <th>negative</th>\n",
       "      <th>positive</th>\n",
       "      <th>sadness</th>\n",
       "      <th>surprise</th>\n",
       "      <th>trust</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>label</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.868213</td>\n",
       "      <td>32.031615</td>\n",
       "      <td>0.386069</td>\n",
       "      <td>0.58984</td>\n",
       "      <td>0.263683</td>\n",
       "      <td>0.478014</td>\n",
       "      <td>0.479908</td>\n",
       "      <td>0.818800</td>\n",
       "      <td>1.280788</td>\n",
       "      <td>0.385315</td>\n",
       "      <td>0.284790</td>\n",
       "      <td>0.830560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.484271</td>\n",
       "      <td>36.398389</td>\n",
       "      <td>0.529232</td>\n",
       "      <td>0.86985</td>\n",
       "      <td>0.416203</td>\n",
       "      <td>0.654371</td>\n",
       "      <td>0.769766</td>\n",
       "      <td>1.152422</td>\n",
       "      <td>1.717428</td>\n",
       "      <td>0.627088</td>\n",
       "      <td>0.375418</td>\n",
       "      <td>1.128341</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       pronouns   text_len     anger  anticipation   disgust      fear  \\\n",
       "label                                                                    \n",
       "0      0.868213  32.031615  0.386069       0.58984  0.263683  0.478014   \n",
       "1      2.484271  36.398389  0.529232       0.86985  0.416203  0.654371   \n",
       "\n",
       "            joy  negative  positive   sadness  surprise     trust  \n",
       "label                                                              \n",
       "0      0.479908  0.818800  1.280788  0.385315  0.284790  0.830560  \n",
       "1      0.769766  1.152422  1.717428  0.627088  0.375418  1.128341  "
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "writings_df[['text', 'label', 'pronouns', 'text_len'] + emotions].groupby('label').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.sentiment import SentimentAnalyzer, SentimentIntensityAnalyzer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "sid = SentimentIntensityAnalyzer()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'neg': 0.0, 'neu': 0.66, 'pos': 0.34, 'compound': 0.5574}"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sid.polarity_scores(\"We are here today happiness is all around\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "writings_df['neg_vader'] = writings_df.text.apply(lambda t: sid.polarity_scores(t)['neg']\n",
    "                                                 if type(t)==str else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subject</th>\n",
       "      <th>title</th>\n",
       "      <th>date</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>tokenized_title</th>\n",
       "      <th>title_len</th>\n",
       "      <th>tokenized_text</th>\n",
       "      <th>text_len</th>\n",
       "      <th>emotions</th>\n",
       "      <th>...</th>\n",
       "      <th>fear</th>\n",
       "      <th>joy</th>\n",
       "      <th>negative</th>\n",
       "      <th>positive</th>\n",
       "      <th>sadness</th>\n",
       "      <th>surprise</th>\n",
       "      <th>trust</th>\n",
       "      <th>pronouns</th>\n",
       "      <th>all_tokens</th>\n",
       "      <th>neg_vader</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>subject8292</td>\n",
       "      <td>If anyone could help with which sub to put thi...</td>\n",
       "      <td>2016-08-02 09:22:12</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>[if, anyone, could, help, with, which, sub, to...</td>\n",
       "      <td>11.0</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[if, anyone, could, help, with, which, sub, to...</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>subject8292</td>\n",
       "      <td>I'm literally never gonna stop waiting...</td>\n",
       "      <td>2016-08-05 09:35:55</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>[i, m, literally, never, gonna, stop, waiting]</td>\n",
       "      <td>7.0</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[i, m, literally, never, gonna, stop, waiting]</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>subject8292</td>\n",
       "      <td>This is a really interesting study! Makes sens...</td>\n",
       "      <td>2016-08-05 21:36:24</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>[this, is, a, really, interesting, study, make...</td>\n",
       "      <td>9.0</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[this, is, a, really, interesting, study, make...</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>subject8292</td>\n",
       "      <td>The only thing Frank is building ...</td>\n",
       "      <td>2016-08-07 23:35:23</td>\n",
       "      <td>... Is hype. Think about it, every time he wor...</td>\n",
       "      <td>0</td>\n",
       "      <td>[the, only, thing, frank, is, building]</td>\n",
       "      <td>6.0</td>\n",
       "      <td>[is, hype, think, about, it, every, time, he, ...</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[is, hype, think, about, it, every, time, he, ...</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>subject8292</td>\n",
       "      <td>Mostly always me during this whole charade</td>\n",
       "      <td>2016-08-09 08:39:41</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>[mostly, always, me, during, this, whole, char...</td>\n",
       "      <td>7.0</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[mostly, always, me, during, this, whole, char...</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170693</th>\n",
       "      <td>subject217</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2018-08-19 11:29:21</td>\n",
       "      <td>this is my personal experience ,it may not ref...</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[this, is, my, personal, experience, it, may, ...</td>\n",
       "      <td>153.0</td>\n",
       "      <td>0.026144</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>[this, is, my, personal, experience, it, may, ...</td>\n",
       "      <td>0.089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170694</th>\n",
       "      <td>subject217</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2018-08-19 16:17:34</td>\n",
       "      <td>stop looking at 20 million saudis as one entit...</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[stop, looking, at, 20, million, saudis, as, o...</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[stop, looking, at, 20, million, saudis, as, o...</td>\n",
       "      <td>0.145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170695</th>\n",
       "      <td>subject217</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2018-08-19 20:00:31</td>\n",
       "      <td>i am aware of stats now and then. i was just s...</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[i, am, aware, of, stats, now, and, then, i, w...</td>\n",
       "      <td>198.0</td>\n",
       "      <td>0.030303</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>[i, am, aware, of, stats, now, and, then, i, w...</td>\n",
       "      <td>0.070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170696</th>\n",
       "      <td>subject217</td>\n",
       "      <td>WHAT DID YOU SAY TO ME?</td>\n",
       "      <td>2018-08-20 10:54:11</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>[what, did, you, say, to, me]</td>\n",
       "      <td>6.0</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[what, did, you, say, to, me]</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170697</th>\n",
       "      <td>subject217</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2018-08-20 12:07:44</td>\n",
       "      <td>me smellz fish,me find no fish!...what the fuc...</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[me, smellz, fish, me, find, no, fish, what, t...</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>[me, smellz, fish, me, find, no, fish, what, t...</td>\n",
       "      <td>0.484</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>170698 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            subject                                              title  \\\n",
       "0       subject8292  If anyone could help with which sub to put thi...   \n",
       "1       subject8292          I'm literally never gonna stop waiting...   \n",
       "2       subject8292  This is a really interesting study! Makes sens...   \n",
       "3       subject8292               The only thing Frank is building ...   \n",
       "4       subject8292         Mostly always me during this whole charade   \n",
       "...             ...                                                ...   \n",
       "170693   subject217                                                NaN   \n",
       "170694   subject217                                                NaN   \n",
       "170695   subject217                                                NaN   \n",
       "170696   subject217                            WHAT DID YOU SAY TO ME?   \n",
       "170697   subject217                                                NaN   \n",
       "\n",
       "                       date  \\\n",
       "0       2016-08-02 09:22:12   \n",
       "1       2016-08-05 09:35:55   \n",
       "2       2016-08-05 21:36:24   \n",
       "3       2016-08-07 23:35:23   \n",
       "4       2016-08-09 08:39:41   \n",
       "...                     ...   \n",
       "170693  2018-08-19 11:29:21   \n",
       "170694  2018-08-19 16:17:34   \n",
       "170695  2018-08-19 20:00:31   \n",
       "170696  2018-08-20 10:54:11   \n",
       "170697  2018-08-20 12:07:44   \n",
       "\n",
       "                                                     text  label  \\\n",
       "0                                                     NaN      0   \n",
       "1                                                     NaN      0   \n",
       "2                                                     NaN      0   \n",
       "3       ... Is hype. Think about it, every time he wor...      0   \n",
       "4                                                     NaN      0   \n",
       "...                                                   ...    ...   \n",
       "170693  this is my personal experience ,it may not ref...      0   \n",
       "170694  stop looking at 20 million saudis as one entit...      0   \n",
       "170695  i am aware of stats now and then. i was just s...      0   \n",
       "170696                                                NaN      0   \n",
       "170697  me smellz fish,me find no fish!...what the fuc...      0   \n",
       "\n",
       "                                          tokenized_title  title_len  \\\n",
       "0       [if, anyone, could, help, with, which, sub, to...       11.0   \n",
       "1          [i, m, literally, never, gonna, stop, waiting]        7.0   \n",
       "2       [this, is, a, really, interesting, study, make...        9.0   \n",
       "3                 [the, only, thing, frank, is, building]        6.0   \n",
       "4       [mostly, always, me, during, this, whole, char...        7.0   \n",
       "...                                                   ...        ...   \n",
       "170693                                               None        NaN   \n",
       "170694                                               None        NaN   \n",
       "170695                                               None        NaN   \n",
       "170696                      [what, did, you, say, to, me]        6.0   \n",
       "170697                                               None        NaN   \n",
       "\n",
       "                                           tokenized_text  text_len  emotions  \\\n",
       "0                                                    None       NaN       NaN   \n",
       "1                                                    None       NaN       NaN   \n",
       "2                                                    None       NaN       NaN   \n",
       "3       [is, hype, think, about, it, every, time, he, ...      26.0  0.000000   \n",
       "4                                                    None       NaN       NaN   \n",
       "...                                                   ...       ...       ...   \n",
       "170693  [this, is, my, personal, experience, it, may, ...     153.0  0.026144   \n",
       "170694  [stop, looking, at, 20, million, saudis, as, o...      15.0  0.000000   \n",
       "170695  [i, am, aware, of, stats, now, and, then, i, w...     198.0  0.030303   \n",
       "170696                                               None       NaN       NaN   \n",
       "170697  [me, smellz, fish, me, find, no, fish, what, t...      11.0  0.000000   \n",
       "\n",
       "        ...  fear  joy  negative  positive  sadness  surprise  trust  \\\n",
       "0       ...   0.0  0.0       0.0       0.0      0.0       0.0    0.0   \n",
       "1       ...   0.0  0.0       0.0       0.0      0.0       0.0    0.0   \n",
       "2       ...   0.0  0.0       0.0       3.0      0.0       0.0    0.0   \n",
       "3       ...   0.0  0.0       3.0       3.0      0.0       0.0    1.0   \n",
       "4       ...   0.0  0.0       1.0       0.0      0.0       0.0    0.0   \n",
       "...     ...   ...  ...       ...       ...      ...       ...    ...   \n",
       "170693  ...   1.0  1.0       1.0       7.0      0.0       1.0    4.0   \n",
       "170694  ...   1.0  0.0       1.0       0.0      0.0       0.0    0.0   \n",
       "170695  ...   2.0  3.0       4.0      11.0      3.0       0.0    6.0   \n",
       "170696  ...   0.0  0.0       0.0       0.0      0.0       0.0    0.0   \n",
       "170697  ...   0.0  0.0       0.0       0.0      0.0       0.0    0.0   \n",
       "\n",
       "        pronouns                                         all_tokens  neg_vader  \n",
       "0            0.0  [if, anyone, could, help, with, which, sub, to...      0.000  \n",
       "1            1.0     [i, m, literally, never, gonna, stop, waiting]      0.000  \n",
       "2            0.0  [this, is, a, really, interesting, study, make...      0.000  \n",
       "3            0.0  [is, hype, think, about, it, every, time, he, ...      0.000  \n",
       "4            1.0  [mostly, always, me, during, this, whole, char...      0.000  \n",
       "...          ...                                                ...        ...  \n",
       "170693       4.0  [this, is, my, personal, experience, it, may, ...      0.089  \n",
       "170694       0.0  [stop, looking, at, 20, million, saudis, as, o...      0.145  \n",
       "170695      16.0  [i, am, aware, of, stats, now, and, then, i, w...      0.070  \n",
       "170696       1.0                      [what, did, you, say, to, me]      0.000  \n",
       "170697       2.0  [me, smellz, fish, me, find, no, fish, what, t...      0.484  \n",
       "\n",
       "[170698 rows x 23 columns]"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "writings_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "writings_df['pos_vader'] = writings_df.text.apply(lambda t: sid.polarity_scores(t)['pos']\n",
    "                                                 if type(t)==str else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pronouns</th>\n",
       "      <th>text_len</th>\n",
       "      <th>neg_vader</th>\n",
       "      <th>pos_vader</th>\n",
       "      <th>anger</th>\n",
       "      <th>anticipation</th>\n",
       "      <th>disgust</th>\n",
       "      <th>fear</th>\n",
       "      <th>joy</th>\n",
       "      <th>negative</th>\n",
       "      <th>positive</th>\n",
       "      <th>sadness</th>\n",
       "      <th>surprise</th>\n",
       "      <th>trust</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>label</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.868213</td>\n",
       "      <td>32.031615</td>\n",
       "      <td>0.054259</td>\n",
       "      <td>0.109981</td>\n",
       "      <td>0.386069</td>\n",
       "      <td>0.58984</td>\n",
       "      <td>0.263683</td>\n",
       "      <td>0.478014</td>\n",
       "      <td>0.479908</td>\n",
       "      <td>0.818800</td>\n",
       "      <td>1.280788</td>\n",
       "      <td>0.385315</td>\n",
       "      <td>0.284790</td>\n",
       "      <td>0.830560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.484271</td>\n",
       "      <td>36.398389</td>\n",
       "      <td>0.079191</td>\n",
       "      <td>0.148154</td>\n",
       "      <td>0.529232</td>\n",
       "      <td>0.86985</td>\n",
       "      <td>0.416203</td>\n",
       "      <td>0.654371</td>\n",
       "      <td>0.769766</td>\n",
       "      <td>1.152422</td>\n",
       "      <td>1.717428</td>\n",
       "      <td>0.627088</td>\n",
       "      <td>0.375418</td>\n",
       "      <td>1.128341</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       pronouns   text_len  neg_vader  pos_vader     anger  anticipation  \\\n",
       "label                                                                      \n",
       "0      0.868213  32.031615   0.054259   0.109981  0.386069       0.58984   \n",
       "1      2.484271  36.398389   0.079191   0.148154  0.529232       0.86985   \n",
       "\n",
       "        disgust      fear       joy  negative  positive   sadness  surprise  \\\n",
       "label                                                                         \n",
       "0      0.263683  0.478014  0.479908  0.818800  1.280788  0.385315  0.284790   \n",
       "1      0.416203  0.654371  0.769766  1.152422  1.717428  0.627088  0.375418   \n",
       "\n",
       "          trust  \n",
       "label            \n",
       "0      0.830560  \n",
       "1      1.128341  "
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "writings_df[['text', 'label', 'pronouns', 'text_len', 'neg_vader', 'pos_vader'] + emotions].groupby('label').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>pronouns</th>\n",
       "      <th>text_len</th>\n",
       "      <th>neg_vader</th>\n",
       "      <th>pos_vader</th>\n",
       "      <th>anger</th>\n",
       "      <th>anticipation</th>\n",
       "      <th>disgust</th>\n",
       "      <th>fear</th>\n",
       "      <th>joy</th>\n",
       "      <th>negative</th>\n",
       "      <th>positive</th>\n",
       "      <th>sadness</th>\n",
       "      <th>surprise</th>\n",
       "      <th>trust</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>label</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.097800</td>\n",
       "      <td>0.033477</td>\n",
       "      <td>0.067170</td>\n",
       "      <td>0.065211</td>\n",
       "      <td>0.022057</td>\n",
       "      <td>0.025666</td>\n",
       "      <td>0.030664</td>\n",
       "      <td>0.019114</td>\n",
       "      <td>0.033977</td>\n",
       "      <td>0.022934</td>\n",
       "      <td>0.019590</td>\n",
       "      <td>0.032641</td>\n",
       "      <td>0.018109</td>\n",
       "      <td>0.024014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pronouns</th>\n",
       "      <td>0.097800</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.332071</td>\n",
       "      <td>0.193938</td>\n",
       "      <td>0.221419</td>\n",
       "      <td>0.076345</td>\n",
       "      <td>0.128030</td>\n",
       "      <td>0.094069</td>\n",
       "      <td>0.063176</td>\n",
       "      <td>0.144011</td>\n",
       "      <td>0.076670</td>\n",
       "      <td>0.106055</td>\n",
       "      <td>0.100827</td>\n",
       "      <td>0.106790</td>\n",
       "      <td>0.122914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>text_len</th>\n",
       "      <td>0.033477</td>\n",
       "      <td>0.332071</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.343154</td>\n",
       "      <td>0.159673</td>\n",
       "      <td>0.360460</td>\n",
       "      <td>0.386351</td>\n",
       "      <td>0.312393</td>\n",
       "      <td>0.381410</td>\n",
       "      <td>0.339398</td>\n",
       "      <td>0.370250</td>\n",
       "      <td>0.330075</td>\n",
       "      <td>0.384031</td>\n",
       "      <td>0.349498</td>\n",
       "      <td>0.389620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>neg_vader</th>\n",
       "      <td>0.067170</td>\n",
       "      <td>0.193938</td>\n",
       "      <td>0.343154</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.169624</td>\n",
       "      <td>0.384510</td>\n",
       "      <td>0.141868</td>\n",
       "      <td>0.362582</td>\n",
       "      <td>0.339245</td>\n",
       "      <td>0.126042</td>\n",
       "      <td>0.431111</td>\n",
       "      <td>0.099767</td>\n",
       "      <td>0.374256</td>\n",
       "      <td>0.159302</td>\n",
       "      <td>0.143060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pos_vader</th>\n",
       "      <td>0.065211</td>\n",
       "      <td>0.221419</td>\n",
       "      <td>0.159673</td>\n",
       "      <td>0.169624</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.079693</td>\n",
       "      <td>0.225925</td>\n",
       "      <td>0.087309</td>\n",
       "      <td>0.071450</td>\n",
       "      <td>0.323148</td>\n",
       "      <td>0.058266</td>\n",
       "      <td>0.270687</td>\n",
       "      <td>0.095040</td>\n",
       "      <td>0.186243</td>\n",
       "      <td>0.231954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>anger</th>\n",
       "      <td>0.022057</td>\n",
       "      <td>0.076345</td>\n",
       "      <td>0.360460</td>\n",
       "      <td>0.384510</td>\n",
       "      <td>0.079693</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.196795</td>\n",
       "      <td>0.583864</td>\n",
       "      <td>0.587460</td>\n",
       "      <td>0.157202</td>\n",
       "      <td>0.631708</td>\n",
       "      <td>0.128169</td>\n",
       "      <td>0.528980</td>\n",
       "      <td>0.273195</td>\n",
       "      <td>0.169261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>anticipation</th>\n",
       "      <td>0.025666</td>\n",
       "      <td>0.128030</td>\n",
       "      <td>0.386351</td>\n",
       "      <td>0.141868</td>\n",
       "      <td>0.225925</td>\n",
       "      <td>0.196795</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.164649</td>\n",
       "      <td>0.241958</td>\n",
       "      <td>0.583107</td>\n",
       "      <td>0.178827</td>\n",
       "      <td>0.452457</td>\n",
       "      <td>0.198972</td>\n",
       "      <td>0.460851</td>\n",
       "      <td>0.469028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>disgust</th>\n",
       "      <td>0.030664</td>\n",
       "      <td>0.094069</td>\n",
       "      <td>0.312393</td>\n",
       "      <td>0.362582</td>\n",
       "      <td>0.087309</td>\n",
       "      <td>0.583864</td>\n",
       "      <td>0.164649</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.440376</td>\n",
       "      <td>0.152731</td>\n",
       "      <td>0.552021</td>\n",
       "      <td>0.116588</td>\n",
       "      <td>0.490181</td>\n",
       "      <td>0.232166</td>\n",
       "      <td>0.153723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fear</th>\n",
       "      <td>0.019114</td>\n",
       "      <td>0.063176</td>\n",
       "      <td>0.381410</td>\n",
       "      <td>0.339245</td>\n",
       "      <td>0.071450</td>\n",
       "      <td>0.587460</td>\n",
       "      <td>0.241958</td>\n",
       "      <td>0.440376</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.159907</td>\n",
       "      <td>0.576962</td>\n",
       "      <td>0.141985</td>\n",
       "      <td>0.583703</td>\n",
       "      <td>0.248160</td>\n",
       "      <td>0.184240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>joy</th>\n",
       "      <td>0.033977</td>\n",
       "      <td>0.144011</td>\n",
       "      <td>0.339398</td>\n",
       "      <td>0.126042</td>\n",
       "      <td>0.323148</td>\n",
       "      <td>0.157202</td>\n",
       "      <td>0.583107</td>\n",
       "      <td>0.152731</td>\n",
       "      <td>0.159907</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.113400</td>\n",
       "      <td>0.645827</td>\n",
       "      <td>0.176440</td>\n",
       "      <td>0.477317</td>\n",
       "      <td>0.582920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>negative</th>\n",
       "      <td>0.022934</td>\n",
       "      <td>0.076670</td>\n",
       "      <td>0.370250</td>\n",
       "      <td>0.431111</td>\n",
       "      <td>0.058266</td>\n",
       "      <td>0.631708</td>\n",
       "      <td>0.178827</td>\n",
       "      <td>0.552021</td>\n",
       "      <td>0.576962</td>\n",
       "      <td>0.113400</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.105821</td>\n",
       "      <td>0.612781</td>\n",
       "      <td>0.226230</td>\n",
       "      <td>0.145220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>positive</th>\n",
       "      <td>0.019590</td>\n",
       "      <td>0.106055</td>\n",
       "      <td>0.330075</td>\n",
       "      <td>0.099767</td>\n",
       "      <td>0.270687</td>\n",
       "      <td>0.128169</td>\n",
       "      <td>0.452457</td>\n",
       "      <td>0.116588</td>\n",
       "      <td>0.141985</td>\n",
       "      <td>0.645827</td>\n",
       "      <td>0.105821</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.139827</td>\n",
       "      <td>0.333998</td>\n",
       "      <td>0.648163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sadness</th>\n",
       "      <td>0.032641</td>\n",
       "      <td>0.100827</td>\n",
       "      <td>0.384031</td>\n",
       "      <td>0.374256</td>\n",
       "      <td>0.095040</td>\n",
       "      <td>0.528980</td>\n",
       "      <td>0.198972</td>\n",
       "      <td>0.490181</td>\n",
       "      <td>0.583703</td>\n",
       "      <td>0.176440</td>\n",
       "      <td>0.612781</td>\n",
       "      <td>0.139827</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.265026</td>\n",
       "      <td>0.171245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>surprise</th>\n",
       "      <td>0.018109</td>\n",
       "      <td>0.106790</td>\n",
       "      <td>0.349498</td>\n",
       "      <td>0.159302</td>\n",
       "      <td>0.186243</td>\n",
       "      <td>0.273195</td>\n",
       "      <td>0.460851</td>\n",
       "      <td>0.232166</td>\n",
       "      <td>0.248160</td>\n",
       "      <td>0.477317</td>\n",
       "      <td>0.226230</td>\n",
       "      <td>0.333998</td>\n",
       "      <td>0.265026</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.354746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>trust</th>\n",
       "      <td>0.024014</td>\n",
       "      <td>0.122914</td>\n",
       "      <td>0.389620</td>\n",
       "      <td>0.143060</td>\n",
       "      <td>0.231954</td>\n",
       "      <td>0.169261</td>\n",
       "      <td>0.469028</td>\n",
       "      <td>0.153723</td>\n",
       "      <td>0.184240</td>\n",
       "      <td>0.582920</td>\n",
       "      <td>0.145220</td>\n",
       "      <td>0.648163</td>\n",
       "      <td>0.171245</td>\n",
       "      <td>0.354746</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 label  pronouns  text_len  neg_vader  pos_vader     anger  \\\n",
       "label         1.000000  0.097800  0.033477   0.067170   0.065211  0.022057   \n",
       "pronouns      0.097800  1.000000  0.332071   0.193938   0.221419  0.076345   \n",
       "text_len      0.033477  0.332071  1.000000   0.343154   0.159673  0.360460   \n",
       "neg_vader     0.067170  0.193938  0.343154   1.000000   0.169624  0.384510   \n",
       "pos_vader     0.065211  0.221419  0.159673   0.169624   1.000000  0.079693   \n",
       "anger         0.022057  0.076345  0.360460   0.384510   0.079693  1.000000   \n",
       "anticipation  0.025666  0.128030  0.386351   0.141868   0.225925  0.196795   \n",
       "disgust       0.030664  0.094069  0.312393   0.362582   0.087309  0.583864   \n",
       "fear          0.019114  0.063176  0.381410   0.339245   0.071450  0.587460   \n",
       "joy           0.033977  0.144011  0.339398   0.126042   0.323148  0.157202   \n",
       "negative      0.022934  0.076670  0.370250   0.431111   0.058266  0.631708   \n",
       "positive      0.019590  0.106055  0.330075   0.099767   0.270687  0.128169   \n",
       "sadness       0.032641  0.100827  0.384031   0.374256   0.095040  0.528980   \n",
       "surprise      0.018109  0.106790  0.349498   0.159302   0.186243  0.273195   \n",
       "trust         0.024014  0.122914  0.389620   0.143060   0.231954  0.169261   \n",
       "\n",
       "              anticipation   disgust      fear       joy  negative  positive  \\\n",
       "label             0.025666  0.030664  0.019114  0.033977  0.022934  0.019590   \n",
       "pronouns          0.128030  0.094069  0.063176  0.144011  0.076670  0.106055   \n",
       "text_len          0.386351  0.312393  0.381410  0.339398  0.370250  0.330075   \n",
       "neg_vader         0.141868  0.362582  0.339245  0.126042  0.431111  0.099767   \n",
       "pos_vader         0.225925  0.087309  0.071450  0.323148  0.058266  0.270687   \n",
       "anger             0.196795  0.583864  0.587460  0.157202  0.631708  0.128169   \n",
       "anticipation      1.000000  0.164649  0.241958  0.583107  0.178827  0.452457   \n",
       "disgust           0.164649  1.000000  0.440376  0.152731  0.552021  0.116588   \n",
       "fear              0.241958  0.440376  1.000000  0.159907  0.576962  0.141985   \n",
       "joy               0.583107  0.152731  0.159907  1.000000  0.113400  0.645827   \n",
       "negative          0.178827  0.552021  0.576962  0.113400  1.000000  0.105821   \n",
       "positive          0.452457  0.116588  0.141985  0.645827  0.105821  1.000000   \n",
       "sadness           0.198972  0.490181  0.583703  0.176440  0.612781  0.139827   \n",
       "surprise          0.460851  0.232166  0.248160  0.477317  0.226230  0.333998   \n",
       "trust             0.469028  0.153723  0.184240  0.582920  0.145220  0.648163   \n",
       "\n",
       "               sadness  surprise     trust  \n",
       "label         0.032641  0.018109  0.024014  \n",
       "pronouns      0.100827  0.106790  0.122914  \n",
       "text_len      0.384031  0.349498  0.389620  \n",
       "neg_vader     0.374256  0.159302  0.143060  \n",
       "pos_vader     0.095040  0.186243  0.231954  \n",
       "anger         0.528980  0.273195  0.169261  \n",
       "anticipation  0.198972  0.460851  0.469028  \n",
       "disgust       0.490181  0.232166  0.153723  \n",
       "fear          0.583703  0.248160  0.184240  \n",
       "joy           0.176440  0.477317  0.582920  \n",
       "negative      0.612781  0.226230  0.145220  \n",
       "positive      0.139827  0.333998  0.648163  \n",
       "sadness       1.000000  0.265026  0.171245  \n",
       "surprise      0.265026  1.000000  0.354746  \n",
       "trust         0.171245  0.354746  1.000000  "
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "writings_df[['text', 'label', 'pronouns', 'text_len', 'neg_vader', 'pos_vader'] + emotions].corr('spearman')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LIWC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from liwc_readDict import readDict\n",
    "\n",
    "liwc = readDict('/home/ana/resources/FakeOrFact/features/LIWC/LIWC/liwc.dic')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'achieve',\n",
       " 'adverb',\n",
       " 'affect',\n",
       " 'anger',\n",
       " 'anx',\n",
       " 'article',\n",
       " 'assent',\n",
       " 'auxverb',\n",
       " 'bio',\n",
       " 'body',\n",
       " 'cause',\n",
       " 'certain',\n",
       " 'cogmech',\n",
       " 'conj',\n",
       " 'death',\n",
       " 'discrep',\n",
       " 'excl',\n",
       " 'family',\n",
       " 'feel',\n",
       " 'filler',\n",
       " 'friend',\n",
       " 'funct',\n",
       " 'future',\n",
       " 'health',\n",
       " 'hear',\n",
       " 'home',\n",
       " 'humans',\n",
       " 'i',\n",
       " 'incl',\n",
       " 'ingest',\n",
       " 'inhib',\n",
       " 'insight',\n",
       " 'ipron',\n",
       " 'leisure',\n",
       " 'money',\n",
       " 'motion',\n",
       " 'negate',\n",
       " 'negemo',\n",
       " 'nonfl',\n",
       " 'number',\n",
       " 'past',\n",
       " 'percept',\n",
       " 'posemo',\n",
       " 'ppron',\n",
       " 'preps',\n",
       " 'present',\n",
       " 'pronoun',\n",
       " 'quant',\n",
       " 'relativ',\n",
       " 'relig',\n",
       " 'sad',\n",
       " 'see',\n",
       " 'sexual',\n",
       " 'shehe',\n",
       " 'social',\n",
       " 'space',\n",
       " 'swear',\n",
       " 'tentat',\n",
       " 'they',\n",
       " 'time',\n",
       " 'verb',\n",
       " 'we',\n",
       " 'work',\n",
       " 'you'}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "categories = [c for (w,c) in liwc]\n",
    "set(categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['a', 'funct'],\n",
       " ['a', 'article'],\n",
       " ['abandon*', 'affect'],\n",
       " ['abandon*', 'negemo'],\n",
       " ['abandon*', 'sad'],\n",
       " ['abandon*', 'cogmech'],\n",
       " ['abandon*', 'inhib'],\n",
       " ['abdomen*', 'bio'],\n",
       " ['abdomen*', 'body'],\n",
       " ['abilit*', 'achieve'],\n",
       " ['able*', 'achieve'],\n",
       " ['abortion*', 'bio'],\n",
       " ['abortion*', 'health'],\n",
       " ['abortion*', 'sexual'],\n",
       " ['about', 'funct'],\n",
       " ['about', 'adverb'],\n",
       " ['about', 'preps'],\n",
       " ['above', 'funct'],\n",
       " ['above', 'preps'],\n",
       " ['above', 'space'],\n",
       " ['above', 'relativ'],\n",
       " ['abrupt*', 'time'],\n",
       " ['abrupt*', 'relativ'],\n",
       " ['abs', 'bio'],\n",
       " ['abs', 'body'],\n",
       " ['absent*', 'work'],\n",
       " ['absolute', 'cogmech'],\n",
       " ['absolute', 'certain'],\n",
       " ['absolutely', 'funct'],\n",
       " ['absolutely', 'adverb'],\n",
       " ['absolutely', 'cogmech'],\n",
       " ['absolutely', 'certain'],\n",
       " ['absolutely', 'assent'],\n",
       " ['abstain*', 'cogmech'],\n",
       " ['abstain*', 'inhib'],\n",
       " ['abuse*', 'affect'],\n",
       " ['abuse*', 'negemo'],\n",
       " ['abuse*', 'anger'],\n",
       " ['abusi*', 'affect'],\n",
       " ['abusi*', 'negemo'],\n",
       " ['abusi*', 'anger'],\n",
       " ['academ*', 'work'],\n",
       " ['accept', 'affect'],\n",
       " ['accept', 'posemo'],\n",
       " ['accept', 'cogmech'],\n",
       " ['accept', 'insight'],\n",
       " ['accepta*', 'affect'],\n",
       " ['accepta*', 'posemo'],\n",
       " ['accepta*', 'cogmech'],\n",
       " ['accepta*', 'insight'],\n",
       " ['accepted', 'verb'],\n",
       " ['accepted', 'past'],\n",
       " ['accepted', 'affect'],\n",
       " ['accepted', 'posemo'],\n",
       " ['accepted', 'cogmech'],\n",
       " ['accepted', 'insight'],\n",
       " ['accepting', 'affect'],\n",
       " ['accepting', 'posemo'],\n",
       " ['accepting', 'cogmech'],\n",
       " ['accepting', 'insight'],\n",
       " ['accepts', 'affect'],\n",
       " ['accepts', 'posemo'],\n",
       " ['accepts', 'cogmech'],\n",
       " ['accepts', 'insight'],\n",
       " ['accomplish*', 'work'],\n",
       " ['accomplish*', 'achieve'],\n",
       " ['account*', 'money'],\n",
       " ['accura*', 'cogmech'],\n",
       " ['accura*', 'certain'],\n",
       " ['ace', 'achieve'],\n",
       " ['ache*', 'affect'],\n",
       " ['ache*', 'negemo'],\n",
       " ['ache*', 'sad'],\n",
       " ['ache*', 'bio'],\n",
       " ['ache*', 'health'],\n",
       " ['achiev*', 'work'],\n",
       " ['achiev*', 'achieve'],\n",
       " ['aching', 'affect'],\n",
       " ['aching', 'negemo'],\n",
       " ['aching', 'sad'],\n",
       " ['aching', 'bio'],\n",
       " ['aching', 'health'],\n",
       " ['acid*', 'percept'],\n",
       " ['acknowledg*', 'cogmech'],\n",
       " ['acknowledg*', 'insight'],\n",
       " ['acne', 'bio'],\n",
       " ['acne', 'health'],\n",
       " ['acquainta*', 'social'],\n",
       " ['acquainta*', 'friend'],\n",
       " ['acquir*', 'achieve'],\n",
       " ['acquisition*', 'achieve'],\n",
       " ['acrid*', 'percept'],\n",
       " ['across', 'funct'],\n",
       " ['across', 'preps'],\n",
       " ['across', 'space'],\n",
       " ['across', 'relativ'],\n",
       " ['act', 'relativ'],\n",
       " ['act', 'motion'],\n",
       " ['action*', 'motion'],\n",
       " ['action*', 'relativ'],\n",
       " ['activat*', 'cogmech'],\n",
       " ['activat*', 'cause'],\n",
       " ['active*', 'affect'],\n",
       " ['active*', 'posemo'],\n",
       " ['actor*', 'leisure'],\n",
       " ['actress*', 'leisure'],\n",
       " ['actually', 'funct'],\n",
       " ['actually', 'adverb'],\n",
       " ['add', 'cogmech'],\n",
       " ['add', 'incl'],\n",
       " ['addict*', 'bio'],\n",
       " ['addict*', 'health'],\n",
       " ['addit*', 'cogmech'],\n",
       " ['addit*', 'incl'],\n",
       " ['address', 'home'],\n",
       " ['adequa*', 'achieve'],\n",
       " ['adjust*', 'cogmech'],\n",
       " ['adjust*', 'insight'],\n",
       " ['administrat*', 'work'],\n",
       " ['admir*', 'affect'],\n",
       " ['admir*', 'posemo'],\n",
       " ['admit', 'verb'],\n",
       " ['admit', 'present'],\n",
       " ['admit', 'social'],\n",
       " ['admit', 'cogmech'],\n",
       " ['admit', 'insight'],\n",
       " ['admits', 'verb'],\n",
       " ['admits', 'present'],\n",
       " ['admits', 'social'],\n",
       " ['admits', 'cogmech'],\n",
       " ['admits', 'insight'],\n",
       " ['admitted', 'verb'],\n",
       " ['admitted', 'past'],\n",
       " ['admitted', 'social'],\n",
       " ['admitted', 'cogmech'],\n",
       " ['admitted', 'insight'],\n",
       " ['admitting', 'social'],\n",
       " ['admitting', 'cogmech'],\n",
       " ['admitting', 'insight'],\n",
       " ['ador*', 'affect'],\n",
       " ['ador*', 'posemo'],\n",
       " ['adult', 'social'],\n",
       " ['adult', 'humans'],\n",
       " ['adults', 'social'],\n",
       " ['adults', 'humans'],\n",
       " ['advanc*', 'motion'],\n",
       " ['advanc*', 'relativ'],\n",
       " ['advanc*', 'achieve'],\n",
       " ['advantag*', 'affect'],\n",
       " ['advantag*', 'posemo'],\n",
       " ['advantag*', 'achieve'],\n",
       " ['adventur*', 'affect'],\n",
       " ['adventur*', 'posemo'],\n",
       " ['advers*', 'affect'],\n",
       " ['advers*', 'negemo'],\n",
       " ['advertising', 'work'],\n",
       " ['advice', 'social'],\n",
       " ['advil', 'bio'],\n",
       " ['advil', 'health'],\n",
       " ['advis*', 'social'],\n",
       " ['advis*', 'work'],\n",
       " ['aerobic*', 'leisure'],\n",
       " ['affair*', 'social'],\n",
       " ['affect', 'cogmech'],\n",
       " ['affect', 'cause'],\n",
       " ['affected', 'verb'],\n",
       " ['affected', 'past'],\n",
       " ['affected', 'cogmech'],\n",
       " ['affected', 'cause'],\n",
       " ['affecting', 'cogmech'],\n",
       " ['affecting', 'cause'],\n",
       " ['affection*', 'affect'],\n",
       " ['affection*', 'posemo'],\n",
       " ['affects', 'cogmech'],\n",
       " ['affects', 'cause'],\n",
       " ['afraid', 'affect'],\n",
       " ['afraid', 'negemo'],\n",
       " ['afraid', 'anx'],\n",
       " ['after', 'funct'],\n",
       " ['after', 'preps'],\n",
       " ['after', 'time'],\n",
       " ['after', 'relativ'],\n",
       " ['afterlife*', 'time'],\n",
       " ['afterlife*', 'relativ'],\n",
       " ['afterlife*', 'relig'],\n",
       " ['aftermath*', 'time'],\n",
       " ['aftermath*', 'relativ'],\n",
       " ['afternoon*', 'time'],\n",
       " ['afternoon*', 'relativ'],\n",
       " ['afterthought*', 'cogmech'],\n",
       " ['afterthought*', 'insight'],\n",
       " ['afterthought*', 'time'],\n",
       " ['afterthought*', 'relativ'],\n",
       " ['afterward*', 'time'],\n",
       " ['afterward*', 'relativ'],\n",
       " ['again', 'funct'],\n",
       " ['again', 'adverb'],\n",
       " ['again', 'time'],\n",
       " ['again', 'relativ'],\n",
       " ['against', 'funct'],\n",
       " ['against', 'preps'],\n",
       " ['age', 'time'],\n",
       " ['age', 'relativ'],\n",
       " ['aged', 'time'],\n",
       " ['aged', 'relativ'],\n",
       " ['agent', 'work'],\n",
       " ['agents', 'work'],\n",
       " ['ages', 'time'],\n",
       " ['ages', 'relativ'],\n",
       " ['aggravat*', 'affect'],\n",
       " ['aggravat*', 'negemo'],\n",
       " ['aggravat*', 'anger'],\n",
       " ['aggravat*', 'cogmech'],\n",
       " ['aggravat*', 'cause'],\n",
       " ['aggress*', 'affect'],\n",
       " ['aggress*', 'negemo'],\n",
       " ['aggress*', 'anger'],\n",
       " ['aging', 'time'],\n",
       " ['aging', 'relativ'],\n",
       " ['agitat*', 'affect'],\n",
       " ['agitat*', 'negemo'],\n",
       " ['agitat*', 'anger'],\n",
       " ['agnost*', 'relig'],\n",
       " ['ago', 'time'],\n",
       " ['ago', 'relativ'],\n",
       " ['agoniz*', 'affect'],\n",
       " ['agoniz*', 'negemo'],\n",
       " ['agoniz*', 'sad'],\n",
       " ['agony', 'affect'],\n",
       " ['agony', 'negemo'],\n",
       " ['agony', 'sad'],\n",
       " ['agree', 'affect'],\n",
       " ['agree', 'posemo'],\n",
       " ['agree', 'assent'],\n",
       " ['agreeab*', 'affect'],\n",
       " ['agreeab*', 'posemo'],\n",
       " ['agreed', 'affect'],\n",
       " ['agreed', 'posemo'],\n",
       " ['agreeing', 'affect'],\n",
       " ['agreeing', 'posemo'],\n",
       " ['agreement*', 'affect'],\n",
       " ['agreement*', 'posemo'],\n",
       " ['agrees', 'affect'],\n",
       " ['agrees', 'posemo'],\n",
       " ['ah', 'assent'],\n",
       " ['ahead', 'funct'],\n",
       " ['ahead', 'preps'],\n",
       " ['ahead', 'time'],\n",
       " ['ahead', 'relativ'],\n",
       " ['ahead', 'achieve'],\n",
       " ['aids', 'bio'],\n",
       " ['aids', 'health'],\n",
       " ['aids', 'sexual'],\n",
       " [\"ain't\", 'verb'],\n",
       " [\"ain't\", 'funct'],\n",
       " [\"ain't\", 'auxverb'],\n",
       " [\"ain't\", 'present'],\n",
       " [\"ain't\", 'negate'],\n",
       " ['aint', 'verb'],\n",
       " ['aint', 'funct'],\n",
       " ['aint', 'auxverb'],\n",
       " ['aint', 'present'],\n",
       " ['aint', 'negate'],\n",
       " ['air', 'relativ'],\n",
       " ['air', 'space'],\n",
       " ['alarm*', 'affect'],\n",
       " ['alarm*', 'negemo'],\n",
       " ['alarm*', 'anx'],\n",
       " ['alcohol*', 'bio'],\n",
       " ['alcohol*', 'health'],\n",
       " ['alcohol*', 'ingest'],\n",
       " ['alive', 'bio'],\n",
       " ['alive', 'health'],\n",
       " ['alive', 'death'],\n",
       " ['all', 'funct'],\n",
       " ['all', 'quant'],\n",
       " ['all', 'cogmech'],\n",
       " ['all', 'certain'],\n",
       " ['alla', 'relig'],\n",
       " ['allah*', 'relig'],\n",
       " ['allerg*', 'bio'],\n",
       " ['allerg*', 'health'],\n",
       " ['allot', 'funct'],\n",
       " ['allot', 'quant'],\n",
       " ['allot', 'cogmech'],\n",
       " ['allot', 'tentat'],\n",
       " ['allow*', 'cogmech'],\n",
       " ['allow*', 'cause'],\n",
       " ['almost', 'cogmech'],\n",
       " ['almost', 'tentat'],\n",
       " ['alone', 'affect'],\n",
       " ['alone', 'negemo'],\n",
       " ['alone', 'sad'],\n",
       " ['along', 'funct'],\n",
       " ['along', 'preps'],\n",
       " ['along', 'cogmech'],\n",
       " ['along', 'incl'],\n",
       " ['alot', 'funct'],\n",
       " ['alot', 'article'],\n",
       " ['alot', 'quant'],\n",
       " ['alot', 'cogmech'],\n",
       " ['alot', 'tentat'],\n",
       " ['already', 'time'],\n",
       " ['already', 'relativ'],\n",
       " ['alright*', 'affect'],\n",
       " ['alright*', 'posemo'],\n",
       " ['alright*', 'assent'],\n",
       " ['also', 'funct'],\n",
       " ['also', 'adverb'],\n",
       " ['also', 'conj'],\n",
       " ['altar*', 'relig'],\n",
       " ['although', 'funct'],\n",
       " ['although', 'conj'],\n",
       " ['altogether', 'cogmech'],\n",
       " ['altogether', 'certain'],\n",
       " ['always', 'cogmech'],\n",
       " ['always', 'certain'],\n",
       " ['always', 'time'],\n",
       " ['always', 'relativ'],\n",
       " ['am', 'verb'],\n",
       " ['am', 'funct'],\n",
       " ['am', 'auxverb'],\n",
       " ['am', 'present'],\n",
       " ['amaz*', 'affect'],\n",
       " ['amaz*', 'posemo'],\n",
       " ['ambigu*', 'cogmech'],\n",
       " ['ambigu*', 'tentat'],\n",
       " ['ambiti*', 'work'],\n",
       " ['ambiti*', 'achieve'],\n",
       " ['amen', 'relig'],\n",
       " ['amigo*', 'social'],\n",
       " ['amigo*', 'friend'],\n",
       " ['amish', 'relig'],\n",
       " ['among*', 'funct'],\n",
       " ['among*', 'preps'],\n",
       " ['among*', 'space'],\n",
       " ['among*', 'relativ'],\n",
       " ['amor*', 'affect'],\n",
       " ['amor*', 'posemo'],\n",
       " ['amount*', 'quant'],\n",
       " ['amput*', 'bio'],\n",
       " ['amput*', 'health'],\n",
       " ['amus*', 'affect'],\n",
       " ['amus*', 'posemo'],\n",
       " ['amus*', 'leisure'],\n",
       " ['an', 'funct'],\n",
       " ['an', 'article'],\n",
       " ['anal', 'cogmech'],\n",
       " ['anal', 'inhib'],\n",
       " ['anal', 'bio'],\n",
       " ['anal', 'body'],\n",
       " ['analy*', 'cogmech'],\n",
       " ['analy*', 'insight'],\n",
       " ['ancient*', 'time'],\n",
       " ['ancient*', 'relativ'],\n",
       " ['and', 'funct'],\n",
       " ['and', 'conj'],\n",
       " ['and', 'cogmech'],\n",
       " ['and', 'incl'],\n",
       " ['angel', 'relig'],\n",
       " ['angelic*', 'relig'],\n",
       " ['angels', 'relig'],\n",
       " ['anger*', 'affect'],\n",
       " ['anger*', 'negemo'],\n",
       " ['anger*', 'anger'],\n",
       " ['angr*', 'affect'],\n",
       " ['angr*', 'negemo'],\n",
       " ['angr*', 'anger'],\n",
       " ['anguish*', 'affect'],\n",
       " ['anguish*', 'negemo'],\n",
       " ['anguish*', 'anx'],\n",
       " ['ankle*', 'bio'],\n",
       " ['ankle*', 'body'],\n",
       " ['annoy*', 'affect'],\n",
       " ['annoy*', 'negemo'],\n",
       " ['annoy*', 'anger'],\n",
       " ['annual*', 'time'],\n",
       " ['annual*', 'relativ'],\n",
       " ['anorexi*', 'bio'],\n",
       " ['anorexi*', 'health'],\n",
       " ['anorexi*', 'ingest'],\n",
       " ['another', 'funct'],\n",
       " ['another', 'quant'],\n",
       " ['answer*', 'cogmech'],\n",
       " ['answer*', 'insight'],\n",
       " ['antacid*', 'bio'],\n",
       " ['antacid*', 'health'],\n",
       " ['antagoni*', 'affect'],\n",
       " ['antagoni*', 'negemo'],\n",
       " ['antagoni*', 'anger'],\n",
       " ['antidepressant*', 'bio'],\n",
       " ['antidepressant*', 'health'],\n",
       " ['anus*', 'bio'],\n",
       " ['anus*', 'body'],\n",
       " ['anxi*', 'affect'],\n",
       " ['anxi*', 'negemo'],\n",
       " ['anxi*', 'anx'],\n",
       " ['any', 'funct'],\n",
       " ['any', 'quant'],\n",
       " ['any', 'cogmech'],\n",
       " ['any', 'tentat'],\n",
       " ['anybod*', 'funct'],\n",
       " ['anybod*', 'pronoun'],\n",
       " ['anybod*', 'ipron'],\n",
       " ['anybod*', 'social'],\n",
       " ['anybod*', 'cogmech'],\n",
       " ['anybod*', 'tentat'],\n",
       " ['anyhow', 'cogmech'],\n",
       " ['anyhow', 'tentat'],\n",
       " ['anymore', 'funct'],\n",
       " ['anymore', 'quant'],\n",
       " ['anymore', 'relativ'],\n",
       " ['anymore', 'time'],\n",
       " ['anyone*', 'funct'],\n",
       " ['anyone*', 'pronoun'],\n",
       " ['anyone*', 'ipron'],\n",
       " ['anyone*', 'social'],\n",
       " ['anyone*', 'cogmech'],\n",
       " ['anyone*', 'tentat'],\n",
       " ['anything', 'funct'],\n",
       " ['anything', 'pronoun'],\n",
       " ['anything', 'ipron'],\n",
       " ['anything', 'cogmech'],\n",
       " ['anything', 'tentat'],\n",
       " ['anytime', 'cogmech'],\n",
       " ['anytime', 'tentat'],\n",
       " ['anytime', 'time'],\n",
       " ['anytime', 'relativ'],\n",
       " ['anyway*', 'funct'],\n",
       " ['anyway*', 'adverb'],\n",
       " ['anywhere', 'funct'],\n",
       " ['anywhere', 'adverb'],\n",
       " ['anywhere', 'cogmech'],\n",
       " ['anywhere', 'tentat'],\n",
       " ['anywhere', 'space'],\n",
       " ['anywhere', 'relativ'],\n",
       " ['aok', 'affect'],\n",
       " ['aok', 'posemo'],\n",
       " ['aok', 'assent'],\n",
       " ['apart', 'space'],\n",
       " ['apart', 'relativ'],\n",
       " ['apartment*', 'leisure'],\n",
       " ['apartment*', 'home'],\n",
       " ['apath*', 'affect'],\n",
       " ['apath*', 'negemo'],\n",
       " ['apolog*', 'social'],\n",
       " ['appall*', 'affect'],\n",
       " ['appall*', 'negemo'],\n",
       " ['apparent', 'cogmech'],\n",
       " ['apparent', 'certain'],\n",
       " ['apparently', 'funct'],\n",
       " ['apparently', 'adverb'],\n",
       " ['apparently', 'cogmech'],\n",
       " ['apparently', 'tentat'],\n",
       " ['appear', 'verb'],\n",
       " ['appear', 'present'],\n",
       " ['appear', 'cogmech'],\n",
       " ['appear', 'tentat'],\n",
       " ['appear', 'motion'],\n",
       " ['appear', 'relativ'],\n",
       " ['appeared', 'verb'],\n",
       " ['appeared', 'past'],\n",
       " ['appeared', 'cogmech'],\n",
       " ['appeared', 'tentat'],\n",
       " ['appeared', 'motion'],\n",
       " ['appeared', 'relativ'],\n",
       " ['appearing', 'cogmech'],\n",
       " ['appearing', 'tentat'],\n",
       " ['appearing', 'motion'],\n",
       " ['appearing', 'relativ'],\n",
       " ['appears', 'verb'],\n",
       " ['appears', 'present'],\n",
       " ['appears', 'cogmech'],\n",
       " ['appears', 'tentat'],\n",
       " ['appears', 'motion'],\n",
       " ['appears', 'relativ'],\n",
       " ['appendic*', 'bio'],\n",
       " ['appendic*', 'health'],\n",
       " ['appendix', 'bio'],\n",
       " ['appendix', 'body'],\n",
       " ['appeti*', 'bio'],\n",
       " ['appeti*', 'ingest'],\n",
       " ['applicant*', 'work'],\n",
       " ['applicat*', 'work'],\n",
       " ['appreciat*', 'affect'],\n",
       " ['appreciat*', 'posemo'],\n",
       " ['appreciat*', 'cogmech'],\n",
       " ['appreciat*', 'insight'],\n",
       " ['apprehens*', 'affect'],\n",
       " ['apprehens*', 'negemo'],\n",
       " ['apprehens*', 'anx'],\n",
       " ['apprentic*', 'work'],\n",
       " ['approach*', 'motion'],\n",
       " ['approach*', 'relativ'],\n",
       " ['approv*', 'achieve'],\n",
       " ['approximat*', 'cogmech'],\n",
       " ['approximat*', 'tentat'],\n",
       " ['april', 'time'],\n",
       " ['april', 'relativ'],\n",
       " ['arbitrar*', 'cogmech'],\n",
       " ['arbitrar*', 'tentat'],\n",
       " ['arch', 'bio'],\n",
       " ['arch', 'body'],\n",
       " ['are', 'verb'],\n",
       " ['are', 'funct'],\n",
       " ['are', 'auxverb'],\n",
       " ['are', 'present'],\n",
       " ['area*', 'space'],\n",
       " ['area*', 'relativ'],\n",
       " [\"aren't\", 'verb'],\n",
       " [\"aren't\", 'funct'],\n",
       " [\"aren't\", 'auxverb'],\n",
       " [\"aren't\", 'present'],\n",
       " [\"aren't\", 'negate'],\n",
       " ['arent', 'verb'],\n",
       " ['arent', 'funct'],\n",
       " ['arent', 'auxverb'],\n",
       " ['arent', 'present'],\n",
       " ['arent', 'negate'],\n",
       " ['argh*', 'affect'],\n",
       " ['argh*', 'negemo'],\n",
       " ['argh*', 'anger'],\n",
       " ['argu*', 'social'],\n",
       " ['argu*', 'affect'],\n",
       " ['argu*', 'negemo'],\n",
       " ['argu*', 'anger'],\n",
       " ['arm', 'bio'],\n",
       " ['arm', 'body'],\n",
       " ['armies', 'social'],\n",
       " ['armpit*', 'bio'],\n",
       " ['armpit*', 'body'],\n",
       " ['arms*', 'bio'],\n",
       " ['arms*', 'body'],\n",
       " ['army', 'social'],\n",
       " ['aroma*', 'percept'],\n",
       " ['around', 'funct'],\n",
       " ['around', 'adverb'],\n",
       " ['around', 'preps'],\n",
       " ['around', 'cogmech'],\n",
       " ['around', 'incl'],\n",
       " ['around', 'space'],\n",
       " ['around', 'relativ'],\n",
       " ['arous*', 'bio'],\n",
       " ['arous*', 'body'],\n",
       " ['arous*', 'sexual'],\n",
       " ['arrival*', 'motion'],\n",
       " ['arrival*', 'relativ'],\n",
       " ['arrive', 'verb'],\n",
       " ['arrive', 'present'],\n",
       " ['arrive', 'motion'],\n",
       " ['arrive', 'relativ'],\n",
       " ['arrived', 'verb'],\n",
       " ['arrived', 'past'],\n",
       " ['arrived', 'motion'],\n",
       " ['arrived', 'relativ'],\n",
       " ['arrives', 'verb'],\n",
       " ['arrives', 'present'],\n",
       " ['arrives', 'motion'],\n",
       " ['arrives', 'relativ'],\n",
       " ['arriving', 'motion'],\n",
       " ['arriving', 'relativ'],\n",
       " ['arrogan*', 'affect'],\n",
       " ['arrogan*', 'negemo'],\n",
       " ['arrogan*', 'anger'],\n",
       " ['arse', 'bio'],\n",
       " ['arse', 'body'],\n",
       " ['arse', 'swear'],\n",
       " ['arsehole*', 'swear'],\n",
       " ['arses', 'bio'],\n",
       " ['arses', 'body'],\n",
       " ['arses', 'swear'],\n",
       " ['art', 'leisure'],\n",
       " ['arter*', 'bio'],\n",
       " ['arter*', 'body'],\n",
       " ['arthr*', 'bio'],\n",
       " ['arthr*', 'health'],\n",
       " ['artist*', 'leisure'],\n",
       " ['arts', 'leisure'],\n",
       " ['as', 'funct'],\n",
       " ['as', 'preps'],\n",
       " ['as', 'conj'],\n",
       " ['asham*', 'affect'],\n",
       " ['asham*', 'negemo'],\n",
       " ['asham*', 'anx'],\n",
       " ['ask', 'verb'],\n",
       " ['ask', 'present'],\n",
       " ['ask', 'social'],\n",
       " ['asked', 'verb'],\n",
       " ['asked', 'past'],\n",
       " ['asked', 'social'],\n",
       " ['asking', 'social'],\n",
       " ['asks', 'verb'],\n",
       " ['asks', 'present'],\n",
       " ['asks', 'social'],\n",
       " ['asleep', 'bio'],\n",
       " ['asleep', 'body'],\n",
       " ['aspirin*', 'bio'],\n",
       " ['aspirin*', 'health'],\n",
       " ['ass', 'bio'],\n",
       " ['ass', 'body'],\n",
       " ['ass', 'sexual'],\n",
       " ['ass', 'swear'],\n",
       " ['assault*', 'affect'],\n",
       " ['assault*', 'negemo'],\n",
       " ['assault*', 'anger'],\n",
       " ['assembl*', 'social'],\n",
       " ['asses', 'bio'],\n",
       " ['asses', 'body'],\n",
       " ['asses', 'sexual'],\n",
       " ['asses', 'swear'],\n",
       " ['asshole*', 'affect'],\n",
       " ['asshole*', 'negemo'],\n",
       " ['asshole*', 'anger'],\n",
       " ['asshole*', 'swear'],\n",
       " ['assign*', 'work'],\n",
       " ['assistan*', 'work'],\n",
       " ['associat*', 'work'],\n",
       " ['assum*', 'cogmech'],\n",
       " ['assum*', 'insight'],\n",
       " ['assum*', 'tentat'],\n",
       " ['assur*', 'affect'],\n",
       " ['assur*', 'posemo'],\n",
       " ['assur*', 'cogmech'],\n",
       " ['assur*', 'certain'],\n",
       " ['asthma*', 'bio'],\n",
       " ['asthma*', 'health'],\n",
       " ['at', 'funct'],\n",
       " ['at', 'preps'],\n",
       " ['at', 'space'],\n",
       " ['at', 'relativ'],\n",
       " ['ate', 'verb'],\n",
       " ['ate', 'past'],\n",
       " ['ate', 'bio'],\n",
       " ['ate', 'ingest'],\n",
       " ['athletic*', 'leisure'],\n",
       " ['atho', 'funct'],\n",
       " ['atho', 'conj'],\n",
       " ['atm', 'money'],\n",
       " ['atms', 'money'],\n",
       " ['atop', 'funct'],\n",
       " ['atop', 'preps'],\n",
       " ['atop', 'space'],\n",
       " ['atop', 'relativ'],\n",
       " ['attachment*', 'affect'],\n",
       " ['attachment*', 'posemo'],\n",
       " ['attack*', 'affect'],\n",
       " ['attack*', 'negemo'],\n",
       " ['attack*', 'anger'],\n",
       " ['attain*', 'achieve'],\n",
       " ['attempt*', 'achieve'],\n",
       " ['attend', 'motion'],\n",
       " ['attend', 'relativ'],\n",
       " ['attended', 'motion'],\n",
       " ['attended', 'relativ'],\n",
       " ['attending', 'motion'],\n",
       " ['attending', 'relativ'],\n",
       " ['attends', 'motion'],\n",
       " ['attends', 'relativ'],\n",
       " ['attent*', 'cogmech'],\n",
       " ['attent*', 'insight'],\n",
       " ['attract*', 'affect'],\n",
       " ['attract*', 'posemo'],\n",
       " ['attribut*', 'cogmech'],\n",
       " ['attribut*', 'cause'],\n",
       " ['auction*', 'money'],\n",
       " ['audibl*', 'percept'],\n",
       " ['audibl*', 'hear'],\n",
       " ['audio*', 'percept'],\n",
       " ['audio*', 'hear'],\n",
       " ['audit', 'money'],\n",
       " ['audited', 'money'],\n",
       " ['auditing', 'money'],\n",
       " ['auditor', 'money'],\n",
       " ['auditorium*', 'work'],\n",
       " ['auditors', 'money'],\n",
       " ['audits', 'money'],\n",
       " ['august', 'time'],\n",
       " ['august', 'relativ'],\n",
       " ['aunt*', 'social'],\n",
       " ['aunt*', 'family'],\n",
       " ['authorit*', 'achieve'],\n",
       " ['autops*', 'death'],\n",
       " ['autumn', 'time'],\n",
       " ['autumn', 'relativ'],\n",
       " ['aversi*', 'affect'],\n",
       " ['aversi*', 'negemo'],\n",
       " ['aversi*', 'anx'],\n",
       " ['avert*', 'cogmech'],\n",
       " ['avert*', 'inhib'],\n",
       " ['avoid*', 'affect'],\n",
       " ['avoid*', 'negemo'],\n",
       " ['avoid*', 'anx'],\n",
       " ['avoid*', 'cogmech'],\n",
       " ['avoid*', 'inhib'],\n",
       " ['aw', 'assent'],\n",
       " ['award*', 'affect'],\n",
       " ['award*', 'posemo'],\n",
       " ['award*', 'work'],\n",
       " ['award*', 'achieve'],\n",
       " ['aware*', 'cogmech'],\n",
       " ['aware*', 'insight'],\n",
       " ['away', 'funct'],\n",
       " ['away', 'preps'],\n",
       " ['away', 'space'],\n",
       " ['away', 'relativ'],\n",
       " ['awesome', 'affect'],\n",
       " ['awesome', 'posemo'],\n",
       " ['awesome', 'assent'],\n",
       " ['awful', 'affect'],\n",
       " ['awful', 'negemo'],\n",
       " ['awhile', 'time'],\n",
       " ['awhile', 'relativ'],\n",
       " ['awkward*', 'affect'],\n",
       " ['awkward*', 'negemo'],\n",
       " ['awkward*', 'anx'],\n",
       " ['babe*', 'social'],\n",
       " ['babe*', 'humans'],\n",
       " ['babies', 'social'],\n",
       " ['babies', 'humans'],\n",
       " ['baby*', 'social'],\n",
       " ['baby*', 'humans'],\n",
       " ['back', 'funct'],\n",
       " ['back', 'adverb'],\n",
       " ['back', 'time'],\n",
       " ['back', 'relativ'],\n",
       " ['backward*', 'space'],\n",
       " ['backward*', 'relativ'],\n",
       " ['backyard', 'home'],\n",
       " ['bad', 'affect'],\n",
       " ['bad', 'negemo'],\n",
       " ['bake*', 'bio'],\n",
       " ['bake*', 'ingest'],\n",
       " ['bake*', 'home'],\n",
       " ['baking', 'bio'],\n",
       " ['baking', 'ingest'],\n",
       " ['baking', 'home'],\n",
       " ['balcon*', 'home'],\n",
       " ['bald', 'bio'],\n",
       " ['bald', 'body'],\n",
       " ['ball', 'leisure'],\n",
       " ['ballet*', 'leisure'],\n",
       " ['bambino*', 'social'],\n",
       " ['bambino*', 'humans'],\n",
       " ['ban', 'cogmech'],\n",
       " ['ban', 'inhib'],\n",
       " ['band', 'social'],\n",
       " ['band', 'leisure'],\n",
       " ['bandage*', 'bio'],\n",
       " ['bandage*', 'health'],\n",
       " ['bandaid', 'bio'],\n",
       " ['bandaid', 'health'],\n",
       " ['bands', 'social'],\n",
       " ['bands', 'leisure'],\n",
       " ['bank*', 'money'],\n",
       " ['banned', 'cogmech'],\n",
       " ['banned', 'inhib'],\n",
       " ['banning', 'cogmech'],\n",
       " ['banning', 'inhib'],\n",
       " ['bans', 'cogmech'],\n",
       " ['bans', 'inhib'],\n",
       " ['baptis*', 'relig'],\n",
       " ['baptiz*', 'relig'],\n",
       " ['bar', 'bio'],\n",
       " ['bar', 'ingest'],\n",
       " ['bar', 'leisure'],\n",
       " ['barely', 'cogmech'],\n",
       " ['barely', 'tentat'],\n",
       " ['bargain*', 'money'],\n",
       " ['barrier*', 'cogmech'],\n",
       " ['barrier*', 'inhib'],\n",
       " ['bars', 'bio'],\n",
       " ['bars', 'ingest'],\n",
       " ['bars', 'leisure'],\n",
       " ['baseball*', 'leisure'],\n",
       " ['based', 'cogmech'],\n",
       " ['based', 'cause'],\n",
       " ['bases', 'cogmech'],\n",
       " ['bases', 'cause'],\n",
       " ['bashful*', 'affect'],\n",
       " ['bashful*', 'negemo'],\n",
       " ['basically', 'funct'],\n",
       " ['basically', 'adverb'],\n",
       " ['basis', 'cogmech'],\n",
       " ['basis', 'cause'],\n",
       " ['basketball*', 'leisure'],\n",
       " ['bastard*', 'affect'],\n",
       " ['bastard*', 'negemo'],\n",
       " ['bastard*', 'anger'],\n",
       " ['bastard*', 'swear'],\n",
       " ['bath*', 'leisure'],\n",
       " ['bath*', 'home'],\n",
       " ['battl*', 'affect'],\n",
       " ['battl*', 'negemo'],\n",
       " ['battl*', 'anger'],\n",
       " ['be', 'verb'],\n",
       " ['be', 'funct'],\n",
       " ['be', 'auxverb'],\n",
       " ['beach*', 'leisure'],\n",
       " ['beat', 'achieve'],\n",
       " ['beaten', 'affect'],\n",
       " ['beaten', 'negemo'],\n",
       " ['beaten', 'anger'],\n",
       " ['beaten', 'work'],\n",
       " ['beaten', 'achieve'],\n",
       " ['beaut*', 'affect'],\n",
       " ['beaut*', 'posemo'],\n",
       " ['beaut*', 'percept'],\n",
       " ['beaut*', 'see'],\n",
       " ['became', 'verb'],\n",
       " ['became', 'funct'],\n",
       " ['became', 'auxverb'],\n",
       " ['became', 'past'],\n",
       " ['became', 'cogmech'],\n",
       " ['became', 'insight'],\n",
       " ['because', 'funct'],\n",
       " ['because', 'conj'],\n",
       " ['because', 'cogmech'],\n",
       " ['because', 'cause'],\n",
       " ['become', 'verb'],\n",
       " ['become', 'funct'],\n",
       " ['become', 'auxverb'],\n",
       " ['become', 'present'],\n",
       " ['become', 'cogmech'],\n",
       " ['become', 'insight'],\n",
       " ['becomes', 'verb'],\n",
       " ['becomes', 'funct'],\n",
       " ['becomes', 'auxverb'],\n",
       " ['becomes', 'present'],\n",
       " ['becomes', 'cogmech'],\n",
       " ['becomes', 'insight'],\n",
       " ['becoming', 'verb'],\n",
       " ['becoming', 'funct'],\n",
       " ['becoming', 'auxverb'],\n",
       " ['becoming', 'cogmech'],\n",
       " ['becoming', 'insight'],\n",
       " ['bed', 'home'],\n",
       " ['bedding', 'home'],\n",
       " ['bedroom*', 'home'],\n",
       " ['beds', 'home'],\n",
       " ['been', 'verb'],\n",
       " ['been', 'funct'],\n",
       " ['been', 'auxverb'],\n",
       " ['been', 'past'],\n",
       " ['beer*', 'bio'],\n",
       " ['beer*', 'ingest'],\n",
       " ['beer*', 'leisure'],\n",
       " ['before', 'funct'],\n",
       " ['before', 'preps'],\n",
       " ['before', 'time'],\n",
       " ['before', 'relativ'],\n",
       " ['began', 'verb'],\n",
       " ['began', 'past'],\n",
       " ['began', 'time'],\n",
       " ['began', 'relativ'],\n",
       " ['beggar*', 'money'],\n",
       " ['begging', 'money'],\n",
       " ['begin', 'verb'],\n",
       " ['begin', 'present'],\n",
       " ['begin', 'time'],\n",
       " ['begin', 'relativ'],\n",
       " ['beginn*', 'time'],\n",
       " ['beginn*', 'relativ'],\n",
       " ['begins', 'verb'],\n",
       " ['begins', 'present'],\n",
       " ['begins', 'time'],\n",
       " ['begins', 'relativ'],\n",
       " ['begun', 'time'],\n",
       " ['begun', 'relativ'],\n",
       " ['behavio*', 'relativ'],\n",
       " ['behavio*', 'motion'],\n",
       " ['behind', 'funct'],\n",
       " ['behind', 'preps'],\n",
       " ['being', 'verb'],\n",
       " ['being', 'funct'],\n",
       " ['being', 'auxverb'],\n",
       " ['belief*', 'cogmech'],\n",
       " ['belief*', 'insight'],\n",
       " ['belief*', 'relig'],\n",
       " ['believe', 'verb'],\n",
       " ['believe', 'present'],\n",
       " ['believe', 'cogmech'],\n",
       " ['believe', 'insight'],\n",
       " ['believed', 'verb'],\n",
       " ['believed', 'past'],\n",
       " ['believed', 'cogmech'],\n",
       " ['believed', 'insight'],\n",
       " ['believes', 'verb'],\n",
       " ['believes', 'present'],\n",
       " ['believes', 'cogmech'],\n",
       " ['believes', 'insight'],\n",
       " ['believing', 'cogmech'],\n",
       " ['believing', 'insight'],\n",
       " ['bellies', 'bio'],\n",
       " ['bellies', 'body'],\n",
       " ['belly', 'bio'],\n",
       " ['belly', 'body'],\n",
       " ['beloved', 'affect'],\n",
       " ['beloved', 'posemo'],\n",
       " ['below', 'funct'],\n",
       " ['below', 'preps'],\n",
       " ['below', 'space'],\n",
       " ['below', 'relativ'],\n",
       " ['bend', 'space'],\n",
       " ['bend', 'relativ'],\n",
       " ['bending', 'space'],\n",
       " ['bending', 'relativ'],\n",
       " ['bends', 'space'],\n",
       " ['bends', 'relativ'],\n",
       " ['beneath', 'funct'],\n",
       " ['beneath', 'preps'],\n",
       " ['beneath', 'space'],\n",
       " ['beneath', 'relativ'],\n",
       " ['benefic*', 'affect'],\n",
       " ['benefic*', 'posemo'],\n",
       " ['benefit', 'affect'],\n",
       " ['benefit', 'posemo'],\n",
       " ['benefits', 'affect'],\n",
       " ['benefits', 'posemo'],\n",
       " ['benefits', 'work'],\n",
       " ['benefitt*', 'affect'],\n",
       " ['benefitt*', 'posemo'],\n",
       " ['benevolen*', 'affect'],\n",
       " ['benevolen*', 'posemo'],\n",
       " ['benign*', 'affect'],\n",
       " ['benign*', 'posemo'],\n",
       " ['bent', 'space'],\n",
       " ['bent', 'relativ'],\n",
       " ['bereave*', 'death'],\n",
       " ['beside', 'funct'],\n",
       " ['beside', 'preps'],\n",
       " ['beside', 'space'],\n",
       " ['beside', 'relativ'],\n",
       " ['besides', 'funct'],\n",
       " ['besides', 'preps'],\n",
       " ['besides', 'quant'],\n",
       " ['besides', 'cogmech'],\n",
       " ['besides', 'discrep'],\n",
       " ['best', 'affect'],\n",
       " ['best', 'posemo'],\n",
       " ['best', 'achieve'],\n",
       " ['best', 'funct'],\n",
       " ['best', 'quant'],\n",
       " ['bet', 'cogmech'],\n",
       " ['bet', 'tentat'],\n",
       " ['bet', 'money'],\n",
       " ['bets', 'cogmech'],\n",
       " ['bets', 'tentat'],\n",
       " ['bets', 'money'],\n",
       " ['better', 'affect'],\n",
       " ['better', 'posemo'],\n",
       " ['better', 'achieve'],\n",
       " ['betting', 'cogmech'],\n",
       " ['betting', 'tentat'],\n",
       " ['betting', 'money'],\n",
       " ['between', 'funct'],\n",
       " ['between', 'preps'],\n",
       " ['beyond', 'funct'],\n",
       " ['beyond', 'adverb'],\n",
       " ['beyond', 'preps'],\n",
       " ['beyond', 'space'],\n",
       " ['beyond', 'relativ'],\n",
       " ['bf*', 'social'],\n",
       " ['bf*', 'friend'],\n",
       " ['bi', 'bio'],\n",
       " ['bi', 'sexual'],\n",
       " ['biannu*', 'time'],\n",
       " ['biannu*', 'relativ'],\n",
       " ['bible*', 'relig'],\n",
       " ['biblic*', 'relig'],\n",
       " ['bicep*', 'bio'],\n",
       " ['bicep*', 'body'],\n",
       " ['bicyc*', 'leisure'],\n",
       " ['big', 'space'],\n",
       " ['big', 'relativ'],\n",
       " ['bigger', 'space'],\n",
       " ['bigger', 'relativ'],\n",
       " ['biggest', 'space'],\n",
       " ['biggest', 'relativ'],\n",
       " ['bike*', 'leisure'],\n",
       " ['bill', 'money'],\n",
       " ['billed', 'money'],\n",
       " ['billing*', 'money'],\n",
       " ['billion*', 'funct'],\n",
       " ['billion*', 'number'],\n",
       " ['bills', 'money'],\n",
       " ['bimonth*', 'time'],\n",
       " ['bimonth*', 'relativ'],\n",
       " ['binding', 'cogmech'],\n",
       " ['binding', 'inhib'],\n",
       " ['binge*', 'bio'],\n",
       " ['binge*', 'health'],\n",
       " ['binge*', 'ingest'],\n",
       " ['binging', 'bio'],\n",
       " ['binging', 'health'],\n",
       " ['binging', 'ingest'],\n",
       " ['biolog*', 'work'],\n",
       " ['bipolar', 'bio'],\n",
       " ['bipolar', 'health'],\n",
       " ['birdie*', 'leisure'],\n",
       " ['birth*', 'time'],\n",
       " ...]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "liwc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "liwc_dict = {}\n",
    "for (w, c) in liwc:\n",
    "    if c not in liwc_dict:\n",
    "        liwc_dict[c] = []\n",
    "    liwc_dict[c].append(w)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['anybod*',\n",
       " 'anyone*',\n",
       " 'anything',\n",
       " 'everybod*',\n",
       " 'everyone*',\n",
       " 'everything*',\n",
       " 'he',\n",
       " \"he'd\",\n",
       " \"he's\",\n",
       " 'hed',\n",
       " 'her',\n",
       " 'hers',\n",
       " 'herself',\n",
       " 'hes',\n",
       " 'him',\n",
       " 'himself',\n",
       " 'his',\n",
       " 'i',\n",
       " \"i'd\",\n",
       " \"i'll\",\n",
       " \"i'm\",\n",
       " \"i've\",\n",
       " 'id',\n",
       " 'im',\n",
       " 'it',\n",
       " \"it'd\",\n",
       " \"it'll\",\n",
       " \"it's\",\n",
       " 'itd',\n",
       " 'itll',\n",
       " 'its',\n",
       " 'itself',\n",
       " 'ive',\n",
       " \"let's\",\n",
       " 'lets',\n",
       " 'me',\n",
       " 'mine',\n",
       " 'my',\n",
       " 'myself',\n",
       " 'nobod*',\n",
       " 'oneself',\n",
       " 'other',\n",
       " 'others',\n",
       " 'our',\n",
       " 'ours',\n",
       " 'ourselves',\n",
       " 'she',\n",
       " \"she'd\",\n",
       " \"she'll\",\n",
       " \"she's\",\n",
       " 'shes',\n",
       " 'somebod*',\n",
       " 'someone*',\n",
       " 'something*',\n",
       " 'somewhere',\n",
       " 'stuff',\n",
       " 'that',\n",
       " \"that'd\",\n",
       " \"that'll\",\n",
       " \"that's\",\n",
       " 'thatd',\n",
       " 'thatll',\n",
       " 'thats',\n",
       " 'thee',\n",
       " 'their*',\n",
       " 'them',\n",
       " 'themselves',\n",
       " 'these',\n",
       " 'they',\n",
       " \"they'd\",\n",
       " \"they'll\",\n",
       " \"they've\",\n",
       " 'theyd',\n",
       " 'theyll',\n",
       " 'theyve',\n",
       " 'thine',\n",
       " 'thing*',\n",
       " 'this',\n",
       " 'those',\n",
       " 'thou',\n",
       " 'thoust',\n",
       " 'thy',\n",
       " 'us',\n",
       " 'we',\n",
       " \"we'd\",\n",
       " \"we'll\",\n",
       " \"we're\",\n",
       " \"we've\",\n",
       " 'weve',\n",
       " 'what',\n",
       " \"what's\",\n",
       " 'whatever',\n",
       " 'whats',\n",
       " 'which',\n",
       " 'whichever',\n",
       " 'who',\n",
       " \"who'd\",\n",
       " \"who'll\",\n",
       " 'whod',\n",
       " 'wholl',\n",
       " 'whom',\n",
       " 'whose',\n",
       " \"y'all\",\n",
       " 'ya',\n",
       " 'yall',\n",
       " 'ye',\n",
       " 'you',\n",
       " \"you'd\",\n",
       " \"you'll\",\n",
       " \"you're\",\n",
       " \"you've\",\n",
       " 'youd',\n",
       " 'youll',\n",
       " 'your',\n",
       " 'youre',\n",
       " 'yours',\n",
       " 'youve']"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "liwc_dict['pronoun']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_liwc_categories(tokens, category_words, relative=True):\n",
    "    category_cnt = 0\n",
    "    if not tokens:\n",
    "        return None\n",
    "    text_len = len(tokens)\n",
    "    for t in tokens:\n",
    "        for word in category_words:\n",
    "            if t==word or (word[-1]=='*' and t.startswith(word[:-1])) \\\n",
    "            or (t==word.split(\"'\")[0]):\n",
    "                category_cnt += 1\n",
    "                break # one token cannot belong to more than one word in the category\n",
    "    if relative:\n",
    "        return category_cnt/text_len\n",
    "    else:\n",
    "        return category_cnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing for category pronoun...\n",
      "CPU times: user 1min 13s, sys: 37.9 ms, total: 1min 13s\n",
      "Wall time: 1min 33s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from functools import partial\n",
    "# for categ in ['negemo', 'posemo', 'affect', 'sad', 'anx', 'pronoun']:#liwc_dict.keys():\n",
    "for categ in liwc_dict.keys():\n",
    "    if categ in writings_df.columns:\n",
    "        continue\n",
    "    print(\"Encoding for category %s...\" % categ)\n",
    "    writings_df[categ] = writings_df['all_tokens'].apply(partial(encode_liwc_categories, \n",
    "                                                                   category_words=liwc_dict[categ], \n",
    "                                                                   relative=True))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>negemo</th>\n",
       "      <th>posemo</th>\n",
       "      <th>affect</th>\n",
       "      <th>sad</th>\n",
       "      <th>anx</th>\n",
       "      <th>pronoun</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>label</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.110183</td>\n",
       "      <td>0.036761</td>\n",
       "      <td>0.079594</td>\n",
       "      <td>0.165661</td>\n",
       "      <td>0.253118</td>\n",
       "      <td>0.404901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>negemo</th>\n",
       "      <td>0.110183</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.169785</td>\n",
       "      <td>0.212622</td>\n",
       "      <td>0.415533</td>\n",
       "      <td>0.402437</td>\n",
       "      <td>0.143275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>posemo</th>\n",
       "      <td>0.036761</td>\n",
       "      <td>-0.169785</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.926702</td>\n",
       "      <td>-0.115436</td>\n",
       "      <td>-0.075223</td>\n",
       "      <td>0.239505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>affect</th>\n",
       "      <td>0.079594</td>\n",
       "      <td>0.212622</td>\n",
       "      <td>0.926702</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.043988</td>\n",
       "      <td>0.079093</td>\n",
       "      <td>0.292047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sad</th>\n",
       "      <td>0.165661</td>\n",
       "      <td>0.415533</td>\n",
       "      <td>-0.115436</td>\n",
       "      <td>0.043988</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.117133</td>\n",
       "      <td>0.104218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>anx</th>\n",
       "      <td>0.253118</td>\n",
       "      <td>0.402437</td>\n",
       "      <td>-0.075223</td>\n",
       "      <td>0.079093</td>\n",
       "      <td>0.117133</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.156770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pronoun</th>\n",
       "      <td>0.404901</td>\n",
       "      <td>0.143275</td>\n",
       "      <td>0.239505</td>\n",
       "      <td>0.292047</td>\n",
       "      <td>0.104218</td>\n",
       "      <td>0.156770</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            label    negemo    posemo    affect       sad       anx   pronoun\n",
       "label    1.000000  0.110183  0.036761  0.079594  0.165661  0.253118  0.404901\n",
       "negemo   0.110183  1.000000 -0.169785  0.212622  0.415533  0.402437  0.143275\n",
       "posemo   0.036761 -0.169785  1.000000  0.926702 -0.115436 -0.075223  0.239505\n",
       "affect   0.079594  0.212622  0.926702  1.000000  0.043988  0.079093  0.292047\n",
       "sad      0.165661  0.415533 -0.115436  0.043988  1.000000  0.117133  0.104218\n",
       "anx      0.253118  0.402437 -0.075223  0.079093  0.117133  1.000000  0.156770\n",
       "pronoun  0.404901  0.143275  0.239505  0.292047  0.104218  0.156770  1.000000"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "writings_df.groupby('subject').mean()[['label', 'negemo', 'posemo', 'affect', 'sad', 'anx', 'pronoun']].corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>negemo</th>\n",
       "      <th>posemo</th>\n",
       "      <th>affect</th>\n",
       "      <th>sad</th>\n",
       "      <th>anx</th>\n",
       "      <th>pronoun</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>label</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.023493</td>\n",
       "      <td>0.050800</td>\n",
       "      <td>0.074548</td>\n",
       "      <td>0.003242</td>\n",
       "      <td>0.002606</td>\n",
       "      <td>0.120154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.026116</td>\n",
       "      <td>0.056145</td>\n",
       "      <td>0.082611</td>\n",
       "      <td>0.003706</td>\n",
       "      <td>0.003591</td>\n",
       "      <td>0.162310</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         negemo    posemo    affect       sad       anx   pronoun\n",
       "label                                                            \n",
       "0      0.023493  0.050800  0.074548  0.003242  0.002606  0.120154\n",
       "1      0.026116  0.056145  0.082611  0.003706  0.003591  0.162310"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "writings_df[['label', 'negemo', 'posemo', 'affect', 'sad', 'anx', 'pronoun']].groupby('label').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "writings_df.groupby('subject').mean()[['label'] + categories].corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "COMET INFO: COMET_OPTIMIZER_ID=601f1ca093c34e76a0e73da1541d65c0\n",
      "COMET INFO: Using optimizer config: {'algorithm': 'random', 'configSpaceSize': 180000000000000, 'endTime': None, 'id': '601f1ca093c34e76a0e73da1541d65c0', 'lastUpdateTime': None, 'maxCombo': 0, 'name': '601f1ca093c34e76a0e73da1541d65c0', 'parameters': {'batch_size': {'max': 512, 'min': 10, 'scalingType': 'loguniform', 'type': 'integer'}, 'decay': {'max': 0.5, 'min': 1e-08, 'scalingType': 'loguniform', 'type': 'float'}, 'dense_bow_units': {'max': 50, 'min': 1, 'scalingType': 'uniform', 'type': 'integer'}, 'dropout': {'max': 0.7, 'min': 0, 'scalingType': 'uniform', 'type': 'float'}, 'freeze_patience': {'max': 151, 'min': 2, 'scalingType': 'uniform', 'type': 'integer'}, 'ignore_layers_values': {'type': 'categorical', 'values': ['attention', 'batchnorm', '']}, 'l2_dense': {'max': 0.05, 'min': 1e-07, 'scalingType': 'loguniform', 'type': 'float'}, 'l2_embeddings': {'max': 0.05, 'min': 1e-07, 'scalingType': 'loguniform', 'type': 'float'}, 'lr': {'max': 0.5, 'min': 1e-05, 'scalingType': 'loguniform', 'type': 'float'}, 'lr_reduce_factor': {'max': 0.8, 'min': 0.0001, 'scalingType': 'uniform', 'type': 'float'}, 'lr_reduce_patience': {'max': 151, 'min': 2, 'scalingType': 'uniform', 'type': 'integer'}, 'lstm_units': {'max': 1000, 'min': 10, 'scalingType': 'uniform', 'type': 'integer'}, 'norm_momentum': {'max': 0.99, 'min': 0.01, 'scalingType': 'uniform', 'type': 'float'}, 'optimizer': {'type': 'categorical', 'values': ['adam', 'adagrad', '']}, 'positive_class_weight': {'max': 25, 'min': 1, 'scalingType': 'uniform', 'type': 'integer'}, 'trainable_embeddings': {'type': 'discrete', 'values': [True, False]}}, 'predictor': None, 'spec': {'gridSize': 10, 'maxCombo': 0, 'metric': 'loss', 'minSampleSize': 100, 'objective': 'minimize', 'retryAssignLimit': 0, 'retryLimit': 20, 'seed': 824904589}, 'startTime': 17285931878, 'state': {'sequence_i': 0, 'sequence_pid': None, 'sequence_retry': 0}, 'status': 'running', 'suggestion_count': 0, 'trials': 1, 'version': '1.0.24'}\n",
      "COMET INFO: Optimizer metrics is 'loss' but no logged values found. Experiment ignored in sweep.\n",
      "COMET INFO: ----------------------------\n",
      "COMET INFO: Comet.ml Experiment Summary:\n",
      "COMET INFO:   Data:\n",
      "COMET INFO:     url: https://www.comet.ml/ananana/mental/1a7dd97e978244b2bed47a17fd91b537\n",
      "COMET INFO:   Metrics [count] (min, max):\n",
      "COMET INFO:     sys.cpu.percent.01 [13] : (7.8, 26.6)\n",
      "COMET INFO:     sys.cpu.percent.02 [13] : (8.2, 26.9)\n",
      "COMET INFO:     sys.cpu.percent.03 [13] : (7.4, 26.8)\n",
      "COMET INFO:     sys.cpu.percent.04 [13] : (8.0, 28.0)\n",
      "COMET INFO:     sys.cpu.percent.avg [13]: (7.85, 27.075)\n",
      "COMET INFO:     sys.gpu.0.total_memory  : (1073414144.0, 1073414144.0)\n",
      "COMET INFO:     sys.load.avg [13]       : (0.35, 2.61)\n",
      "COMET INFO:     sys.ram.total [13]      : (8277331968.0, 8277331968.0)\n",
      "COMET INFO:     sys.ram.used [13]       : (6447763456.0, 6758252544.0)\n",
      "COMET INFO:   Other [count]:\n",
      "COMET INFO:     optimizer_count       : 1\n",
      "COMET INFO:     optimizer_id          : 3e265955d9364023a28ba40b217993a4\n",
      "COMET INFO:     optimizer_metric      : loss\n",
      "COMET INFO:     optimizer_metric_value: None\n",
      "COMET INFO:     optimizer_parameters  : {'batch_size': 132, 'decay': 0.0015960419035962298, 'dense_bow_units': 2, 'dropout': 0.5749248404010519, 'freeze_patience': 3, 'l2_dense': 3.336783578570176e-05, 'lr': 1.425102296324654e-05, 'lr_reduce_factor': 0.03766006984624381, 'lr_reduce_patience': 130, 'lstm_units': 33, 'optimizer': 'adagrad', 'positive_class_weight': 18, 'trainable_embeddings': False}\n",
      "COMET INFO:     optimizer_pid         : 8324ac67a06eb1bddffe9ead0b5c4e9dfadc7f02\n",
      "COMET INFO:     optimizer_process     : 14959\n",
      "COMET INFO:     optimizer_trial       : 1\n",
      "COMET INFO:     optimizer_version     : 1.0.24\n",
      "COMET INFO:   Uploads:\n",
      "COMET INFO:     git-patch: 1\n",
      "COMET INFO: ----------------------------\n",
      "COMET INFO: old comet version (3.0.2) detected. current: 3.1.0 please update your comet lib with command: `pip install --no-cache-dir --upgrade comet_ml`\n",
      "COMET INFO: Experiment is live on comet.ml https://www.comet.ml/ananana/mental/6ec613b1fc8a49b0b6faa084ab884b32\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 166 samples, validate on 103 samples\n",
      "Epoch 1/150\n"
     ]
    }
   ],
   "source": [
    "# Declare your hyperparameters search:\n",
    "tune_epochs=150\n",
    "config = {\n",
    "      \"algorithm\": \"random\",\n",
    "      \"parameters\": {\n",
    "          \"lstm_units\": {\"type\": \"integer\", \"min\": 10, \"max\": 1000},\n",
    "          \"dense_bow_units\": {\"type\": \"integer\", \"min\": 1, \"max\": 50},\n",
    "          \"lr\": {\"type\": \"float\", \"min\": 0.00001, \"max\": 0.5, \"scalingType\": \"loguniform\"},\n",
    "          \"l2_dense\": {\"type\": \"float\", \"min\": 0.0000001, \"max\": 0.05, \"scalingType\": \"loguniform\"},\n",
    "          \"l2_embeddings\": {\"type\": \"float\", \"min\": 0.0000001, \"max\": 0.05, \"scalingType\": \"loguniform\"},\n",
    "          \"dropout\": {\"type\": \"float\", \"min\": 0, \"max\": 0.7, \"scalingType\": \"uniform\"},\n",
    "          \"norm_momentum\": {\"type\": \"float\", \"min\": 0.01, \"max\": 0.99, \"scalingType\": \"uniform\"},\n",
    "          \"optimizer\": {\"type\": \"categorical\", \"values\": [\"adam\", \"adagrad\", \"\"]},\n",
    "          \"batch_size\": {\"type\": \"integer\", \"min\": 10, \"max\": 512, \"scalingType\": \"loguniform\"},\n",
    "          \"positive_class_weight\": {\"type\": \"integer\", \"min\": 1, \"max\": 25},\n",
    "          \"trainable_embeddings\": {\"type\": \"discrete\", \"values\": [True, False]},\n",
    "          \"freeze_patience\": {\"type\": \"integer\", \"min\": 2, \"max\": tune_epochs+1},\n",
    "          \"lr_reduce_factor\": {\"type\": \"float\", \"min\": 0.0001, \"max\": 0.8},\n",
    "          \"lr_reduce_patience\": {\"type\": \"integer\", \"min\": 2, \"max\": tune_epochs+1},\n",
    "          \"decay\": {\"type\": \"float\", \"min\": 0.00000001, \"max\": 0.5, \"scalingType\": \"loguniform\"},\n",
    "          \"ignore_layers_values\": {\"type\": \"categorical\", \"values\": [\"attention\", \"batchnorm\", \"\"]}\n",
    "      },\n",
    "      \"spec\": {\n",
    "          \"metric\": \"loss\",\n",
    "          \"objective\": \"minimize\",\n",
    "      },\n",
    "  }\n",
    "optimizer = Optimizer(config, api_key=\"eoBdVyznAhfg3bK9pZ58ZSXfv\")\n",
    "\n",
    "for experiment in optimizer.get_experiments(project_name=\"mental\"):\n",
    "    experiment.add_tag(\"tune\")\n",
    "    \n",
    "    # Test the model\n",
    "    hyperparams_config = {\n",
    "        param: experiment.get_parameter(param) for param in config['parameters'].keys()}\n",
    "    if not hyperparams_config['optimizer']:\n",
    "        hyperparams_config['optimizer'] = optimizers.Adam(lr=hyperparams_config['lr'], \n",
    "                                   decay=hyperparams_config['decay'])\n",
    "    hyperparams_config[\"ignore_layers\"] = []\n",
    "    if hyperparams_config[\"ignore_layers_values\"]:\n",
    "        hyperparams_config[\"ignore_layers\"] = [hyperparams_config[\"ignore_layers_values\"]]\n",
    "    model = build_model(hyperparams=hyperparams_config,\n",
    "                        hyperparams_features=hyperparams_features, \n",
    "                        embedding_matrix=embedding_matrix, emotions=emotions,\n",
    "                       stopwords_list=stopword_list, liwc_categories=categories)\n",
    "    freeze_layer = FreezeLayer(patience=experiment.get_parameter('freeze_patience'),\n",
    "                              set_to=not experiment.get_parameter('trainable_embeddings'))\n",
    "    reduce_lr = callbacks.ReduceLROnPlateau(monitor='val_loss', \n",
    "                                            factor=experiment.get_parameter('lr_reduce_factor'),\n",
    "                                            patience=experiment.get_parameter('lr_reduce_patience'), \n",
    "                                            min_lr=0.000001, verbose=1)\n",
    "    model, history = train_model(model, \n",
    "            x_train, y_train, x_test, y_test,\n",
    "            epochs=tune_epochs, batch_size=experiment.get_parameter('batch_size'),\n",
    "                      class_weight={0:1, 1:experiment.get_parameter('positive_class_weight')}, \n",
    "                          workers=2,\n",
    "                          callback_list = [freeze_layer, reduce_lr],\n",
    "                      model_path='models/experiment')\n",
    "    loss = history.history['loss'][-1]\n",
    "    \n",
    "    # Report the loss, if not auto-logged:\n",
    "    experiment.log_metric(\"loss\", loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
