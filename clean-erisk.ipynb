{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import xml.etree.ElementTree as ET\n",
    "import glob, os\n",
    "import numpy as np\n",
    "from comet_ml import Experiment, Optimizer\n",
    "import pickle\n",
    "import logging\n",
    "import sys\n",
    "from sklearn.utils import class_weight\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "import json\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "# os.environ['CUDA_VISIBLE_DEVICES'] = '-1' # When cudnn implementation not found, run this\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\" # Note: when starting kernel, for gpu_available to be true, this needs to be run\n",
    "# only reserve 1 GPU\n",
    "os.environ['TFHUB_CACHE_DIR'] = '/home/anasab/tf_cache'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# confirm TensorFlow sees the GPU\n",
    "from tensorflow.python.client import device_lib\n",
    "assert 'GPU' in str(device_lib.list_local_devices())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['TF_KERAS'] = '1'\n",
    "from tensorflow.keras.preprocessing import sequence\n",
    "from tensorflow.keras.models import Sequential, Model, load_model\n",
    "from tensorflow.keras.layers import Dense, Dropout, Embedding, LSTM, Lambda, BatchNormalization, TimeDistributed, \\\n",
    "    Bidirectional, Input, concatenate, Flatten, RepeatVector, Activation, Multiply, Permute, \\\n",
    "    Conv1D, GlobalMaxPooling1D\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras import callbacks, optimizers\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.utils import plot_model, Sequence\n",
    "\n",
    "from keras.utils import np_utils\n",
    "\n",
    "from nltk.tokenize import RegexpTokenizer, TweetTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "import tensorflow as tf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_type = \"selfharm\"\n",
    "transfer_type = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.test.is_gpu_available()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_subject_writings(subject_file):\n",
    "    writings = []\n",
    "    with open(subject_file) as sf:\n",
    "        contents = sf.read()\n",
    "        root = ET.fromstring(contents)\n",
    "        try:\n",
    "            subject = root.findall('ID')[0].text.strip()\n",
    "        except Exception:\n",
    "            print('Cannot extract ID', contents[:500], '\\n-------\\n')        \n",
    "        for w in root.iter('WRITING'):\n",
    "            subject_writings = {'subject': subject}\n",
    "            for title in w.findall('TITLE'):\n",
    "                subject_writings['title'] = title.text\n",
    "            for text in w.findall('TEXT'):\n",
    "                subject_writings['text'] = text.text\n",
    "            for date in w.findall('DATE'):\n",
    "                subject_writings['date'] = date.text\n",
    "            writings.append(subject_writings)\n",
    "    return writings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_dir = '/home/anasab/' \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### eRisk 2020 T1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datadirs_T1_2020 = {\n",
    "    'train': ['./data/'],\n",
    "    'test': ['./DATA/']\n",
    "}\n",
    "datadir_root_T1_2020 = {\n",
    "    'train': root_dir + '/eRisk/data/eRisk2020_T1_train/eRISK2020_T1_training_data/eRISK2020_training_data/',\n",
    "    'test': root_dir + '/eRisk/data/2020/T1/'\n",
    "}\n",
    "    \n",
    "labels_files_T1_2020 = {\n",
    "    'train': ['golden_truth.txt'],\n",
    "    'test': ['T1_erisk_golden_truth.txt']\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_texts_2020(datadir_root_T1_2020,\n",
    "                   datadirs_T1_2020,\n",
    "                   labels_files_T1_2020,\n",
    "                   test_suffix='0000',\n",
    "                    chunked_subsets=None):\n",
    "\n",
    "\n",
    "    writings = {'train': [], 'test': []}\n",
    "    writings_df = pd.DataFrame()\n",
    "    labels_df = pd.DataFrame()\n",
    "#     for subset in ('train', 'test'):\n",
    "    for subset in ('test',):\n",
    "        for subdir in [os.path.join(datadir_root_T1_2020[subset], subp) for subp in datadirs_T1_2020[subset]]:\n",
    "\n",
    "            for subject_file in os.listdir(subdir):\n",
    "                writings[subset].extend(read_subject_writings(os.path.join(subdir, subject_file)))\n",
    "        writings_df_part = pd.DataFrame(writings[subset])\n",
    "        # add a suffix for users in the test -- the numbers are duplicated with the ones in train\n",
    "        if subset=='test':\n",
    "            writings_df_part['subject'] = writings_df_part['subject'].apply(lambda s: s+test_suffix)\n",
    "            print(subset, writings_df_part.subject)\n",
    "        writings_df_part['subset'] = subset\n",
    "        writings_df = pd.concat([writings_df, writings_df_part])\n",
    "        writings_df.reindex()\n",
    "\n",
    "        for label_file in labels_files_T1_2020[subset]:\n",
    "            labels = pd.read_csv(os.path.join(datadir_root_T1_2020[subset], label_file), \n",
    "                                 delimiter='\\s+', names=['subject', 'label'])\n",
    "            # add a suffix for users in the test -- the numbers are duplicated with the ones in train\n",
    "            if subset=='test':\n",
    "                labels['subject'] = labels['subject'].apply(lambda s: s+test_suffix)\n",
    "            labels_df = pd.concat([labels_df, labels])\n",
    "    labels_df = labels_df.drop_duplicates()\n",
    "    labels_df = labels_df.set_index('subject')\n",
    "\n",
    "    writings_df = writings_df.drop_duplicates()\n",
    "    \n",
    "    writings_df = writings_df.join(labels_df, on='subject')\n",
    "    \n",
    "    return writings_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if dataset_type == 'selfharm':\n",
    "    writings_df = read_texts_2020(datadir_root_T1_2020,\n",
    "                   datadirs_T1_2020,\n",
    "                   labels_files_T1_2020,\n",
    "                   test_suffix='0000',\n",
    "                    chunked_subsets=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regtokenizer = RegexpTokenizer(r'\\w+')\n",
    "tweet_tokenizer = TweetTokenizer()\n",
    "sw = stopwords.words(\"english\")\n",
    "\n",
    "def tokenize(t, tokenizer=regtokenizer):\n",
    "    return regtokenizer.tokenize(t.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from feature_encoders import encode_pronouns, encode_emotions, tokenize_fields, encode_stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "writings_df = tokenize_fields(writings_df, tokenize_fct=tokenize)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recurrent NN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract features and encode data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparams_features = json.load(open('config.json'))\n",
    "hyperparams = json.load(open('hyperparams.json'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if transfer_type:\n",
    "    pretrained_model_path = hyperparams_features['pretrained_model_path']\n",
    "    hyperparams, hyperparams_features = load_params(hyperparams_features['pretrained_model_path'])\n",
    "    hyperparams_features['pretrained_model_path'] = pretrained_model_path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Emotions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from resource_loading import load_NRC, load_LIWC\n",
    "\n",
    "nrc_lexicon_path = root_dir + '/resources/NRC-Emotion-Lexicon-Wordlevel-v0.92.txt'\n",
    "nrc_lexicon = load_NRC(nrc_lexicon_path)\n",
    "emotions = list(nrc_lexicon.keys())\n",
    "liwc_dict = load_LIWC(root_dir + '/resources/liwc.dic')\n",
    "\n",
    "liwc_categories = set(liwc_dict.keys())\n",
    "liwc_words_for_categories = pickle.load(open(\"data/liwc_categories_for_vocabulary_erisk_clpsych_stop_20K.pkl\", \"rb\"))\n",
    "\n",
    "stopword_list = stopwords.words(\"english\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Personal pronouns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encode data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_loading import load_erisk_data, load_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocabulary_list = pickle.load(open(hyperparams_features['vocabulary_path'], 'rb'))\n",
    "vocabulary_dict={}\n",
    "for i,w in enumerate(vocabulary_list):\n",
    "    vocabulary_dict[w] = i\n",
    "user_level_data, subjects_split, vocabulary = load_erisk_data(writings_df, \n",
    "                                                            voc_size=hyperparams_features['max_features'],\n",
    "                                                           emotion_lexicon=nrc_lexicon,\n",
    "                                                           emotions=emotions,\n",
    "                                                              liwc_categories=liwc_categories,\n",
    "                                                                                logger=None,\n",
    "#                                                            vocabulary=pickle.load(open('vocabulary_40K_all.pkl', 'rb')),\n",
    "#                                                            vocabulary=pickle.load(open('vocab_clpsych_10000.pkl', 'rb')),\n",
    "                                                              vocabulary=vocabulary_dict,\n",
    "                                                              by_subset=True,\n",
    "#                                                               labelcol = 'condition',\n",
    "#                                                               label_index={'depression':1, \"ptsd\":0}\n",
    "                                                                               )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from DataGenerator import DataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model import build_hierarchical_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DataGenerator(user_level_data=user_level_data, subjects_split=subjects_split, set_type='train',\n",
    "                 batch_size=32, seq_len=512, vocabulary=vocabulary,\n",
    "                 voc_size=hyperparams_features['max_features'], emotion_lexicon=nrc_lexicon,\n",
    "                 post_groups_per_user=None, posts_per_group=10, post_offset = 0,\n",
    "                 emotions=emotions, pronouns=[\"i\", \"me\", \"my\", \"mine\", \"myself\"], liwc_categories=liwc_categories,\n",
    "                 liwc_dict=liwc_dict, compute_liwc=False, liwc_words_for_categories=None,\n",
    "                 max_posts_per_user=None,\n",
    "                 shuffle=True, keep_last_batch=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "pretrained_embeddings_path = hyperparams_features['embeddings_path']\n",
    "embedding_matrix = load_embeddings(pretrained_embeddings_path, hyperparams_features['embedding_dim'], \n",
    "                                    voc=vocabulary_dict)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model import build_hierarchical_model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "hyperparams['optimizer'] = optimizers.Adam(lr=hyperparams['lr'], #beta_1=0.9, beta_2=0.999, epsilon=0.0001,\n",
    "                                   decay=hyperparams['decay'])\n",
    "    \n",
    "if transfer_type:\n",
    "#     hyperparams, _ = load_params(hyperparams_features['pretrained_model_path'])\n",
    "    if 'optimizer' not in hyperparams:\n",
    "        hyperparams['optimizer'] = optimizers.Adam(lr=hyperparams['lr'], #beta_1=0.9, beta_2=0.999, epsilon=0.0001,\n",
    "                                       decay=hyperparams['decay'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "from train import initialize_experiment, train\n",
    "\n",
    "experiment = initialize_experiment(hyperparams, nrc_lexicon_path, emotions, pretrained_embeddings_path, \n",
    "                      dataset_type, transfer_type, hyperparams_features)\n",
    "models, history = train(user_level_data, subjects_split, \n",
    "          hyperparams, hyperparams_features, \n",
    "          embedding_matrix, emotions, stopword_list, liwc_categories,\n",
    "              experiment, dataset_type=dataset_type, transfer_type=transfer_type,\n",
    "              validation_set='valid',\n",
    "          version=102, epochs=25, start_epoch=0, classes=1,\n",
    "\n",
    "                                       )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes=1\n",
    "hyperparams_loaded = json.load(open('%s.hp.json' % hyperparams_features['pretrained_model_path']))\n",
    "if 'optimizer' not in hyperparams_loaded:\n",
    "    hyperparams_loaded['optimizer'] = optimizers.Adam(lr=hyperparams_loaded['lr'], #beta_1=0.9, beta_2=0.999, epsilon=0.0001,\n",
    "                                   decay=hyperparams_loaded['decay'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_collection = {}\n",
    "key='lstm_seq'\n",
    "# hyperparams_loaded['trainable_embeddings']=True\n",
    "models_collection[key] = load_saved_model_weights(hyperparams_features['pretrained_model_path'], \n",
    "                                                      hyperparams_loaded, \n",
    "                                                      emotions, stopword_list, liwc_categories, classes=classes, \n",
    "                                                      h5=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparams1, hyperparams_features1 = load_params(model_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyperparams_features1['embeddings_path']=[\n",
    "#     '/home/anasab//eRisk/embeddings/finetuned_glove_clpsych_erisk_stop_20000_2.pkl']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparams_features1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_model = load_saved_model(model_path, hyperparams1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocabulary_list = pickle.load(open(hyperparams_features1['vocabulary_path'], 'rb'))\n",
    "vocabulary_dict={}\n",
    "for i,w in enumerate(vocabulary_list):\n",
    "    vocabulary_dict[w] = i\n",
    "embedding_matrix = load_embeddings2(hyperparams_features1['embeddings_path'], \n",
    "                                    hyperparams_features1['embedding_dim'], vocabulary_dict)\n",
    "liwc_words_for_categories = pickle.load(open(hyperparams_features1['liwc_words_cached'], 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if 'optimizer' not in hyperparams1:\n",
    "#         hyperparams1['optimizer'] = optimizers.Adam(lr=hyperparams1['lr'], #beta_1=0.9, beta_2=0.999, epsilon=0.0001,\n",
    "#                                        decay=hyperparams1['decay'])\n",
    "# loaded_model = initialize_model(hyperparams1, hyperparams_features1, embedding_matrix, emotions, stopword_list,\n",
    "#                     liwc_categories)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_model.load_weights(model_path + \"_weights.h5\", by_name=True)\n",
    "# metrics_class = Metrics(threshold=0.5)\n",
    "# loaded_model.compile(hyperparams1['optimizer'], binary_crossentropy_custom,\n",
    "#                   metrics=[metrics_class.f1_m, metrics_class.precision_m, metrics_class.recall_m])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Server data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_runs = {\n",
    "    'bert': 0,\n",
    "    'lstm_seq': 1,\n",
    "    'cnn_hierarch': 2,\n",
    "    'transfer': 3,\n",
    "    'ensemble': 4,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_key = 'lstm_seq'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "def load_erisk_server_data(datarounds_json, voc_size, emotion_lexicon, tokenizer,\n",
    "                           liwc_words_for_categories,\n",
    "                           emotions =  \n",
    "                    ['anger', 'anticipation', 'disgust', 'fear', 'joy', \n",
    "                     'negative', 'positive', 'sadness', 'surprise', 'trust'],\n",
    "                    liwc_categories = liwc_categories, \n",
    "                    pronouns = [\"i\", \"me\", \"my\", \"mine\", \"myself\"],\n",
    "                    user_level=True, vocabulary=vocabulary_dict,\n",
    "                   logger=logger):\n",
    "    def __encode_liwc_categories(tokens, liwc_words_for_categories, relative=True):\n",
    "        categories_cnt = [0 for c in liwc_categories]\n",
    "        if not tokens:\n",
    "            return categories_cnt\n",
    "        text_len = len(tokens)\n",
    "        for i, category in enumerate(liwc_categories):\n",
    "            for t in tokens:\n",
    "                if t in liwc_words_for_categories[category]:\n",
    "                    categories_cnt[i] += 1\n",
    "            if relative and text_len:\n",
    "                categories_cnt[i] = categories_cnt[i]/text_len\n",
    "        return categories_cnt\n",
    "    logger.debug(\"Loading data...\\n\")\n",
    "     \n",
    "    subjects_split = {'test': []}\n",
    " \n",
    "    user_level_texts = {}\n",
    "    for datapoints_json in datarounds_json:\n",
    "        for datapoint in datapoints_json:\n",
    "            words = []\n",
    "            raw_text = \"\"\n",
    "            if \"title\" in datapoint:\n",
    "                tokenized_title = tokenizer.tokenize(datapoint[\"title\"])\n",
    "                words.extend(tokenized_title)\n",
    "                raw_text += datapoint[\"title\"]\n",
    "            if \"content\" in datapoint:\n",
    "                tokenized_text = tokenizer.tokenize(datapoint[\"content\"])\n",
    "                words.extend(tokenized_text)\n",
    "                raw_text += datapoint[\"content\"]\n",
    "            \n",
    "            liwc_categs = __encode_liwc_categories(words, liwc_words_for_categories)\n",
    "            if datapoint[\"nick\"] not in user_level_texts.keys():\n",
    "                user_level_texts[datapoint[\"nick\"]] = {}\n",
    "                user_level_texts[datapoint[\"nick\"]]['texts'] = [words]\n",
    "                user_level_texts[datapoint[\"nick\"]]['liwc'] = [liwc_categs]\n",
    "                user_level_texts[datapoint[\"nick\"]]['raw'] = [raw_text]\n",
    "                subjects_split['test'].append(datapoint['nick'])\n",
    "            else:\n",
    "                user_level_texts[datapoint[\"nick\"]]['texts'].append(words)\n",
    "                user_level_texts[datapoint[\"nick\"]]['liwc'].append(liwc_categs)\n",
    "                user_level_texts[datapoint[\"nick\"]]['raw'].append(raw_text)\n",
    "            \n",
    "    return user_level_texts, subjects_split, vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_json_datapoint(jlpath):\n",
    "    datapoints = []\n",
    "    with open(jlpath) as f:\n",
    "        for line in f:\n",
    "            datapoints.append(json.loads(line))\n",
    "    return datapoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# erisk_server_data, erisk_server_subjects_split, vocabulary = load_erisk_server_data(data,\n",
    "#                        tokenizer=regtokenizer,\n",
    "#                        liwc_words_for_categories=liwc_words_for_categories,\n",
    "#                     voc_size=hyperparams_features['max_features'],\n",
    "#                     emotion_lexicon=nrc_lexicon,\n",
    "#                     emotions=emotions,\n",
    "#                     user_level=hyperparams_features['user_level'],\n",
    "#                        vocabulary=vocabulary_dict,\n",
    "#     #                                                            vocabulary=pickle.load(open('vocabulary20K_selfharm.pkl', 'rb'))\n",
    "#                     logger=logger)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "erisk_server_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "#TODO: predict only on last 50 posts\n",
    "\n",
    "with session_collection[model_key].as_default():\n",
    "    with session_collection[model_key].graph.as_default():\n",
    "        server_erisk_predictions = models_collection[model_key].predict(DataGenerator(erisk_server_data, erisk_server_subjects_split, \n",
    "                                             set_type='test', vocabulary=vocabulary_dict, \n",
    "                                           hierarchical=hyperparams_collection[model_key]['hierarchical'],\n",
    "                                        seq_len=hyperparams['maxlen'], batch_size=hyperparams['batch_size'],\n",
    "                                             max_posts_per_user=None,\n",
    "                                           pad_with_duplication=False,\n",
    "                                            posts_per_group=hyperparams['posts_per_group'],\n",
    "                                            post_groups_per_user=None, \n",
    "                                             sample_seqs=False, shuffle=False,\n",
    "                                                    compute_liwc=False)\n",
    "                                                                       )\n",
    "        pd.Series(server_erisk_predictions.flatten()).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Series(server_erisk_predictions.flatten()).describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Seding results to server!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# subjects = [d['nick'] for d in read_json_datapoint(\"client/data0.jl\")]\n",
    "# results = {s: 0 for s in subjects}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_next_data(rnd, results):\n",
    "#     # TODO: send results to get data\n",
    "#     response = build_response(results)\n",
    "#     # Send response\n",
    "#     data = {\"...\"}\n",
    "#     # Make sure it's the correct round\n",
    "#     assert data['number'] == rnd\n",
    "#     serialize_data(data)\n",
    "#     return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_next_data_dummy(rnd, results):\n",
    "#     return read_json_datapoint(\"client/data0.jl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Results for round and model\n",
    "results = {key: {} for key in models_runs}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_chunk(rnds):\n",
    "    # Send same results for a chunk of rounds to get new posts\n",
    "    data = [read_json_datapoint(\"data_server/data%d.jl\" % i) for i in rnds]\n",
    "#     data_chunks = []\n",
    "#     for rnd in rnds:\n",
    "#         # TODO: REPLACE THIS WITH THE CORRECT ONE\n",
    "#         data = get_next_data_dummy(rnd, results)\n",
    "#         data_chunks.append(data)\n",
    "#         all_data[rnd] = data\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "def predict_for_round_chunk(model, hyperparams, hyperparams_features, vocabulary, data_chunk, subjects=[],\n",
    "                           model_key='', cache_round=None): \n",
    "    # preload for subjects not occurring in the round with results from previous round\n",
    "#     results = {s: 0 for s in subjects}\n",
    "    if cache_round:\n",
    "        results = load_results(model_key, cache_round)\n",
    "    else:\n",
    "        results = {s: 0 for s in subjects}\n",
    "        \n",
    "    \n",
    "    erisk_server_data, erisk_server_subjects_split, vocabulary = load_erisk_server_data(data_chunk,\n",
    "                       tokenizer=regtokenizer,\n",
    "                       liwc_words_for_categories=liwc_words_for_categories,\n",
    "                    voc_size=hyperparams_features['max_features'],\n",
    "                    emotion_lexicon=nrc_lexicon,\n",
    "                    emotions=emotions,\n",
    "                    user_level=1,\n",
    "                       vocabulary=vocabulary,\n",
    "                    logger=logger)\n",
    "\n",
    "    for features, subjects, _ in DataGenerator(erisk_server_data, erisk_server_subjects_split, \n",
    "                                         set_type='test', vocabulary=vocabulary, \n",
    "                                       hierarchical=hyperparams['hierarchical'],\n",
    "                                    seq_len=hyperparams['maxlen'], batch_size=hyperparams['batch_size'],\n",
    "                                         max_posts_per_user=None,\n",
    "                                       pad_with_duplication=False,\n",
    "                                        posts_per_group=hyperparams['posts_per_group'],\n",
    "                                        post_groups_per_user=None, \n",
    "                                         sample_seqs=False, shuffle=False,\n",
    "                                      return_subjects=True):\n",
    "        predictions = model.predict_on_batch(features)\n",
    "        print(len(features[0]), len(subjects), len(predictions), len(results))\n",
    "        for i,s in enumerate(subjects):\n",
    "            results[\"subject\" + str(s)] = predictions[i].item()\n",
    "    return(results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_response(results, decision_thresh=0.5, model_name='', rnd=0):\n",
    "    response = []\n",
    "    for subject, score in results.items():\n",
    "        prediction = 1 if score >= decision_thresh else 0\n",
    "        response.append({'nick': subject, 'score': score, 'decision': prediction})\n",
    "    json.dump(response, open(\"data_server/response_run%s_rnd%d.json\" % (model_name, rnd), 'w+'))\n",
    "    return response\n",
    "# build_response(results, 50000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_ensemble_results(rnd, all_results, model_keys_to_average=['lstm_seq', 'cnn_hierarch']):\n",
    "#     subjects = [s for s in all_results[model_keys_to_average[0]][rnd]]\n",
    "#     results_ensemble = {}\n",
    "#     for sub in subjects:\n",
    "#         s = 0\n",
    "#         for k in model_keys_to_average:\n",
    "#             s += all_results[k][rnd][sub]\n",
    "#         results_ensemble[sub] = s/len(model_keys_to_average)\n",
    "#     return results_ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ensemble_results(results_to_average):\n",
    "    subjects = [s for s in results_to_average[0]]\n",
    "    results_ensemble = {}\n",
    "    for sub in subjects:\n",
    "        s = 0\n",
    "        for res in results_to_average:\n",
    "            s += res[sub]\n",
    "        results_ensemble[sub] = s/len(results_to_average)\n",
    "    return results_ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_transfer_results(rnd, all_results, model_to_average='lstm_seq', rounds_back=100):\n",
    "    subjects = [s for s in all_results[model_to_average][rnd]]\n",
    "    results_ensemble = {}\n",
    "    for sub in subjects:\n",
    "        s = 0\n",
    "        existing_rounds = 0\n",
    "        for prev_rnd in range(rnd-rounds_back, rnd+1):\n",
    "#             print(\"rolling rnds\", prev_rnd)\n",
    "            if prev_rnd in all_results[model_to_average]:\n",
    "                s += all_results[model_to_average][prev_rnd][sub]\n",
    "                existing_rounds += 1\n",
    "        results_ensemble[sub] = s/existing_rounds\n",
    "#         print(\"Have found a rolling window of %d for the transfer model\" % existing_rounds)\n",
    "    return results_ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_results(model_key, rnd):\n",
    "    results = {}\n",
    "    with open(\"data_server/response_run%s_rnd%d.json\" % (models_runs[model_key], rnd)) as f:\n",
    "        response = json.loads(f.read())\n",
    "        for line in response:\n",
    "            results[line['nick']] = line['score']\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# results['lstm_seq'][20] = load_results('lstm_seq', 20)\n",
    "# results['lstm_seq'][40] = \n",
    "results# results['bert'][40] = load_results('bert', 40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnds = range(500,600)\n",
    "decision_thresh = 0.5\n",
    "data_chunks = get_data_chunk(rnds)\n",
    "subjects = [d['nick'] for d in read_json_datapoint(\"data_server/data0.jl\")]\n",
    "# for key in ['transfer', 'ensemble']:\n",
    "for model_key in [\n",
    "                  'lstm_seq',\n",
    "                    'bert',\n",
    "                  'cnn_hierarch', \n",
    "                  'transfer', \n",
    "                  'ensemble',\n",
    "                ]:\n",
    "    print(model_key)\n",
    "    end_rnd = rnds[-1]\n",
    "#     if model_key=='lstm_seq':\n",
    "#         results[model_key][end_rnd]=load_results('lstm_seq', 20)\n",
    "    if model_key=='cnn_hierarch':\n",
    "        results[model_key][end_rnd]=load_results('cnn_hierarch', 40)\n",
    "    elif model_key=='bert':\n",
    "        results[model_key][end_rnd]=load_results('bert', end_rnd)\n",
    "    elif model_key=='ensemble':\n",
    "        model_keys_to_average=['bert', 'cnn_hierarch', 'lstm_seq']\n",
    "        missing_models = [m for m in model_keys_to_average if not results[m]]\n",
    "        if len(missing_models)!=0:\n",
    "            print(\"Missing models! cannot compute ensemble results\", missing_models)\n",
    "            continue\n",
    "        results_to_average = [results[m][end_rnd] for m in model_keys_to_average]\n",
    "#         results[model_key][end_rnd] = get_ensemble_results(rnd, results, \n",
    "#                                                 model_keys_to_average)\n",
    "        results[model_key][end_rnd] = get_ensemble_results(results_to_average)\n",
    "    ## For now\n",
    "    elif model_key=='transfer':\n",
    "        results[model_key][end_rnd]=get_transfer_results(\n",
    "            end_rnd, results, model_to_average='lstm_seq', rounds_back=60)\n",
    "#         results[model_key][end_rnd]=results['lstm_seq'][end_rnd]\n",
    "    ##\n",
    "    else:\n",
    "        with session_collection[model_key].as_default():\n",
    "            with session_collection[model_key].graph.as_default():\n",
    "                results[model_key][end_rnd] = predict_for_round_chunk(models_collection[model_key], \n",
    "                                              hyperparams_collection[model_key], hyperparams_features, \n",
    "                                              vocabulary_dict, \n",
    "                                          data_chunks, subjects=subjects, model_key=model_key, cache_round=499)\n",
    "\n",
    "    \n",
    "    print(len(results[model_key][end_rnd].values()), \"positive:\", \n",
    "      len([r for r in results[model_key][end_rnd].values() if r >=0.5]))\n",
    "    response1 = build_response(results[model_key][end_rnd], rnd=end_rnd, \n",
    "                               model_name=models_runs[model_key], decision_thresh=decision_thresh)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results['lstm_seq'].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Series(list(results['transfer'][180].values())).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import pearsonr\n",
    "pearsonr(list(results['bert'][220].values()), list(results['bert'][180].values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Series(list(results['lstm_seq'][160].values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict on eRisk data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# results = {}\n",
    "# labels = {}\n",
    "# featuresall = {}\n",
    "# with session_collection['lstm_seq2'].as_default():\n",
    "#     with session_collection['lstm_seq2'].graph.as_default():\n",
    "        # for features, subjects, lbls in DataGenerator(user_level_data, subjects_split, \n",
    "        #                                          set_type='train', vocabulary=vocabulary_dict,\n",
    "        #                                        hierarchical=hyperparams1['hierarchical'],\n",
    "        #                                     seq_len=hyperparams1['maxlen'], batch_size=hyperparams1['batch_size'],\n",
    "        #                                          max_posts_per_user=None,\n",
    "        #                                        pad_with_duplication=False,\n",
    "        #                                         posts_per_group=hyperparams1['posts_per_group'],\n",
    "        #                                         post_groups_per_user=None, \n",
    "        #                                          sample_seqs=False, shuffle=False,\n",
    "        #                                                return_subjects=True):\n",
    "\n",
    "        #     predictions = loaded_model.predict_on_batch(features)\n",
    "        #     print(len(features[0]), len(subjects), len(predictions), len(labels), len(results))\n",
    "        #     for i,s in enumerate(subjects):\n",
    "        #         if s not in results:\n",
    "        #             results[s] = []\n",
    "        #             featuresall[s] = []\n",
    "        #         results[s].append(predictions[i].item())\n",
    "        #         featuresall[s].append([features[j][i] for j in range(len(features))])\n",
    "        #         labels[s] = lbls[i]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for subject in results:\n",
    "    if not labels[subject]:\n",
    "        if np.std(results[subject])>0.0:\n",
    "            print(subject), print(results[subject][0], results[subject][-1]-results[subject][0])\n",
    "            pd.Series(results[subject]).rolling(window=5).mean().plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[featuresall[4278][i][0].sum() for i in range(len(featuresall[4278]))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(user_level_data['subject4278']['raw'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x, s, y in DataGenerator(user_level_data, subjects_split, \n",
    "                                         set_type='test', vocabulary=vocabulary_dict,\n",
    "                                       hierarchical=hyperparams1['hierarchical'],\n",
    "                                    seq_len=hyperparams1['maxlen'], batch_size=hyperparams1['batch_size'],\n",
    "                                         max_posts_per_user=None,\n",
    "                                       pad_with_duplication=False,\n",
    "                                        posts_per_group=hyperparams1['posts_per_group'],\n",
    "                                        post_groups_per_user=None, \n",
    "                                         sample_seqs=False, shuffle=False,\n",
    "                                               return_subjects=True):\n",
    "    print(\"subject\", s, \"features\", x[0].sum(axis=1))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_key='lstm_seq'\n",
    "with session_collection[model_key].as_default():\n",
    "    with session_collection[model_key].graph.as_default():\n",
    "        res = models_collection[model_key].evaluate_generator(DataGenerator(user_level_data, subjects_split, \n",
    "                                              liwc_words_for_categories=liwc_words_for_categories,\n",
    "                                         set_type='test', vocabulary=vocabulary_dict,\n",
    "                                       hierarchical=hyperparams_collection[model_key]['hierarchical'],\n",
    "                                    seq_len=hyperparams_collection[model_key]['maxlen'], \n",
    "                                    batch_size=hyperparams['batch_size'],\n",
    "                                         max_posts_per_user=None,\n",
    "                                       pad_with_duplication=False,\n",
    "                                        posts_per_group=hyperparams_collection[model_key]['posts_per_group'],\n",
    "                                        post_groups_per_user=1,#None, \n",
    "                                         sample_seqs=False, shuffle=False,\n",
    "                                             compute_liwc=False))\n",
    "        print(res)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (tfconda)",
   "language": "python",
   "name": "tfconda"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {
    "height": "362px",
    "width": "218px"
   },
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
