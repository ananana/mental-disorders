{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import xml.etree.ElementTree as ET\n",
    "import glob, os\n",
    "import numpy as np\n",
    "from comet_ml import Experiment, Optimizer\n",
    "import pickle\n",
    "import logging\n",
    "import sys\n",
    "from sklearn.utils import class_weight\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from matplotlib import pyplot as plt\n",
    "from scipy.stats import pearsonr, ttest_ind\n",
    "\n",
    "import json\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_type = \"anorexia\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if dataset_type == \"combined\":\n",
    "    writings_df_selfharm = pickle.load(open('data/writings_df_selfharm_all', 'rb'))\n",
    "    writings_df_anorexia = pickle.load(open('data/writings_df_anorexia_liwc', 'rb'))\n",
    "    writings_df_depression = pickle.load(open('data/writings_df_depression_liwc', 'rb'))\n",
    "    writings_df = pd.DataFrame()\n",
    "    writings_df = pd.concat([writings_df, writings_df_depression])\n",
    "    writings_df = pd.concat([writings_df, writings_df_selfharm])\n",
    "    writings_df = pd.concat([writings_df, writings_df_anorexia])\n",
    "elif dataset_type == \"combined_depr\":\n",
    "    writings_df = pd.DataFrame.from_dict(json.load(open('data/writings_df_depression_all.json')))\n",
    "elif dataset_type == \"clpsych\":\n",
    "    writings_df = pd.DataFrame.from_dict(json.load(open('data/writings_df_%s_liwc_affect.json' % dataset_type)))#read_texts_clpsych(datadir_root_clpsych, datadirs_clpsych, labels_files_clpsych)\n",
    "#     writings_df_test = pd.DataFrame.from_dict(json.load(open('writings_df_%s_test.json' % dataset_type)))#read_texts_clpsych(datadir_root_clpsych, datadirs_clpsych, labels_files_clpsych)\n",
    "#     writings_df_test = read_texts_clpsych(datadir_root_clpsych, datadirs_clpsych, labels_files_clpsych)\n",
    "    label_by = ['depression', 'ptsd']\n",
    "    writings_df = writings_df.drop(writings_df[writings_df['condition']=='depression'].index)\n",
    "#     writings_df['label'] = writings_df['condition'].apply(lambda c: 1 if c in label_by else 0)\n",
    "#     writings_df['date'] = writings_df['created_at']\n",
    "# elif dataset_type == \"symanto\":\n",
    "#     writings_df = read_texts_symanto()\n",
    "    writings_df = read_texts_symanto()\n",
    "elif dataset_type == 'selfharm':\n",
    "    writings_df = pickle.load(open('data/writings_df_%s_all' % dataset_type, 'rb'))\n",
    "elif dataset_type in [\"depression\", \"anorexia\", \"selfharm\", \"symanto\"]:\n",
    "    writings_df = pickle.load(open('data/writings_df_%s_liwc' % dataset_type, 'rb'))\n",
    "else:\n",
    "    logger.error(\"Unknown dataset %s\" % dataset_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_NRC(nrc_path):\n",
    "    word_emotions = {}\n",
    "    emotion_words = {}\n",
    "    with open(nrc_path) as in_f:\n",
    "        for line in in_f:\n",
    "            line = line.strip()\n",
    "            if not line:\n",
    "                continue\n",
    "            word, emotion, label = line.split()\n",
    "            if word not in word_emotions:\n",
    "                word_emotions[word] = set()\n",
    "            if emotion not in emotion_words:\n",
    "                emotion_words[emotion] = set()\n",
    "            label = int(label)\n",
    "            if label:\n",
    "                word_emotions[word].add(emotion)\n",
    "                emotion_words[emotion].add(word)\n",
    "    return emotion_words\n",
    "\n",
    "nrc_lexicon_path = '/home/anasab/resources/NRC-Emotion-Lexicon-Wordlevel-v0.92.txt'\n",
    "nrc_lexicon = load_NRC(nrc_lexicon_path)\n",
    "emotions = list(nrc_lexicon.keys())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from liwc_readDict import readDict\n",
    "\n",
    "liwc_dict = {}\n",
    "for (w, c) in readDict('/home/anasab/resources/liwc.dic'):\n",
    "    if c not in liwc_dict:\n",
    "        liwc_dict[c] = []\n",
    "    liwc_dict[c].append(w)\n",
    "\n",
    "categories = set(liwc_dict.keys())\n",
    "len(categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auxwords = {}\n",
    "\n",
    "positive_df = writings_df[writings_df['label']==1]\n",
    "negative_df = writings_df[writings_df['label']==0]\n",
    "\n",
    "for word in liwc_dict['auxverb']:\n",
    "    auxwords[word + \"_pos\"] = positive_df.tokenized_text.apply(\n",
    "        lambda tokens: len([t for t in tokens if t==word])/len(tokens) if tokens else 0)\n",
    "    auxwords[word + \"_neg\"] = negative_df.tokenized_text.apply(\n",
    "        lambda tokens: len([t for t in tokens if t==word])/len(tokens) if tokens else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for word in liwc_dict['auxverb']:\n",
    "    print(word, np.mean(auxwords[word + \"_pos\"]), np.mean(auxwords[word + \"_neg\"]), \n",
    "          np.mean(auxwords[word + \"_pos\"]) / np.mean(auxwords[word + \"_neg\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auxwords.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature = 'negemo'\n",
    "writings_df[writings_df['label']==1].groupby('subject').mean()[feature].hist(alpha=0.5, label='positive', bins=40)\n",
    "writings_df[writings_df['label']==0].groupby('subject').mean()[feature].hist(alpha=0.5, label='negative', bins=20)\n",
    "ttest = ttest_ind(writings_df[writings_df['label']==0].groupby('subject').mean()[feature].values,\n",
    "                              writings_df[writings_df['label']==1].groupby('subject').mean()[feature].values, \n",
    "                  nan_policy='omit')\n",
    "print('\\tttest', ttest)\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "writings_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_tokens(row, has_title=True):\n",
    "    tokens = []\n",
    "    if row.tokenized_text:\n",
    "        tokens += row.tokenized_text\n",
    "    if has_title:\n",
    "        if row.tokenized_title:\n",
    "            tokens += row.tokenized_title\n",
    "    return tokens\n",
    "writings_df['all_tokens'] = writings_df.apply (lambda row: merge_tokens(row,\n",
    "                                                                       has_title='title' in writings_df.columns), \n",
    "                                               axis=1)\n",
    "\n",
    "def extract_emotions(tokens, emotion, relative=True):\n",
    "    if not tokens:\n",
    "        return None\n",
    "    emotion_words = [t for t in tokens \n",
    "                     if t in nrc_lexicon[emotion]]\n",
    "    if relative and len(tokens):\n",
    "        return len(emotion_words) / len(tokens)\n",
    "    else:\n",
    "        return len(emotion_words)\n",
    "    \n",
    "    return encoded_emotions\n",
    "\n",
    "from functools import partial\n",
    "for emotion in emotions:\n",
    "    writings_df[emotion] = writings_df['all_tokens'].apply(partial(extract_emotions, emotion=emotion, \n",
    "                                                                   relative=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mentions(tokenized_text, terms=['diagnosis', 'diagnosed', 'diagnose']):\n",
    "    if not tokenized_text:\n",
    "        return False\n",
    "    for term in terms:\n",
    "        if term in tokenized_text:\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "writings_df['diagnosis'] = writings_df['tokenized_text'].apply(mentions)\n",
    "writings_df['depression_mention'] = writings_df['tokenized_text'].apply(lambda t: \n",
    "                                                                        mentions(t, ['depressed', 'depression']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "writings_df[writings_df['label']==1].groupby('subject').sum()[['label', 'diagnosis', 'depression_mention']\n",
    "                                                             ].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Statistical tests between classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "writings_df.groupby('subject').mean()[['label'] + \n",
    "                list(categories)].corr()['label'].sort_values().head(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "writings_df.groupby('subject').mean()[['label'] + \n",
    "                emotions].corr()['label'].sort_values().head(100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "def normalize_date(date):\n",
    "        return \" \".join(date.strip().split())\n",
    "\n",
    "writings_df['date'] = writings_df['date'].apply(normalize_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "writings_df['datetime'] = writings_df.date.apply(lambda d: datetime.datetime.strptime(\n",
    "            normalize_date(d), '%Y-%m-%d %H:%M:%S'))\n",
    "# writings_df['datetime'] = writings_df.date.apply(lambda d: datetime.datetime.strptime(\n",
    "#             normalize_date(d), '%a %b %d %H:%M:%S +%f %Y'))\n",
    "\n",
    "\n",
    "writings_df['date_day'] = writings_df.datetime.apply(lambda d: d.date())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_days = {}\n",
    "for subject in set(writings_df.subject.values):\n",
    "    first_day = writings_df[writings_df['subject']==subject].groupby('subject').min().datetime.values[0]\n",
    "    first_days[subject] = first_day\n",
    "    \n",
    "print(first_days)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "last_days = {}\n",
    "for subject in set(writings_df.subject.values):\n",
    "    last_day = writings_df[writings_df['subject']==subject].groupby('subject').max().datetime.values[0]\n",
    "    last_days[subject] = last_day\n",
    "    \n",
    "print(last_days)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "def days_difference(date1, subject, reversed=False, unit='days', date_format='%Y-%m-%d %H:%M:%S'):\n",
    "    \n",
    "    if reversed:\n",
    "        try:\n",
    "#             date1 = datetime.datetime.strptime(\n",
    "#             normalize_date(date1), date_format\n",
    "#                                       )\n",
    "#             date2 = datetime.datetime.strptime(normalize_date(last_days[subject]), date_format)\n",
    "            date2 = last_days[subject]\n",
    "            o = date1 - date2\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            return None\n",
    "    else:\n",
    "        try:\n",
    "            date2 = first_days[subject]\n",
    "            o = date1 - date2\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            return None\n",
    "    if unit=='days':\n",
    "        return o.days\n",
    "    if unit=='weeks':\n",
    "        return o.days//7\n",
    "    if unit=='months':\n",
    "        return o.days//30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "writings_df['writing_days'] = writings_df.apply(lambda x: days_difference(x['datetime'], x['subject'], reversed=False, \n",
    "                                                                          unit='days'),\n",
    "                                                \n",
    "                                                axis=1)\n",
    "#                                                                           date_format='%a %b %d %H:%M:%S +%f %Y'), \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "writings_df['writing_days_reverse'] = writings_df.apply(lambda x: days_difference(x['datetime'], x['subject'], reversed=True, \n",
    "                                                                          unit='days'), \n",
    "#                                                                                   date_format='%a %b %d %H:%M:%S +%f %Y'), \n",
    "                                                axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "writings_df['first_day'] = writings_df['subject'].apply(lambda u: first_days[u])\n",
    "writings_df['last_day'] = writings_df['subject'].apply(lambda u: last_days[u])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "writings_df = writings_df.loc[:,~writings_df.columns.duplicated()]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_df = writings_df[writings_df['label']==1]\n",
    "negative_df = writings_df[writings_df['label']==0] #.sample(frac=1)[:len(positive_df)]\n",
    "\n",
    "def plot_evolution(df, emotion, writing_day_cutoff, rolling_window, label='', date_field='writing_days'):\n",
    "\n",
    "#     df[df[date_field]>=writing_day_cutoff][\n",
    "#             ['text', 'label', 'pronouns', 'text_len', 'subject', 'date', 'date_day', 'writing_days', 'negemo', 'posemo'\n",
    "#             ] + emotions + list(categories)\n",
    "#     ].groupby(date_field).mean()[emotion].rolling(rolling_window).mean().plot(label=label)\n",
    "    \n",
    "#     df[df['date_day']>=writing_day_cutoff][\n",
    "    df[df['writing_days']<=writing_day_cutoff][\n",
    "            ['text', 'label', 'text_len', 'subject', 'date', 'date_day', 'writing_days', 'writing_days_reverse', \n",
    "            'depression_mention', 'diagnosis'] + emotions + [c for c in set(categories) if c in df.columns]\n",
    "    ].groupby(date_field).mean()[emotion].rolling(rolling_window).mean().plot(label=label)\n",
    "#                                 ].apply(lambda c: np.log(c) if c>0 else 0\n",
    "#                                        ).rolling(rolling_window).mean().plot(label=label)\n",
    "\n",
    "def plot_subjects(df, emotion, writing_day_cutoff, rolling_window, label=''):\n",
    "\n",
    "    df[abs(df['writing_days'])<=writing_day_cutoff][\n",
    "            ['text', 'label', 'text_len', 'subject', 'date', 'date_day', 'writing_days',  'writing_days_reverse',\n",
    "            ] + emotions + [c for c in set(categories) if c in df.columns]\n",
    "    ].groupby('date_day').count().subject.plot(label=label)\n",
    "\n",
    "def plot_stationary(df, emotion, writing_day_cutoff, label='', date_field='date_day'):\n",
    "    df[df[date_field]>=writing_day_cutoff][\n",
    "            ['text', 'label', 'text_len', 'subject', 'date', 'writing_days', 'date_day', 'datetime', 'writing_days_reverse',\n",
    "            ] + emotions + [c for c in set(categories) if c in df.columns]\n",
    "    ].groupby(date_field).mean()[emotion].diff().plot(label=label)\n",
    "    \n",
    "\n",
    "emo = 'posemo'\n",
    "# days = datetime.datetime.strptime('2000','%Y').date()\n",
    "days = 365\n",
    "\n",
    "# disorder = dataset_type\n",
    "disorder = \"positive\"\n",
    "plot_evolution(positive_df, emo, days, 7, disorder + ' diagnosis', 'date_day')\n",
    "# plot_evolution(writings_df, emo, days, 100, 'all', 'writing_days_reverse')\n",
    "plot_evolution(negative_df, emo, days, 7, 'no ' + disorder + ' diagnosis', 'date_day')\n",
    "\n",
    "# plot_stationary(positive_df, emo, days, dataset_type + ' diagnosis', 'date_day')\n",
    "# plot_stationary(writings_df, emo, days, 'all', 'date_day')\n",
    "# plot_stationary(negative_df, emo, days, 'no ' + dataset_type + ' diagnosis', 'date_day')\n",
    "\n",
    "# plot_subjects(positive_df, emo, days, 100, dataset_type + ' diagnosis')\n",
    "# plot_subjects(writings_df, emo, days, 100, 'all')\n",
    "# plot_subjects(negative_df, emo, days, 100, 'no ' + dataset_type + ' diagnosis')\n",
    "\n",
    "plt.xlabel(\"Days from first post\")\n",
    "plt.ylabel(emo + \" scores\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evolution correlations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(set(writings_df[writings_df['label']==1].subject))\n",
    "# len(set(writings_df[writings_df['subset']=='test'].subject))\n",
    "# writings_df = writings_df[writings_df['subset']=='train']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_evolution_series(df, emotion, writing_day_cutoff, rolling_window, date_field='writing_days'):\n",
    "\n",
    "#     df[df[date_field]>=writing_day_cutoff][\n",
    "#             ['text', 'label', 'pronouns', 'text_len', 'subject', 'date', 'date_day', 'writing_days', 'negemo', 'posemo'\n",
    "#             ] + emotions + list(categories)\n",
    "#     ].groupby(date_field).mean()[emotion].rolling(rolling_window).mean().plot(label=label)\n",
    "    \n",
    "#     return df[df['date_day']>=writing_day_cutoff][\n",
    "    return df[df['writing_days']<=writing_day_cutoff][\n",
    "            ['text', 'label', 'text_len', 'subject', 'date', 'date_day', 'writing_days', 'writing_days_reverse', \n",
    "            'depression_mention', 'diagnosis'] + emotions + [c for c in set(categories) if c in df.columns]\n",
    "    ].groupby(date_field).mean()[emotion].rolling(rolling_window).mean()\n",
    "#                                 ].apply(lambda c: np.log(c) if c>0 else 0\n",
    "#                                        ).rolling(rolling_window).mean().plot(label=label)\n",
    "\n",
    "\n",
    "# emo = 'positive'\n",
    "# days = datetime.datetime.strptime('2000','%Y').date()\n",
    "days = 5000\n",
    "evolution_df_pos = pd.DataFrame()\n",
    "evolution_df_pos['anger'] = pd.Series()\n",
    "evolution_df_pos['positive'] = get_evolution_series(writings_df[writings_df['label']==1], 'positive', days, 100, 'writing_days')\n",
    "evolution_df_pos['negative'] = get_evolution_series(writings_df[writings_df['label']==1], 'negative', days, 100, 'writing_days')\n",
    "for emo in emotions[1:]:\n",
    "    evolution = get_evolution_series(writings_df[writings_df['label']==1], emo, days, 100, 'writing_days')\n",
    "    evolution_df_pos[emo] = evolution\n",
    "for emo in categories:\n",
    "    evolution = get_evolution_series(writings_df[writings_df['label']==1], emo, days, 100, 'writing_days')\n",
    "    try:\n",
    "        evolution_df_pos[emo] = evolution\n",
    "    except:\n",
    "        print(emo)\n",
    "        \n",
    "evolution_df_neg = pd.DataFrame()\n",
    "evolution_df_neg['anger'] = pd.Series()\n",
    "evolution_df_neg['positive'] = get_evolution_series(writings_df[writings_df['label']==0], 'positive', days, 100, 'writing_days')\n",
    "evolution_df_neg['negative'] = get_evolution_series(writings_df[writings_df['label']==0], 'negative', days, 100, 'writing_days')\n",
    "for emo in emotions[1:]:\n",
    "    evolution = get_evolution_series(writings_df[writings_df['label']==0], emo, days, 100, 'writing_days')\n",
    "    evolution_df_neg[emo] = evolution\n",
    "for emo in categories:\n",
    "    evolution = get_evolution_series(writings_df[writings_df['label']==0], emo, days, 100, 'writing_days')\n",
    "    try:\n",
    "        evolution_df_neg[emo] = evolution\n",
    "    except Exception as e:\n",
    "        print(emo, e)\n",
    "# evolution_df_pos.corr()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evolution_df_pos.negative.rolling(5).mean().plot(label='negative')\n",
    "evolution_df_pos.cause.rolling(5).mean().plot(label='cause')\n",
    "evolution_df_pos.positive.rolling(5).mean().plot(label='positive')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import pearsonr, spearmanr\n",
    "\n",
    "def calculate_pvalues(df, method='pearson'):\n",
    "    df = df.dropna()._get_numeric_data()\n",
    "    dfcols = pd.DataFrame(columns=df.columns)\n",
    "    pvalues = dfcols.transpose().join(dfcols, how='outer')\n",
    "    for r in df.columns:\n",
    "        for c in df.columns:\n",
    "            if method=='pearson':\n",
    "                pvalues[r][c] = round(pearsonr(df[r], df[c])[1], 4)\n",
    "            elif method=='spearman':\n",
    "                pvalues[r][c] = round(spearmanr(df[r], df[c])[1], 4)\n",
    "                \n",
    "    return pvalues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evolution_df_pos.corr('spearman')[['positive', 'negative'] + [e for e in emotions if e not in ['positive', 'negative', 'anger']]\n",
    "                       ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evolution_pos_correlations = evolution_df_pos.corr('pearson')[['positive', 'negative'] + [e for e in emotions if e not in ['positive', 'negative']]]\n",
    "evolution_neg_correlations = evolution_df_neg.corr('pearson')[['positive', 'negative'] + [e for e in emotions if e not in ['positive', 'negative']]]\n",
    "evolution_pos_correlations = evolution_pos_correlations.rename(columns={c: c+\"_ptsd\" for c in evolution_pos_correlations.columns})\n",
    "evolution_neg_correlations = evolution_neg_correlations.rename(columns={c: c+\"_notptsd\" for c in evolution_neg_correlations.columns})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evolution_pos_pvalues = calculate_pvalues(evolution_df_pos, 'pearson')[['positive', 'negative'] + [e for e in emotions if e not in ['positive', 'negative']]]\n",
    "evolution_neg_pvalues = calculate_pvalues(evolution_df_neg, 'pearson')[['positive', 'negative'] + [e for e in emotions if e not in ['positive', 'negative']]]\n",
    "evolution_pos_pvalues = evolution_pos_pvalues.rename(columns={c: c+\"_ptsd_pval\" for c in evolution_pos_pvalues.columns})\n",
    "evolution_neg_pvalues = evolution_neg_pvalues.rename(columns={c: c+\"_notptsd_pval\" for c in evolution_neg_pvalues.columns})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evolution_df = pd.concat([evolution_pos_correlations, evolution_neg_correlations], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evolution_df_pvals = pd.concat([evolution_pos_pvalues, evolution_neg_pvalues], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evolution_df['diff'] = evolution_df.apply(lambda x: abs(x['negative_depr'] - x['negative_notdepr']), axis=1)\n",
    "# evolution_df.sort_values('diff', ascending=False)\n",
    "evolution_df = pd.concat([evolution_df, evolution_df_pvals], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evolution_df.drop([e for e in emotions], inplace=True)\n",
    "evolution_df_pvals.drop([e for e in emotions], inplace=True)\n",
    "# evolution_df.drop(columns=['diff'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evolution_df=evolution_df.combine(evolution_df_pvals, func=lambda x, y: x.astype(str)+\",\"+y.astype(str))\n",
    "emotion_columns = ['positive', 'negative'] + [e for e in emotions if e not in ['positive', 'negative']]\n",
    "evolution_df = evolution_df[sum([[e + \"_ptsd\", e + \"_ptsd_pval\"\n",
    "                                 ] for e in emotion_columns], []\n",
    "                               ) + sum([[e + \"_notptsd\", e + \"_notptsd_pval\"\n",
    "                                 ] for e in emotion_columns], [])\n",
    "                                ]\n",
    "evolution_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evolution_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"evolution_correlations_selfharm_vsnot_erisk_rolling100_pearson_withpvalues.csv\", \"w+\") as f:\n",
    "    f.write(evolution_df.to_csv())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare correlations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from CorrelationStats.corrstats import independent_corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_sample_size = len(evolution_df_pos.index)\n",
    "neg_sample_size = len(evolution_df_neg.index)\n",
    "print(pos_sample_size, neg_sample_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in emotions:\n",
    "    evolution_df['%s_diff_zval' % col] = evolution_df.apply(\n",
    "        lambda x: round(\n",
    "            independent_corr(x['%s_selfharm' % col], x['%s_notselfharm' % col], pos_sample_size, neg_sample_size)[0], 4),\n",
    "    axis=1)\n",
    "    evolution_df['%s_diff_pval' % col] = evolution_df.apply(\n",
    "        lambda x: round(\n",
    "            independent_corr(x['%s_selfharm' % col], x['%s_notselfharm' % col], pos_sample_size, neg_sample_size)[1], 4),\n",
    "    axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evolution_df[['negative_selfharm', 'negative_notselfharm', 'negative_diff_zval', 'negative_diff_pval']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort columns\n",
    "emotion_columns = ['positive', 'negative'] + [e for e in emotions if e not in ['positive', 'negative']]\n",
    "evolution_df = evolution_df[sum([[e + \"_selfharm\", e + \"_selfharm_pval\", \n",
    "                                 ] for e in emotion_columns], []\n",
    "                               ) + sum([[e + \"_notselfharm\", e + \"_notselfharm_pval\", e + \"_diff_zval\", e + \"_diff_pval\"\n",
    "                                 ] for e in emotion_columns], [])\n",
    "                                ]\n",
    "evolution_df\n",
    "evolution_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"evolution_correlations_selfharm_vsnot_erisk_rolling100_pearson_with_diffsignificance.csv\", \"w+\") as f:\n",
    "    f.write(evolution_df.to_csv())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topics_emotions_significance = {}\n",
    "for emotion in emotions:\n",
    "    topics_emotions_significance[emotion] = {\n",
    "        'significant': \", \".join(evolution_df[evolution_df[emotion + \"_diff_pval\"] < 0.005].index.values),\n",
    "        'not significant': \", \".join(evolution_df[evolution_df[emotion + \"_diff_pval\"] >= 0.005].index.values)\n",
    "    }\n",
    "\n",
    "with open(\"selfharm_notselfharm_significant_differences.csv\", \"w+\") as f:\n",
    "    f.write(pd.DataFrame.from_dict(topics_emotions_significance).to_csv())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Co-occurrence / prevalence analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming probabilities that 2 categories occur in a text are independent\n",
    "# Even though some categories have some common words..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categories1 = ['cause', 'certain']\n",
    "categories2 = ['negative', 'positive']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# categories1 = categories\n",
    "# categories2 = ['negative', 'positive']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### At text level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "writings_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_pmis(df, categories1, categories2):\n",
    "    # Compute joint probabilities\n",
    "    for cat1 in categories1:\n",
    "        for cat2 in categories2:\n",
    "            df[cat1 + \"_\" + cat2] = df.apply(lambda x: x[cat1] * x[cat2], axis=1)\n",
    "    # Compute pmi\n",
    "    pmis = {}\n",
    "    for cat1 in categories1:\n",
    "        for cat2 in categories2:\n",
    "            pmis[(cat1, cat2)] = np.log(df[cat1 + \"_\" + cat2].mean() / (df[cat1].mean() * df[cat2].mean()))\n",
    "            \n",
    "    return pmis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "writings_df_training = writings_df[writings_df['subset']=='train']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "writings_df_training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "pmis_positive = compute_pmis(writings_df_training[writings_df_training['label']==1], categories1=categories, categories2=emotions)\n",
    "pmis_negative = compute_pmis(writings_df_training[writings_df_training['label']==0], categories1=categories, categories2=emotions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open(\"pmis_depressed_training.pkl\", \"wb+\") as f:\n",
    "#     pickle.dump(pmis_positive, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[i for i in pmis_positive.items() if i[1] > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pmis_negative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open(\"pmis_notdepressed_training.pkl\", \"wb+\") as f:\n",
    "#     pickle.dump(pmis_negative, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[i for i in pmis_negative.items() if i[1] > 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pmis_per_subject_positive = {}\n",
    "for subject in set(writings_df[writings_df['label']==1].subject):\n",
    "    pmis_positive = compute_pmis(writings_df[writings_df['subject']==subject],\n",
    "                                 categories, emotions)\n",
    "    pmis_per_subject_positive[subject] = pmis_positive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Series([t[('certain', 'negative')] \n",
    "           for (s, t) in pmis_per_subject_positive.items()\n",
    "           if t[('certain', 'negative')]>0 \n",
    "          ]).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open(\"pmis_depressed_persubject.part.pkl\", \"wb+\") as f:\n",
    "#     pickle.dump(pmis_per_subject_positive, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pmis_per_subject_negative = {}\n",
    "for subject in set(writings_df[writings_df['label']==0].subject):\n",
    "    pmis_negative = compute_pmis(writings_df[writings_df['subject']==subject],\n",
    "                                 categories, emotions)\n",
    "    pmis_per_subject_negative[subject] = pmis_negative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open(\"pmis_notdepressed_persubject.pkl\", \"wb+\") as f:\n",
    "#     pickle.dump(pmis_per_subject_negative, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### At day level (same day same user)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "writings_df.groupby(['writing_days', 'subject']).mean()[['negative', 'positive']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pmis_positive_days = compute_pmis(writings_df_training[writings_df_training['label']==1].groupby(['date_day', 'subject']).mean(),\n",
    "                                 categories, emotions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pmis_negative_days = compute_pmis(writings_df_training[writings_df_training['label']==0].groupby(['date_day', 'subject']).mean(),\n",
    "                                                                  categories, emotions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[pmis_positive_days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pmis_negative_days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open(\"pmis_depressed_perday_training.pkl\", \"wb+\") as f:\n",
    "#     pickle.dump(pmis_positive_days, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open(\"pmis_notdepressed_perday_training.pkl\", \"wb+\") as f:\n",
    "#     pickle.dump(pmis_negative_days, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pmis_per_subject_positive = {}\n",
    "for subject in set(writings_df[writings_df['label']==1].subject):\n",
    "    pmis_positive_days = compute_pmis(writings_df[writings_df['subject']==subject].groupby(['date_day', 'subject']).mean(),\n",
    "                                 categories, emotions)\n",
    "    pmis_per_subject_positive[subject] = pmis_positive_days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open(\"pmis_depressed_persubject_perday.pkl\", \"wb+\") as f:\n",
    "#     pickle.dump(pmis_per_subject_positive, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pmis_per_subject_negative = {}\n",
    "for subject in set(writings_df[writings_df['label']==0].subject):\n",
    "    pmis_negative_days = compute_pmis(writings_df[writings_df['subject']==subject].groupby(['date_day', 'subject']).mean(),\n",
    "                                 categories, emotions)\n",
    "    pmis_per_subject_negative[subject] = pmis_negative_days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open(\"pmis_notdepressed_persubject_perday.pkl\", \"wb+\") as f:\n",
    "#     pickle.dump(pmis_per_subject_negative, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_pmis_cause = 0\n",
    "positive_pmis_certain = 0\n",
    "avg_pmi_cause = 0\n",
    "avg_pmi_certain = 0\n",
    "all_pmis_negative_cause = []\n",
    "all_pmis_negative_certain = []\n",
    "for subject, pmis in pmis_per_subject_negative.items():\n",
    "    print(subject, [p for p in pmis.items() if p[1]>0 and p[0][1]=='negative' \n",
    "                    and p[0][0] in ['cause', 'certain']])\n",
    "    positive_pmis_cause += len([p for p in pmis.items() if p[1]>0 and p[0][1]=='negative' \n",
    "                    and p[0][0] == 'cause'])\n",
    "    positive_pmis_certain += len([p for p in pmis.items() if p[1]>0 and p[0][1]=='negative' \n",
    "                    and p[0][0] == 'certain'])\n",
    "    try:\n",
    "        avg_pmi_cause += [p[1] for p in pmis.items() if p[1]>0 and p[0][1]=='negative' \n",
    "                    and p[0][0] == 'cause'][0]\n",
    "        all_pmis_negative_cause.append([p[1] for p in pmis.items() if p[1]>0 and p[0][1]=='negative' \n",
    "                    and p[0][0] == 'cause'][0])\n",
    "    except:\n",
    "        all_pmis_negative_cause.append(0)\n",
    "\n",
    "        pass\n",
    "    try:\n",
    "        avg_pmi_certain += [p[1] for p in pmis.items() if p[1]>0 and p[0][1]=='negative' \n",
    "                    and p[0][0] == 'certain'][0]\n",
    "        all_pmis_negative_certain.append([p[1] for p in pmis.items() if p[1]>0 and p[0][1]=='negative' \n",
    "                    and p[0][0] == 'certain'][0])\n",
    "    except:\n",
    "        all_pmis_negative_certain.append(0)\n",
    "\n",
    "        pass\n",
    "print(positive_pmis_cause/len(pmis_per_subject_negative))\n",
    "print(positive_pmis_certain/len(pmis_per_subject_negative))\n",
    "print(avg_pmi_cause/len(pmis_per_subject_negative))\n",
    "print(avg_pmi_certain/len(pmis_per_subject_negative))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_pmis_cause = 0\n",
    "positive_pmis_certain = 0\n",
    "all_pmis_positive_cause = []\n",
    "all_pmis_positive_certain = []\n",
    "avg_pmi_cause = 0\n",
    "avg_pmi_certain = 0\n",
    "for subject, pmis in pmis_per_subject_positive.items():\n",
    "    print(subject, [p for p in pmis.items() if p[1]>0 and p[0][1]=='negative' \n",
    "                    and p[0][0] in ['cause', 'certain']])\n",
    "    positive_pmis_cause += len([p for p in pmis.items() if p[1]>0 and p[0][1]=='negative' \n",
    "                    and p[0][0] == 'cause'])\n",
    "    positive_pmis_certain += len([p for p in pmis.items() if p[1]>0 and p[0][1]=='negative' \n",
    "                    and p[0][0] == 'certain'])\n",
    "    try:\n",
    "        avg_pmi_cause += [p[1] for p in pmis.items() if p[1]>0 and p[0][1]=='negative' \n",
    "                    and p[0][0] == 'cause'][0]\n",
    "        all_pmis_positive_cause.append([p[1] for p in pmis.items() if p[1]>0 and p[0][1]=='negative' \n",
    "                    and p[0][0] == 'cause'][0])\n",
    "    except:\n",
    "        all_pmis_positive_cause.append(0)\n",
    "        pass\n",
    "    try:\n",
    "        avg_pmi_certain += [p[1] for p in pmis.items() if p[1]>0 and p[0][1]=='negative' \n",
    "                    and p[0][0] == 'certain'][0]\n",
    "        all_pmis_positive_certain.append([p[1] for p in pmis.items() if p[1]>0 and p[0][1]=='negative' \n",
    "                    and p[0][0] == 'certain'][0])\n",
    "    except:\n",
    "        all_pmis_positive_certain.append(0)\n",
    "\n",
    "        pass\n",
    "print(positive_pmis_cause/len(pmis_per_subject_positive))\n",
    "print(positive_pmis_certain/len(pmis_per_subject_positive))\n",
    "print(avg_pmi_cause/len(pmis_per_subject_positive))\n",
    "print(avg_pmi_certain/len(pmis_per_subject_positive))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Series(all_pmis_positive_cause).hist(alpha=0.5, label = 'depressed', bins=30)\n",
    "pd.Series(all_pmis_negative_cause).hist(alpha=0.5, label = 'not depressed', bins=40)\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.Series(all_pmis_positive_cause).describe()\n",
    "pd.Series(all_pmis_negative_cause).describe()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Series(all_pmis_positive_certain).hist(alpha=0.5, label = 'depressed', bins=30, log=True)\n",
    "pd.Series(all_pmis_negative_certain).hist(alpha=0.5, label = 'not depressed', bins=30, log=True)\n",
    "plt.xlabel(\"Co-occurrence scores certain-negative\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Series(all_pmis_positive_cause).hist(alpha=0.5, label = 'depressed', bins=30, log=True)\n",
    "pd.Series(all_pmis_negative_cause).hist(alpha=0.5, label = 'not depressed', bins=30, log=True)\n",
    "plt.xlabel(\"Co-occurrence scores cause-negative\")\n",
    "\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Series(all_pmis_negative_certain + all_pmis_positive_certain).hist(bins=30)\n",
    "# pd.Series(all_pmis_negative_certain).hist(bins=30)\n",
    "# pd.Series(all_pmis_positive_certain).hist(bins=30)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.Series(all_pmis_negative_cause + all_pmis_positive_cause).hist(bins=30)\n",
    "pd.Series(all_pmis_positive_cause).hist(bins=30)\n",
    "# pd.Series(all_pmis_negative_cause).hist(bins=30)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf2conda",
   "language": "python",
   "name": "tf2conda"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
