{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import xml.etree.ElementTree as ET\n",
    "import glob, os\n",
    "import numpy as np\n",
    "from comet_ml import Experiment, Optimizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import numpy as np\n",
    "\n",
    "from tensorflow.keras.preprocessing import sequence\n",
    "from tensorflow.keras.models import Sequential, Model, load_model\n",
    "from tensorflow.keras.layers import Dense, Dropout, Embedding, LSTM, Bidirectional, Input, concatenate\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras import callbacks\n",
    "from tensorflow.keras import backend as K\n",
    "\n",
    "from nltk.tokenize import RegexpTokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "datadir_T1 = '/home/ana/eRisk/data/eRisk2020_T1_train/eRISK2020_T1_training_data/eRISK2020_training_data/data/'\n",
    "labels_file_T1 = '/home/ana/eRisk/data/eRisk2020_T1_train/eRISK2020_T1_training_data/eRISK2020_training_data/golden_truth.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_T1 = pd.read_csv(labels_file_T1, delimiter=' ', names=['subject', 'label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f3c9c40c490>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "labels_T1.label.hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>subject</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>subject671</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>subject9917</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>subject6238</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>subject8581</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>subject7238</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>subject2182</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>subject9829</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>subject3270</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>subject6464</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>subject8721</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>340 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             label\n",
       "subject           \n",
       "subject671       1\n",
       "subject9917      1\n",
       "subject6238      1\n",
       "subject8581      1\n",
       "subject7238      1\n",
       "...            ...\n",
       "subject2182      0\n",
       "subject9829      0\n",
       "subject3270      0\n",
       "subject6464      0\n",
       "subject8721      0\n",
       "\n",
       "[340 rows x 1 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_T1 = labels_T1.set_index('subject')\n",
    "labels_T1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "subject8292.xml\n",
      "subject6644.xml\n",
      "subject7982.xml\n",
      "subject9260.xml\n",
      "subject9918.xml\n",
      "subject4284.xml\n",
      "subject9829.xml\n",
      "subject7661.xml\n",
      "subject8361.xml\n",
      "subject4831.xml\n",
      "subject2181.xml\n",
      "subject9077.xml\n",
      "subject2922.xml\n",
      "subject2238.xml\n",
      "subject4513.xml\n",
      "subject269.xml\n",
      "subject2678.xml\n",
      "subject9197.xml\n",
      "subject4143.xml\n",
      "subject2605.xml\n",
      "subject4226.xml\n",
      "subject7627.xml\n",
      "subject5150.xml\n",
      "subject4510.xml\n",
      "subject2182.xml\n",
      "subject280.xml\n",
      "subject1105.xml\n",
      "subject187.xml\n",
      "subject8001.xml\n",
      "subject9285.xml\n",
      "subject2621.xml\n",
      "subject4414.xml\n",
      "subject2685.xml\n",
      "subject9961.xml\n",
      "subject8065.xml\n",
      "subject8225.xml\n",
      "subject6866.xml\n",
      "subject9949.xml\n",
      "subject1507.xml\n",
      "subject8329.xml\n",
      "subject9411.xml\n",
      "subject7857.xml\n",
      "subject1545.xml\n",
      "subject9811.xml\n",
      "subject5000.xml\n",
      "subject4843.xml\n",
      "subject569.xml\n",
      "subject51.xml\n",
      "subject9156.xml\n",
      "subject6453.xml\n",
      "subject1210.xml\n",
      "subject5528.xml\n",
      "subject1485.xml\n",
      "subject5935.xml\n",
      "subject4527.xml\n",
      "subject3301.xml\n",
      "subject4074.xml\n",
      "subject6093.xml\n",
      "subject2088.xml\n",
      "subject8990.xml\n",
      "subject6459.xml\n",
      "subject7830.xml\n",
      "subject8395.xml\n",
      "subject4247.xml\n",
      "subject3667.xml\n",
      "subject5003.xml\n",
      "subject992.xml\n",
      "subject5644.xml\n",
      "subject242.xml\n",
      "subject7764.xml\n",
      "subject3283.xml\n",
      "subject6322.xml\n",
      "subject7678.xml\n",
      "subject6668.xml\n",
      "subject4333.xml\n",
      "subject1288.xml\n",
      "subject8200.xml\n",
      "subject5383.xml\n",
      "subject9039.xml\n",
      "subject7698.xml\n",
      "subject9652.xml\n",
      "subject5223.xml\n",
      "subject9725.xml\n",
      "subject1512.xml\n",
      "subject3994.xml\n",
      "subject7018.xml\n",
      "subject3644.xml\n",
      "subject1786.xml\n",
      "subject1027.xml\n",
      "subject8094.xml\n",
      "subject974.xml\n",
      "subject2947.xml\n",
      "subject9575.xml\n",
      "subject4570.xml\n",
      "subject5062.xml\n",
      "subject4729.xml\n",
      "subject5100.xml\n",
      "subject5177.xml\n",
      "subject505.xml\n",
      "subject5974.xml\n",
      "subject7499.xml\n",
      "subject1264.xml\n",
      "subject4071.xml\n",
      "subject7740.xml\n",
      "subject8721.xml\n",
      "subject9222.xml\n",
      "subject8432.xml\n",
      "subject2547.xml\n",
      "subject5995.xml\n",
      "subject6930.xml\n",
      "subject8472.xml\n",
      "subject6918.xml\n",
      "subject4198.xml\n",
      "subject501.xml\n",
      "subject7777.xml\n",
      "subject5375.xml\n",
      "subject7229.xml\n",
      "subject4762.xml\n",
      "subject5622.xml\n",
      "subject7637.xml\n",
      "subject47.xml\n",
      "subject1962.xml\n",
      "subject8795.xml\n",
      "subject4785.xml\n",
      "subject5840.xml\n",
      "subject3014.xml\n",
      "subject6464.xml\n",
      "subject522.xml\n",
      "subject5984.xml\n",
      "subject641.xml\n",
      "subject7326.xml\n",
      "subject4227.xml\n",
      "subject7428.xml\n",
      "subject203.xml\n",
      "subject6946.xml\n",
      "subject4563.xml\n",
      "subject682.xml\n",
      "subject9014.xml\n",
      "subject7435.xml\n",
      "subject8626.xml\n",
      "subject4459.xml\n",
      "subject733.xml\n",
      "subject7238.xml\n",
      "subject6428.xml\n",
      "subject7262.xml\n",
      "subject0.xml\n",
      "subject2269.xml\n",
      "subject8233.xml\n",
      "subject2522.xml\n",
      "subject5456.xml\n",
      "subject1064.xml\n",
      "subject8822.xml\n",
      "subject5033.xml\n",
      "subject1089.xml\n",
      "subject3277.xml\n",
      "subject5549.xml\n",
      "subject6352.xml\n",
      "subject6652.xml\n",
      "subject7669.xml\n",
      "subject5833.xml\n",
      "subject4795.xml\n",
      "subject4002.xml\n",
      "subject5878.xml\n",
      "subject1524.xml\n",
      "subject3928.xml\n",
      "subject9318.xml\n",
      "subject2935.xml\n",
      "subject1093.xml\n",
      "subject6786.xml\n",
      "subject3612.xml\n",
      "subject9114.xml\n",
      "subject4719.xml\n",
      "subject7439.xml\n",
      "subject1623.xml\n",
      "subject6290.xml\n",
      "subject8973.xml\n",
      "subject3844.xml\n",
      "subject7898.xml\n",
      "subject3605.xml\n",
      "subject2097.xml\n",
      "subject9381.xml\n",
      "subject3178.xml\n",
      "subject5908.xml\n",
      "subject3191.xml\n",
      "subject4196.xml\n",
      "subject8882.xml\n",
      "subject8845.xml\n",
      "subject5256.xml\n",
      "subject7318.xml\n",
      "subject4777.xml\n",
      "subject6309.xml\n",
      "subject4479.xml\n",
      "subject9393.xml\n",
      "subject4961.xml\n",
      "subject6247.xml\n",
      "subject1055.xml\n",
      "subject4644.xml\n",
      "subject7338.xml\n",
      "subject6284.xml\n",
      "subject5699.xml\n",
      "subject2580.xml\n",
      "subject2446.xml\n",
      "subject5409.xml\n",
      "subject1914.xml\n",
      "subject7263.xml\n",
      "subject5148.xml\n",
      "subject1793.xml\n",
      "subject9729.xml\n",
      "subject7952.xml\n",
      "subject9917.xml\n",
      "subject3868.xml\n",
      "subject5793.xml\n",
      "subject4934.xml\n",
      "subject3674.xml\n",
      "subject6019.xml\n",
      "subject2974.xml\n",
      "subject2857.xml\n",
      "subject855.xml\n",
      "subject5937.xml\n",
      "subject671.xml\n",
      "subject4318.xml\n",
      "subject5112.xml\n",
      "subject9249.xml\n",
      "subject7107.xml\n",
      "subject2996.xml\n",
      "subject5603.xml\n",
      "subject511.xml\n",
      "subject6518.xml\n",
      "subject5140.xml\n",
      "subject3737.xml\n",
      "subject9095.xml\n",
      "subject3227.xml\n",
      "subject7355.xml\n",
      "subject1617.xml\n",
      "subject6670.xml\n",
      "subject5387.xml\n",
      "subject3883.xml\n",
      "subject6146.xml\n",
      "subject2949.xml\n",
      "subject1763.xml\n",
      "subject2980.xml\n",
      "subject8933.xml\n",
      "subject6833.xml\n",
      "subject8802.xml\n",
      "subject8657.xml\n",
      "subject6259.xml\n",
      "subject1947.xml\n",
      "subject3635.xml\n",
      "subject8978.xml\n",
      "subject6423.xml\n",
      "subject1748.xml\n",
      "subject4702.xml\n",
      "subject8062.xml\n",
      "subject3555.xml\n",
      "subject2577.xml\n",
      "subject2475.xml\n",
      "subject8357.xml\n",
      "subject9492.xml\n",
      "subject3914.xml\n",
      "subject2495.xml\n",
      "subject7581.xml\n",
      "subject3725.xml\n",
      "subject6173.xml\n",
      "subject2247.xml\n",
      "subject8481.xml\n",
      "subject7946.xml\n",
      "subject7131.xml\n",
      "subject4848.xml\n",
      "subject747.xml\n",
      "subject5270.xml\n",
      "subject5979.xml\n",
      "subject6041.xml\n",
      "subject1950.xml\n",
      "subject7333.xml\n",
      "subject7247.xml\n",
      "subject814.xml\n",
      "subject5938.xml\n",
      "subject9160.xml\n",
      "subject6238.xml\n",
      "subject6957.xml\n",
      "subject8770.xml\n",
      "subject9497.xml\n",
      "subject807.xml\n",
      "subject6899.xml\n",
      "subject4014.xml\n",
      "subject2696.xml\n",
      "subject1885.xml\n",
      "subject8064.xml\n",
      "subject8081.xml\n",
      "subject2690.xml\n",
      "subject7462.xml\n",
      "subject8193.xml\n",
      "subject4526.xml\n",
      "subject7316.xml\n",
      "subject7290.xml\n",
      "subject463.xml\n",
      "subject4379.xml\n",
      "subject3181.xml\n",
      "subject5920.xml\n",
      "subject1728.xml\n",
      "subject2567.xml\n",
      "subject3904.xml\n",
      "subject4392.xml\n",
      "subject8581.xml\n",
      "subject9242.xml\n",
      "subject379.xml\n",
      "subject3881.xml\n",
      "subject8565.xml\n",
      "subject4505.xml\n",
      "subject3977.xml\n",
      "subject7489.xml\n",
      "subject2948.xml\n",
      "subject5342.xml\n",
      "subject8544.xml\n",
      "subject6903.xml\n",
      "subject7377.xml\n",
      "subject8769.xml\n",
      "subject3270.xml\n",
      "subject3224.xml\n",
      "subject2239.xml\n",
      "subject7801.xml\n",
      "subject3596.xml\n",
      "subject1469.xml\n",
      "subject4278.xml\n",
      "subject5282.xml\n",
      "subject3357.xml\n",
      "subject6013.xml\n",
      "subject5036.xml\n",
      "subject796.xml\n",
      "subject7692.xml\n",
      "subject7560.xml\n",
      "subject6035.xml\n",
      "subject1824.xml\n",
      "subject8726.xml\n",
      "subject6665.xml\n",
      "subject835.xml\n",
      "subject3117.xml\n",
      "subject519.xml\n",
      "subject1655.xml\n",
      "subject217.xml\n"
     ]
    }
   ],
   "source": [
    "writings = []\n",
    "for subject_file in os.listdir(datadir_T1):\n",
    "    print(subject_file)\n",
    "    with open(os.path.join(datadir_T1, subject_file)) as sf:\n",
    "        contents = sf.read()\n",
    "        root = ET.fromstring(contents)\n",
    "        try:\n",
    "            subject = root.findall('ID')[0].text\n",
    "        except Exception:\n",
    "            print('Cannot extract ID', contents[:500], '\\n-------\\n')        \n",
    "        for w in root.iter('WRITING'):\n",
    "            subject_writings = {'subject': subject}\n",
    "            for title in w.findall('TITLE'):\n",
    "                subject_writings['title'] = title.text\n",
    "            for text in w.findall('TEXT'):\n",
    "                subject_writings['text'] = text.text\n",
    "            for date in w.findall('DATE'):\n",
    "                subject_writings['date'] = date.text\n",
    "            writings.append(subject_writings)\n",
    "            # TODO: Date\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "writings_df = pd.DataFrame(writings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subject</th>\n",
       "      <th>title</th>\n",
       "      <th>date</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>subject8292</td>\n",
       "      <td>If anyone could help with which sub to put thi...</td>\n",
       "      <td>2016-08-02 09:22:12</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>subject8292</td>\n",
       "      <td>I'm literally never gonna stop waiting...</td>\n",
       "      <td>2016-08-05 09:35:55</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>subject8292</td>\n",
       "      <td>This is a really interesting study! Makes sens...</td>\n",
       "      <td>2016-08-05 21:36:24</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>subject8292</td>\n",
       "      <td>The only thing Frank is building ...</td>\n",
       "      <td>2016-08-07 23:35:23</td>\n",
       "      <td>... Is hype. Think about it, every time he wor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>subject8292</td>\n",
       "      <td>Mostly always me during this whole charade</td>\n",
       "      <td>2016-08-09 08:39:41</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170693</th>\n",
       "      <td>subject217</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2018-08-19 11:29:21</td>\n",
       "      <td>this is my personal experience ,it may not ref...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170694</th>\n",
       "      <td>subject217</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2018-08-19 16:17:34</td>\n",
       "      <td>stop looking at 20 million saudis as one entit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170695</th>\n",
       "      <td>subject217</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2018-08-19 20:00:31</td>\n",
       "      <td>i am aware of stats now and then. i was just s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170696</th>\n",
       "      <td>subject217</td>\n",
       "      <td>WHAT DID YOU SAY TO ME?</td>\n",
       "      <td>2018-08-20 10:54:11</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170697</th>\n",
       "      <td>subject217</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2018-08-20 12:07:44</td>\n",
       "      <td>me smellz fish,me find no fish!...what the fuc...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>170698 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            subject                                              title  \\\n",
       "0       subject8292  If anyone could help with which sub to put thi...   \n",
       "1       subject8292          I'm literally never gonna stop waiting...   \n",
       "2       subject8292  This is a really interesting study! Makes sens...   \n",
       "3       subject8292               The only thing Frank is building ...   \n",
       "4       subject8292         Mostly always me during this whole charade   \n",
       "...             ...                                                ...   \n",
       "170693   subject217                                                NaN   \n",
       "170694   subject217                                                NaN   \n",
       "170695   subject217                                                NaN   \n",
       "170696   subject217                            WHAT DID YOU SAY TO ME?   \n",
       "170697   subject217                                                NaN   \n",
       "\n",
       "                       date                                               text  \n",
       "0       2016-08-02 09:22:12                                                NaN  \n",
       "1       2016-08-05 09:35:55                                                NaN  \n",
       "2       2016-08-05 21:36:24                                                NaN  \n",
       "3       2016-08-07 23:35:23  ... Is hype. Think about it, every time he wor...  \n",
       "4       2016-08-09 08:39:41                                                NaN  \n",
       "...                     ...                                                ...  \n",
       "170693  2018-08-19 11:29:21  this is my personal experience ,it may not ref...  \n",
       "170694  2018-08-19 16:17:34  stop looking at 20 million saudis as one entit...  \n",
       "170695  2018-08-19 20:00:31  i am aware of stats now and then. i was just s...  \n",
       "170696  2018-08-20 10:54:11                                                NaN  \n",
       "170697  2018-08-20 12:07:44  me smellz fish,me find no fish!...what the fuc...  \n",
       "\n",
       "[170698 rows x 4 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "writings_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "writings_df['label'] = writings_df['subject'].apply(\n",
    "    lambda s: labels_T1.loc[s, 'label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f3c9ba80890>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "writings_df.label.hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = RegexpTokenizer(r'\\w+')\n",
    "\n",
    "def tokenize(t):\n",
    "    return tokenizer.tokenize(t.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i', 'wasn', 't', 'ready', 'to', 'leave', 'buh', 'buw', 'dd', 'sasa']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenize(\"I wasn't ready to leave! buh-buw(dd). Sasa .\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "writings_df['tokenized_title'] = writings_df['title'].apply(lambda t: tokenize(t) if type(t)==str else np.nan)\n",
    "writings_df['title_len'] = writings_df['tokenized_title'].apply(lambda t: len(t) if type(t)==list else np.nan)\n",
    "writings_df['tokenized_text'] = writings_df['text'].apply(lambda t: tokenize(t) if type(t)==str else np.nan)\n",
    "writings_df['text_len'] = writings_df['tokenized_text'].apply(lambda t: len(t) if type(t)==list else np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    127941.000000\n",
       "mean         32.268929\n",
       "std          82.590713\n",
       "min           0.000000\n",
       "25%           6.000000\n",
       "50%          13.000000\n",
       "75%          31.000000\n",
       "max        7201.000000\n",
       "Name: text_len, dtype: float64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "writings_df.text_len.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    49762.000000\n",
       "mean        10.699771\n",
       "std          9.282454\n",
       "min          0.000000\n",
       "25%          4.000000\n",
       "50%          8.000000\n",
       "75%         14.000000\n",
       "max        149.000000\n",
       "Name: title_len, dtype: float64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "writings_df.title_len.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>title_len</th>\n",
       "      <th>text_len</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>subject</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>subject0</th>\n",
       "      <td>0</td>\n",
       "      <td>20.285714</td>\n",
       "      <td>31.711712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>subject1027</th>\n",
       "      <td>0</td>\n",
       "      <td>7.769231</td>\n",
       "      <td>1.190476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>subject1055</th>\n",
       "      <td>0</td>\n",
       "      <td>16.666667</td>\n",
       "      <td>79.983193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>subject1064</th>\n",
       "      <td>1</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>68.410256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>subject1089</th>\n",
       "      <td>0</td>\n",
       "      <td>9.823529</td>\n",
       "      <td>13.254902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>subject9917</th>\n",
       "      <td>1</td>\n",
       "      <td>8.983607</td>\n",
       "      <td>95.806897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>subject9918</th>\n",
       "      <td>0</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>11.865269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>subject992</th>\n",
       "      <td>0</td>\n",
       "      <td>5.872928</td>\n",
       "      <td>19.876190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>subject9949</th>\n",
       "      <td>0</td>\n",
       "      <td>10.609756</td>\n",
       "      <td>42.346979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>subject9961</th>\n",
       "      <td>0</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>26.389313</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>340 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             label  title_len   text_len\n",
       "subject                                 \n",
       "subject0         0  20.285714  31.711712\n",
       "subject1027      0   7.769231   1.190476\n",
       "subject1055      0  16.666667  79.983193\n",
       "subject1064      1  13.000000  68.410256\n",
       "subject1089      0   9.823529  13.254902\n",
       "...            ...        ...        ...\n",
       "subject9917      1   8.983607  95.806897\n",
       "subject9918      0   5.000000  11.865269\n",
       "subject992       0   5.872928  19.876190\n",
       "subject9949      0  10.609756  42.346979\n",
       "subject9961      0   5.000000  26.389313\n",
       "\n",
       "[340 rows x 3 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "writings_df.groupby('subject').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subject</th>\n",
       "      <th>title</th>\n",
       "      <th>date</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>tokenized_title</th>\n",
       "      <th>title_len</th>\n",
       "      <th>tokenized_text</th>\n",
       "      <th>text_len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>subject8292</td>\n",
       "      <td>Okay friends so I messed up and posted to do a...</td>\n",
       "      <td>2017-04-25 22:37:57</td>\n",
       "      <td>Sorry for that, I truly didn't think it was go...</td>\n",
       "      <td>0</td>\n",
       "      <td>[okay, friends, so, i, messed, up, and, posted...</td>\n",
       "      <td>34.0</td>\n",
       "      <td>[sorry, for, that, i, truly, didn, t, think, i...</td>\n",
       "      <td>120.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>390</th>\n",
       "      <td>subject8292</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2017-09-16 06:29:13</td>\n",
       "      <td>You've got plenty of time to fix that. You can...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[you, ve, got, plenty, of, time, to, fix, that...</td>\n",
       "      <td>104.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498</th>\n",
       "      <td>subject8292</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2017-11-24 01:33:22</td>\n",
       "      <td>LCD, Glass animals, Kendrick, The Weeknd, Jack...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[lcd, glass, animals, kendrick, the, weeknd, j...</td>\n",
       "      <td>127.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>752</th>\n",
       "      <td>subject8292</td>\n",
       "      <td>Getting that coachella bod</td>\n",
       "      <td>2018-01-09 00:54:06</td>\n",
       "      <td>First I want to say whatever skin is your skin...</td>\n",
       "      <td>0</td>\n",
       "      <td>[getting, that, coachella, bod]</td>\n",
       "      <td>4.0</td>\n",
       "      <td>[first, i, want, to, say, whatever, skin, is, ...</td>\n",
       "      <td>149.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>904</th>\n",
       "      <td>subject8292</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2018-03-12 17:14:03</td>\n",
       "      <td>Not the same but me and my wife saw a man and ...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[not, the, same, but, me, and, my, wife, saw, ...</td>\n",
       "      <td>151.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170652</th>\n",
       "      <td>subject217</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2018-05-28 12:23:00</td>\n",
       "      <td>/r/keto /r/ketorecipes /r/ketodessert all are ...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[r, keto, r, ketorecipes, r, ketodessert, all,...</td>\n",
       "      <td>197.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170653</th>\n",
       "      <td>subject217</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2018-05-28 12:32:36</td>\n",
       "      <td>its okay dont worry . as long as you don't exc...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[its, okay, dont, worry, as, long, as, you, do...</td>\n",
       "      <td>109.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170662</th>\n",
       "      <td>subject217</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2018-06-20 00:33:57</td>\n",
       "      <td>the national number is :1919 here are more com...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[the, national, number, is, 1919, here, are, m...</td>\n",
       "      <td>115.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170693</th>\n",
       "      <td>subject217</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2018-08-19 11:29:21</td>\n",
       "      <td>this is my personal experience ,it may not ref...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[this, is, my, personal, experience, it, may, ...</td>\n",
       "      <td>153.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170695</th>\n",
       "      <td>subject217</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2018-08-19 20:00:31</td>\n",
       "      <td>i am aware of stats now and then. i was just s...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[i, am, aware, of, stats, now, and, then, i, w...</td>\n",
       "      <td>198.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7655 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            subject                                              title  \\\n",
       "122     subject8292  Okay friends so I messed up and posted to do a...   \n",
       "390     subject8292                                                NaN   \n",
       "498     subject8292                                                NaN   \n",
       "752     subject8292                         Getting that coachella bod   \n",
       "904     subject8292                                                NaN   \n",
       "...             ...                                                ...   \n",
       "170652   subject217                                                NaN   \n",
       "170653   subject217                                                NaN   \n",
       "170662   subject217                                                NaN   \n",
       "170693   subject217                                                NaN   \n",
       "170695   subject217                                                NaN   \n",
       "\n",
       "                       date  \\\n",
       "122     2017-04-25 22:37:57   \n",
       "390     2017-09-16 06:29:13   \n",
       "498     2017-11-24 01:33:22   \n",
       "752     2018-01-09 00:54:06   \n",
       "904     2018-03-12 17:14:03   \n",
       "...                     ...   \n",
       "170652  2018-05-28 12:23:00   \n",
       "170653  2018-05-28 12:32:36   \n",
       "170662  2018-06-20 00:33:57   \n",
       "170693  2018-08-19 11:29:21   \n",
       "170695  2018-08-19 20:00:31   \n",
       "\n",
       "                                                     text  label  \\\n",
       "122     Sorry for that, I truly didn't think it was go...      0   \n",
       "390     You've got plenty of time to fix that. You can...      0   \n",
       "498     LCD, Glass animals, Kendrick, The Weeknd, Jack...      0   \n",
       "752     First I want to say whatever skin is your skin...      0   \n",
       "904     Not the same but me and my wife saw a man and ...      0   \n",
       "...                                                   ...    ...   \n",
       "170652  /r/keto /r/ketorecipes /r/ketodessert all are ...      0   \n",
       "170653  its okay dont worry . as long as you don't exc...      0   \n",
       "170662  the national number is :1919 here are more com...      0   \n",
       "170693  this is my personal experience ,it may not ref...      0   \n",
       "170695  i am aware of stats now and then. i was just s...      0   \n",
       "\n",
       "                                          tokenized_title  title_len  \\\n",
       "122     [okay, friends, so, i, messed, up, and, posted...       34.0   \n",
       "390                                                   NaN        NaN   \n",
       "498                                                   NaN        NaN   \n",
       "752                       [getting, that, coachella, bod]        4.0   \n",
       "904                                                   NaN        NaN   \n",
       "...                                                   ...        ...   \n",
       "170652                                                NaN        NaN   \n",
       "170653                                                NaN        NaN   \n",
       "170662                                                NaN        NaN   \n",
       "170693                                                NaN        NaN   \n",
       "170695                                                NaN        NaN   \n",
       "\n",
       "                                           tokenized_text  text_len  \n",
       "122     [sorry, for, that, i, truly, didn, t, think, i...     120.0  \n",
       "390     [you, ve, got, plenty, of, time, to, fix, that...     104.0  \n",
       "498     [lcd, glass, animals, kendrick, the, weeknd, j...     127.0  \n",
       "752     [first, i, want, to, say, whatever, skin, is, ...     149.0  \n",
       "904     [not, the, same, but, me, and, my, wife, saw, ...     151.0  \n",
       "...                                                   ...       ...  \n",
       "170652  [r, keto, r, ketorecipes, r, ketodessert, all,...     197.0  \n",
       "170653  [its, okay, dont, worry, as, long, as, you, do...     109.0  \n",
       "170662  [the, national, number, is, 1919, here, are, m...     115.0  \n",
       "170693  [this, is, my, personal, experience, it, may, ...     153.0  \n",
       "170695  [i, am, aware, of, stats, now, and, then, i, w...     198.0  \n",
       "\n",
       "[7655 rows x 9 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "writings_df[(~writings_df['text_len'].isna()) & (writings_df['text_len'] > 100)]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recurrent NN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract features and encode data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparams_features = {\n",
    "    \"max_features\": 20000,\n",
    "    # cut texts after this number of words\n",
    "    # (among top max_features most common words)\n",
    "    \"maxlen\": 100,\n",
    "    \"embedding_dim\": 100\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_NRC(nrc_path):\n",
    "    word_emotions = {}\n",
    "    emotion_words = {}\n",
    "    with open(nrc_path) as in_f:\n",
    "        for line in in_f:\n",
    "            line = line.strip()\n",
    "            if not line:\n",
    "                continue\n",
    "            word, emotion, label = line.split()\n",
    "            if word not in word_emotions:\n",
    "                word_emotions[word] = set()\n",
    "            if emotion not in emotion_words:\n",
    "                emotion_words[emotion] = set()\n",
    "            label = int(label)\n",
    "            if label:\n",
    "                word_emotions[word].add(emotion)\n",
    "                emotion_words[emotion].add(word)\n",
    "    return emotion_words\n",
    "\n",
    "nrc_lexicon_path = '/home/ana/resources/NRC-Sentiment-Emotion-Lexicons/NRC-Sentiment-Emotion-Lexicons/NRC-Emotion-Lexicon-v0.92/NRC-Emotion-Lexicon-Wordlevel-v0.92.txt'\n",
    "nrc_lexicon = load_NRC(nrc_lexicon_path)\n",
    "emotions = list(nrc_lexicon.keys())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['anger',\n",
       " 'anticipation',\n",
       " 'disgust',\n",
       " 'fear',\n",
       " 'joy',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'sadness',\n",
       " 'surprise',\n",
       " 'trust']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emotions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "def load_erisk_data(writings_df, voc_size, emotion_lexicon, seq_len, emotions =  \n",
    "                    ['anger', 'anticipation', 'disgust', 'fear', 'joy', \n",
    "                     'negative', 'positive', 'sadness', 'surprise', 'trust'],\n",
    "                    train_prop=0.7, min_post_len=3, min_word_len=1):\n",
    "    print(\"Loading data...\")\n",
    "    vocabulary = {}\n",
    "    word_freqs = Counter()\n",
    "    for words in writings_df[~writings_df['tokenized_text'].isna()].tokenized_text:\n",
    "        word_freqs.update(words)\n",
    "    i = 1\n",
    "    for w, f in word_freqs.most_common(voc_size-2): # keeping voc_size-1 for unk\n",
    "        if len(w) < min_word_len:\n",
    "            continue\n",
    "        vocabulary[w] = i\n",
    "        i += 1\n",
    "    tokens_data_train = []\n",
    "    emotions_data_train = []\n",
    "    tokens_data_test = []\n",
    "    emotions_data_test = []\n",
    "    labels_train = []\n",
    "    labels_test = []\n",
    "    # TODO: shuffle?\n",
    "    all_subjects = list(set(writings_df.subject))\n",
    "    training_subjects_size = int(len(all_subjects) * train_prop)\n",
    "    training_subjects = all_subjects[:training_subjects_size]\n",
    "    training_rows = writings_df[writings_df['subject'].isin(training_subjects)]\n",
    "    test_rows = writings_df[~writings_df['subject'].isin(training_subjects)]\n",
    "    def encode_text(tokens):\n",
    "        # Using voc_size=1 value for OOV token\n",
    "        encoded_tokens = [vocabulary.get(w, voc_size-1) for w in tokens]\n",
    "        text_len = len(tokens)\n",
    "        encoded_emotions = [0 for e in emotions]\n",
    "        for i, emotion in enumerate(emotions):\n",
    "            try:\n",
    "                emotion_words = [t for t in tokens if t in emotion_lexicon[emotion]]\n",
    "                encoded_emotions[i] = len(emotion_words) / len(tokens)\n",
    "            except ValueError:\n",
    "                print(\"Emotion not found.\")\n",
    "        return (encoded_tokens, encoded_emotions)\n",
    "    for row in training_rows[~training_rows['tokenized_text'].isna()].itertuples():\n",
    "        words = row.tokenized_text\n",
    "        if not words or len(words)<min_post_len:\n",
    "            continue\n",
    "        label = row.label\n",
    "        encoded_tokens, encoded_emotions = encode_text(words)\n",
    "        tokens_data_train.append(encoded_tokens)\n",
    "        emotions_data_train.append(encoded_emotions)\n",
    "        labels_train.append(label)\n",
    "    for row in test_rows[~test_rows['tokenized_text'].isna()].itertuples():\n",
    "        words = row.tokenized_text\n",
    "        if not words or len(words)<min_post_len:\n",
    "            continue\n",
    "        label = row.label\n",
    "        encoded_tokens, encoded_emotions = encode_text(words)\n",
    "        tokens_data_test.append(encoded_tokens)\n",
    "        emotions_data_test.append(encoded_emotions)\n",
    "        labels_test.append(label)\n",
    "        \n",
    "    # using zeros for padding\n",
    "    tokens_data_train_padded = sequence.pad_sequences(tokens_data_train, maxlen=seq_len)\n",
    "    tokens_data_test_padded = sequence.pad_sequences(tokens_data_test, maxlen=seq_len)\n",
    "        \n",
    "    return ([np.array(tokens_data_train_padded), np.array(emotions_data_train)], np.array(labels_train)), \\\n",
    "            ([np.array(tokens_data_test_padded), np.array(emotions_data_test)], np.array(labels_test)), vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n"
     ]
    }
   ],
   "source": [
    "(x_train, y_train), (x_test, y_test), voc = load_erisk_data(writings_df, \n",
    "                                                            seq_len=hyperparams_features['maxlen'],\n",
    "                                                            voc_size=hyperparams_features['max_features'],\n",
    "                                                           emotion_lexicon=nrc_lexicon,\n",
    "                                                           emotions=emotions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "78383 train sequences\n",
      "36559 test sequences\n"
     ]
    }
   ],
   "source": [
    "x_train_seq, x_train_categ = x_train\n",
    "x_test_seq, x_test_categ = x_test\n",
    "print(len(x_train_seq), 'train sequences')\n",
    "print(len(x_test_seq), 'test sequences')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4945 positive training examples\n",
      "1431 positive test examples\n"
     ]
    }
   ],
   "source": [
    "print(pd.Series(y_train).sum(), \"positive training examples\")\n",
    "print(pd.Series(y_test).sum(), \"positive test examples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.53366786, 7.92548028])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.utils import class_weight\n",
    "\n",
    "class_weights = class_weight.compute_class_weight('balanced',\n",
    "                                                 np.unique(y_train),\n",
    "                                                 y_train)\n",
    "class_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total 20000 word vectors.\n"
     ]
    }
   ],
   "source": [
    "def load_embeddings(path, embedding_dim, voc):\n",
    "    # random matrix with mean value = 0\n",
    "    embedding_matrix = np.random.random((len(voc)+2, embedding_dim)) - 0.5 # voc + unk + pad value(0)\n",
    "#     embedding_matrix = np.zeros((len(voc)+1, embedding_dim))\n",
    "\n",
    "    f = open(path)\n",
    "    for line in f:\n",
    "        values = line.split()\n",
    "        word = values[0]\n",
    "        coefs = np.asarray(values[1:], dtype='float32')\n",
    "        word_i = voc.get(word)\n",
    "        if word_i is not None:\n",
    "            embedding_matrix[word_i] = coefs\n",
    "    f.close()\n",
    "\n",
    "    print('Total %s word vectors.' % len(embedding_matrix))\n",
    "\n",
    " \n",
    "    return embedding_matrix\n",
    "\n",
    "pretrained_embeddings_path = '/home/ana/resources/glove.6B/glove.6B.%dd.txt' % hyperparams_features['embedding_dim']\n",
    "embedding_matrix = load_embeddings(pretrained_embeddings_path, hyperparams_features['embedding_dim'], voc)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparams = {\n",
    "    'lstm_units': 64,\n",
    "    'dropout': 0.5,\n",
    "    'l2_dense': 0.0001,\n",
    "    'optimizer': 'adagrad', # 'adam'\n",
    "    \"batch_size\": 32,\n",
    "\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recall_m(y_true, y_pred):\n",
    "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "        possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "        recall = true_positives / (possible_positives + K.epsilon())\n",
    "        return recall\n",
    "\n",
    "def precision_m(y_true, y_pred):\n",
    "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "        predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "        precision = true_positives / (predicted_positives + K.epsilon())\n",
    "        return precision\n",
    "\n",
    "def f1_m(y_true, y_pred):\n",
    "    precision = precision_m(y_true, y_pred)\n",
    "    recall = recall_m(y_true, y_pred)\n",
    "    return 2*((precision*recall)/(precision+recall+K.epsilon()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(hyperparams, hyperparams_features, embedding_matrix, emotions):\n",
    "\n",
    "    tokens_features = Input(shape=(hyperparams_features['maxlen'], ))\n",
    "    embedding_layer = Embedding(hyperparams_features['max_features'], hyperparams_features['embedding_dim'], input_length=hyperparams_features['maxlen'], \n",
    "                        weights=[embedding_matrix], trainable=True)(tokens_features)\n",
    "    lstm_layers = Bidirectional(LSTM(hyperparams['lstm_units']))(embedding_layer)\n",
    "    dropout_layer = Dropout(hyperparams['dropout'])(lstm_layers)\n",
    "\n",
    "    categorical_features = Input(shape=(len(emotions), ))\n",
    "    dense_layer = Dense(units=len(emotions),\n",
    "                        kernel_regularizer=regularizers.l2(hyperparams['l2_dense'])\n",
    "                       )(categorical_features)\n",
    "\n",
    "    merged_layers = concatenate([dropout_layer, dense_layer])\n",
    "    output_layer = Dense(1, activation='sigmoid')(merged_layers)\n",
    "\n",
    "    model = Model(inputs=[tokens_features, categorical_features], outputs=output_layer)\n",
    "    model.compile(hyperparams['optimizer'], 'binary_crossentropy',\n",
    "              metrics=['binary_accuracy', f1_m, precision_m, recall_m])\n",
    "    \n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_3 (InputLayer)            (None, 100)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, 100, 100)     2000000     input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_1 (Bidirectional) (None, 128)          84480       embedding_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "input_4 (InputLayer)            (None, 10)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 128)          0           bidirectional_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 10)           110         input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 138)          0           dropout_1[0][0]                  \n",
      "                                                                 dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 1)            139         concatenate_1[0][0]              \n",
      "==================================================================================================\n",
      "Total params: 2,084,729\n",
      "Trainable params: 2,084,729\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = build_model(hyperparams, hyperparams_features, embedding_matrix, emotions)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "COMET INFO: ----------------------------\n",
      "COMET INFO: Comet.ml Experiment Summary:\n",
      "COMET INFO:   Data:\n",
      "COMET INFO:     url: https://www.comet.ml/ananana/mental/10b685b390c34f53b6ff81ce52a1fe6b\n",
      "COMET INFO:   Metrics [count] (min, max):\n",
      "COMET INFO:     sys.cpu.percent.01    : (76.0, 76.0)\n",
      "COMET INFO:     sys.cpu.percent.02    : (73.3, 73.3)\n",
      "COMET INFO:     sys.cpu.percent.03    : (53.9, 53.9)\n",
      "COMET INFO:     sys.cpu.percent.04    : (53.5, 53.5)\n",
      "COMET INFO:     sys.cpu.percent.avg   : (64.17500000000001, 64.17500000000001)\n",
      "COMET INFO:     sys.gpu.0.total_memory: (1073414144.0, 1073414144.0)\n",
      "COMET INFO:     sys.load.avg          : (2.97, 2.97)\n",
      "COMET INFO:     sys.ram.total         : (8277307392.0, 8277307392.0)\n",
      "COMET INFO:     sys.ram.used          : (7093157888.0, 7093157888.0)\n",
      "COMET INFO:   Uploads:\n",
      "COMET INFO:     git-patch: 1\n",
      "COMET INFO: ----------------------------\n",
      "COMET INFO: Experiment is live on comet.ml https://www.comet.ml/ananana/mental/a48b3e0a21044abe8d62273625809625\n",
      "\n"
     ]
    }
   ],
   "source": [
    "experiment = Experiment(api_key=\"eoBdVyznAhfg3bK9pZ58ZSXfv\",\n",
    "                        project_name=\"mental\", workspace=\"ananana\")\n",
    "\n",
    "experiment.log_parameters(hyperparams_features)\n",
    "\n",
    "experiment.log_parameter('emotion_lexicon', nrc_lexicon_path)\n",
    "experiment.log_parameter('emotions', emotions)\n",
    "experiment.log_parameter('embeddings_path', pretrained_embeddings_path)\n",
    "\n",
    "experiment.log_parameters(hyperparams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, \n",
    "                x_train, y_train, x_test, y_test, \n",
    "                batch_size, epochs, class_weight, start_epoch=0, workers=4,\n",
    "                model_path='/tmp/model'):\n",
    "    print('Train...')\n",
    "    experiment.log_parameter('class_weight', class_weight.values())\n",
    "\n",
    "    history = model.fit(x_train, y_train,\n",
    "              batch_size=batch_size,\n",
    "              epochs=epochs, initial_epoch=start_epoch, \n",
    "              class_weight=class_weight,\n",
    "              validation_data=[x_test, y_test],\n",
    "                       workers=workers,\n",
    "            callbacks = [\n",
    "                callbacks.ModelCheckpoint(filepath='%s_best' % model_path, verbose=1, save_best_only=True),\n",
    "                callbacks.EarlyStopping(),\n",
    "            ])\n",
    "    model.save(model_path)\n",
    "    experiment.log_parameter('model_path', model_path)\n",
    "    return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "COMET WARNING: Set model graph ignored; already set and not overwrite\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train...\n",
      "Train on 78383 samples, validate on 36559 samples\n",
      "Epoch 1/10\n",
      " 5472/78383 [=>............................] - ETA: 56:23 - loss: 0.6752 - binary_accuracy: 0.7728 - f1_m: 0.1123 - precision_m: 0.0826 - recall_m: 0.2455"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-62-3b17f148461d>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(model, x_train, y_train, x_test, y_test, batch_size, epochs, class_weight, start_epoch, model_path)\u001b[0m\n\u001b[1;32m     13\u001b[0m             callbacks = [\n\u001b[1;32m     14\u001b[0m                 \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mModelCheckpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'%s_best'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mmodel_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msave_best_only\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m                 \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEarlyStopping\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m             ])\n\u001b[1;32m     17\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf/lib/python3.7/site-packages/comet_ml/monkey_patching.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    244\u001b[0m                     )\n\u001b[1;32m    245\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 246\u001b[0;31m         \u001b[0mreturn_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moriginal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    247\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    248\u001b[0m         \u001b[0;31m# Call after callbacks once we have the return value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    878\u001b[0m           \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    879\u001b[0m           \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 880\u001b[0;31m           validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m    881\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    882\u001b[0m   def evaluate(self,\n",
      "\u001b[0;32m~/anaconda3/envs/tf/lib/python3.7/site-packages/tensorflow/python/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mmodel_iteration\u001b[0;34m(model, inputs, targets, sample_weights, batch_size, epochs, verbose, callbacks, val_inputs, val_targets, val_sample_weights, shuffle, initial_epoch, steps_per_epoch, validation_steps, mode, validation_in_fit, **kwargs)\u001b[0m\n\u001b[1;32m    327\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    328\u001b[0m         \u001b[0;31m# Get outputs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 329\u001b[0;31m         \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    330\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    331\u001b[0m           \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf/lib/python3.7/site-packages/tensorflow/python/keras/backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   3074\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3075\u001b[0m     fetched = self._callable_fn(*array_vals,\n\u001b[0;32m-> 3076\u001b[0;31m                                 run_metadata=self.run_metadata)\n\u001b[0m\u001b[1;32m   3077\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_fetch_callbacks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3078\u001b[0m     return nest.pack_sequence_as(self._outputs_structure,\n",
      "\u001b[0;32m~/anaconda3/envs/tf/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1437\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[1;32m   1438\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1439\u001b[0;31m               run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1440\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1441\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "%%time\n",
    "history = train_model(model, x_train, y_train, x_test, y_test,\n",
    "           epochs=10, batch_size=hyperparams['batch_size'],\n",
    "                      class_weight={0:0.5, 1:7}, \n",
    "                      model_path='models/lstm_plus3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "dependencies = {\n",
    "    'f1_m': f1_m,\n",
    "    'precision_m': precision_m,\n",
    "    'recall_m': recall_m\n",
    "}\n",
    "model = load_model('models/lstm_plus1', custom_objects=dependencies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32043/32043 [==============================] - 193s 6ms/sample - loss: 0.8202 - binary_accuracy: 0.8299 - f1_m: 0.0249 - precision_m: 0.0890 - recall_m: 0.0162\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.8201780113331502, 0.8298848, 0.02489142, 0.08895819, 0.016238175]"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate([np.array(x_test_seq), np.array(x_test_categ)], y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f34c2a9b690>"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYMAAAD4CAYAAAAO9oqkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAQKklEQVR4nO3df6zd9V3H8edrdExkm7B13BBaV0w6M4S4sRuoWaJ3YkqpyYoJMxC2FkRrEIw/GiPqH13AJVODSyCTrcsaimFjOJ1tNmZtKjeoWZHOTQqbSyurcNeGupXVdcTNzrd/nO9dTspp7+k595zTe8/zkZyc7/mcz/f7/bzPvdxXv5/v93tIVSFJGm+vGvUAJEmjZxhIkgwDSZJhIEnCMJAkAUtGPYBeLV26tFasWNHTut/97nc5//zz53dAZzlrHg/jVvO41Qv91/zFL37xm1X1ppPbF2wYrFixgr179/a07vT0NFNTU/M7oLOcNY+Hcat53OqF/mtO8p+d2p0mkiQZBpIkw0CShGEgScIwkCRhGEiSMAwkSRgGkiQMA0kSC/gO5H7s+8Yxbrnrc0Pf78EP/uLQ9ylJ3fDIQJJkGEiSDANJEoaBJAnDQJKEYSBJwjCQJGEYSJIwDCRJGAaSJAwDSRKGgSQJw0CShGEgScIwkCRhGEiSMAwkSRgGkiQMA0kShoEkCcNAkkQXYZBkeZLHk3w1ybNJfqtpf0OSXUn2N88XNu1Jcl+SA0meTnJl27Y2NP33J9nQ1v6OJPuade5LkkEUK0nqrJsjgxPApqp6K7AKuCPJZcBdwO6qWgnsbl4DXAesbB4bgQegFR7AZuBq4Cpg82yANH02tq23pv/SJEndmjMMqupwVf1rs/wd4KvAJcA6YFvTbRtwfbO8DnioWvYAFyS5GLgW2FVVR6vqJWAXsKZ57/VV9YWqKuChtm1JkoZgyZl0TrICeDvwJDBRVYehFRhJLmq6XQK80LbaTNN2uvaZDu2d9r+R1hEEExMTTE9Pn8nwf2jiPNh0xYme1u1Hr+OdD8ePHx/p/kfBmhe/casXBldz12GQ5LXAXwO/XVX/fZpp/U5vVA/tr2ys2gJsAZicnKypqak5Rt3Z/Q9v5959Z5SD8+LgzVND3+es6elpev28FiprXvzGrV4YXM1dXU2U5NW0guDhqvqbpvnFZoqH5vlI0z4DLG9bfRlwaI72ZR3aJUlD0s3VRAE+Dny1qv687a0dwOwVQRuA7W3t65urilYBx5rppJ3A6iQXNieOVwM7m/e+k2RVs6/1bduSJA1BN3Ml7wTeB+xL8uWm7Q+BDwKPJrkNeB54T/PeY8Ba4ADwMnArQFUdTXIP8FTT7+6qOtos3w48CJwHfL55SJKGZM4wqKp/ovO8PsA1HfoXcMcptrUV2NqhfS9w+VxjkSQNhncgS5IMA0mSYSBJwjCQJGEYSJIwDCRJGAaSJAwDSRKGgSQJw0CShGEgScIwkCRhGEiSMAwkSRgGkiQMA0kShoEkCcNAkoRhIEnCMJAkYRhIkjAMJEkYBpIkDANJEoaBJAnDQJKEYSBJwjCQJGEYSJIwDCRJGAaSJAwDSRKGgSQJw0CShGEgScIwkCTRRRgk2ZrkSJJn2tren+QbSb7cPNa2vfcHSQ4k+VqSa9va1zRtB5Lc1dZ+aZInk+xP8qkk585ngZKkuXVzZPAgsKZD+4eq6m3N4zGAJJcBNwI/1azzF0nOSXIO8GHgOuAy4KamL8CfNNtaCbwE3NZPQZKkMzdnGFTVE8DRLre3Dnikqr5XVV8HDgBXNY8DVfVcVX0feARYlyTAzwOfbtbfBlx/hjVIkvq0pI9170yyHtgLbKqql4BLgD1tfWaaNoAXTmq/Gngj8O2qOtGh/ysk2QhsBJiYmGB6erqngU+cB5uuODF3x3nW63jnw/Hjx0e6/1Gw5sVv3OqFwdXcaxg8ANwDVPN8L/ArQDr0LTofgdRp+ndUVVuALQCTk5M1NTV1RoOedf/D27l3Xz852JuDN08NfZ+zpqen6fXzWqisefEbt3phcDX39Bexql6cXU7yMeCzzcsZYHlb12XAoWa5U/s3gQuSLGmODtr7S5KGpKdLS5Nc3Pbyl4DZK412ADcmeU2SS4GVwL8ATwErmyuHzqV1knlHVRXwOHBDs/4GYHsvY5Ik9W7OI4MknwSmgKVJZoDNwFSSt9Ga0jkI/DpAVT2b5FHgK8AJ4I6q+kGznTuBncA5wNaqerbZxe8DjyT5Y+BLwMfnrTpJUlfmDIOquqlD8yn/YFfVB4APdGh/DHisQ/tztK42kiSNiHcgS5IMA0mSYSBJwjCQJGEYSJIwDCRJGAaSJAwDSRKGgSQJw0CShGEgScIwkCRhGEiSMAwkSRgGkiQMA0kShoEkCcNAkoRhIEnCMJAkYRhIkjAMJEkYBpIkDANJEoaBJAnDQJKEYSBJwjCQJGEYSJIwDCRJGAaSJAwDSRKGgSQJw0CShGEgScIwkCRhGEiS6CIMkmxNciTJM21tb0iyK8n+5vnCpj1J7ktyIMnTSa5sW2dD039/kg1t7e9Isq9Z574kme8iJUmn182RwYPAmpPa7gJ2V9VKYHfzGuA6YGXz2Ag8AK3wADYDVwNXAZtnA6Tps7FtvZP3JUkasDnDoKqeAI6e1LwO2NYsbwOub2t/qFr2ABckuRi4FthVVUer6iVgF7Cmee/1VfWFqirgobZtSZKGZEmP601U1WGAqjqc5KKm/RLghbZ+M03b6dpnOrR3lGQjraMIJiYmmJ6e7m3w58GmK070tG4/eh3vfDh+/PhI9z8K1rz4jVu9MLiaew2DU+k03189tHdUVVuALQCTk5M1NTXVwxDh/oe3c++++S59bgdvnhr6PmdNT0/T6+e1UFnz4jdu9cLgau71aqIXmykemucjTfsMsLyt3zLg0Bztyzq0S5KGqNcw2AHMXhG0Adje1r6+uapoFXCsmU7aCaxOcmFz4ng1sLN57ztJVjVXEa1v25YkaUjmnCtJ8klgCliaZIbWVUEfBB5NchvwPPCepvtjwFrgAPAycCtAVR1Ncg/wVNPv7qqaPSl9O60rls4DPt88JElDNGcYVNVNp3jrmg59C7jjFNvZCmzt0L4XuHyucUiSBsc7kCVJhoEkyTCQJGEYSJIwDCRJGAaSJAwDSRKGgSQJw0CShGEgScIwkCRhGEiSMAwkSRgGkiQMA0kShoEkCcNAkoRhIEnCMJAkYRhIkjAMJEkYBpIkDANJEoaBJAnDQJKEYSBJwjCQJGEYSJIwDCRJGAaSJAwDSRKGgSQJw0CShGEgScIwkCRhGEiS6DMMkhxMsi/Jl5PsbdrekGRXkv3N84VNe5Lcl+RAkqeTXNm2nQ1N//1JNvRXkiTpTM3HkcG7quptVTXZvL4L2F1VK4HdzWuA64CVzWMj8AC0wgPYDFwNXAVsng0QSdJwDGKaaB2wrVneBlzf1v5QtewBLkhyMXAtsKuqjlbVS8AuYM0AxiVJOoUlfa5fwN8nKeCjVbUFmKiqwwBVdTjJRU3fS4AX2tadadpO1f4KSTbSOqpgYmKC6enpngY9cR5suuJET+v2o9fxzofjx4+PdP+jYM2L37jVC4Orud8weGdVHWr+4O9K8u+n6ZsObXWa9lc2tsJmC8Dk5GRNTU2d4XBb7n94O/fu67f0M3fw5qmh73PW9PQ0vX5eC5U1L37jVi8Mrua+pomq6lDzfAT4DK05/xeb6R+a5yNN9xlgedvqy4BDp2mXJA1Jz2GQ5Pwkr5tdBlYDzwA7gNkrgjYA25vlHcD65qqiVcCxZjppJ7A6yYXNiePVTZskaUj6mSuZAD6TZHY7n6iqv0vyFPBoktuA54H3NP0fA9YCB4CXgVsBqupoknuAp5p+d1fV0T7GJUk6Qz2HQVU9B/x0h/ZvAdd0aC/gjlNsayuwtdexSJL64x3IkiTDQJJkGEiSMAwkSRgGkiQMA0kShoEkCcNAkoRhIEnCMJAkYRhIkjAMJEkYBpIkDANJEoaBJAnDQJKEYSBJwjCQJNHf/wNZksbWirs+N5L9Prjm/IFs1yMDSZJhIEkyDCRJGAaSJAwDSRKGgSQJw0CShGEgScIwkCThHchDNao7FmFwdy1KWhw8MpAkGQaSJMNAkoTnDMbGvm8c45YRnrMYhVGdJ/HckBYiw0CL1jgG4LjVvOmKE2NV7yA5TSRJMgwkSYaBJImzKAySrEnytSQHktw16vFI0jg5K8IgyTnAh4HrgMuAm5JcNtpRSdL4OCvCALgKOFBVz1XV94FHgHUjHpMkjY1U1ajHQJIbgDVV9avN6/cBV1fVnSf12whsbF7+JPC1Hne5FPhmj+suVNY8Hsat5nGrF/qv+c1V9aaTG8+W+wzSoe0VKVVVW4Atfe8s2VtVk/1uZyGx5vEwbjWPW70wuJrPlmmiGWB52+tlwKERjUWSxs7ZEgZPASuTXJrkXOBGYMeIxyRJY+OsmCaqqhNJ7gR2AucAW6vq2QHusu+ppgXImsfDuNU8bvXCgGo+K04gS5JG62yZJpIkjZBhIEla3GEw11dcJHlNkk817z+ZZMXwRzl/uqj3d5N8JcnTSXYnefMoxjmfuv0akyQ3JKkkC/4yxG5qTvLLzc/62SSfGPYY51sXv9s/nuTxJF9qfr/XjmKc8yXJ1iRHkjxziveT5L7m83g6yZV977SqFuWD1ono/wB+AjgX+DfgspP6/AbwkWb5RuBTox73gOt9F/CjzfLtC7nebmtu+r0OeALYA0yOetxD+DmvBL4EXNi8vmjU4x5CzVuA25vly4CDox53nzX/LHAl8Mwp3l8LfJ7WPVqrgCf73ediPjLo5isu1gHbmuVPA9ck6XQD3EIwZ71V9XhVvdy83EPrfo6FrNuvMbkH+FPgf4Y5uAHppuZfAz5cVS8BVNWRIY9xvnVTcwGvb5Z/jAV+n1JVPQEcPU2XdcBD1bIHuCDJxf3sczGHwSXAC22vZ5q2jn2q6gRwDHjjUEY3/7qpt91ttP5lsZDNWXOStwPLq+qzwxzYAHXzc34L8JYk/5xkT5I1QxvdYHRT8/uB9yaZAR4DfnM4QxuZM/3vfU5nxX0GA9LNV1x09TUYC0TXtSR5LzAJ/NxARzR4p605yauADwG3DGtAQ9DNz3kJramiKVpHf/+Y5PKq+vaAxzYo3dR8E/BgVd2b5GeAv2xq/r/BD28k5v1v12I+MujmKy5+2CfJElqHl6c7NDubdfWVHkl+Afgj4N1V9b0hjW1Q5qr5dcDlwHSSg7TmVncs8JPI3f5eb6+q/62qr9P6QseVQxrfIHRT823AowBV9QXgR2h9odtiNe9f4bOYw6Cbr7jYAWxolm8A/qGaszML0Jz1NlMmH6UVBAt9HhnmqLmqjlXV0qpaUVUraJ0neXdV7R3NcOdFN7/Xf0vrYgGSLKU1bfTcUEc5v7qp+XngGoAkb6UVBv811FEO1w5gfXNV0SrgWFUd7meDi3aaqE7xFRdJ7gb2VtUO4OO0DicP0DoiuHF0I+5Pl/X+GfBa4K+a8+TPV9W7RzboPnVZ86LSZc07gdVJvgL8APi9qvrW6Ebdny5r3gR8LMnv0JouuWUB/8OOJJ+kNc23tDkPshl4NUBVfYTWeZG1wAHgZeDWvve5gD8vSdI8WczTRJKkLhkGkiTDQJJkGEiSMAwkSRgGkiQMA0kS8P+BIzqSNWzoTAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pd.Series(predictions.flatten()).hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5424])"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(predictions>0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([26518])"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(predictions<0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "COMET INFO: COMET_OPTIMIZER_ID=fdd0fded8f6645dcb45374682e2f93a1\n",
      "COMET INFO: Using optimizer config: {'algorithm': 'bayes', 'configSpaceSize': 'infinite', 'endTime': None, 'id': 'fdd0fded8f6645dcb45374682e2f93a1', 'lastUpdateTime': None, 'maxCombo': 0, 'name': 'fdd0fded8f6645dcb45374682e2f93a1', 'parameters': {'batch_size': {'max': 512, 'min': 10, 'scalingType': 'uniform', 'type': 'integer'}, 'dropout': {'max': 0.7, 'min': 0, 'scalingType': 'uniform', 'type': 'float'}, 'l2_dense': {'max': 0.5, 'min': 1e-05, 'scalingType': 'loguniform', 'type': 'float'}, 'lr': {'max': 1.0, 'min': 1e-05, 'scalingType': 'loguniform', 'type': 'float'}, 'lstm_units': {'max': 100, 'min': 10, 'scalingType': 'uniform', 'type': 'integer'}, 'optimizer': {'type': 'categorical', 'values': ['adam', 'adagrad']}}, 'predictor': None, 'spec': {'gridSize': 10, 'maxCombo': 0, 'metric': 'loss', 'minSampleSize': 100, 'objective': 'minimize', 'retryAssignLimit': 0, 'retryLimit': 20, 'seed': 740949148}, 'startTime': 15293154917, 'state': {'sequence_i': 0, 'sequence_pid': None, 'sequence_retry': 0}, 'status': 'running', 'suggestion_count': 0, 'trials': 1, 'version': '1.0.24'}\n",
      "COMET INFO: Optimizer metrics is 'loss' but no logged values found. Experiment ignored in sweep.\n",
      "COMET INFO: ----------------------------\n",
      "COMET INFO: Comet.ml Experiment Summary:\n",
      "COMET INFO:   Data:\n",
      "COMET INFO:     url: https://www.comet.ml/ananana/mental/2af74bee5fa8492593e6998faf318735\n",
      "COMET INFO:   Metrics [count] (min, max):\n",
      "COMET INFO:     sys.cpu.percent.01 [2] : (34.5, 76.7)\n",
      "COMET INFO:     sys.cpu.percent.02 [2] : (18.5, 73.0)\n",
      "COMET INFO:     sys.cpu.percent.03 [2] : (17.5, 53.7)\n",
      "COMET INFO:     sys.cpu.percent.04 [2] : (18.6, 51.4)\n",
      "COMET INFO:     sys.cpu.percent.avg [2]: (22.275, 63.699999999999996)\n",
      "COMET INFO:     sys.gpu.0.total_memory : (1073414144.0, 1073414144.0)\n",
      "COMET INFO:     sys.load.avg [2]       : (4.08, 4.41)\n",
      "COMET INFO:     sys.ram.total [2]      : (8277307392.0, 8277307392.0)\n",
      "COMET INFO:     sys.ram.used [2]       : (7388332032.0, 7631515648.0)\n",
      "COMET INFO:   Other [count]:\n",
      "COMET INFO:     optimizer_count       : 1\n",
      "COMET INFO:     optimizer_id          : 7525b966ea9f4383b8f995bf580b3af5\n",
      "COMET INFO:     optimizer_metric      : loss\n",
      "COMET INFO:     optimizer_metric_value: None\n",
      "COMET INFO:     optimizer_parameters  : {'batch_size': 453, 'dropout': 0.20976021969387448, 'l2_dense': 0.004173909969668019, 'lr': 0.04340304533305237, 'lstm_units': 90, 'optimizer': 'adagrad'}\n",
      "COMET INFO:     optimizer_pid         : 14080225e5f9e51aa36a67c7f2795903e1882372\n",
      "COMET INFO:     optimizer_process     : 15989\n",
      "COMET INFO:     optimizer_trial       : 1\n",
      "COMET INFO:     optimizer_version     : 1.0.24\n",
      "COMET INFO:     trainable_params      : 2137821\n",
      "COMET INFO:   Uploads:\n",
      "COMET INFO:     git-patch: 1\n",
      "COMET INFO: ----------------------------\n",
      "COMET INFO: Experiment is live on comet.ml https://www.comet.ml/ananana/mental/9f6188ebad48457b96b631cc9dc90883\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train...\n",
      "Train on 78383 samples, validate on 36559 samples\n",
      "Epoch 1/3\n",
      "78177/78383 [============================>.] - ETA: 2s - loss: 0.8010 - binary_accuracy: 0.7009 - f1_m: 0.1936 - precision_m: 0.1242 - recall_m: 0.5498\n",
      "Epoch 00001: val_loss improved from inf to 0.70711, saving model to models/experiment_best\n",
      "78383/78383 [==============================] - 926s 12ms/sample - loss: 0.8009 - binary_accuracy: 0.7005 - f1_m: 0.1932 - precision_m: 0.1239 - recall_m: 0.5503 - val_loss: 0.7071 - val_binary_accuracy: 0.5890 - val_f1_m: 0.1028 - val_precision_m: 0.0567 - val_recall_m: 0.6049\n",
      "Epoch 2/3\n",
      "78177/78383 [============================>.] - ETA: 3s - loss: 0.5511 - binary_accuracy: 0.7642 - f1_m: 0.2712 - precision_m: 0.1745 - recall_m: 0.6837\n",
      "Epoch 00002: val_loss improved from 0.70711 to 0.57098, saving model to models/experiment_best\n",
      "78383/78383 [==============================] - 1320s 17ms/sample - loss: 0.5511 - binary_accuracy: 0.7641 - f1_m: 0.2714 - precision_m: 0.1747 - recall_m: 0.6837 - val_loss: 0.5710 - val_binary_accuracy: 0.6964 - val_f1_m: 0.1030 - val_precision_m: 0.0587 - val_recall_m: 0.4582\n",
      "Epoch 3/3\n",
      "48323/78383 [=================>............] - ETA: 7:40 - loss: 0.4109 - binary_accuracy: 0.8169 - f1_m: 0.3575 - precision_m: 0.2364 - recall_m: 0.7899"
     ]
    }
   ],
   "source": [
    "# Declare your hyperparameters search:\n",
    "config = {\n",
    "      \"algorithm\": \"bayes\",\n",
    "      \"parameters\": {\n",
    "          \"lstm_units\": {\"type\": \"integer\", \"min\": 10, \"max\": 100},\n",
    "          \"lr\": {\"type\": \"float\", \"min\": 0.00001, \"max\": 1.0, \"scalingType\": \"loguniform\"},\n",
    "          \"l2_dense\": {\"type\": \"float\", \"min\": 0.00001, \"max\": 0.5, \"scalingType\": \"loguniform\"},\n",
    "          \"dropout\": {\"type\": \"float\", \"min\": 0, \"max\": 0.7, \"scalingType\": \"uniform\"},\n",
    "          \"optimizer\": {\"type\": \"categorical\", \"values\": [\"adam\", \"adagrad\"]},\n",
    "          \"batch_size\": {\"type\": \"integer\", \"min\": 10, \"max\": 512}\n",
    "          \"positive_class_weight\": {\"type\": \"integer\", \"min\": 1, \"max\": 25}\n",
    "\n",
    "      },\n",
    "      \"spec\": {\n",
    "          \"metric\": \"loss\",\n",
    "          \"objective\": \"minimize\",\n",
    "      },\n",
    "  }\n",
    "optimizer = Optimizer(config, api_key=\"eoBdVyznAhfg3bK9pZ58ZSXfv\")\n",
    "\n",
    "for experiment in optimizer.get_experiments(project_name=\"mental\"):\n",
    "    experiment.add_tag(\"tune\")\n",
    "    \n",
    "    # Test the model\n",
    "    model = build_model(hyperparams = {\n",
    "        \"lstm_units\": experiment.get_parameter('lstm_units'),\n",
    "        \"l2_dense\": experiment.get_parameter('l2_dense'),\n",
    "        \"dropout\": experiment.get_parameter('dropout'),\n",
    "        \"optimizer\": experiment.get_parameter('optimizer')\n",
    "        }, \n",
    "                        hyperparams_features=hyperparams_features, \n",
    "                        embedding_matrix=embedding_matrix, emotions=emotions)\n",
    "    history = train_model(model, \n",
    "            x_train, y_train, x_test, y_test,\n",
    "            epochs=7, batch_size=experiment.get_parameter('batch_size'),\n",
    "                      class_weight={0:1, 1:experiment.get_parameter('positive_class_weight')}, \n",
    "                          workers=4,\n",
    "                      model_path='models/experiment')\n",
    "    loss = history.history['loss'][-1]\n",
    "    \n",
    "    # Report the loss, if not auto-logged:\n",
    "    experiment.log_metric(\"loss\", loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
