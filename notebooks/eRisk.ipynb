{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import xml.etree.ElementTree as ET\n",
    "import glob, os\n",
    "import numpy as np\n",
    "from comet_ml import Experiment, Optimizer\n",
    "import pickle\n",
    "import logging\n",
    "import sys\n",
    "from sklearn.utils import class_weight\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "import json\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "# os.environ['CUDA_VISIBLE_DEVICES'] = '-1' # When cudnn implementation not found, run this\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\" # Note: when starting kernel, for gpu_available to be true, this needs to be run\n",
    "# only reserve 1 GPU\n",
    "os.environ['TFHUB_CACHE_DIR'] = '/home/anasab/tf_cache'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-c7836455e52f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# confirm TensorFlow sees the GPU\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclient\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdevice_lib\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32massert\u001b[0m \u001b[0;34m'GPU'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice_lib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlist_local_devices\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# # confirm Keras sees the GPU (for TensorFlow 1.X + Keras)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# confirm TensorFlow sees the GPU\n",
    "from tensorflow.python.client import device_lib\n",
    "assert 'GPU' in str(device_lib.list_local_devices())\n",
    "\n",
    "# # confirm Keras sees the GPU (for TensorFlow 1.X + Keras)\n",
    "# from keras import backend\n",
    "# assert len(backend.tensorflow_backend._get_available_gpus()) > 0\n",
    "\n",
    "# # confirm PyTorch sees the GPU\n",
    "# from torch import cuda\n",
    "# assert cuda.is_available()\n",
    "# assert cuda.device_count() > 0\n",
    "# print(cuda.get_device_name(cuda.current_device()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[name: \"/device:CPU:0\"\n",
       " device_type: \"CPU\"\n",
       " memory_limit: 268435456\n",
       " locality {\n",
       " }\n",
       " incarnation: 1776361591339185001,\n",
       " name: \"/device:XLA_CPU:0\"\n",
       " device_type: \"XLA_CPU\"\n",
       " memory_limit: 17179869184\n",
       " locality {\n",
       " }\n",
       " incarnation: 18369713350546881249\n",
       " physical_device_desc: \"device: XLA_CPU device\"]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device_lib.list_local_devices()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['TF_KERAS'] = '1'\n",
    "from tensorflow.keras.preprocessing import sequence\n",
    "from tensorflow.keras.models import Sequential, Model, load_model\n",
    "from tensorflow.keras.layers import Dense, Dropout, Embedding, LSTM, Lambda, BatchNormalization, TimeDistributed, \\\n",
    "    Bidirectional, Input, InputLayer, concatenate, Flatten, RepeatVector, Activation, Multiply, Permute, \\\n",
    "    Conv1D, GlobalMaxPooling1D\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras import callbacks, optimizers\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.utils import plot_model, Sequence\n",
    "\n",
    "from keras.utils import np_utils\n",
    "\n",
    "from nltk.tokenize import RegexpTokenizer, TweetTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "import tensorflow as tf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_type = \"symanto\"\n",
    "transfer_type = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transfer_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger = logging.getLogger('training')\n",
    "ch = logging.StreamHandler(sys.stdout)\n",
    "# create formatter\n",
    "formatter = logging.Formatter(\"%(asctime)s;%(levelname)s;%(message)s\")\n",
    "# add formatter to ch\n",
    "ch.setFormatter(formatter)\n",
    "# add ch to logger\n",
    "logger.addHandler(ch)\n",
    "logger.setLevel(logging.DEBUG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.setrecursionlimit(10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tf.enable_eager_execution()\n",
    "my_seed = 1234\n",
    "# tf.set_random_seed(my_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-11-17bb7203622b>:1: is_gpu_available (from tensorflow.python.framework.test_util) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.config.list_physical_devices('GPU')` instead.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.test.is_gpu_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.backend import manual_variable_initialization \n",
    "manual_variable_initialization(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_subject_writings(subject_file):\n",
    "    writings = []\n",
    "    with open(subject_file) as sf:\n",
    "        contents = sf.read()\n",
    "        root = ET.fromstring(contents)\n",
    "        try:\n",
    "            subject = root.findall('ID')[0].text.strip()\n",
    "        except Exception:\n",
    "            print('Cannot extract ID', contents[:500], '\\n-------\\n')        \n",
    "        for w in root.iter('WRITING'):\n",
    "            subject_writings = {'subject': subject}\n",
    "            for title in w.findall('TITLE'):\n",
    "                subject_writings['title'] = title.text\n",
    "            for text in w.findall('TEXT'):\n",
    "                subject_writings['text'] = text.text\n",
    "            for date in w.findall('DATE'):\n",
    "                subject_writings['date'] = date.text\n",
    "            writings.append(subject_writings)\n",
    "    return writings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# root_dir = '/home/anasab/' \n",
    "root_dir = '..' \n",
    "# root_dir = '/home/ana/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### eRisk 2020 T1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# datadir_T1 = root_dir + '/eRisk/data/eRisk2020_T1_train/eRISK2020_T1_training_data/eRISK2020_training_data/data/'\n",
    "# labels_file_T1 = root_dir + '/eRisk/data//eRisk2020_T1_train/eRISK2020_T1_training_data/eRISK2020_training_data/golden_truth.txt'\n",
    "\n",
    "datadirs_T1_2020 = {\n",
    "    'train': ['./data/'],\n",
    "    'test': ['./DATA/']\n",
    "}\n",
    "datadir_root_T1_2020 = {\n",
    "    'train': root_dir + '/eRisk/data/eRisk2020_T1_train/eRISK2020_T1_training_data/eRISK2020_training_data/',\n",
    "    'test': root_dir + '/eRisk/data/2020/T1/'\n",
    "}\n",
    "    \n",
    "labels_files_T1_2020 = {\n",
    "    'train': ['golden_truth.txt'],\n",
    "    'test': ['T1_erisk_golden_truth.txt']\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_texts_2020(datadir_root_T1_2020,\n",
    "                   datadirs_T1_2020,\n",
    "                   labels_files_T1_2020,\n",
    "                   test_suffix='0000',\n",
    "                    chunked_subsets=None):\n",
    "\n",
    "\n",
    "    writings = {'train': [], 'test': []}\n",
    "    writings_df = pd.DataFrame()\n",
    "    labels_df = pd.DataFrame()\n",
    "#     for subset in ('train', 'test'):\n",
    "    for subset in ('test',):\n",
    "        for subdir in [os.path.join(datadir_root_T1_2020[subset], subp) for subp in datadirs_T1_2020[subset]]:\n",
    "\n",
    "            for subject_file in os.listdir(subdir):\n",
    "                writings[subset].extend(read_subject_writings(os.path.join(subdir, subject_file)))\n",
    "        writings_df_part = pd.DataFrame(writings[subset])\n",
    "        # add a suffix for users in the test -- the numbers are duplicated with the ones in train\n",
    "        if subset=='test':\n",
    "            writings_df_part['subject'] = writings_df_part['subject'].apply(lambda s: s+test_suffix)\n",
    "            print(subset, writings_df_part.subject)\n",
    "        writings_df_part['subset'] = subset\n",
    "        writings_df = pd.concat([writings_df, writings_df_part])\n",
    "        writings_df.reindex()\n",
    "\n",
    "        for label_file in labels_files_T1_2020[subset]:\n",
    "            labels = pd.read_csv(os.path.join(datadir_root_T1_2020[subset], label_file), \n",
    "                                 delimiter='\\s+', names=['subject', 'label'])\n",
    "            # add a suffix for users in the test -- the numbers are duplicated with the ones in train\n",
    "            if subset=='test':\n",
    "                labels['subject'] = labels['subject'].apply(lambda s: s+test_suffix)\n",
    "            labels_df = pd.concat([labels_df, labels])\n",
    "    labels_df = labels_df.drop_duplicates()\n",
    "    labels_df = labels_df.set_index('subject')\n",
    "\n",
    "    writings_df = writings_df.drop_duplicates()\n",
    "    \n",
    "    writings_df = writings_df.join(labels_df, on='subject')\n",
    "    \n",
    "    return writings_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### eRisk 2019 T1 (Anorexia)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "datadirs_T1_2019 = {\n",
    "    'train': ['2018 test/', '2018 train/positive_examples/', '2018 train/negative_examples/'],\n",
    "    'test': ['data/']\n",
    "}\n",
    "datadir_root_T1_2019 = {\n",
    "    'train': root_dir + '/eRisk/data/past/eRisk2019_T1/training data - t1/',\n",
    "    'test': root_dir + '/eRisk/data/past/eRisk2019_T1/test data - T1/'\n",
    "}\n",
    "    \n",
    "labels_files_T1_2019 = {\n",
    "    'train': ['2018 train/risk_golden_truth.txt', '2018 test/risk-golden-truth-test.txt'],\n",
    "    'test': ['T1_erisk_golden_truth.txt']\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_texts_2019(datadir_root_T1_2019,\n",
    "                   datadirs_T1_2019,\n",
    "                   labels_files_T1_2019,\n",
    "                   test_suffix='0000',\n",
    "                    chunked_subsets='train'):\n",
    "    writings = {'train': [], 'test': []}\n",
    "    writings_df = pd.DataFrame()\n",
    "    labels_df = pd.DataFrame()\n",
    "\n",
    "    for subset in ('train', 'test'):\n",
    "        for subdir in [os.path.join(datadir_root_T1_2019[subset], subp) for subp in datadirs_T1_2019[subset]]:\n",
    "            if subset in chunked_subsets:\n",
    "                chunkdirs = [os.path.join(datadir_root_T1_2019[subset], subdir, chunkdir) \n",
    "                             for chunkdir in os.listdir(subdir)]\n",
    "            else:\n",
    "                chunkdirs = [os.path.join(datadir_root_T1_2019[subset], subdir)]\n",
    "                \n",
    "            for chunkdir in chunkdirs:\n",
    "                print(chunkdir)\n",
    "                if not os.path.isdir(chunkdir):\n",
    "                    continue\n",
    "                for subject_file in os.listdir(chunkdir):\n",
    "                    writings[subset].extend(read_subject_writings(os.path.join(chunkdir, subject_file)))\n",
    "        writings_df_part = pd.DataFrame(writings[subset])\n",
    "        # add a suffix for users in the test -- the numbers are duplicated with the ones in train\n",
    "        if subset=='test':\n",
    "            writings_df_part['subject'] = writings_df_part['subject'].apply(lambda s: s+test_suffix)\n",
    "            print(subset, writings_df_part.subject)\n",
    "        writings_df_part['subset'] = subset\n",
    "        writings_df = pd.concat([writings_df, writings_df_part])\n",
    "        writings_df.reindex()\n",
    "\n",
    "        for label_file in labels_files_T1_2019[subset]:\n",
    "            labels = pd.read_csv(os.path.join(datadir_root_T1_2019[subset], label_file), \n",
    "                                 delimiter='\\s+', names=['subject', 'label'])\n",
    "            # add a suffix for users in the test -- the numbers are duplicated with the ones in train\n",
    "            if subset=='test':\n",
    "                labels['subject'] = labels['subject'].apply(lambda s: s+test_suffix)\n",
    "            labels_df = pd.concat([labels_df, labels])\n",
    "    labels_df = labels_df.drop_duplicates()\n",
    "    labels_df = labels_df.set_index('subject')\n",
    "\n",
    "    writings_df = writings_df.drop_duplicates()\n",
    "    \n",
    "    writings_df = writings_df.join(labels_df, on='subject')\n",
    "    \n",
    "    return writings_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### eRisk 2018 (Depression)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "datadirs_T1_2018 = {\n",
    "    'train': ['train/positive_examples_anonymous_chunks/', 'train/positive_examples_anonymous_chunks/', 'test/'],\n",
    "    'test': ['task 1 - depression (test split, train split is 2017 data)/']\n",
    "}\n",
    "datadir_root_T1_2018 = {\n",
    "    'train': root_dir + '/eRisk/data/2017/',\n",
    "    'test': root_dir + '/eRisk/data/2018/'\n",
    "}\n",
    "    \n",
    "labels_files_T1_2018 = {\n",
    "    'train': ['train/risk_golden_truth.txt', 'test/test_golden_truth.txt'],\n",
    "    'test': ['task 1 - depression (test split, train split is 2017 data)/risk-golden-truth-test.txt']\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CLPsych\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "datadirs_clpsych = {\n",
    "    'train': [''],\n",
    "    'test': ['']\n",
    "}\n",
    "datadir_root_clpsych = {\n",
    "    'train': root_dir + '/eRisk/data/clpsych/final_training_data/',\n",
    "    'test': root_dir + '/eRisk/data/clpsych/final_testing_data/'\n",
    "}\n",
    "    \n",
    "labels_files_clpsych = [root_dir + '/eRisk/data/clpsych/anonymized_user_info_by_chunk.csv']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_subject_data_clpsych(subject_file):\n",
    "    writings = []\n",
    "    with open(subject_file, \"rt\", encoding=\"utf-8\") as sf:\n",
    "        user = subject_file.split(\"/\")[-1].split(\".\")[0]\n",
    "        print(subject_file)\n",
    "\n",
    "        for line in sf:\n",
    "            data = json.loads(line)#.encode('utf-16','surrogatepass').decode('utf-16'))\n",
    "            data['subject'] = user\n",
    "            writings.append(data)\n",
    "    return writings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_texts_clpsych(datadir_root_clpsych,\n",
    "                   datadirs_clpsych,\n",
    "                   labels_files_T1_2019,\n",
    "                      label_by=['depression']):\n",
    "    writings = {'train': [], 'test': []}\n",
    "    writings_df = pd.DataFrame()\n",
    "    labels_df = pd.DataFrame()\n",
    "\n",
    "    for subset in ('test',):#, 'test'):\n",
    "        for subdir in [os.path.join(datadir_root_clpsych[subset], subp) for subp in datadirs_clpsych[subset]]:\n",
    "            for subject_file in glob.glob(subdir + \"/*.tweets\"):\n",
    "#                 if subject_file.split(\"/\")[-1] != 'sZVVktDN8qqjA.tweets':\n",
    "#                     continue\n",
    "                writings[subset].extend(read_subject_data_clpsych(os.path.join(subdir, subject_file)))\n",
    "        writings_df_part = pd.DataFrame(writings[subset])\n",
    "        writings_df_part['subset'] = subset\n",
    "        writings_df = pd.concat([writings_df, writings_df_part])\n",
    "        writings_df.reindex()\n",
    "\n",
    "    for label_file in labels_files_clpsych:\n",
    "        labels = pd.read_csv(label_file, \n",
    "                    names=['subject','age','num_tweets','gender','condition','chunk_index'])\n",
    "        labels['label'] = labels['condition'].apply(lambda c: 1 if c in label_by else 0)\n",
    "        \n",
    "        labels_df = pd.concat([labels_df, labels])\n",
    "        labels_df = labels_df.drop_duplicates()\n",
    "        labels_df = labels_df.set_index('subject')\n",
    "\n",
    "        # TODO: this deduplication throws some unicode, surrogates not allowed, exception\n",
    "#     writings_df = writings_df.drop_duplicates(subset=['id', 'subject', 'subset', 'created_at', 'text'])\n",
    "    \n",
    "    writings_df = writings_df.join(labels_df, on='subject')\n",
    "    writings_df['date'] = writings_df['created_at']\n",
    "    \n",
    "    return writings_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Symanto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_texts_symanto(tsv_path=\"/eRisk/data/symanto/clean_dataset_with_timeline_balancedUsers.tsv\"):\n",
    "    label_key = {'REAL_LABEL_IS_DEPRESSED': 1,\n",
    "             'REAL_LABEL_IS_NON_DEPRESSED': 0}\n",
    "    prediction_key = {'predicted_as_depressed': 1,\n",
    "                     'predicted_as_non_depressed': 0,\n",
    "                     'DEPRESS_STRING_WAS_MENTIONED': -1}\n",
    "    \n",
    "    writings_df = pd.read_csv(root_dir + tsv_path, \n",
    "                              sep='\\t', names=['subject', 'date', 'text', 'prediction_text', 'real_label_text'])\n",
    "\n",
    "    writings_df = writings_df.dropna()\n",
    "    writings_df['label'] = writings_df['real_label_text'].apply(lambda l: label_key[l])\n",
    "    writings_df['prediction'] = writings_df['prediction_text'].apply(lambda l: prediction_key[l])\n",
    "#     By ommitting -1s we are excluding tweets where \"DEPRESSED\" was mentioned, and all after\n",
    "    writings_df = writings_df.drop(writings_df[writings_df['prediction']==-1].index)\n",
    "\n",
    "    \n",
    "    return writings_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# writings_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# writings_df = read_texts_2020(datadir_T1, labels_file_T1)\n",
    "# writings_df = read_texts_2019(datadir_root_T1_2019,\n",
    "#                    datadirs_T1_2019,\n",
    "#                    labels_files_T1_2019)\n",
    "# writings_df_depression = read_texts_2019(datadir_root_T1_2018,\n",
    "#                    datadirs_T1_2018,\n",
    "#                    labels_files_T1_2018,\n",
    "#                              chunked_subsets=['train', 'test'])\n",
    "\n",
    "if dataset_type == \"combined\":\n",
    "    writings_df_selfharm = pickle.load(open('data/writings_df_selfharm_all', 'rb'))\n",
    "    writings_df_anorexia = pickle.load(open('data/writings_df_anorexia_liwc', 'rb'))\n",
    "    writings_df_depression = pickle.load(open('data/writings_df_depression_liwc', 'rb'))\n",
    "    writings_df_selfharm['source'] = 'selfharm'\n",
    "    writings_df_anorexia['source'] = 'anorexia'\n",
    "    writings_df_depression['source'] = 'depression'\n",
    "    writings_df = pd.DataFrame()\n",
    "    writings_df = pd.concat([writings_df, writings_df_depression])\n",
    "    writings_df = pd.concat([writings_df, writings_df_selfharm])\n",
    "    writings_df = pd.concat([writings_df, writings_df_anorexia])\n",
    "elif dataset_type == \"combined_depr\":\n",
    "    writings_df = pd.DataFrame.from_dict(json.load(open('data/writings_df_depression_all.json')))\n",
    "elif dataset_type == \"clpsych\":\n",
    "    writings_df = pd.DataFrame.from_dict(json.load(open('data/writings_df_%s_liwc_affect.json' % dataset_type)))#read_texts_clpsych(datadir_root_clpsych, datadirs_clpsych, labels_files_clpsych)\n",
    "#     writings_df_test = pd.DataFrame.from_dict(json.load(open('writings_df_%s_test.json' % dataset_type)))#read_texts_clpsych(datadir_root_clpsych, datadirs_clpsych, labels_files_clpsych)\n",
    "#     writings_df_test = read_texts_clpsych(datadir_root_clpsych, datadirs_clpsych, labels_files_clpsych)\n",
    "    label_by = ['depression', 'ptsd']\n",
    "    writings_df.drop(writings_df[writings_df['condition']=='depression'].index, inplace=True)\n",
    "    writings_df['label'] = writings_df['condition'].apply(lambda c: 1 if c in label_by else 0)\n",
    "#     writings_df['date'] = writings_df['created_at']\n",
    "elif dataset_type == \"symanto\":\n",
    "#     writings_df = read_texts_symanto()\n",
    "    writings_df = pickle.load(open('../data/%s/writings_df_%s_liwc' % (dataset_type,dataset_type), 'rb'))\n",
    "elif dataset_type == 'selfharm':\n",
    "    writings_df = pickle.load(open('data/writings_df_%s_all' % dataset_type, 'rb'))\n",
    "elif dataset_type in [\"depression\", \"anorexia\", \"selfharm\"]:\n",
    "    writings_df = pickle.load(open('data/writings_df_%s_liwc' % dataset_type, 'rb'))\n",
    "else:\n",
    "    logger.error(\"Unknown dataset %s\" % dataset_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# writings_df[writings_df['condition']!='control'].head(150)[['label', 'condition', 'date']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['subject', 'date', 'text', 'prediction_text', 'real_label_text',\n",
       "       'label', 'prediction', 'tokenized_text', 'text_len', 'all_tokens',\n",
       "       'funct', 'article', 'affect', 'negemo', 'sad', 'cogmech', 'inhib',\n",
       "       'bio', 'body', 'achieve', 'health', 'sexual', 'adverb', 'preps',\n",
       "       'space', 'relativ', 'time', 'work', 'certain', 'assent', 'anger',\n",
       "       'posemo', 'insight', 'verb', 'past', 'money', 'percept', 'social',\n",
       "       'friend', 'motion', 'cause', 'leisure', 'incl', 'home', 'present',\n",
       "       'humans', 'anx', 'relig', 'auxverb', 'negate', 'ingest', 'death',\n",
       "       'quant', 'tentat', 'conj', 'pronoun', 'ipron', 'swear', 'hear',\n",
       "       'family', 'see', 'discrep', 'number', 'filler', 'feel', 'excl',\n",
       "       'future', 'nonfl', 'ppron', 'shehe', 'i', 'we', 'you', 'they'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# writings_df.label.hist()\n",
    "writings_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(set(writings_df[writings_df['label']==1].subject))\n",
    "# len(set(writings_df[writings_df['label']==0].subject))\n",
    "# len(set(writings_df[writings_df['subset']=='test'].subject))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set(writings_df['source'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "regtokenizer = RegexpTokenizer(r'\\w+')\n",
    "tweet_tokenizer = TweetTokenizer()\n",
    "sw = stopwords.words(\"english\")\n",
    "\n",
    "def tokenize(t, tokenizer=regtokenizer):\n",
    "    return regtokenizer.tokenize(t.lower())\n",
    "\n",
    "def tokenize_tweets(t, stop=True):\n",
    "    tokens = tweet_tokenizer.tokenize(t.lower())\n",
    "    tokens_clean = [re.sub(\"^#\", \"\", token) for token in tokens]\n",
    "    tokens_clean = [token for token in tokens_clean \n",
    "                            if re.match(\"^[a-z]*$\", token)]\n",
    "    if not stop:\n",
    "        tokens_clean = [token for token in tokens\n",
    "                       if (token not in sw)]\n",
    "    return tokens_clean\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# re.sub(\"^#\", \"\", \"#h#ash\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_fields(writings_df, tokenize_fct=tokenize, columns=['title', 'text']):\n",
    "    for c in columns:\n",
    "        writings_df['tokenized_%s' % c] = writings_df['%s' % c].apply(lambda t: tokenize_fct(t) \n",
    "                                                                if type(t)==str and t else None)\n",
    "        writings_df['%s_len' % c] = writings_df['tokenized_%s' % c].apply(lambda t: len(t) \n",
    "                                                                    if type(t)==list and t else None)\n",
    "    return writings_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# writings_df = tokenize_fields(writings_df, tokenize_fct=tokenize_tweets, columns=['title'])\n",
    "writings_df = tokenize_fields(writings_df, tokenize_fct=tokenize_tweets, columns=['text'])\n",
    "# writings_df = tokenize_fields(writings_df, tokenize_fct=tokenize, columns=['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# writings_df.text_len.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# writings_df.title_len.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# writings_df.groupby('subject').mean().describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# writings_df.groupby('subject').max().groupby('label').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"Average number of posts per user\", writings_df.groupby('subject').count().title.mean())\n",
    "# print(\"Average number of comments per user\", writings_df.groupby('subject').count().text.mean())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# writings_df.groupby('subject').count().title.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# writings_df.groupby('subject').count().text.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# writings_df.tokenized_text.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# writings_dict = writings_df.to_dict()\n",
    "# json.dump(writings_dict, open(\"writings_df_clpsych_all.json\", \"w+\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"Total examples\", writings_df[['subject', 'subset', 'label'\n",
    "#                                     ]].groupby('subject').min().groupby('subset').count())\n",
    "# print(\"Positive examples\", writings_df[['subject', 'subset', 'label'\n",
    "#                                     ]].groupby('subject').min().groupby('subset').sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# writings_df[['label', 'source']].groupby('source').sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# writings_df['text'] = writings_df['text'].fillna(\"\")\n",
    "# writings_df['title'] = writings_df['title'].fillna(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recurrent NN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract features and encode data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model_and_params(model, model_path, hyperparams, hyperparams_features):\n",
    "    model.save_weights(model_path + \"_weights.h5\", save_format='h5')\n",
    "#     model.save(model_path + \"_model.model\")\n",
    "#     model.save(model_path + \"_model.h5\")\n",
    "    with open(model_path + '.hp.json', 'w+') as hpf:\n",
    "        hpf.write(json.dumps({k:v for (k,v) in hyperparams.items() if k!='optimizer'}))\n",
    "    with open(model_path + '.hpf.json', 'w+') as hpff:\n",
    "        hpff.write(json.dumps(hyperparams_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_params(model_path):\n",
    "    with open(model_path + '.hp.json', 'r') as hpf:\n",
    "        hyperparams = json.loads(hpf.read())\n",
    "    with open(model_path + '.hpf.json', 'r') as hpff:\n",
    "        hyperparams_features = json.loads(hpff.read())\n",
    "    return hyperparams, hyperparams_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparams_features = {\n",
    "    \"max_features\": 20002,\n",
    "    # cut texts after this number of words\n",
    "    # (among top max_features most common words)\n",
    "    \"embedding_dim\": 300,\n",
    "    'vocabulary_path': root_dir+'/data/all_vocab_clpsych_erisk_stop_20000.pkl',\n",
    "#     'embeddings_path': root_dir + '/eRisk/embeddings/finetuned_glove_clpsych_erisk_stop_normalized_20000.pkl',\n",
    "    'embeddings_path': root_dir + '/resources/glove.840B/glove.840B.300d.txt',\n",
    "    'liwc_words_cached': root_dir +'/data/liwc_categories_for_vocabulary_erisk_clpsych_stop_20K.pkl',\n",
    "    \"user_level\": True, # deprecated\n",
    "    \"transfer\": transfer_type,\n",
    "#     \"pretrained_model_path\": 'models/lstm_clpsych_hierarchical64_ptsdvsdepr'\n",
    "#     \"pretrained_model_path\": 'models/lstm_clpsych_hierarchical64_ptsd'\n",
    "    \"pretrained_model_path\": 'models/lstm_symanto_hierarchical64'\n",
    "#     \"pretrained_model_path\": 'models/lstm_clpsych_hierarchical65'\n",
    "#     \"pretrained_model_path\": 'models/lstm_depression_hierarchical56'\n",
    "#     \"pretrained_model_path\": 'models/lstm_anorexia_hierarchical64'\n",
    "#     \"pretrained_model_path\": 'models/lstm_selfharm_hierarchical59'\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "if transfer_type:\n",
    "    pretrained_model_path = hyperparams_features['pretrained_model_path']\n",
    "    hyperparams, hyperparams_features = load_params(hyperparams_features['pretrained_model_path'])\n",
    "    hyperparams_features['pretrained_model_path'] = pretrained_model_path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Emotions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_NRC(nrc_path):\n",
    "    word_emotions = {}\n",
    "    emotion_words = {}\n",
    "    with open(nrc_path) as in_f:\n",
    "        for line in in_f:\n",
    "            line = line.strip()\n",
    "            if not line:\n",
    "                continue\n",
    "            word, emotion, label = line.split()\n",
    "            if word not in word_emotions:\n",
    "                word_emotions[word] = set()\n",
    "            if emotion not in emotion_words:\n",
    "                emotion_words[emotion] = set()\n",
    "            label = int(label)\n",
    "            if label:\n",
    "                word_emotions[word].add(emotion)\n",
    "                emotion_words[emotion].add(word)\n",
    "    return emotion_words\n",
    "\n",
    "nrc_lexicon_path = root_dir + '/resources/NRC-Emotion-Lexicon-Wordlevel-v0.92.txt'\n",
    "nrc_lexicon = load_NRC(nrc_lexicon_path)\n",
    "emotions = list(nrc_lexicon.keys())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_emotions(tokens, emotion_lexicon, emotions, relative=True):\n",
    "    text_len = len(tokens)\n",
    "    encoded_emotions = [0 for e in emotions]\n",
    "    for i, emotion in enumerate(emotions):\n",
    "        try:\n",
    "            emotion_words = [t for t in tokens if t in emotion_lexicon[emotion]]\n",
    "            if relative and len(tokens):\n",
    "                encoded_emotions[i] = len(emotion_words) / len(tokens)\n",
    "            else:\n",
    "                encoded_emotions[i] = len(emotion_words)\n",
    "        except ValueError:\n",
    "            print(\"Emotion not found.\")\n",
    "    return encoded_emotions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "64"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from liwc_readDict import readDict\n",
    "\n",
    "liwc_dict = {}\n",
    "for (w, c) in readDict(root_dir + '/resources/liwc.dic'):\n",
    "    if c not in liwc_dict:\n",
    "        liwc_dict[c] = []\n",
    "    liwc_dict[c].append(w)\n",
    "\n",
    "categories = set(liwc_dict.keys())\n",
    "len(categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "liwc_categories=[c for c in categories]# if c in writings_df.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "liwc_words_for_categories = pickle.load(open(root_dir+\"/data/liwc_categories_for_vocabulary_erisk_clpsych_stop_20K.pkl\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"liwc_categories.txt\",\"w+\") as f:\n",
    "    for cat in liwc_dict:\n",
    "        f.write(\"%s: %s\\n\" % (cat, \",\".join(liwc_dict[cat])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"nrc_emotions.txt\",\"w+\") as f:\n",
    "    for cat in nrc_lexicon:\n",
    "        f.write(\"%s: %s\\n\" % (cat, \",\".join(nrc_lexicon[cat])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Style features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Char n-grams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_ngrams(tokens):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Personal pronouns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_person_pronouns = {\"i\", \"me\", \"my\", \"mine\", \"myself\"}\n",
    "def encode_pronouns(tokens, pronouns={\"i\", \"me\", \"my\", \"mine\", \"myself\"}, relative=True):\n",
    "    if not tokens:\n",
    "        return 0\n",
    "    text_len = len(tokens)\n",
    "    nr_pronouns = len([t for t in tokens if t in pronouns])\n",
    "    if relative and text_len:\n",
    "        return nr_pronouns/text_len\n",
    "    else:\n",
    "        return nr_pronouns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopword_list = stopwords.words(\"english\")\n",
    "def encode_stopwords(tokens, stopwords=stopword_list):\n",
    "    encoded_stopwords = [0 for s in stopword_list]\n",
    "    if not tokens:\n",
    "        return encoded_stopwords\n",
    "    for i, stopword in enumerate(stopwords):\n",
    "        if stopword in tokens:\n",
    "            encoded_stopwords[i] += 1\n",
    "    return encoded_stopwords"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Topics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BERT\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow_hub as hub\n",
    "bert_path = \"https://tfhub.dev/google/bert_uncased_L-12_H-768_A-12/1\"\n",
    "from bert.tokenization import FullTokenizer\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "class InputExample(object):\n",
    "    \"\"\"A single training/test example for simple sequence classification.\"\"\"\n",
    "\n",
    "    def __init__(self, guid, text_a, text_b=None, label=None):\n",
    "        \"\"\"Constructs a InputExample.\n",
    "    Args:\n",
    "      guid: Unique id for the example.\n",
    "      text_a: string. The untokenized text of the first sequence. For single\n",
    "        sequence tasks, only this sequence must be specified.\n",
    "      text_b: (Optional) string. The untokenized text of the second sequence.\n",
    "        Only must be specified for sequence pair tasks.\n",
    "      label: (Optional) string. The label of the example. This should be\n",
    "        specified for train and dev examples, but not for test examples.\n",
    "    \"\"\"\n",
    "        self.guid = guid\n",
    "        self.text_a = text_a\n",
    "        self.text_b = text_b\n",
    "        self.label = label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_text_for_bert(tokenizer, example, max_seq_length=256):\n",
    "    \"\"\"Converts a single `InputExample` into a single `InputFeatures`.\"\"\"\n",
    "\n",
    "#     if isinstance(example, PaddingInputExample):\n",
    "#         input_ids = [0] * max_seq_length\n",
    "#         input_mask = [0] * max_seq_length\n",
    "#         segment_ids = [0] * max_seq_length\n",
    "#         label = 0\n",
    "#         return input_ids, input_mask, segment_ids, label\n",
    "\n",
    "    tokens_a = tokenizer.tokenize(example.text_a)\n",
    "    if len(tokens_a) > max_seq_length - 2:\n",
    "        tokens_a = tokens_a[0 : (max_seq_length - 2)]\n",
    "\n",
    "    tokens = []\n",
    "    segment_ids = []\n",
    "    tokens.append(\"[CLS]\")\n",
    "    segment_ids.append(0)\n",
    "    for token in tokens_a:\n",
    "        tokens.append(token)\n",
    "        segment_ids.append(0)\n",
    "    tokens.append(\"[SEP]\")\n",
    "    segment_ids.append(0)\n",
    "\n",
    "    input_ids = tokenizer.convert_tokens_to_ids(tokens)\n",
    "\n",
    "    # The mask has 1 for real tokens and 0 for padding tokens. Only real\n",
    "    # tokens are attended to.\n",
    "    input_mask = [1] * len(input_ids)\n",
    "\n",
    "    # Zero-pad up to the sequence length.\n",
    "    while len(input_ids) < max_seq_length:\n",
    "        input_ids.append(0)\n",
    "        input_mask.append(0)\n",
    "        segment_ids.append(0)\n",
    "\n",
    "    assert len(input_ids) == max_seq_length\n",
    "    assert len(input_mask) == max_seq_length\n",
    "    assert len(segment_ids) == max_seq_length\n",
    "\n",
    "    return input_ids, input_mask, segment_ids, example.label\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_tokenizer_from_hub_module(sess):\n",
    "    \"\"\"Get the vocab file and casing info from the Hub module.\"\"\"\n",
    "    bert_module =  hub.Module(bert_path)\n",
    "    tokenization_info = bert_module(signature=\"tokenization_info\", as_dict=True)\n",
    "    vocab_file, do_lower_case = sess.run(\n",
    "        [\n",
    "            tokenization_info[\"vocab_file\"],\n",
    "            tokenization_info[\"do_lower_case\"],\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    return FullTokenizer(vocab_file=vocab_file, do_lower_case=do_lower_case)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_sess(sess=None):\n",
    "    if not sess:\n",
    "        sess_config = tf.ConfigProto(\n",
    "            device_count={ 'GPU' : 1, 'CPU': 4 },\n",
    "            intra_op_parallelism_threads = 0,\n",
    "            inter_op_parallelism_threads = 4,\n",
    "            allow_soft_placement=False,\n",
    "            log_device_placement=True,\n",
    "        )\n",
    "        sess_config.gpu_options.allow_growth = True\n",
    "        sess_config.gpu_options.per_process_gpu_memory_fraction = 1\n",
    "        sess = tf.Session(config=sess_config)\n",
    "\n",
    "    sess.run(tf.local_variables_initializer())\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    sess.run(tf.tables_initializer())\n",
    "    K.set_session(sess)\n",
    "    return sess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_saved_model(model_path, hyperparams):\n",
    "    metrics_class = Metrics(threshold=hyperparams['threshold'])\n",
    "    dependencies = {\n",
    "    'f1_m': metrics_class.f1_m,\n",
    "    'auc': metrics_class.auc,\n",
    "    'precision_m': metrics_class.precision_m,\n",
    "    'recall_m': metrics_class.recall_m,\n",
    "    'binary_crossentropy_custom': binary_crossentropy_custom,\n",
    "    'BertLayer': BertLayer\n",
    "    }\n",
    "    loaded_model = load_model(model_path + \"_model.h5\", custom_objects=dependencies)\n",
    "#     loaded_model = load_model(model_path + \"_model.model\", custom_objects=dependencies)\n",
    "    return loaded_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_saved_model_weights(model_path, hyperparams, emotions, stopword_list, liwc_categories, classes, h5=False):\n",
    "    metrics_class = Metrics(threshold=hyperparams['threshold'])\n",
    "    dependencies = {\n",
    "    'f1_m': metrics_class.f1_m,\n",
    "    'auc': metrics_class.auc,\n",
    "    'precision_m': metrics_class.precision_m,\n",
    "    'recall_m': metrics_class.recall_m,\n",
    "    'binary_crossentropy_custom': binary_crossentropy_custom,\n",
    "    'BertLayer': BertLayer\n",
    "    }\n",
    "    loaded_model = initialize_model(hyperparams=hyperparams, hyperparams_features=hyperparams_features, \n",
    "                                    embedding_matrix=embedding_matrix, \n",
    "                                 emotions=emotions, stopword_list=stopword_list, liwc_categories=liwc_categories,\n",
    "                                classes=classes)\n",
    "    loaded_model.summary()\n",
    "#     loaded_model.load_weights(model_path + \"_weights\")\n",
    "    path = model_path + \"_weights\"\n",
    "    by_name = False\n",
    "    if h5:\n",
    "        path += \".h5\"\n",
    "        by_name=True\n",
    "    loaded_model.load_weights(path, by_name=by_name)\n",
    "    #     loaded_model = load_model(model_path + \"_model.model\", custom_objects=dependencies)\n",
    "    return loaded_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "tf.test.is_gpu_available()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encode data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "def load_erisk_data(writings_df, voc_size, emotion_lexicon, emotions =  \n",
    "                    ['anger', 'anticipation', 'disgust', 'fear', 'joy', \n",
    "                     'negative', 'positive', 'sadness', 'surprise', 'trust'],\n",
    "                    liwc_categories = categories, by_subset=True,\n",
    "                    pronouns = [\"i\", \"me\", \"my\", \"mine\", \"myself\"],\n",
    "                    train_prop=0.7, valid_prop=0.3, test_slice=2,\n",
    "                    nr_slices=5,\n",
    "                    min_post_len=3, min_word_len=1, \n",
    "                    user_level=True, vocabulary=None, labelcol='label', label_index=None,\n",
    "                   logger=logger):\n",
    "    logger.debug(\"Loading data...\\n\")\n",
    "    \n",
    "    ## Build vocabulary\n",
    "    vocabulary_all = {}\n",
    "    word_freqs = Counter()\n",
    "    \n",
    "    for words in writings_df.tokenized_text:\n",
    "        word_freqs.update(words)\n",
    "    if 'tokenized_title' in writings_df.columns:\n",
    "        for words in writings_df.tokenized_title:\n",
    "            word_freqs.update(words)\n",
    "    i = 1\n",
    "    for w, f in word_freqs.most_common(voc_size-2): # keeping voc_size-1 for unk\n",
    "        if len(w) < min_word_len:\n",
    "            continue\n",
    "        vocabulary_all[w] = i\n",
    "        i += 1\n",
    "    if not vocabulary:\n",
    "        vocabulary = vocabulary_all\n",
    "    else:\n",
    "        logger.info(\"Words not found in the vocabulary: %d\\n\" % len(set(vocabulary_all.keys()).difference(\n",
    "            set(vocabulary.keys()))))\n",
    "\n",
    "    if labelcol != 'label' and not label_index:\n",
    "        label_index = {}\n",
    "        l = 0\n",
    "        for label in set(writings_df[labelcol]):\n",
    "            label_index[label] = l\n",
    "            l += 1\n",
    "        print(\"Label index\", label_index)\n",
    "   \n",
    "    if by_subset and 'subset' in writings_df.columns:\n",
    "        training_subjects = list(set(writings_df[writings_df['subset']=='train'].subject))\n",
    "        test_subjects = list(set(writings_df[writings_df['subset']=='test'].subject))\n",
    "    else:\n",
    "        all_subjects = sorted(list(set(writings_df.subject)))\n",
    "        training_subjects_size = int(len(all_subjects) * train_prop)\n",
    "        test_subjects_size = len(all_subjects) - training_subjects_size\n",
    "        logger.info(\"%d training subjects, %d test subjects\\n\" % (training_subjects_size, test_subjects_size))\n",
    "        # Cross-validation, with fixed slice as input\n",
    "        test_prop = 1-train_prop\n",
    "        test_slice = min(test_slice, nr_slices)\n",
    "        logger.debug(\"start index: %f, from %f\\n\" % (\n",
    "            len(all_subjects)*(1/nr_slices)*test_slice, test_prop*test_slice))\n",
    "        start_slice = int(len(all_subjects)*(1/nr_slices)*test_slice)\n",
    "        test_subjects = all_subjects[start_slice: start_slice+test_subjects_size]\n",
    "        training_subjects = [s for s in all_subjects if s not in test_subjects]\n",
    "    training_subjects = sorted(training_subjects) # ensuring reproducibility\n",
    "    valid_subjects_size = int(len(training_subjects) * valid_prop)\n",
    "    valid_subjects = training_subjects[:valid_subjects_size]\n",
    "    training_subjects = training_subjects[valid_subjects_size:]\n",
    "    categories = [c for c in liwc_categories if c in writings_df.columns]\n",
    "    logger.debug(\"%d training users, %d validation users, %d test users.\" % (\n",
    "        len(training_subjects), \n",
    "          len(valid_subjects),\n",
    "          len(test_subjects)))\n",
    "    subjects_split = {'train': training_subjects, \n",
    "                      'valid': valid_subjects, \n",
    "                      'test': test_subjects}\n",
    "\n",
    "    user_level_texts = {}\n",
    "    for row in writings_df.sort_values(by='date').itertuples():\n",
    "        words = []\n",
    "        raw_text = \"\"\n",
    "        if hasattr(row, 'tokenized_title'):\n",
    "            if row.tokenized_title:\n",
    "                words.extend(row.tokenized_title)\n",
    "                raw_text += row.title\n",
    "        if hasattr(row, 'tokenized_text'):\n",
    "            if row.tokenized_text:\n",
    "                words.extend(row.tokenized_text)\n",
    "                raw_text += row.text\n",
    "        if not words or len(words)<min_post_len:\n",
    "#             logger.debug(row.subject)\n",
    "            continue\n",
    "        if labelcol == 'label':\n",
    "            label = row.label\n",
    "        else:\n",
    "            label = label_index[getattr(row, labelcol)]\n",
    "        liwc_categs = [getattr(row, categ) for categ in categories]\n",
    "        if row.subject not in user_level_texts.keys():\n",
    "            user_level_texts[row.subject] = {}\n",
    "            user_level_texts[row.subject]['texts'] = [words]\n",
    "            user_level_texts[row.subject]['label'] = label\n",
    "            user_level_texts[row.subject]['liwc'] = [liwc_categs]\n",
    "            user_level_texts[row.subject]['raw'] = [raw_text]\n",
    "        else:\n",
    "            user_level_texts[row.subject]['texts'].append(words)\n",
    "            user_level_texts[row.subject]['liwc'].append(liwc_categs)\n",
    "            user_level_texts[row.subject]['raw'].append(raw_text)\n",
    "            \n",
    "    return user_level_texts, subjects_split, vocabulary\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# del writings_df['tokenized_title']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-11-29 16:58:13,518;DEBUG;Loading data...\n",
      "\n",
      "2021-11-29 16:58:13,695;INFO;Words not found in the vocabulary: 7599\n",
      "\n",
      "2021-11-29 16:58:13,700;INFO;363 training subjects, 156 test subjects\n",
      "\n",
      "2021-11-29 16:58:13,701;DEBUG;start index: 207.600000, from 0.600000\n",
      "\n",
      "2021-11-29 16:58:13,703;DEBUG;255 training users, 108 validation users, 156 test users.\n"
     ]
    }
   ],
   "source": [
    "vocabulary_list = pickle.load(open(hyperparams_features['vocabulary_path'], 'rb'))\n",
    "vocabulary_dict={}\n",
    "for i,w in enumerate(vocabulary_list):\n",
    "    vocabulary_dict[w] = i\n",
    "user_level_data, subjects_split, vocabulary = load_erisk_data(writings_df, \n",
    "                                                            voc_size=hyperparams_features['max_features'],\n",
    "                                                           emotion_lexicon=nrc_lexicon,\n",
    "                                                           emotions=emotions,\n",
    "                                                           user_level=hyperparams_features['user_level'],\n",
    "                                                                                logger=logger,\n",
    "#                                                            vocabulary=pickle.load(open('vocabulary_40K_all.pkl', 'rb')),\n",
    "#                                                            vocabulary=pickle.load(open('vocab_clpsych_10000.pkl', 'rb')),\n",
    "                                                              vocabulary=vocabulary_dict,\n",
    "                                                              by_subset=True,\n",
    "#                                                               labelcol = 'condition',\n",
    "#                                                               label_index={'depression':1, \"ptsd\":0}\n",
    "                                                                               )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# writings_df['subset'] = writings_df['subject'].apply(lambda s: 'test' if s in subjects_split['test'] else 'train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20000"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vocabulary_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [bit, of, a, storm, coming, through, archdal, ...\n",
       "1    [not, to, bad, considering, all, i, had, was, ...\n",
       "2    [please, tell, me, how, we, can, expect, our, ...\n",
       "3    [if, someone, offers, you, something, that, se...\n",
       "4    [you, spend, your, whole, life, holding, the, ...\n",
       "Name: tokenized_text, dtype: object"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "writings_df['tokenized_text'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "writings_df.text_len.hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pickle.dump(writings_df, open('writings_df_selfharm_liwc_subsets', 'wb+'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('bookstore', 0),\n",
       " ('weeds', 1),\n",
       " ('matty', 2),\n",
       " ('manufacture', 3),\n",
       " ('exchanges', 4),\n",
       " ('lag', 5),\n",
       " ('huge', 6),\n",
       " ('psychopath', 7),\n",
       " ('unnecessarily', 8),\n",
       " ('melania', 9),\n",
       " ('naturally', 10),\n",
       " ('perspectives', 11),\n",
       " ('legendary', 12),\n",
       " ('barbarian', 13),\n",
       " ('fatalities', 14),\n",
       " ('related', 15),\n",
       " ('inflated', 16),\n",
       " ('landslide', 17),\n",
       " ('winter', 18),\n",
       " ('legality', 19),\n",
       " ('upstairs', 20),\n",
       " ('papa', 21),\n",
       " ('blatantly', 22),\n",
       " ('oregon', 23),\n",
       " ('offend', 24),\n",
       " ('spears', 25),\n",
       " ('boom', 26),\n",
       " ('lrt', 27),\n",
       " ('snarky', 28),\n",
       " ('shallow', 29),\n",
       " ('illustrator', 30),\n",
       " ('cups', 31),\n",
       " ('airlines', 32),\n",
       " ('l', 33),\n",
       " ('twilight', 34),\n",
       " ('espresso', 35),\n",
       " ('creek', 36),\n",
       " ('swearing', 37),\n",
       " ('abomination', 38),\n",
       " ('boosie', 39),\n",
       " ('snowman', 40),\n",
       " ('recipes', 41),\n",
       " ('wiretap', 42),\n",
       " ('fapping', 43),\n",
       " ('intoxicated', 44),\n",
       " ('phrased', 45),\n",
       " ('oppression', 46),\n",
       " ('remix', 47),\n",
       " ('sailor', 48),\n",
       " ('lewis', 49),\n",
       " ('they', 50),\n",
       " ('shin', 51),\n",
       " ('airconsole', 52),\n",
       " ('accused', 53),\n",
       " ('spike', 54),\n",
       " ('delay', 55),\n",
       " ('skeleton', 56),\n",
       " ('unfollow', 57),\n",
       " ('admired', 58),\n",
       " ('informing', 59),\n",
       " ('crazies', 60),\n",
       " ('handle', 61),\n",
       " ('warmer', 62),\n",
       " ('resembles', 63),\n",
       " ('recommendations', 64),\n",
       " ('galactic', 65),\n",
       " ('palin', 66),\n",
       " ('elses', 67),\n",
       " ('ecuador', 68),\n",
       " ('rnc', 69),\n",
       " ('hay', 70),\n",
       " ('logos', 71),\n",
       " ('performances', 72),\n",
       " ('tripping', 73),\n",
       " ('diets', 74),\n",
       " ('joshua', 75),\n",
       " ('hide', 76),\n",
       " ('all', 77),\n",
       " ('ain', 78),\n",
       " ('moustache', 79),\n",
       " ('celeb', 80),\n",
       " ('safari', 81),\n",
       " ('emotions', 82),\n",
       " ('giddy', 83),\n",
       " ('opposing', 84),\n",
       " ('guardians', 85),\n",
       " ('negotiations', 86),\n",
       " ('teased', 87),\n",
       " ('officially', 88),\n",
       " ('nom', 89),\n",
       " ('bbs', 90),\n",
       " ('gist', 91),\n",
       " ('ohhhhh', 92),\n",
       " ('nahh', 93),\n",
       " ('inception', 94),\n",
       " ('drugged', 95),\n",
       " ('historic', 96),\n",
       " ('reef', 97),\n",
       " ('paula', 98),\n",
       " ('fv', 99),\n",
       " ('interactive', 100),\n",
       " ('sap', 101),\n",
       " ('preliminary', 102),\n",
       " ('smirk', 103),\n",
       " ('gunfire', 104),\n",
       " ('prejudice', 105),\n",
       " ('crates', 106),\n",
       " ('nostalgic', 107),\n",
       " ('trivial', 108),\n",
       " ('apt', 109),\n",
       " ('lasting', 110),\n",
       " ('awesomeness', 111),\n",
       " ('calming', 112),\n",
       " ('reputation', 113),\n",
       " ('monroe', 114),\n",
       " ('walls', 115),\n",
       " ('truths', 116),\n",
       " ('illusion', 117),\n",
       " ('variability', 118),\n",
       " ('nodding', 119),\n",
       " ('ninja', 120),\n",
       " ('spirituality', 121),\n",
       " ('marketplace', 122),\n",
       " ('credible', 123),\n",
       " ('sjw', 124),\n",
       " ('nathan', 125),\n",
       " ('buzzing', 126),\n",
       " ('rockford', 127),\n",
       " ('uphill', 128),\n",
       " ('billy', 129),\n",
       " ('contaminated', 130),\n",
       " ('baths', 131),\n",
       " ('psychologically', 132),\n",
       " ('newark', 133),\n",
       " ('squirrels', 134),\n",
       " ('dropped', 135),\n",
       " ('logs', 136),\n",
       " ('functions', 137),\n",
       " ('strategy', 138),\n",
       " ('dealer', 139),\n",
       " ('grassroots', 140),\n",
       " ('reopen', 141),\n",
       " ('protocols', 142),\n",
       " ('colombian', 143),\n",
       " ('raleigh', 144),\n",
       " ('explicit', 145),\n",
       " ('exile', 146),\n",
       " ('hawkeye', 147),\n",
       " ('mention', 148),\n",
       " ('ego', 149),\n",
       " ('goin', 150),\n",
       " ('monumental', 151),\n",
       " ('eww', 152),\n",
       " ('margot', 153),\n",
       " ('thts', 154),\n",
       " ('apollo', 155),\n",
       " ('placebo', 156),\n",
       " ('cancels', 157),\n",
       " ('startups', 158),\n",
       " ('yemen', 159),\n",
       " ('mango', 160),\n",
       " ('combination', 161),\n",
       " ('locker', 162),\n",
       " ('lmaoooo', 163),\n",
       " ('penn', 164),\n",
       " ('paused', 165),\n",
       " ('fn', 166),\n",
       " ('derogatory', 167),\n",
       " ('wid', 168),\n",
       " ('magically', 169),\n",
       " ('uc', 170),\n",
       " ('going', 171),\n",
       " ('watcher', 172),\n",
       " ('coat', 173),\n",
       " ('always', 174),\n",
       " ('calculator', 175),\n",
       " ('pistons', 176),\n",
       " ('um', 177),\n",
       " ('glanced', 178),\n",
       " ('mona', 179),\n",
       " ('manor', 180),\n",
       " ('dumbass', 181),\n",
       " ('articulate', 182),\n",
       " ('sciences', 183),\n",
       " ('chomsky', 184),\n",
       " ('gloomy', 185),\n",
       " ('elaborate', 186),\n",
       " ('culturally', 187),\n",
       " ('hyper', 188),\n",
       " ('babysit', 189),\n",
       " ('tweeting', 190),\n",
       " ('shark', 191),\n",
       " ('contradiction', 192),\n",
       " ('gamble', 193),\n",
       " ('spat', 194),\n",
       " ('cartel', 195),\n",
       " ('prefers', 196),\n",
       " ('annoy', 197),\n",
       " ('devos', 198),\n",
       " ('owl', 199),\n",
       " ('tldr', 200),\n",
       " ('nationalists', 201),\n",
       " ('octane', 202),\n",
       " ('traffic', 203),\n",
       " ('mankind', 204),\n",
       " ('speculation', 205),\n",
       " ('primaries', 206),\n",
       " ('gullible', 207),\n",
       " ('compulsive', 208),\n",
       " ('supporters', 209),\n",
       " ('peeled', 210),\n",
       " ('suggests', 211),\n",
       " ('timeout', 212),\n",
       " ('isis', 213),\n",
       " ('mac', 214),\n",
       " ('coherent', 215),\n",
       " ('mall', 216),\n",
       " ('mumbai', 217),\n",
       " ('flee', 218),\n",
       " ('attitudes', 219),\n",
       " ('silk', 220),\n",
       " ('proposing', 221),\n",
       " ('only', 222),\n",
       " ('quad', 223),\n",
       " ('tourism', 224),\n",
       " ('shuttle', 225),\n",
       " ('selection', 226),\n",
       " ('clarity', 227),\n",
       " ('ahhhh', 228),\n",
       " ('donna', 229),\n",
       " ('phrase', 230),\n",
       " ('weaken', 231),\n",
       " ('famu', 232),\n",
       " ('command', 233),\n",
       " ('skate', 234),\n",
       " ('refrain', 235),\n",
       " ('sideline', 236),\n",
       " ('sb', 237),\n",
       " ('roi', 238),\n",
       " ('sobs', 239),\n",
       " ('sighting', 240),\n",
       " ('calcium', 241),\n",
       " ('ounce', 242),\n",
       " ('sticker', 243),\n",
       " ('futuristic', 244),\n",
       " ('antibiotics', 245),\n",
       " ('exiting', 246),\n",
       " ('booth', 247),\n",
       " ('smith', 248),\n",
       " ('settlers', 249),\n",
       " ('completion', 250),\n",
       " ('terran', 251),\n",
       " ('borders', 252),\n",
       " ('fuck', 253),\n",
       " ('childbirth', 254),\n",
       " ('function', 255),\n",
       " ('permanent', 256),\n",
       " ('spit', 257),\n",
       " ('kirby', 258),\n",
       " ('kann', 259),\n",
       " ('scorpio', 260),\n",
       " ('employers', 261),\n",
       " ('metallica', 262),\n",
       " ('flips', 263),\n",
       " ('idols', 264),\n",
       " ('thus', 265),\n",
       " ('execution', 266),\n",
       " ('wip', 267),\n",
       " ('streaks', 268),\n",
       " ('bieber', 269),\n",
       " ('strengths', 270),\n",
       " ('lone', 271),\n",
       " ('funk', 272),\n",
       " ('hiphop', 273),\n",
       " ('preseason', 274),\n",
       " ('endeavor', 275),\n",
       " ('tropical', 276),\n",
       " ('applaud', 277),\n",
       " ('essentials', 278),\n",
       " ('claiming', 279),\n",
       " ('appearances', 280),\n",
       " ('coworker', 281),\n",
       " ('viral', 282),\n",
       " ('writing', 283),\n",
       " ('average', 284),\n",
       " ('rejection', 285),\n",
       " ('betting', 286),\n",
       " ('forever', 287),\n",
       " ('unsubscribe', 288),\n",
       " ('homosexuals', 289),\n",
       " ('wines', 290),\n",
       " ('mansion', 291),\n",
       " ('junction', 292),\n",
       " ('flirt', 293),\n",
       " ('drug', 294),\n",
       " ('relive', 295),\n",
       " ('warriors', 296),\n",
       " ('bubbles', 297),\n",
       " ('lamps', 298),\n",
       " ('report', 299),\n",
       " ('insulted', 300),\n",
       " ('brewery', 301),\n",
       " ('chewing', 302),\n",
       " ('instability', 303),\n",
       " ('insidious', 304),\n",
       " ('overly', 305),\n",
       " ('ortiz', 306),\n",
       " ('leggings', 307),\n",
       " ('showman', 308),\n",
       " ('hes', 309),\n",
       " ('galleries', 310),\n",
       " ('job', 311),\n",
       " ('uhhhh', 312),\n",
       " ('flavia', 313),\n",
       " ('ummmm', 314),\n",
       " ('fir', 315),\n",
       " ('norse', 316),\n",
       " ('nr', 317),\n",
       " ('stalks', 318),\n",
       " ('diamond', 319),\n",
       " ('shortage', 320),\n",
       " ('simmons', 321),\n",
       " ('jack', 322),\n",
       " ('kya', 323),\n",
       " ('labs', 324),\n",
       " ('culinary', 325),\n",
       " ('noobs', 326),\n",
       " ('css', 327),\n",
       " ('fob', 328),\n",
       " ('messaged', 329),\n",
       " ('projectile', 330),\n",
       " ('raider', 331),\n",
       " ('spawning', 332),\n",
       " ('nurses', 333),\n",
       " ('showing', 334),\n",
       " ('so', 335),\n",
       " ('assume', 336),\n",
       " ('battalion', 337),\n",
       " ('investigating', 338),\n",
       " ('champs', 339),\n",
       " ('grabbing', 340),\n",
       " ('clerk', 341),\n",
       " ('stabs', 342),\n",
       " ('homebrew', 343),\n",
       " ('drag', 344),\n",
       " ('staggering', 345),\n",
       " ('flipping', 346),\n",
       " ('crossover', 347),\n",
       " ('swore', 348),\n",
       " ('audi', 349),\n",
       " ('afterlife', 350),\n",
       " ('teddy', 351),\n",
       " ('gunshot', 352),\n",
       " ('assets', 353),\n",
       " ('ethics', 354),\n",
       " ('consumption', 355),\n",
       " ('offence', 356),\n",
       " ('refreshed', 357),\n",
       " ('mahomies', 358),\n",
       " ('sensible', 359),\n",
       " ('separating', 360),\n",
       " ('pete', 361),\n",
       " ('friction', 362),\n",
       " ('itch', 363),\n",
       " ('square', 364),\n",
       " ('principles', 365),\n",
       " ('regions', 366),\n",
       " ('ughh', 367),\n",
       " ('scotland', 368),\n",
       " ('investigated', 369),\n",
       " ('meet', 370),\n",
       " ('buildings', 371),\n",
       " ('fig', 372),\n",
       " ('absurdly', 373),\n",
       " ('bjj', 374),\n",
       " ('knitting', 375),\n",
       " ('acclaimed', 376),\n",
       " ('presents', 377),\n",
       " ('barbie', 378),\n",
       " ('cl', 379),\n",
       " ('educated', 380),\n",
       " ('brace', 381),\n",
       " ('handsome', 382),\n",
       " ('projection', 383),\n",
       " ('channing', 384),\n",
       " ('orientation', 385),\n",
       " ('psbattle', 386),\n",
       " ('spent', 387),\n",
       " ('communicate', 388),\n",
       " ('washington', 389),\n",
       " ('entertaining', 390),\n",
       " ('patrick', 391),\n",
       " ('plz', 392),\n",
       " ('trading', 393),\n",
       " ('progressively', 394),\n",
       " ('division', 395),\n",
       " ('approximately', 396),\n",
       " ('dame', 397),\n",
       " ('widget', 398),\n",
       " ('todays', 399),\n",
       " ('muster', 400),\n",
       " ('structures', 401),\n",
       " ('honolulu', 402),\n",
       " ('wan', 403),\n",
       " ('evaluated', 404),\n",
       " ('annoying', 405),\n",
       " ('olympics', 406),\n",
       " ('llc', 407),\n",
       " ('alert', 408),\n",
       " ('demi', 409),\n",
       " ('insiders', 410),\n",
       " ('mets', 411),\n",
       " ('ringtone', 412),\n",
       " ('fov', 413),\n",
       " ('esports', 414),\n",
       " ('arab', 415),\n",
       " ('grove', 416),\n",
       " ('bankrupt', 417),\n",
       " ('dominant', 418),\n",
       " ('activate', 419),\n",
       " ('fines', 420),\n",
       " ('deprived', 421),\n",
       " ('prophets', 422),\n",
       " ('symphony', 423),\n",
       " ('pneumonia', 424),\n",
       " ('reproduce', 425),\n",
       " ('startup', 426),\n",
       " ('recovered', 427),\n",
       " ('thesis', 428),\n",
       " ('admits', 429),\n",
       " ('yesss', 430),\n",
       " ('cereal', 431),\n",
       " ('righteous', 432),\n",
       " ('wait', 433),\n",
       " ('subscribing', 434),\n",
       " ('detect', 435),\n",
       " ('robe', 436),\n",
       " ('ina', 437),\n",
       " ('latch', 438),\n",
       " ('admiral', 439),\n",
       " ('shxt', 440),\n",
       " ('clusterfuck', 441),\n",
       " ('ms', 442),\n",
       " ('tank', 443),\n",
       " ('doomsday', 444),\n",
       " ('hater', 445),\n",
       " ('suggesting', 446),\n",
       " ('morphine', 447),\n",
       " ('xl', 448),\n",
       " ('js', 449),\n",
       " ('stickers', 450),\n",
       " ('urgency', 451),\n",
       " ('ocean', 452),\n",
       " ('syrian', 453),\n",
       " ('citizen', 454),\n",
       " ('collusion', 455),\n",
       " ('jonas', 456),\n",
       " ('introverted', 457),\n",
       " ('blaze', 458),\n",
       " ('devastated', 459),\n",
       " ('staffers', 460),\n",
       " ('histories', 461),\n",
       " ('ft', 462),\n",
       " ('endo', 463),\n",
       " ('objects', 464),\n",
       " ('cia', 465),\n",
       " ('elite', 466),\n",
       " ('loner', 467),\n",
       " ('styling', 468),\n",
       " ('bladder', 469),\n",
       " ('particles', 470),\n",
       " ('deserve', 471),\n",
       " ('martinez', 472),\n",
       " ('friendzone', 473),\n",
       " ('lawsuits', 474),\n",
       " ('athens', 475),\n",
       " ('gaping', 476),\n",
       " ('carriage', 477),\n",
       " ('advert', 478),\n",
       " ('lucifer', 479),\n",
       " ('triggers', 480),\n",
       " ('emailing', 481),\n",
       " ('paramedics', 482),\n",
       " ('builds', 483),\n",
       " ('scientific', 484),\n",
       " ('studs', 485),\n",
       " ('oo', 486),\n",
       " ('adolescents', 487),\n",
       " ('stir', 488),\n",
       " ('exceptions', 489),\n",
       " ('qualifying', 490),\n",
       " ('expresses', 491),\n",
       " ('creeped', 492),\n",
       " ('seize', 493),\n",
       " ('urged', 494),\n",
       " ('inspection', 495),\n",
       " ('spectre', 496),\n",
       " ('impairment', 497),\n",
       " ('cow', 498),\n",
       " ('wonderful', 499),\n",
       " ('mtv', 500),\n",
       " ('clause', 501),\n",
       " ('pep', 502),\n",
       " ('shortcuts', 503),\n",
       " ('tummy', 504),\n",
       " ('halfway', 505),\n",
       " ('spirited', 506),\n",
       " ('spinal', 507),\n",
       " ('slammed', 508),\n",
       " ('exclusive', 509),\n",
       " ('satellite', 510),\n",
       " ('declares', 511),\n",
       " ('rails', 512),\n",
       " ('dopamine', 513),\n",
       " ('ranked', 514),\n",
       " ('clears', 515),\n",
       " ('heidi', 516),\n",
       " ('filipino', 517),\n",
       " ('stalker', 518),\n",
       " ('tumors', 519),\n",
       " ('f', 520),\n",
       " ('letters', 521),\n",
       " ('herpes', 522),\n",
       " ('frightened', 523),\n",
       " ('twitition', 524),\n",
       " ('deposits', 525),\n",
       " ('idle', 526),\n",
       " ('fudge', 527),\n",
       " ('debated', 528),\n",
       " ('would', 529),\n",
       " ('alchemist', 530),\n",
       " ('gamergate', 531),\n",
       " ('bein', 532),\n",
       " ('leadership', 533),\n",
       " ('colors', 534),\n",
       " ('kr', 535),\n",
       " ('bunch', 536),\n",
       " ('owe', 537),\n",
       " ('exp', 538),\n",
       " ('scenes', 539),\n",
       " ('constantly', 540),\n",
       " ('thousands', 541),\n",
       " ('pricks', 542),\n",
       " ('university', 543),\n",
       " ('meditation', 544),\n",
       " ('pleasant', 545),\n",
       " ('observing', 546),\n",
       " ('obligatory', 547),\n",
       " ('ughhh', 548),\n",
       " ('stinks', 549),\n",
       " ('gifting', 550),\n",
       " ('loser', 551),\n",
       " ('snuggle', 552),\n",
       " ('filling', 553),\n",
       " ('straw', 554),\n",
       " ('seminar', 555),\n",
       " ('threatens', 556),\n",
       " ('perk', 557),\n",
       " ('brave', 558),\n",
       " ('sleeve', 559),\n",
       " ('pauses', 560),\n",
       " ('catcher', 561),\n",
       " ('poised', 562),\n",
       " ('substantial', 563),\n",
       " ('ib', 564),\n",
       " ('hiiii', 565),\n",
       " ('slim', 566),\n",
       " ('clapper', 567),\n",
       " ('wen', 568),\n",
       " ('bench', 569),\n",
       " ('dirk', 570),\n",
       " ('plow', 571),\n",
       " ('referred', 572),\n",
       " ('progressing', 573),\n",
       " ('vmas', 574),\n",
       " ('categories', 575),\n",
       " ('strategies', 576),\n",
       " ('rose', 577),\n",
       " ('climb', 578),\n",
       " ('hooking', 579),\n",
       " ('png', 580),\n",
       " ('whoop', 581),\n",
       " ('pillow', 582),\n",
       " ('contagious', 583),\n",
       " ('macdonald', 584),\n",
       " ('slip', 585),\n",
       " ('wesley', 586),\n",
       " ('cracking', 587),\n",
       " ('narration', 588),\n",
       " ('heals', 589),\n",
       " ('knot', 590),\n",
       " ('hate', 591),\n",
       " ('inhale', 592),\n",
       " ('movement', 593),\n",
       " ('hobby', 594),\n",
       " ('lectures', 595),\n",
       " ('mutually', 596),\n",
       " ('rocket', 597),\n",
       " ('interact', 598),\n",
       " ('grit', 599),\n",
       " ('deterrent', 600),\n",
       " ('congregation', 601),\n",
       " ('warp', 602),\n",
       " ('fire', 603),\n",
       " ('introduction', 604),\n",
       " ('feelin', 605),\n",
       " ('fragrance', 606),\n",
       " ('aladdin', 607),\n",
       " ('defending', 608),\n",
       " ('processors', 609),\n",
       " ('uniforms', 610),\n",
       " ('salon', 611),\n",
       " ('considerate', 612),\n",
       " ('network', 613),\n",
       " ('discontinued', 614),\n",
       " ('kidneys', 615),\n",
       " ('register', 616),\n",
       " ('such', 617),\n",
       " ('podium', 618),\n",
       " ('koji', 619),\n",
       " ('hannah', 620),\n",
       " ('celestial', 621),\n",
       " ('approves', 622),\n",
       " ('shown', 623),\n",
       " ('dumbledore', 624),\n",
       " ('rear', 625),\n",
       " ('wrap', 626),\n",
       " ('startled', 627),\n",
       " ('muslim', 628),\n",
       " ('beauties', 629),\n",
       " ('need', 630),\n",
       " ('erect', 631),\n",
       " ('weirder', 632),\n",
       " ('novice', 633),\n",
       " ('speaker', 634),\n",
       " ('tailor', 635),\n",
       " ('tying', 636),\n",
       " ('disney', 637),\n",
       " ('candidates', 638),\n",
       " ('neo', 639),\n",
       " ('nas', 640),\n",
       " ('compilation', 641),\n",
       " ('diaper', 642),\n",
       " ('unanswered', 643),\n",
       " ('doughnuts', 644),\n",
       " ('eff', 645),\n",
       " ('prizes', 646),\n",
       " ('storm', 647),\n",
       " ('covering', 648),\n",
       " ('alter', 649),\n",
       " ('college', 650),\n",
       " ('tooth', 651),\n",
       " ('gotten', 652),\n",
       " ('gel', 653),\n",
       " ('agriculture', 654),\n",
       " ('models', 655),\n",
       " ('cyborg', 656),\n",
       " ('siberian', 657),\n",
       " ('anticipating', 658),\n",
       " ('reversed', 659),\n",
       " ('hahahahaha', 660),\n",
       " ('beckham', 661),\n",
       " ('midlands', 662),\n",
       " ('snap', 663),\n",
       " ('proverb', 664),\n",
       " ('phrasing', 665),\n",
       " ('purse', 666),\n",
       " ('remnant', 667),\n",
       " ('tame', 668),\n",
       " ('revoked', 669),\n",
       " ('authentic', 670),\n",
       " ('tug', 671),\n",
       " ('relegated', 672),\n",
       " ('inventor', 673),\n",
       " ('resolved', 674),\n",
       " ('admission', 675),\n",
       " ('pi', 676),\n",
       " ('shivers', 677),\n",
       " ('rcmp', 678),\n",
       " ('toward', 679),\n",
       " ('einen', 680),\n",
       " ('handgun', 681),\n",
       " ('injected', 682),\n",
       " ('supposedly', 683),\n",
       " ('fibre', 684),\n",
       " ('tibetan', 685),\n",
       " ('smash', 686),\n",
       " ('clashes', 687),\n",
       " ('beforehand', 688),\n",
       " ('patriotism', 689),\n",
       " ('submit', 690),\n",
       " ('concentrations', 691),\n",
       " ('person', 692),\n",
       " ('attain', 693),\n",
       " ('upgrade', 694),\n",
       " ('exist', 695),\n",
       " ('poland', 696),\n",
       " ('overwhelmingly', 697),\n",
       " ('imagined', 698),\n",
       " ('folds', 699),\n",
       " ('vo', 700),\n",
       " ('fentanyl', 701),\n",
       " ('purposely', 702),\n",
       " ('whistling', 703),\n",
       " ('agreement', 704),\n",
       " ('international', 705),\n",
       " ('skeptical', 706),\n",
       " ('pasadena', 707),\n",
       " ('mohammed', 708),\n",
       " ('swarm', 709),\n",
       " ('hanks', 710),\n",
       " ('fluid', 711),\n",
       " ('vigilante', 712),\n",
       " ('waves', 713),\n",
       " ('hall', 714),\n",
       " ('spur', 715),\n",
       " ('aswell', 716),\n",
       " ('plasma', 717),\n",
       " ('abnormal', 718),\n",
       " ('warmed', 719),\n",
       " ('grooming', 720),\n",
       " ('slowdown', 721),\n",
       " ('factory', 722),\n",
       " ('malibu', 723),\n",
       " ('tin', 724),\n",
       " ('burrito', 725),\n",
       " ('lotion', 726),\n",
       " ('lul', 727),\n",
       " ('glass', 728),\n",
       " ('moss', 729),\n",
       " ('sect', 730),\n",
       " ('charges', 731),\n",
       " ('scheduling', 732),\n",
       " ('boylan', 733),\n",
       " ('higher', 734),\n",
       " ('mystery', 735),\n",
       " ('change', 736),\n",
       " ('attach', 737),\n",
       " ('influential', 738),\n",
       " ('aoe', 739),\n",
       " ('particle', 740),\n",
       " ('genitals', 741),\n",
       " ('washes', 742),\n",
       " ('sensational', 743),\n",
       " ('tsa', 744),\n",
       " ('checkpoint', 745),\n",
       " ('shade', 746),\n",
       " ('slay', 747),\n",
       " ('account', 748),\n",
       " ('possession', 749),\n",
       " ('booking', 750),\n",
       " ('kaya', 751),\n",
       " ('theater', 752),\n",
       " ('kl', 753),\n",
       " ('bully', 754),\n",
       " ('uncle', 755),\n",
       " ('salts', 756),\n",
       " ('existed', 757),\n",
       " ('colorado', 758),\n",
       " ('suspect', 759),\n",
       " ('watchin', 760),\n",
       " ('marry', 761),\n",
       " ('wrath', 762),\n",
       " ('coz', 763),\n",
       " ('tags', 764),\n",
       " ('interviewing', 765),\n",
       " ('inb', 766),\n",
       " ('scratches', 767),\n",
       " ('couples', 768),\n",
       " ('sexist', 769),\n",
       " ('medical', 770),\n",
       " ('dominos', 771),\n",
       " ('vermont', 772),\n",
       " ('tmi', 773),\n",
       " ('licence', 774),\n",
       " ('replies', 775),\n",
       " ('inflicted', 776),\n",
       " ('broadway', 777),\n",
       " ('golem', 778),\n",
       " ('bring', 779),\n",
       " ('cognitive', 780),\n",
       " ('client', 781),\n",
       " ('destroys', 782),\n",
       " ('duped', 783),\n",
       " ('nailed', 784),\n",
       " ('cliches', 785),\n",
       " ('block', 786),\n",
       " ('dipping', 787),\n",
       " ('compile', 788),\n",
       " ('jokes', 789),\n",
       " ('comprised', 790),\n",
       " ('blackness', 791),\n",
       " ('ranting', 792),\n",
       " ('month', 793),\n",
       " ('envious', 794),\n",
       " ('closure', 795),\n",
       " ('shrugged', 796),\n",
       " ('largest', 797),\n",
       " ('furry', 798),\n",
       " ('potential', 799),\n",
       " ('half', 800),\n",
       " ('trippy', 801),\n",
       " ('defensive', 802),\n",
       " ('invited', 803),\n",
       " ('los', 804),\n",
       " ('rafael', 805),\n",
       " ('revolver', 806),\n",
       " ('nauseous', 807),\n",
       " ('evasion', 808),\n",
       " ('playstation', 809),\n",
       " ('bruhh', 810),\n",
       " ('program', 811),\n",
       " ('jenner', 812),\n",
       " ('speaking', 813),\n",
       " ('butter', 814),\n",
       " ('nk', 815),\n",
       " ('lush', 816),\n",
       " ('prosecute', 817),\n",
       " ('offender', 818),\n",
       " ('menace', 819),\n",
       " ('callin', 820),\n",
       " ('demonic', 821),\n",
       " ('charisma', 822),\n",
       " ('hybrid', 823),\n",
       " ('gyms', 824),\n",
       " ('blasio', 825),\n",
       " ('introduce', 826),\n",
       " ('obvious', 827),\n",
       " ('asimov', 828),\n",
       " ('sesh', 829),\n",
       " ('bath', 830),\n",
       " ('beast', 831),\n",
       " ('spring', 832),\n",
       " ('glitch', 833),\n",
       " ('fabric', 834),\n",
       " ('blessed', 835),\n",
       " ('untrue', 836),\n",
       " ('disagreed', 837),\n",
       " ('filing', 838),\n",
       " ('yveltal', 839),\n",
       " ('gtm', 840),\n",
       " ('cunning', 841),\n",
       " ('descent', 842),\n",
       " ('heater', 843),\n",
       " ('observe', 844),\n",
       " ('frankie', 845),\n",
       " ('womb', 846),\n",
       " ('remain', 847),\n",
       " ('caviar', 848),\n",
       " ('multiple', 849),\n",
       " ('fixes', 850),\n",
       " ('listens', 851),\n",
       " ('cooler', 852),\n",
       " ('wolverine', 853),\n",
       " ('complete', 854),\n",
       " ('ae', 855),\n",
       " ('donate', 856),\n",
       " ('detroit', 857),\n",
       " ('muttered', 858),\n",
       " ('puttin', 859),\n",
       " ('paragraphs', 860),\n",
       " ('wards', 861),\n",
       " ('cuties', 862),\n",
       " ('anecdote', 863),\n",
       " ('fund', 864),\n",
       " ('glee', 865),\n",
       " ('fsa', 866),\n",
       " ('intruder', 867),\n",
       " ('highlight', 868),\n",
       " ('emotion', 869),\n",
       " ('graham', 870),\n",
       " ('dps', 871),\n",
       " ('submissions', 872),\n",
       " ('hex', 873),\n",
       " ('minimum', 874),\n",
       " ('remained', 875),\n",
       " ('chic', 876),\n",
       " ('crocs', 877),\n",
       " ('fiasco', 878),\n",
       " ('annihilation', 879),\n",
       " ('gaze', 880),\n",
       " ('stated', 881),\n",
       " ('philosophy', 882),\n",
       " ('keef', 883),\n",
       " ('quran', 884),\n",
       " ('sunscreen', 885),\n",
       " ('literal', 886),\n",
       " ('reflection', 887),\n",
       " ('intern', 888),\n",
       " ('excuses', 889),\n",
       " ('fascinating', 890),\n",
       " ('wasps', 891),\n",
       " ('despicable', 892),\n",
       " ('electricity', 893),\n",
       " ('scrap', 894),\n",
       " ('feminine', 895),\n",
       " ('tablet', 896),\n",
       " ('tpp', 897),\n",
       " ('fad', 898),\n",
       " ('sins', 899),\n",
       " ('stinky', 900),\n",
       " ('carving', 901),\n",
       " ('musicians', 902),\n",
       " ('subtitle', 903),\n",
       " ('monuments', 904),\n",
       " ('repealing', 905),\n",
       " ('gegen', 906),\n",
       " ('testament', 907),\n",
       " ('create', 908),\n",
       " ('sending', 909),\n",
       " ('peter', 910),\n",
       " ('stalled', 911),\n",
       " ('principle', 912),\n",
       " ('pcpartpicker', 913),\n",
       " ('hooker', 914),\n",
       " ('ffs', 915),\n",
       " ('syndrome', 916),\n",
       " ('situation', 917),\n",
       " ('dating', 918),\n",
       " ('relieved', 919),\n",
       " ('cynical', 920),\n",
       " ('bitterness', 921),\n",
       " ('pinpoint', 922),\n",
       " ('stems', 923),\n",
       " ('intellectuals', 924),\n",
       " ('evolutionary', 925),\n",
       " ('questionnaire', 926),\n",
       " ('filthy', 927),\n",
       " ('disaster', 928),\n",
       " ('crane', 929),\n",
       " ('barney', 930),\n",
       " ('workout', 931),\n",
       " ('hits', 932),\n",
       " ('perpetrators', 933),\n",
       " ('dice', 934),\n",
       " ('reports', 935),\n",
       " ('cooked', 936),\n",
       " ('jet', 937),\n",
       " ('audrey', 938),\n",
       " ('superbiiz', 939),\n",
       " ('measles', 940),\n",
       " ('icky', 941),\n",
       " ('embarrassing', 942),\n",
       " ('bandwidth', 943),\n",
       " ('driverless', 944),\n",
       " ('shortcomings', 945),\n",
       " ('announcer', 946),\n",
       " ('cals', 947),\n",
       " ('bonus', 948),\n",
       " ('widely', 949),\n",
       " ('phillips', 950),\n",
       " ('beings', 951),\n",
       " ('rey', 952),\n",
       " ('undeniable', 953),\n",
       " ('egyptian', 954),\n",
       " ('moving', 955),\n",
       " ('bug', 956),\n",
       " ('bell', 957),\n",
       " ('soooooooo', 958),\n",
       " ('ava', 959),\n",
       " ('accepted', 960),\n",
       " ('lowe', 961),\n",
       " ('berkeley', 962),\n",
       " ('who', 963),\n",
       " ('provided', 964),\n",
       " ('noting', 965),\n",
       " ('swords', 966),\n",
       " ('chewed', 967),\n",
       " ('hathaway', 968),\n",
       " ('comment', 969),\n",
       " ('tickle', 970),\n",
       " ('implanted', 971),\n",
       " ('alec', 972),\n",
       " ('fu', 973),\n",
       " ('aren', 974),\n",
       " ('turning', 975),\n",
       " ('commodity', 976),\n",
       " ('cal', 977),\n",
       " ('savage', 978),\n",
       " ('feast', 979),\n",
       " ('fingernails', 980),\n",
       " ('referenced', 981),\n",
       " ('narcissistic', 982),\n",
       " ('quota', 983),\n",
       " ('heated', 984),\n",
       " ('slate', 985),\n",
       " ('reactionary', 986),\n",
       " ('washed', 987),\n",
       " ('spared', 988),\n",
       " ('jpg', 989),\n",
       " ('encountered', 990),\n",
       " ('elementary', 991),\n",
       " ('distorted', 992),\n",
       " ('algae', 993),\n",
       " ('ugh', 994),\n",
       " ('draws', 995),\n",
       " ('cst', 996),\n",
       " ('railroad', 997),\n",
       " ('transforming', 998),\n",
       " ('unfair', 999),\n",
       " ...]"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(vocabulary.items(), key=lambda t:t[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# session_collection = {}\n",
    "# models_collection = {}\n",
    "# hyperparams_collection = {}\n",
    "# user_level_data['subject57080000']['label']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataGenerator(Sequence):\n",
    "    'Generates data for Keras'\n",
    "    def __init__(self, user_level_data, subjects_split, session=None, use_bert=False, set_type='train',\n",
    "                 batch_size=32, seq_len=512, vocabulary=vocabulary,\n",
    "                 voc_size=hyperparams_features['max_features'], emotion_lexicon=nrc_lexicon,\n",
    "                 hierarchical=False, pad_value=0, padding='pre',\n",
    "                 post_groups_per_user=None, posts_per_group=10, post_offset = 0,\n",
    "                 sampling_distr_alfa=0.1, sampling_distr='exp', # 'exp', 'uniform'\n",
    "                 emotions=emotions, pronouns=[\"i\", \"me\", \"my\", \"mine\", \"myself\"], liwc_categories=liwc_categories,\n",
    "                 liwc_dict=liwc_dict, compute_liwc=False, liwc_words_for_categories=None,\n",
    "                 pad_with_duplication=False,\n",
    "                 max_posts_per_user=None, sample_seqs=True,\n",
    "                 shuffle=True, return_subjects=False, keep_last_batch=True, class_weights=None,\n",
    "                classes=1):\n",
    "        'Initialization'\n",
    "        self.seq_len = seq_len\n",
    "        # Instantiate tokenizer\n",
    "        if session:\n",
    "            self.bert_tokenizer = create_tokenizer_from_hub_module(session)\n",
    "            session.run(tf.local_variables_initializer())\n",
    "            session.run(tf.global_variables_initializer())\n",
    "            session.run(tf.tables_initializer())\n",
    "        else:\n",
    "            if use_bert:\n",
    "                logger.error(\"Need a session to use bert in data generation\")\n",
    "            self.bert_tokenizer = None\n",
    "        self.use_bert = use_bert\n",
    "        self.subjects_split = subjects_split\n",
    "        self.set = set_type\n",
    "        self.emotion_lexicon = emotion_lexicon\n",
    "        self.batch_size = batch_size\n",
    "        self.hierarchical = hierarchical\n",
    "        self.data = user_level_data\n",
    "        self.pad_value = pad_value\n",
    "        self.return_subjects = return_subjects\n",
    "        self.sampling_distr_alfa = sampling_distr_alfa\n",
    "        self.sampling_distr = sampling_distr\n",
    "        self.emotions = emotions\n",
    "        self.pronouns = pronouns\n",
    "        self.liwc_categories = liwc_categories\n",
    "        self.liwc_dict = liwc_dict\n",
    "        self.liwc_words_for_categories = liwc_words_for_categories\n",
    "        self.compute_liwc = compute_liwc\n",
    "        self.sample_seqs = sample_seqs\n",
    "        self.pad_with_duplication = pad_with_duplication\n",
    "        self.padding = padding\n",
    "        self.keep_last_batch = keep_last_batch\n",
    "        self.shuffle = shuffle\n",
    "        self.voc_size = voc_size\n",
    "        self.vocabulary = vocabulary\n",
    "        self.max_posts_per_user = max_posts_per_user\n",
    "        self.post_groups_per_user = post_groups_per_user\n",
    "        self.post_offset = post_offset\n",
    "        self.posts_per_group = posts_per_group\n",
    "        self.classes = classes\n",
    "        self.class_weights = class_weights\n",
    "        self.generated_labels = []\n",
    "        self.__post_indexes_per_user()\n",
    "        self.on_epoch_end()\n",
    "        \n",
    "    @staticmethod\n",
    "    def _random_sample(population_size, sample_size, sampling_distr, alfa=0.1, replacement=False):\n",
    "        if sampling_distr == 'exp':\n",
    "            # Exponential sampling\n",
    "            sample = sorted(np.random.choice(population_size, \n",
    "                            min(sample_size, population_size),\n",
    "                            p = DataGenerator.__generate_reverse_exponential_indices(population_size, alfa),\n",
    "                            replace=replacement))\n",
    "                                                                # if pad_with_duplication, \n",
    "                                                                # pad by adding the same post multiple times\n",
    "                                                                # if there are not enough posts\n",
    "        elif sampling_distr == 'uniform':\n",
    "            # Uniform sampling\n",
    "            sample = sorted(np.random.choice(population_size,\n",
    "                            min(sample_size, population_size),\n",
    "                            replace=replacement))\n",
    "        return sample\n",
    "    \n",
    "    @staticmethod\n",
    "    def __generate_reverse_exponential_indices(max_index, alfa=1):\n",
    "        probabilities = []\n",
    "        for x in range(max_index):\n",
    "            probabilities.append(alfa * (np.exp(alfa*x)))\n",
    "        reverse_probabilities = [p for p in probabilities]\n",
    "        sump = sum(reverse_probabilities)\n",
    "        normalized_probabilities = [p/sump for p in reverse_probabilities]\n",
    "        return normalized_probabilities\n",
    "    \n",
    "    def __post_indexes_per_user(self):\n",
    "        self.indexes_per_user = {u: [] for u in range(len(self.subjects_split[self.set]))}\n",
    "        self.indexes_with_user = []\n",
    "        self.item_weights = []\n",
    "        for u in range(len(self.subjects_split[self.set])):\n",
    "            if self.subjects_split[self.set][u] not in self.data:\n",
    "                logger.warning(\"User %s has no posts in %s set. Ignoring.\\n\" % (\n",
    "                    self.subjects_split[self.set][u], self.set))\n",
    "                continue\n",
    "            user_posts = self.data[self.subjects_split[self.set][u]]['texts']\n",
    "            if self.max_posts_per_user:\n",
    "                user_posts = user_posts[:self.max_posts_per_user]\n",
    "            nr_post_groups = int(np.ceil(len(user_posts) / self.posts_per_group))\n",
    "            \n",
    "            if self.post_groups_per_user:\n",
    "                nr_post_groups = min(self.post_groups_per_user, nr_post_groups)\n",
    "            for i in range(nr_post_groups):\n",
    "                # Generate random ordered samples of the posts\n",
    "                if self.sample_seqs:\n",
    "                    indexes_sample = DataGenerator._random_sample(population_size=len(user_posts),\n",
    "                                                         sample_size=self.posts_per_group,\n",
    "                                                         sampling_distr=self.sampling_distr,\n",
    "                                                         alfa=self.sampling_distr_alfa,\n",
    "                                                         replacement=self.pad_with_duplication)\n",
    "                    self.indexes_per_user[u].append(indexes_sample)\n",
    "                    self.indexes_with_user.append((u, indexes_sample))\n",
    "                    # break # just generate one?\n",
    "                # Generate all subsets of the posts in order\n",
    "                # TODO: Change here if you want a sliding window\n",
    "                else:\n",
    "                    self.indexes_per_user[u].append(range(i*self.posts_per_group + self.post_offset,\n",
    "                                                        min((i+1)*self.posts_per_group + self.post_offset, len(user_posts))))\n",
    "                    self.indexes_with_user.append((u, range(i*self.posts_per_group ,\n",
    "                                                        min((i+1)*self.posts_per_group + self.post_offset, len(user_posts)))))\n",
    "\n",
    "        if self.class_weights:\n",
    "            for item in self.indexes_with_user:\n",
    "                u, _ = item\n",
    "                s = self.subjects_split[self.set][u]\n",
    "                # Note: weight 1 is default.\n",
    "                try:\n",
    "                    self.item_weights.append(1./self.class_weights[self.data[s]['label']])\n",
    "                except Exception as e:\n",
    "                    self.item_weights.append(1)\n",
    "                    logger.error(\"Could not compute item weight for user %s. \" % s + str(e) + \"\\n\")\n",
    "        else:\n",
    "            self.item_weights = []\n",
    "\n",
    "    def __encode_text(self, tokens, raw_text):\n",
    "        # Using voc_size-1 value for OOV token\n",
    "        encoded_tokens = [self.vocabulary.get(w, self.voc_size-1) for w in tokens]\n",
    "        encoded_emotions = encode_emotions(tokens, self.emotion_lexicon, self.emotions)\n",
    "        encoded_pronouns = encode_pronouns(tokens, self.pronouns)\n",
    "        encoded_stopwords = encode_stopwords(tokens)\n",
    "        if not self.compute_liwc:\n",
    "            encoded_liwc = None\n",
    "        else:\n",
    "            encoded_liwc = self.__encode_liwc_categories(tokens)\n",
    "        if self.bert_tokenizer:\n",
    "            bert_ids, bert_masks, bert_segments, label = encode_text_for_bert(self.bert_tokenizer, InputExample(None, \n",
    "                                               raw_text), self.seq_len)\n",
    "        else:\n",
    "            bert_ids, bert_masks, bert_segments = [[0]*self.seq_len, [0]*self.seq_len, [0]*self.seq_len]\n",
    "        return (encoded_tokens, encoded_emotions, encoded_pronouns, encoded_stopwords, encoded_liwc,\n",
    "               bert_ids, bert_masks, bert_segments)\n",
    "    \n",
    "    def __encode_liwc_categories_full(self, tokens, relative=True):\n",
    "        categories_cnt = [0 for c in self.liwc_categories]\n",
    "        if not tokens:\n",
    "            return categories_cnt\n",
    "        text_len = len(tokens)\n",
    "        for i, category in enumerate(self.liwc_categories):\n",
    "            category_words = self.liwc_dict[category]\n",
    "            for t in tokens:\n",
    "                for word in category_words:\n",
    "                    if t==word or (word[-1]=='*' and t.startswith(word[:-1])) \\\n",
    "                    or (t==word.split(\"'\")[0]):\n",
    "                        categories_cnt[i] += 1\n",
    "                        break # one token cannot belong to more than one word in the category\n",
    "            if relative and text_len:\n",
    "                categories_cnt[i] = categories_cnt[i]/text_len\n",
    "        return categories_cnt\n",
    "        \n",
    "        \n",
    "    def __encode_liwc_categories(self, tokens, relative=True):\n",
    "        categories_cnt = [0 for c in self.liwc_categories]\n",
    "        if not tokens:\n",
    "            return categories_cnt\n",
    "        text_len = len(tokens)\n",
    "        for i, category in enumerate(self.liwc_categories):\n",
    "            for t in tokens:\n",
    "                if t in self.liwc_words_for_categories[category]:\n",
    "                    categories_cnt[i] += 1\n",
    "            if relative and text_len:\n",
    "                categories_cnt[i] = categories_cnt[i]/text_len\n",
    "        return categories_cnt\n",
    "        \n",
    "    def __len__(self):\n",
    "        'Denotes the number of batches per epoch'\n",
    "        if self.keep_last_batch:\n",
    "            return int(np.ceil(len(self.indexes) / self.batch_size)) # + 1 to not discard last batch\n",
    "        return int((len(self.indexes))/self.batch_size)\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        'Generate one batch of data'\n",
    "        # Reset generated labels\n",
    "        if index == 0:\n",
    "             self.generated_labels = []\n",
    "        # Generate indexes of the batch\n",
    "        indexes = self.indexes[index*self.batch_size:(index+1)*self.batch_size]\n",
    "        # Find users\n",
    "        user_indexes = [t[0] for t in indexes]\n",
    "        users = set([self.subjects_split[self.set][i] for i in user_indexes\n",
    "                    if self.subjects_split[self.set][i] in self.data.keys()]) # TODO: maybe needs a warning that user is missing\n",
    "        post_indexes_per_user = {u: [] for u in users}\n",
    "        # Sample post ids\n",
    "        for u, post_indexes in indexes:\n",
    "            user = self.subjects_split[self.set][u]\n",
    "            # Note: was bug here - changed it into a list\n",
    "            post_indexes_per_user[user].append(post_indexes)\n",
    "\n",
    "        # Generate data\n",
    "        if self.hierarchical:\n",
    "            X, s, y = self.__data_generation_hierarchical(users, post_indexes_per_user)\n",
    "        else:\n",
    "            X, s, y = self.__data_generation(users, post_indexes_per_user)\n",
    "\n",
    "        if self.return_subjects:\n",
    "            return X, s, y\n",
    "        else:\n",
    "            return X, y\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        'Updates indexes after each epoch'\n",
    "        self.indexes = self.indexes_with_user\n",
    "#         np.arange(len(self.subjects_split[self.set]))\n",
    "        if self.shuffle:\n",
    "            np.random.shuffle(self.indexes)\n",
    "        if self.class_weights:\n",
    "            # Sample users according to class weight (Or do this for each batch instead?)\n",
    "            normalized_weights = [w/sum(self.item_weights) for w in self.item_weights]\n",
    "            random_user_indexes = np.random.choice(len(self.indexes_with_user), \n",
    "                            len(self.indexes_with_user),\n",
    "                            p = normalized_weights, replace=True)\n",
    "            self.indexes = [self.indexes_with_user[i] for i in random_user_indexes]\n",
    "    def __data_generation(self, users, post_indexes):\n",
    "        'Generates data containing batch_size samples' # X : (n_samples, *dim, n_channels)\n",
    "        tokens_data = []\n",
    "        categ_data = []\n",
    "        sparse_data = []\n",
    "        subjects = []\n",
    "        bert_ids_data = []\n",
    "        bert_masks_data = []\n",
    "        bert_segments_data = []\n",
    "        labels = []\n",
    "\n",
    "        for subject in users:\n",
    "\n",
    "            if 'label' in self.data[subject]:\n",
    "                label = self.data[subject]['label']\n",
    "            else:\n",
    "                label = None\n",
    "\n",
    "            \n",
    "            all_words = []\n",
    "            all_raw_texts = []\n",
    "            liwc_aggreg = []\n",
    "\n",
    "            for post_index_range in post_indexes[subject]:\n",
    "                # Sample\n",
    "                texts = [self.data[subject]['texts'][i] for i in post_index_range]\n",
    "                if 'liwc' in self.data[subject] and not self.compute_liwc:\n",
    "                    liwc_selection = [self.data[subject]['liwc'][i] for i in post_index_range]\n",
    "                raw_texts = [self.data[subject]['raw'][i] for i in post_index_range]\n",
    "\n",
    "                all_words.append(sum(texts, [])) # merge all texts in group in one list\n",
    "                if 'liwc' in self.data[subject] and not self.compute_liwc:\n",
    "                    liwc_aggreg.append(np.array(liwc_selection).mean(axis=0).tolist())\n",
    "                all_raw_texts.append(\" \".join(raw_texts))\n",
    "            for i, words in enumerate(all_words):\n",
    "                encoded_tokens, encoded_emotions, encoded_pronouns, encoded_stopwords, encoded_liwc, \\\n",
    "                    bert_ids, bert_masks, bert_segments = self.__encode_text(words, all_raw_texts[i])\n",
    "                try:\n",
    "                    subject_id = int(re.findall('[0-9]+', subject)[0])\n",
    "                except IndexError:\n",
    "                    subject_id = subject\n",
    "                tokens_data.append(encoded_tokens)\n",
    "                # TODO: what will be the difference between these?\n",
    "                # I think instead of averaging for the post group, it just does it correctly\n",
    "                # for the whole post group (when computing, non-lazily)\n",
    "                if 'liwc' in self.data[subject] and not self.compute_liwc:  \n",
    "                    categ_data.append(encoded_emotions + [encoded_pronouns] + liwc_aggreg[i])\n",
    "                   \n",
    "                else:\n",
    "                    categ_data.append(encoded_emotions + [encoded_pronouns] + encoded_liwc)\n",
    "                    \n",
    "                sparse_data.append(encoded_stopwords)\n",
    "                bert_ids_data.append(bert_ids)\n",
    "                bert_masks_data.append(bert_masks)\n",
    "                bert_segments_data.append(bert_segments)\n",
    "                \n",
    "                labels.append(label)\n",
    "                subjects.append(subject_id)\n",
    "\n",
    "        \n",
    "        self.generated_labels.extend(labels)\n",
    "        # using zeros for padding\n",
    "        tokens_data_padded = sequence.pad_sequences(tokens_data, maxlen=self.seq_len, \n",
    "                                                    padding=self.padding,\n",
    "                                                   truncating=self.padding)\n",
    "\n",
    "        if self.use_bert:\n",
    "            return ([np.array(tokens_data_padded), np.array(categ_data), np.array(sparse_data),\n",
    "                 np.array(bert_ids_data), np.array(bert_masks_data), np.array(bert_segments_data),\n",
    "                ],\n",
    "                np.array(subjects),\n",
    "                np.array(labels))\n",
    "        else:\n",
    "            return ([np.array(tokens_data_padded), np.array(categ_data), np.array(sparse_data),\n",
    "                ],\n",
    "                np.array(subjects),\n",
    "                np.array(labels))\n",
    "    \n",
    "    def __data_generation_hierarchical(self, users, post_indexes):\n",
    "        'Generates data containing batch_size samples' # X : (n_samples, *dim, n_channels)\n",
    "        user_tokens = []\n",
    "        user_categ_data = []\n",
    "        user_sparse_data = []\n",
    "        user_bert_ids_data = []\n",
    "        user_bert_masks_data = []\n",
    "        user_bert_segments_data = []\n",
    "        \n",
    "        labels = []\n",
    "        subjects = []\n",
    "        for subject in users:\n",
    "             \n",
    "            all_words = []\n",
    "            all_raw_texts = []\n",
    "            liwc_scores = []\n",
    "            \n",
    "            if 'label' in self.data[subject]:\n",
    "                if self.classes==1:\n",
    "                    label = self.data[subject]['label']\n",
    "                else:\n",
    "                    label = list(np_utils.to_categorical(self.data[subject]['label'], num_classes=self.classes))\n",
    "            else:\n",
    "                label = None\n",
    "\n",
    "            for post_index_range in post_indexes[subject]:\n",
    "                # Sample\n",
    "                texts = [self.data[subject]['texts'][i] for i in post_index_range]\n",
    "                if 'liwc' in self.data[subject] and not self.compute_liwc:\n",
    "                    liwc_selection = [self.data[subject]['liwc'][i] for i in post_index_range]\n",
    "                raw_texts = [self.data[subject]['raw'][i] for i in post_index_range]\n",
    "\n",
    "                all_words.append(texts)\n",
    "                if 'liwc' in self.data[subject] and not self.compute_liwc:\n",
    "                    liwc_scores.append(liwc_selection)\n",
    "                all_raw_texts.append(raw_texts)\n",
    "            \n",
    "#             if len(texts) < self.max_posts_per_user:\n",
    "#                 # TODO: pad with zeros\n",
    "#                 pass\n",
    "\n",
    "            for i, words in enumerate(all_words):\n",
    "                tokens_data = []\n",
    "                categ_data = []\n",
    "                sparse_data = []\n",
    "                bert_ids_data = []\n",
    "                bert_masks_data = []\n",
    "                bert_segments_data = []\n",
    "                \n",
    "                raw_text = all_raw_texts[i]\n",
    "                words = all_words[i]\n",
    "                \n",
    "                for p, posting in enumerate(words): \n",
    "                    encoded_tokens, encoded_emotions, encoded_pronouns, encoded_stopwords, encoded_liwc, \\\n",
    "                        bert_ids, bert_masks, bert_segments = self.__encode_text(words[p], raw_text[p])\n",
    "                    if 'liwc' in self.data[subject] and not self.compute_liwc:\n",
    "                        liwc = liwc_scores[i][p]\n",
    "                    else:\n",
    "                        liwc = encoded_liwc\n",
    "                    try:\n",
    "                        subject_id = int(re.findall('[0-9]+', subject)[0])\n",
    "                    except IndexError:\n",
    "                        subject_id = subject\n",
    "                    tokens_data.append(encoded_tokens)\n",
    "                    # using zeros for padding\n",
    "                    # TODO: there is something wrong with this\n",
    "                    categ_data.append(encoded_emotions + [encoded_pronouns] + liwc)\n",
    "                    sparse_data.append(encoded_stopwords)\n",
    "                    bert_ids_data.append(bert_ids)\n",
    "                    bert_masks_data.append(bert_masks)\n",
    "                    bert_segments_data.append(bert_segments)\n",
    "                \n",
    "                # For each range\n",
    "                tokens_data_padded = np.array(sequence.pad_sequences(tokens_data, maxlen=self.seq_len,\n",
    "                                              padding=self.padding,\n",
    "                                            truncating=self.padding))\n",
    "                user_tokens.append(tokens_data_padded)\n",
    "\n",
    "                user_categ_data.append(categ_data)\n",
    "                user_sparse_data.append(sparse_data)\n",
    "\n",
    "                user_bert_ids_data.append(bert_ids_data)\n",
    "                user_bert_masks_data.append(bert_masks_data)\n",
    "                user_bert_segments_data.append(bert_segments_data)\n",
    "\n",
    "                labels.append(label)\n",
    "                subjects.append(subject_id)\n",
    "\n",
    "        user_tokens = sequence.pad_sequences(user_tokens, \n",
    "                                             maxlen=self.posts_per_group, \n",
    "                                             value=self.pad_value)\n",
    "        user_tokens = np.rollaxis(np.dstack(user_tokens), -1)\n",
    "        user_categ_data = sequence.pad_sequences(user_categ_data,  \n",
    "                                                 maxlen=self.posts_per_group, \n",
    "                                                 value=self.pad_value, dtype='float32')\n",
    "        user_categ_data = np.rollaxis(np.dstack(user_categ_data), -1)\n",
    "        \n",
    "        user_sparse_data = sequence.pad_sequences(user_sparse_data, \n",
    "                                                  maxlen=self.posts_per_group, \n",
    "                                                  value=self.pad_value)\n",
    "        user_sparse_data = np.rollaxis(np.dstack(user_sparse_data), -1)\n",
    "        \n",
    "        user_bert_ids_data = sequence.pad_sequences(user_bert_ids_data, \n",
    "                                                    maxlen=self.posts_per_group, \n",
    "                                                    value=self.pad_value)\n",
    "        user_bert_ids_data = np.rollaxis(np.dstack(user_bert_ids_data), -1)\n",
    "        \n",
    "        user_bert_masks_data = sequence.pad_sequences(user_bert_masks_data, \n",
    "                                                      maxlen=self.posts_per_group, \n",
    "                                                      value=self.pad_value)\n",
    "        user_bert_masks_data = np.rollaxis(np.dstack(user_bert_masks_data), -1)\n",
    "        \n",
    "        user_bert_segments_data = sequence.pad_sequences(user_bert_segments_data, \n",
    "                                                         maxlen=self.posts_per_group, \n",
    "                                                         value=self.pad_value)\n",
    "        user_bert_segments_data = np.rollaxis(np.dstack(user_bert_segments_data), -1)\n",
    "\n",
    "        self.generated_labels.extend(labels)\n",
    "\n",
    "        labels = np.array(labels, dtype=np.float32)\n",
    "        \n",
    "        if self.use_bert:\n",
    "            return ((user_tokens, user_categ_data, user_sparse_data, \n",
    "                 user_bert_ids_data, user_bert_masks_data, uifser_bert_segments_data),\n",
    "                np.array(subjects),\n",
    "                labels)\n",
    "        else:\n",
    "            return ((user_tokens, user_categ_data, user_sparse_data), \n",
    "                np.array(subjects),\n",
    "                labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataGeneratorFromText(Sequence):\n",
    "    'Generates data for Keras'\n",
    "    def __init__(self, texts, batch_size=32, seq_len=512, vocabulary=vocabulary,\n",
    "                 voc_size=hyperparams_features['max_features'], emotion_lexicon=nrc_lexicon,\n",
    "                 hierarchical=False, pad_value=0, padding='pre',\n",
    "                 emotions=emotions, pronouns=[\"i\", \"me\", \"my\", \"mine\", \"myself\"], liwc_categories=liwc_categories,\n",
    "                 liwc_dict=liwc_dict, compute_liwc=False, liwc_words_for_categories=None,\n",
    "                 pad_with_duplication=False, posts_per_group=50,\n",
    "                 shuffle=True, keep_last_batch=True):\n",
    "        'Initialization'\n",
    "        self.seq_len = seq_len\n",
    "        # Instantiate tokenizer\n",
    "        \n",
    "        self.texts = texts\n",
    "        self.emotion_lexicon = emotion_lexicon\n",
    "        self.batch_size = batch_size\n",
    "        self.hierarchical = hierarchical\n",
    " \n",
    "        self.pad_value = pad_value\n",
    "\n",
    "        self.keep_last_batch = keep_last_batch\n",
    "        self.emotions = emotions\n",
    "        self.pronouns = pronouns\n",
    "        self.liwc_categories = liwc_categories\n",
    "        self.liwc_dict = liwc_dict\n",
    "        self.liwc_words_for_categories = liwc_words_for_categories\n",
    "        self.compute_liwc = compute_liwc\n",
    "        \n",
    "        self.use_bert = False\n",
    "      \n",
    "        self.pad_with_duplication = pad_with_duplication\n",
    "        self.padding = padding\n",
    "        self.shuffle = shuffle\n",
    "        self.voc_size = voc_size\n",
    "        self.vocabulary = vocabulary\n",
    "        \n",
    "        self.posts_per_group = posts_per_group\n",
    "       \n",
    "        self.on_epoch_end()\n",
    "        \n",
    "   \n",
    "\n",
    "    def __encode_text(self, tokens, raw_text):\n",
    "        # Using voc_size-1 value for OOV token\n",
    "        encoded_tokens = [self.vocabulary.get(w, self.voc_size-1) for w in tokens]\n",
    "        encoded_emotions = encode_emotions(tokens, self.emotion_lexicon, self.emotions)\n",
    "        encoded_pronouns = encode_pronouns(tokens, self.pronouns)\n",
    "        encoded_stopwords = encode_stopwords(tokens)\n",
    "\n",
    "        encoded_liwc = self.__encode_liwc_categories(tokens)\n",
    "      \n",
    "        bert_ids, bert_masks, bert_segments = [[0]*self.seq_len, [0]*self.seq_len, [0]*self.seq_len]\n",
    "        return (encoded_tokens, encoded_emotions, encoded_pronouns, encoded_stopwords, encoded_liwc,\n",
    "               bert_ids, bert_masks, bert_segments)\n",
    "    \n",
    "    def __encode_liwc_categories_full(self, tokens, relative=True):\n",
    "        categories_cnt = [0 for c in self.liwc_categories]\n",
    "        if not tokens:\n",
    "            return categories_cnt\n",
    "        text_len = len(tokens)\n",
    "        for i, category in enumerate(self.liwc_categories):\n",
    "            category_words = self.liwc_dict[category]\n",
    "            for t in tokens:\n",
    "                for word in category_words:\n",
    "                    if t==word or (word[-1]=='*' and t.startswith(word[:-1])) \\\n",
    "                    or (t==word.split(\"'\")[0]):\n",
    "                        categories_cnt[i] += 1\n",
    "                        break # one token cannot belong to more than one word in the category\n",
    "            if relative and text_len:\n",
    "                categories_cnt[i] = categories_cnt[i]/text_len\n",
    "        return categories_cnt\n",
    "        \n",
    "        \n",
    "    def __encode_liwc_categories(self, tokens, relative=True):\n",
    "        categories_cnt = [0 for c in self.liwc_categories]\n",
    "        if not tokens:\n",
    "            return categories_cnt\n",
    "        text_len = len(tokens)\n",
    "        for i, category in enumerate(self.liwc_categories):\n",
    "            for t in tokens:\n",
    "                if t in self.liwc_words_for_categories[category]:\n",
    "                    categories_cnt[i] += 1\n",
    "            if relative and text_len:\n",
    "                categories_cnt[i] = categories_cnt[i]/text_len\n",
    "        return categories_cnt\n",
    "        \n",
    "    def __len__(self):\n",
    "        'Denotes the number of batches per epoch'\n",
    "        if self.keep_last_batch:\n",
    "            return int(np.ceil(len(self.indexes) / self.batch_size)) # + 1 to not discard last batch\n",
    "        return int((len(self.indexes))/self.batch_size)\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        'Generate one batch of data'\n",
    "        # Generate indexes of the batch\n",
    "        indexes = self.indexes[index*self.batch_size:(index+1)*self.batch_size]\n",
    "       \n",
    "        # Generate data\n",
    "        if self.hierarchical:\n",
    "            X, s, y = self.__data_generation_hierarchical(indexes)\n",
    "        else:\n",
    "            X, s, y = self.__data_generation(indexes)\n",
    "      \n",
    "        return X, y\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        'Updates indexes after each epoch'\n",
    "        self.indexes = np.arange(len(self.texts))\n",
    "        if self.shuffle:\n",
    "            np.random.shuffle(self.indexes)\n",
    "\n",
    "    def __data_generation(self, indexes):\n",
    "        'Generates data containing batch_size samples' # X : (n_samples, *dim, n_channels)\n",
    "        tokens_data = []\n",
    "        categ_data = []\n",
    "        sparse_data = []\n",
    "        subjects = []\n",
    "        bert_ids_data = []\n",
    "        bert_masks_data = []\n",
    "        bert_segments_data = []\n",
    "        labels = []\n",
    "\n",
    "        label = None\n",
    "\n",
    "\n",
    "        all_words = []\n",
    "        all_raw_texts = []\n",
    "        liwc_aggreg = []\n",
    "\n",
    "        # Sample\n",
    "        all_words = [tokenize(self.texts[i]) for i in indexes]\n",
    "\n",
    "        all_raw_texts = [self.texts[i] for i in indexes]\n",
    "\n",
    "\n",
    "        for i, words in enumerate(all_words):\n",
    "            encoded_tokens, encoded_emotions, encoded_pronouns, encoded_stopwords, encoded_liwc, \\\n",
    "                bert_ids, bert_masks, bert_segments = self.__encode_text(words, all_raw_texts[i])\n",
    "\n",
    "            tokens_data.append(encoded_tokens)\n",
    "            # TODO: what will be the difference between these?\n",
    "            # I think instead of averaging for the post group, it just does it correctly\n",
    "            # for the whole post group (when computing, non-lazily)\n",
    "\n",
    "            categ_data.append(encoded_emotions + [encoded_pronouns] + encoded_liwc)\n",
    "\n",
    "            sparse_data.append(encoded_stopwords)\n",
    "            bert_ids_data.append(bert_ids)\n",
    "            bert_masks_data.append(bert_masks)\n",
    "            bert_segments_data.append(bert_segments)\n",
    "\n",
    "            labels.append(None)\n",
    "            subjects.append(None)\n",
    "\n",
    "        \n",
    "        # using zeros for padding\n",
    "        tokens_data_padded = sequence.pad_sequences(tokens_data, maxlen=self.seq_len, \n",
    "                                                    padding=self.padding,\n",
    "                                                   truncating=self.padding)\n",
    "\n",
    "       \n",
    "        return ([np.array(tokens_data_padded), np.array(categ_data), np.array(sparse_data),\n",
    "                ],\n",
    "                np.array(subjects),\n",
    "                np.array(labels))\n",
    "    \n",
    "    def __data_generation_hierarchical(self, indexes):\n",
    "#         pass\n",
    "#         'Generates data containing batch_size samples' # X : (n_samples, *dim, n_channels)\n",
    "        user_tokens = []\n",
    "        user_categ_data = []\n",
    "        user_sparse_data = []\n",
    "        user_bert_ids_data = []\n",
    "        user_bert_masks_data = []\n",
    "        user_bert_segments_data = []\n",
    "\n",
    "        labels = []\n",
    "        subjects = []\n",
    "#         for subject in users:\n",
    "             \n",
    "        all_words = []\n",
    "        all_raw_texts = []\n",
    "        liwc_scores = []\n",
    "\n",
    "        label = -1\n",
    "\n",
    "#         for index_range in indexes:\n",
    "            # Sample\n",
    "        texts = [tokenize(self.texts[i]) for i in indexes] # is this good or am I repeating the same texts?\n",
    "\n",
    "        raw_texts = [self.texts[i] for i in indexes]\n",
    "        all_words.append(texts)\n",
    "\n",
    "        all_raw_texts.append(raw_texts)\n",
    "\n",
    "#             if len(texts) < self.max_posts_per_user:\n",
    "#                 # TODO: pad with zeros\n",
    "#                 pass\n",
    "\n",
    "        for i, words in enumerate(all_words):\n",
    "            tokens_data = []\n",
    "            categ_data = []\n",
    "            sparse_data = []\n",
    "            bert_ids_data = []\n",
    "            bert_masks_data = []\n",
    "            bert_segments_data = []\n",
    "\n",
    "            raw_text = all_raw_texts[i]\n",
    "            words = all_words[i]\n",
    "\n",
    "            for p, posting in enumerate(words): \n",
    "                encoded_tokens, encoded_emotions, encoded_pronouns, encoded_stopwords, encoded_liwc, \\\n",
    "                    bert_ids, bert_masks, bert_segments = self.__encode_text(words[p], raw_text[p])\n",
    "                \n",
    "\n",
    "                liwc = encoded_liwc\n",
    "      \n",
    "                tokens_data.append(encoded_tokens)\n",
    "                # using zeros for padding\n",
    "                # TODO: there is something wrong with this\n",
    "                categ_data.append(encoded_emotions + [encoded_pronouns] + liwc)\n",
    "                sparse_data.append(encoded_stopwords)\n",
    "                bert_ids_data.append(bert_ids)\n",
    "                bert_masks_data.append(bert_masks)\n",
    "                bert_segments_data.append(bert_segments)\n",
    "                \n",
    "                labels.append(None)\n",
    "                subjects.append(None)\n",
    "\n",
    "                # For each range\n",
    "                tokens_data_padded = np.array(sequence.pad_sequences(tokens_data, maxlen=self.seq_len,\n",
    "                                              padding=self.padding,\n",
    "                                            truncating=self.padding))\n",
    "                user_tokens.append(tokens_data_padded)\n",
    "\n",
    "                user_categ_data.append(categ_data)\n",
    "                user_sparse_data.append(sparse_data)\n",
    "\n",
    "                user_bert_ids_data.append(bert_ids_data)\n",
    "                user_bert_masks_data.append(bert_masks_data)\n",
    "                user_bert_segments_data.append(bert_segments_data)\n",
    "\n",
    "\n",
    "\n",
    "        user_tokens = sequence.pad_sequences(user_tokens, \n",
    "                                             maxlen=self.posts_per_group, \n",
    "                                             value=self.pad_value)\n",
    "        user_tokens = np.rollaxis(np.dstack(user_tokens), -1)\n",
    "        user_categ_data = sequence.pad_sequences(user_categ_data,  \n",
    "                                                 maxlen=self.posts_per_group, \n",
    "                                                 value=self.pad_value, dtype='float32')\n",
    "        user_categ_data = np.rollaxis(np.dstack(user_categ_data), -1)\n",
    "        \n",
    "        user_sparse_data = sequence.pad_sequences(user_sparse_data, \n",
    "                                                  maxlen=self.posts_per_group, \n",
    "                                                  value=self.pad_value)\n",
    "        user_sparse_data = np.rollaxis(np.dstack(user_sparse_data), -1)\n",
    "        \n",
    "        user_bert_ids_data = sequence.pad_sequences(user_bert_ids_data, \n",
    "                                                    maxlen=self.posts_per_group, \n",
    "                                                    value=self.pad_value)\n",
    "        user_bert_ids_data = np.rollaxis(np.dstack(user_bert_ids_data), -1)\n",
    "        \n",
    "        user_bert_masks_data = sequence.pad_sequences(user_bert_masks_data, \n",
    "                                                      maxlen=self.posts_per_group, \n",
    "                                                      value=self.pad_value)\n",
    "        user_bert_masks_data = np.rollaxis(np.dstack(user_bert_masks_data), -1)\n",
    "        \n",
    "        user_bert_segments_data = sequence.pad_sequences(user_bert_segments_data, \n",
    "                                                         maxlen=self.posts_per_group, \n",
    "                                                         value=self.pad_value)\n",
    "        user_bert_segments_data = np.rollaxis(np.dstack(user_bert_segments_data), -1)\n",
    "        \n",
    "\n",
    "        labels = np.array(labels)\n",
    "\n",
    "        return ([user_tokens, user_categ_data, user_sparse_data], \n",
    "            np.array(subjects),\n",
    "            np.array(labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 512) (2, 75) (2, 179)\n"
     ]
    }
   ],
   "source": [
    "for x, y in DataGeneratorFromText([\"This is the first text\", \"and this is the second text\"], \n",
    "                                  liwc_words_for_categories=liwc_words_for_categories, \n",
    "                                  compute_liwc=True):\n",
    "    print(x[0].shape, x[1].shape, x[2].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "# g = DataGenerator(user_level_data, subjects_split, \n",
    "#                                          set_type='test', \n",
    "#                                     seq_len=hyperparams_collection[key]['maxlen'],   \n",
    "# #                                         batch_size=len(subjects_split['test']), # on all data at once\n",
    "#                                         batch_size=hyperparams_collection[key]['batch_size'], # on all data at once\n",
    "#                                        hierarchical=hyperparams_collection[key]['hierarchical'],\n",
    "#                                          max_posts_per_user=None,\n",
    "#                                        pad_with_duplication=False,\n",
    "#                                         posts_per_group=hyperparams_collection[key]['posts_per_group'],\n",
    "#                                         post_groups_per_user=1,  compute_liwc=True,\n",
    "#                                         liwc_words_for_categories=liwc_words_for_categories,\n",
    "#                                         emotions=emotions, liwc_categories=liwc_categories,\n",
    "#                                          sample_seqs=False, shuffle=False, classes=classes,\n",
    "#                  class_weights={0:2,1:1,2:1})\n",
    "# # g = DataGenerator(user_level_data, subjects_split, sample_seqs=False, max_posts_per_user=None,\n",
    "# #                                           set_type='test', hierarchical=True, post_groups_per_user=None,\n",
    "# #                               posts_per_group=50, shuffle=False,\n",
    "# #                              sampling_distr='exp', liwc_words_for_categories=liwc_words_for_categories,\n",
    "# #                           \"Co\"   compute_liwc=True, classes=3)\n",
    "# for cnt, x in enumerate(g):\n",
    "#     continue\n",
    "# print(cnt)\n",
    "# print(g.generated_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(g.generated_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-11-29 17:09:20,282;WARNING;User Sbee6icreated_at-664370083.json has no posts in train set. Ignoring.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:training:User Sbee6icreated_at-664370083.json has no posts in train set. Ignoring.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-11-29 17:09:20,285;WARNING;User oSPW7CE3HXKsf4icreated_at309684088.json has no posts in train set. Ignoring.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:training:User oSPW7CE3HXKsf4icreated_at309684088.json has no posts in train set. Ignoring.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-11-29 17:09:20,286;WARNING;User pun1i_created_at-77564069.json has no posts in train set. Ignoring.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:training:User pun1i_created_at-77564069.json has no posts in train set. Ignoring.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-11-29 17:09:20,288;WARNING;User r7oooba25created_at110126231.json has no posts in train set. Ignoring.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:training:User r7oooba25created_at110126231.json has no posts in train set. Ignoring.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-11-29 17:09:20,289;WARNING;User xr_zhcreated_at274446519.json has no posts in train set. Ignoring.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:training:User xr_zhcreated_at274446519.json has no posts in train set. Ignoring.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-11-29 17:09:20,703;INFO;0 train positive examples\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:training:0 train positive examples\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-11-29 17:09:21,053;INFO;0 train positive examples\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:training:0 train positive examples\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-11-29 17:09:21,463;INFO;0 train positive examples\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:training:0 train positive examples\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-11-29 17:09:21,850;INFO;0 train positive examples\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:training:0 train positive examples\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-11-29 17:09:22,213;INFO;0 train positive examples\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:training:0 train positive examples\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-11-29 17:09:22,568;INFO;0 train positive examples\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:training:0 train positive examples\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-11-29 17:09:23,009;INFO;0 train positive examples\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:training:0 train positive examples\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-11-29 17:09:23,327;INFO;0 train positive examples\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:training:0 train positive examples\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-11-29 17:09:23,330;WARNING;User 3PXKJMBxLl7NVrIcreated_at-312359495.json has no posts in valid set. Ignoring.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:training:User 3PXKJMBxLl7NVrIcreated_at-312359495.json has no posts in valid set. Ignoring.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-11-29 17:09:23,331;WARNING;User 7iqs7uI3T3MwBflcreated_at110126231.json has no posts in valid set. Ignoring.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:training:User 7iqs7uI3T3MwBflcreated_at110126231.json has no posts in valid set. Ignoring.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-11-29 17:09:23,332;WARNING;User A3qKlV8I5O4bKOzcreated_at-793452802.json has no posts in valid set. Ignoring.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:training:User A3qKlV8I5O4bKOzcreated_at-793452802.json has no posts in valid set. Ignoring.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-11-29 17:09:23,333;WARNING;User EliThePotatocreated_at732169814.json has no posts in valid set. Ignoring.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:training:User EliThePotatocreated_at732169814.json has no posts in valid set. Ignoring.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-11-29 17:09:23,334;WARNING;User I5Pmucreated_at696932245.json has no posts in valid set. Ignoring.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:training:User I5Pmucreated_at696932245.json has no posts in valid set. Ignoring.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-11-29 17:09:24,009;INFO;0 valid positive examples\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:training:0 valid positive examples\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-11-29 17:09:24,468;INFO;0 valid positive examples\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:training:0 valid positive examples\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-11-29 17:09:24,880;INFO;0 valid positive examples\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:training:0 valid positive examples\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-11-29 17:09:24,979;INFO;0 valid positive examples\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:training:0 valid positive examples\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-11-29 17:09:24,981;WARNING;User abo5401created_at180601369.json has no posts in test set. Ignoring.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:training:User abo5401created_at180601369.json has no posts in test set. Ignoring.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-11-29 17:09:24,983;WARNING;User i__f5rcreated_at-500049795.json has no posts in test set. Ignoring.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:training:User i__f5rcreated_at-500049795.json has no posts in test set. Ignoring.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-11-29 17:09:25,379;INFO;0 test positive examples\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:training:0 test positive examples\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-11-29 17:09:25,822;INFO;0 test positive examples\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:training:0 test positive examples\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-11-29 17:09:26,191;INFO;0 test positive examples\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:training:0 test positive examples\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-11-29 17:09:26,536;INFO;0 test positive examples\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:training:0 test positive examples\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-11-29 17:09:26,831;INFO;0 test positive examples\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:training:0 test positive examples\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 6.49 s, sys: 31 ms, total: 6.52 s\n",
      "Wall time: 6.55 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "logger.setLevel(logging.DEBUG)\n",
    "\n",
    "# TODO: it is skipping the last batch\n",
    "x_data = {'train': [], 'valid': [], 'test': []}\n",
    "y_data = {'train': [], 'valid': [], 'test': []}\n",
    "for set_type in ['train', 'valid', 'test']:\n",
    "    total_positive = 0\n",
    "    for x, y in DataGenerator(user_level_data, subjects_split, sample_seqs=False, max_posts_per_user=None,\n",
    "                                          set_type=set_type, hierarchical=True, post_groups_per_user=1,\n",
    "                              posts_per_group=50, shuffle=False,\n",
    "                             sampling_distr='exp', liwc_words_for_categories=liwc_words_for_categories,\n",
    "                             compute_liwc=True, classes=3):\n",
    "#         total_positive += pd.Series(y).sum()\n",
    "        x_data[set_type].append(x)\n",
    "        y_data[set_type].append(y)\n",
    "        logger.info(\"%s %s positive examples\\n\" % (total_positive, set_type))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-11-29 17:09:26,839;WARNING;User Sbee6icreated_at-664370083.json has no posts in train set. Ignoring.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:training:User Sbee6icreated_at-664370083.json has no posts in train set. Ignoring.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-11-29 17:09:26,842;WARNING;User oSPW7CE3HXKsf4icreated_at309684088.json has no posts in train set. Ignoring.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:training:User oSPW7CE3HXKsf4icreated_at309684088.json has no posts in train set. Ignoring.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-11-29 17:09:26,844;WARNING;User pun1i_created_at-77564069.json has no posts in train set. Ignoring.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:training:User pun1i_created_at-77564069.json has no posts in train set. Ignoring.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-11-29 17:09:26,846;WARNING;User r7oooba25created_at110126231.json has no posts in train set. Ignoring.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:training:User r7oooba25created_at110126231.json has no posts in train set. Ignoring.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-11-29 17:09:26,848;WARNING;User xr_zhcreated_at274446519.json has no posts in train set. Ignoring.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:training:User xr_zhcreated_at274446519.json has no posts in train set. Ignoring.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-11-29 17:09:26,915;INFO;19 train positive examples\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:training:19 train positive examples\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-11-29 17:09:26,961;INFO;37 train positive examples\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:training:37 train positive examples\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-11-29 17:09:27,012;INFO;55 train positive examples\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:training:55 train positive examples\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-11-29 17:09:27,065;INFO;72 train positive examples\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:training:72 train positive examples\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-11-29 17:09:27,110;INFO;88 train positive examples\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:training:88 train positive examples\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-11-29 17:09:27,174;INFO;104 train positive examples\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:training:104 train positive examples\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-11-29 17:09:27,232;INFO;121 train positive examples\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:training:121 train positive examples\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-11-29 17:09:27,280;INFO;129 train positive examples\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:training:129 train positive examples\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-11-29 17:09:27,282;WARNING;User 3PXKJMBxLl7NVrIcreated_at-312359495.json has no posts in valid set. Ignoring.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:training:User 3PXKJMBxLl7NVrIcreated_at-312359495.json has no posts in valid set. Ignoring.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-11-29 17:09:27,284;WARNING;User 7iqs7uI3T3MwBflcreated_at110126231.json has no posts in valid set. Ignoring.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:training:User 7iqs7uI3T3MwBflcreated_at110126231.json has no posts in valid set. Ignoring.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-11-29 17:09:27,285;WARNING;User A3qKlV8I5O4bKOzcreated_at-793452802.json has no posts in valid set. Ignoring.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:training:User A3qKlV8I5O4bKOzcreated_at-793452802.json has no posts in valid set. Ignoring.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-11-29 17:09:27,287;WARNING;User EliThePotatocreated_at732169814.json has no posts in valid set. Ignoring.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:training:User EliThePotatocreated_at732169814.json has no posts in valid set. Ignoring.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-11-29 17:09:27,288;WARNING;User I5Pmucreated_at696932245.json has no posts in valid set. Ignoring.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:training:User I5Pmucreated_at696932245.json has no posts in valid set. Ignoring.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-11-29 17:09:27,336;INFO;15 valid positive examples\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:training:15 valid positive examples\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-11-29 17:09:27,402;INFO;33 valid positive examples\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:training:33 valid positive examples\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-11-29 17:09:27,462;INFO;50 valid positive examples\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:training:50 valid positive examples\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-11-29 17:09:27,478;INFO;54 valid positive examples\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:training:54 valid positive examples\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-11-29 17:09:27,479;WARNING;User abo5401created_at180601369.json has no posts in test set. Ignoring.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:training:User abo5401created_at180601369.json has no posts in test set. Ignoring.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-11-29 17:09:27,481;WARNING;User i__f5rcreated_at-500049795.json has no posts in test set. Ignoring.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:training:User i__f5rcreated_at-500049795.json has no posts in test set. Ignoring.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-11-29 17:09:27,539;INFO;17 test positive examples\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:training:17 test positive examples\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-11-29 17:09:27,597;INFO;31 test positive examples\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:training:31 test positive examples\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-11-29 17:09:27,646;INFO;47 test positive examples\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:training:47 test positive examples\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-11-29 17:09:27,700;INFO;64 test positive examples\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:training:64 test positive examples\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-11-29 17:09:27,740;INFO;75 test positive examples\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:training:75 test positive examples\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 914 ms, sys: 12.3 ms, total: 927 ms\n",
      "Wall time: 902 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# TODO: it is skipping the last batch\n",
    "x_data2 = {'train': [], 'valid': [], 'test': []}\n",
    "y_data2 = {'train': [], 'valid': [], 'test': []}\n",
    "for set_type in ['train', 'valid', 'test']:\n",
    "    total_positive = 0\n",
    "    for x, y in DataGenerator(user_level_data, subjects_split, sample_seqs=False, max_posts_per_user=None,\n",
    "                                          set_type=set_type, hierarchical=False, post_groups_per_user=1,\n",
    "                              posts_per_group=50, shuffle=False,\n",
    "                             sampling_distr='exp', liwc_words_for_categories=liwc_words_for_categories,\n",
    "                             compute_liwc=False):\n",
    "        total_positive += pd.Series(y).sum()\n",
    "        x_data2[set_type].append(x)\n",
    "        y_data2[set_type].append(y)\n",
    "        logger.info(\"%d %s positive examples\\n\" % (total_positive, set_type))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[1., 0., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [0., 1., 0.]], dtype=float32),\n",
       " array([[1., 0., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [0., 1., 0.]], dtype=float32),\n",
       " array([[1., 0., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [1., 0., 0.]], dtype=float32),\n",
       " array([[1., 0., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [1., 0., 0.]], dtype=float32),\n",
       " array([[0., 1., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [0., 1., 0.]], dtype=float32),\n",
       " array([[1., 0., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [0., 1., 0.]], dtype=float32),\n",
       " array([[0., 1., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [0., 1., 0.]], dtype=float32),\n",
       " array([[0., 1., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [1., 0., 0.]], dtype=float32)]"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_data['train'][0][1][0]\n",
    "y_data['train']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.03703704, 0.05349794, 0.02469136, 0.01646091, 0.04115226,\n",
       "       0.06995885, 0.0617284 , 0.04938272, 0.00823045, 0.03703704,\n",
       "       0.05349794, 0.        , 0.0180025 , 0.01587302, 0.00340136,\n",
       "       0.        , 0.02428193, 0.01963414, 0.        , 0.09308463,\n",
       "       0.07092854, 0.06223618, 0.        , 0.        , 0.        ,\n",
       "       0.06973153, 0.02626025, 0.04941784, 0.00972222, 0.03000174,\n",
       "       0.0552285 , 0.        , 0.00198413, 0.003663  , 0.01953602,\n",
       "       0.08157015, 0.01984127, 0.        , 0.        , 0.        ,\n",
       "       0.12653497, 0.00564713, 0.4384877 , 0.12216117, 0.00907029,\n",
       "       0.02615341, 0.01247166, 0.05259535, 0.06869513, 0.00491308,\n",
       "       0.00226757, 0.0334845 , 0.01738473, 0.00198413, 0.13419167,\n",
       "       0.095374  , 0.12075847, 0.00340136, 0.07936508, 0.003663  ,\n",
       "       0.03118641, 0.12100558, 0.06514332, 0.03613728, 0.00529101,\n",
       "       0.        , 0.01020408, 0.00566893, 0.00529101, 0.08869702,\n",
       "       0.02380952, 0.0642988 , 0.0047619 , 0.01726845, 0.02215608])"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_data2['train'][0][1][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #x_data['train'][]\n",
    "# featureindex = 1\n",
    "\n",
    "# from scipy.stats import pearsonr, spearmanr\n",
    "# for i in range(len(x_data['train'][0][featureindex])):\n",
    "#     print(spearmanr(x_data['train'][0][featureindex][i], x_data2['train'][0][featureindex][i]))    \n",
    "#     plt.scatter(x_data['train'][0][featureindex][i], x_data2['train'][0][featureindex][i])\n",
    "# #     break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "64"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum([len(liwc_words_for_categories[c]) for c in categories])\n",
    "len(categories)\n",
    "len(set(categories))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (x_data['valid'][0][0].shape, x_data['valid'][0][1].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encoded_for_bert = encode_text_for_bert(bert_tokenizer, InputExample(None, \n",
    "#                                                \"Ana are mere\"), 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ids, masks, segments, label = encoded_for_bert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class_weights = class_weight.compute_class_weight('balanced',\n",
    "#                                                  np.unique(y_data['train']),\n",
    "#                                                  y_data['train'])\n",
    "# class_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total 20002 word vectors.\n",
      "Words not found in embedding space 163\n"
     ]
    }
   ],
   "source": [
    "def load_embeddings(path, embedding_dim, voc):\n",
    "    # random matrix with mean value = 0\n",
    "    embedding_matrix = np.random.random((len(voc)+2, embedding_dim)) - 0.5 # voc + unk + pad value(0)\n",
    "    cnt_inv = 0\n",
    "    f = open(path, encoding='utf8')\n",
    "    for i, line in enumerate(f):\n",
    "#         print(i)\n",
    "        values = line.split()\n",
    "        word = ''.join(values[:-hyperparams_features['embedding_dim']])\n",
    "        coefs = np.asarray(values[-hyperparams_features['embedding_dim']:], dtype='float32')\n",
    "        word_i = voc.get(word)\n",
    "        if word_i is not None:\n",
    "            embedding_matrix[word_i] = coefs\n",
    "            cnt_inv += 1\n",
    "    f.close()\n",
    "\n",
    "    print('Total %s word vectors.' % len(embedding_matrix))\n",
    "    print('Words not found in embedding space %d' % (len(embedding_matrix)-cnt_inv))\n",
    " \n",
    "    return embedding_matrix\n",
    "\n",
    "def load_embeddings2(path, embedding_dim, voc):\n",
    "    # random matrix with mean value = 0\n",
    "    embedding_matrix = np.random.random((len(voc)+2, embedding_dim)) #- 0.5 # voc + unk + pad value(0)\n",
    "    cnt_inv = 0\n",
    "    with open(path, \"rb\") as f:\n",
    "        embedding_dict = pickle.load(f)\n",
    "    for word, coefs in embedding_dict.items():\n",
    "        word_i = voc.get(word)\n",
    "        if word_i is not None:\n",
    "            embedding_matrix[word_i] = coefs\n",
    "            cnt_inv += 1\n",
    "    print('Total %s word vectors.' % len(embedding_matrix))\n",
    "    print('Words not found in embedding space %d' % (len(embedding_matrix)-cnt_inv))\n",
    " \n",
    "    return embedding_matrix\n",
    "# \n",
    "# pretrained_embeddings_path = root_dir + '/resources/glove.twitter.27B/glove.twitter.27B.%dd.txt' % hyperparams_features['embedding_dim']\n",
    "# pretrained_embeddings_path = root_dir + '/resources/glove.840B/glove.840B.%dd.txt' % hyperparams_features['embedding_dim']\n",
    "pretrained_embeddings_path = hyperparams_features['embeddings_path']#root_dir + '/eRisk/finetuned_glove_clpsych_erisk_normalized_2_20000.pkl'\n",
    "embedding_matrix = load_embeddings(pretrained_embeddings_path, hyperparams_features['embedding_dim'], \n",
    "                                    voc=vocabulary_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.0039033889818644025"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_matrix.mean()\n",
    "# hyperparams_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Metrics():\n",
    "    def __init__(self, threshold=0.5):\n",
    "        self.threshold=threshold\n",
    "        \n",
    "    def recall_m(self, y_true, y_pred):\n",
    "            y_labels = y_true\n",
    "            y_pred = K.cast(K.greater(K.clip(y_pred, 0, 1), self.threshold), K.floatx())        \n",
    "            possible_positives = K.sum(K.round(K.clip(y_labels, 0, 1)))\n",
    "            true_positives = K.sum(K.round(K.clip(y_labels * y_pred, 0, 1)))\n",
    "            recall = true_positives / (possible_positives + K.epsilon())\n",
    "            return recall\n",
    "\n",
    "    def precision_m(self, y_true, y_pred):\n",
    "            y_labels = y_true\n",
    "            y_pred = K.cast(K.greater(K.clip(y_pred, 0, 1), self.threshold), K.floatx())        \n",
    "            true_positives = K.sum(K.round(K.clip(y_labels * y_pred, 0, 1)))\n",
    "            predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "            precision = true_positives / (predicted_positives + K.epsilon())\n",
    "            return precision\n",
    "\n",
    "    def f1_m(self, y_true, y_pred):\n",
    "        precision = self.precision_m(y_true, y_pred)\n",
    "        recall = self.recall_m(y_true, y_pred)\n",
    "        return 2*((precision*recall)/(precision+recall+K.epsilon()))\n",
    "    \n",
    "    def auc2(self, y_true, y_pred):\n",
    "        auc = tf.metrics.auc(y_true, y_pred)[1]\n",
    "        K.get_session().run(tf.local_variables_initializer())\n",
    "        return auc\n",
    "\n",
    "    def auc(self, y_true, y_pred):\n",
    "#         has_true_examples = K.greater(K.cast(K.sum(y_true), K.floatx()),0)\n",
    "#         has_false_examples = K.less(K.cast(K.mean(y_true), K.floatx()),1)\n",
    "#         score = tf.cond(tf.logical_and(has_true_examples, has_false_examples), \n",
    "#                         lambda:tf.py_function(roc_auc_score, (\n",
    "#                             K.cast(y_true, K.floatx()), \n",
    "#                             K.cast(y_pred, K.floatx())), tf.float32), \n",
    "#                         lambda:0.0)\n",
    "        return 0\n",
    "        \n",
    "def binary_crossentropy_custom(y_true, y_pred):\n",
    "    y_labels = y_true\n",
    "    return K.binary_crossentropy(y_labels, \n",
    "                                 y_pred)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BertLayer(tf.keras.layers.Layer):\n",
    "    def __init__(\n",
    "        self,\n",
    "        n_fine_tune_layers=10,\n",
    "        pooling=\"first\",\n",
    "        trainable=True,\n",
    "        bert_path=\"https://tfhub.dev/google/bert_uncased_L-12_H-768_A-12/1\", \n",
    "        **kwargs\n",
    "    ):\n",
    "        self.n_fine_tune_layers = n_fine_tune_layers\n",
    "        self.trainable = trainable\n",
    "        self.output_size = 768\n",
    "        self.pooling = pooling\n",
    "        self.bert_path = bert_path\n",
    "        if self.pooling not in [\"first\", \"mean\"]:\n",
    "            raise NameError(\n",
    "               \"Undefined pooling type (must be either first or mean, but is %s)\" % self.pooling\n",
    "            )\n",
    "\n",
    "        super(BertLayer, self).__init__(**kwargs)\n",
    "        \n",
    "    def get_config(self):\n",
    "\n",
    "        config = super(BertLayer, self).get_config().copy()\n",
    "        config.update({\n",
    "            'n_fine_tune_layers': self.n_fine_tune_layers,\n",
    "            'trainable': self.trainable,\n",
    "            'output_size': self.output_size,\n",
    "            'pooling': self.pooling,\n",
    "            'bert_path': self.bert_path,\n",
    "        })\n",
    "\n",
    "        return config\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.bert = hub.Module(\n",
    "            self.bert_path, trainable=self.trainable, name=\"%s_module\" % self.name\n",
    "        )\n",
    "\n",
    "        # Remove unused layers\n",
    "        trainable_vars = self.bert.variables\n",
    "        if self.pooling == \"first\":\n",
    "            trainable_vars = [var for var in trainable_vars if not \"/cls/\" in var.name]\n",
    "            trainable_layers = [\"pooler/dense\"]\n",
    "\n",
    "        elif self.pooling == \"mean\":\n",
    "            trainable_vars = [\n",
    "                var\n",
    "                for var in trainable_vars\n",
    "                if not \"/cls/\" in var.name and not \"/pooler/\" in var.name\n",
    "            ]\n",
    "            trainable_layers = []\n",
    "        else:\n",
    "            raise NameError(\n",
    "                \"Undefined pooling type (must be either first or mean, but is %s)\" % self.pooling\n",
    "            )\n",
    "\n",
    "        # Select how many layers to fine tune\n",
    "        for i in range(self.n_fine_tune_layers):\n",
    "            trainable_layers.append(\"encoder/layer_%s\" % str(11 - i))\n",
    "\n",
    "        # Update trainable vars to contain only the specified layers\n",
    "        trainable_vars = [\n",
    "            var\n",
    "            for var in trainable_vars\n",
    "            if any([l in var.name for l in trainable_layers])\n",
    "        ]\n",
    "\n",
    "        # Add to trainable weights\n",
    "        for var in trainable_vars:\n",
    "            self._trainable_weights.append(var)\n",
    "\n",
    "        for var in self.bert.variables:\n",
    "            if var not in self._trainable_weights:\n",
    "                self._non_trainable_weights.append(var)\n",
    "\n",
    "        super(BertLayer, self).build(input_shape)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        inputs = [K.cast(x, dtype=\"int32\") for x in inputs]\n",
    "        input_ids, input_mask, segment_ids = inputs\n",
    "        bert_inputs = dict(\n",
    "            input_ids=input_ids, input_mask=input_mask, segment_ids=segment_ids\n",
    "        )\n",
    "        if self.pooling == \"first\":\n",
    "            pooled = self.bert(inputs=bert_inputs, signature=\"tokens\", as_dict=True)[\n",
    "                \"pooled_output\"\n",
    "            ]\n",
    "        elif self.pooling == \"mean\":\n",
    "            result = self.bert(inputs=bert_inputs, signature=\"tokens\", as_dict=True)[\n",
    "                \"sequence_output\"\n",
    "            ]\n",
    "\n",
    "            mul_mask = lambda x, m: x * tf.expand_dims(m, axis=-1)\n",
    "            masked_reduce_mean = lambda x, m: tf.reduce_sum(mul_mask(x, m), axis=1) / (\n",
    "                    tf.reduce_sum(m, axis=1, keepdims=True) + 1e-10)\n",
    "            input_mask = tf.cast(input_mask, tf.float32)\n",
    "            pooled = masked_reduce_mean(result, input_mask)\n",
    "        else:\n",
    "            raise NameError(\"Undefined pooling type (must be either first or mean, but is %s)\" % self.pooling)\n",
    "\n",
    "        return pooled\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return (input_shape[0], self.output_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(hyperparams, hyperparams_features, embedding_matrix, emotions, stopwords_list,\n",
    "                liwc_categories,\n",
    "               ignore_layer=[], classes=1):\n",
    "    def attention(xin):\n",
    "        return K.sum(xin, axis=1) \n",
    "    tokens_features = Input(shape=(hyperparams['maxlen'],), name='word_seq')\n",
    "    embedding_layer = Embedding(hyperparams_features['max_features'], \n",
    "                                hyperparams_features['embedding_dim'], \n",
    "                                input_length=hyperparams['maxlen'],\n",
    "                                embeddings_regularizer=regularizers.l2(hyperparams['l2_embeddings']),\n",
    "                                weights=[embedding_matrix], \n",
    "                                trainable=hyperparams['trainable_embeddings'],\n",
    "                               name='embeddings_layer')(\n",
    "        tokens_features)\n",
    "#     if 'batchnorm' not in ignore_layer:\n",
    "#         embedding_layer_norm = BatchNormalization(axis=1, momentum=hyperparams['norm_momentum'],\n",
    "#                                                      name='embeddings_layer_norm')(embedding_layer)\n",
    "    embedding_layer = Dropout(hyperparams['dropout'], name='embedding_dropout')(embedding_layer)\n",
    "\n",
    "    if 'lstm' not in hyperparams['ignore_layer']:\n",
    "        if False: #tf.test.is_gpu_available():\n",
    "            lstm_layers = Bidirectional(CuDNNLSTM(\n",
    "                            hyperparams['lstm_units'], \n",
    "                                    return_sequences='attention' not in hyperparams['ignore_layer'], # only True if using attention\n",
    "                          name='LSTM_layer'), name='bilstm')(embedding_layer)\n",
    "        else:\n",
    "            lstm_layers = Bidirectional(LSTM(hyperparams['lstm_units'], \n",
    "                               return_sequences='attention' not in ignore_layer,\n",
    "                          name='LSTM_layer'), name='bilstm')(embedding_layer)\n",
    "#             lstm_layers = LSTM(hyperparams['lstm_units'], \n",
    "#                                return_sequences='attention' not in hyperparams['ignore_layer'],\n",
    "#                           name='LSTM_layer')(embedding_layer)\n",
    "            \n",
    "    elif 'cnn' not in hyperparams['ignore_layer']:\n",
    "        cnn_layers = Conv1D(hyperparams['filters'],\n",
    "                             hyperparams['kernel_size'],\n",
    "                             padding='valid',\n",
    "                             activation='relu',\n",
    "                             strides=1, name='convolution')(embedding_layer)\n",
    "        # we use max pooling:\n",
    "        cnn_layers = GlobalMaxPooling1D()(cnn_layers)\n",
    "    \n",
    "    # Attention\n",
    "    if 'attention' not in hyperparams['ignore_layer']:\n",
    "        attention = Dense(1, activation='tanh', name='attention')(lstm_layers)\n",
    "        attention = Flatten()(attention)\n",
    "        attention = Activation('softmax')(attention)\n",
    "        attention = RepeatVector(hyperparams['lstm_units']*2)(attention)\n",
    "        attention = Permute([2, 1])(attention)\n",
    "\n",
    "        sent_representation = Multiply()([lstm_layers, attention])\n",
    "        sent_representation = Lambda(lambda xin: K.sum(xin, axis=1), \n",
    "                                     output_shape=(hyperparams['lstm_units'],)\n",
    "                                    )(sent_representation)\n",
    "#         sent_representation = Lambda(attention, \n",
    "#                                          output_shape=(hyperparams['lstm_units'],\n",
    "#                                         ))(sent_representation)\n",
    "\n",
    "        \n",
    "    elif 'lstm' not in hyperparams['ignore_layer']:\n",
    "        sent_representation = lstm_layers\n",
    "    elif 'cnn' not in hyperparams['ignore_layer']:\n",
    "        sent_representation = cnn_layers\n",
    "    else:\n",
    "        sent_representation = None\n",
    "        \n",
    "    if sent_representation is not None:\n",
    "        sent_representation = Dropout(hyperparams['dropout'], name='lstm_att_dropout')(sent_representation)\n",
    "        if hyperparams['dense_sentence_units']:\n",
    "            sent_representation = Dense(units=hyperparams['dense_sentence_units'], activation='relu',\n",
    "                                       name='dense_sent_representation')(sent_representation)\n",
    "    \n",
    "    # Other features\n",
    "    numerical_features = Input(shape=(len(emotions) + 1 + len(liwc_categories),), name='numeric_input') # emotions and pronouns\n",
    "    sparse_features = Input(shape=(len(stopwords_list),), name='sparse_input') # stopwords\n",
    "\n",
    "    dense_layer_sparse = Dense(units=hyperparams['dense_bow_units'],\n",
    "                              name='sparse_feat_dense_layer', activation='relu',\n",
    "                                kernel_regularizer=regularizers.l2(hyperparams['l2_dense']),\n",
    "                              )(sparse_features)\n",
    "    \n",
    "    # BERT encoder\n",
    "    if 'bert_layer' not in hyperparams['ignore_layer']:\n",
    "        in_id_bert = Input(shape=(hyperparams['maxlen'],), name=\"input_ids_bert\")\n",
    "        in_mask_bert = Input(shape=(hyperparams['maxlen'],), name=\"input_masks_bert\")\n",
    "        in_segment_bert = Input(shape=(hyperparams['maxlen'],), name=\"segment_ids_bert\")\n",
    "        bert_inputs = [in_id_bert, in_mask_bert, in_segment_bert]\n",
    "\n",
    "        bert_output = BertLayer(n_fine_tune_layers=hyperparams['bert_finetune_layers'], \n",
    "                                pooling=hyperparams['bert_pooling'],\n",
    "                               trainable=hyperparams['bert_trainable'],\n",
    "                               name='bert_layer')(bert_inputs)\n",
    "        dense_bert = Dense(hyperparams['bert_dense_units'], activation='relu',\n",
    "                           kernel_regularizer=regularizers.l2(hyperparams['l2_bert']),\n",
    "                          name='bert_dense_layer')(bert_output)\n",
    "    else:\n",
    "        dense_bert = None\n",
    "\n",
    "\n",
    "    \n",
    "    # Batch normalization\n",
    "    if 'batchnorm' not in hyperparams['ignore_layer']:\n",
    "        numerical_features_norm = BatchNormalization(axis=1, momentum=hyperparams['norm_momentum'],\n",
    "                                                     name='numerical_features_norm')(numerical_features)\n",
    "        sent_representation_norm = BatchNormalization(axis=1, momentum=hyperparams['norm_momentum'],\n",
    "                                                      name='sent_repr_norm')(sent_representation)\n",
    "        dense_layer_sparse_norm = BatchNormalization(axis=1, momentum=hyperparams['norm_momentum'],\n",
    "                                                     name='sparse_features_norm')(dense_layer_sparse)\n",
    "        if 'bert_layer' not in hyperparams['ignore_layer']:\n",
    "            if hyperparams['bert_dense_units']:\n",
    "                dense_bert_norm = BatchNormalization(axis=1, momentum=hyperparams['norm_momentum'],\n",
    "                                                         name='bert_layer_norm')(dense_bert)\n",
    "            else:\n",
    "                dense_bert_norm = BatchNormalization(axis=1, momentum=hyperparams['norm_momentum'],\n",
    "                                                         name='bert_layer_norm')(bert_output)\n",
    "        else:\n",
    "            dense_bert_norm = None\n",
    "        \n",
    "#     subjects = Input(shape=(1,), name='subjects')\n",
    "    \n",
    "\n",
    "    all_layers = {\n",
    "        'user_encoded': sent_representation,\n",
    "        'numerical_dense_layer': numerical_features,\n",
    "        'sparse_feat_dense_layer': dense_layer_sparse,\n",
    "        'bert_layer': dense_bert if hyperparams['bert_dense_units'] else bert_output,\n",
    "    }\n",
    "    if 'batchnorm' not in hyperparams['ignore_layer']:\n",
    "        all_layers = {\n",
    "            'user_encoded': sent_representation_norm,\n",
    "            'numerical_dense_layer': numerical_features_norm,\n",
    "            'sparse_feat_dense_layer': dense_layer_sparse_norm,\n",
    "            'bert_layer': dense_bert_norm\n",
    "        }\n",
    "    layers_to_merge = []\n",
    "    for n, l in all_layers.items():\n",
    "        if n in hyperparams['ignore_layer'] or l is None:\n",
    "            continue\n",
    "        layers_to_merge.append(l)\n",
    "        \n",
    "    if len(layers_to_merge) == 1:\n",
    "        merged_layers = layers_to_merge[0]\n",
    "    else:\n",
    "        merged_layers = concatenate(layers_to_merge)\n",
    "    output_layer = Dense(classes, activation='sigmoid' if classes==1 else 'softmax',\n",
    "                         name='output_layer',\n",
    "                        kernel_regularizer=regularizers.l2(hyperparams['l2_dense']),\n",
    "                        )(merged_layers)\n",
    "\n",
    "    # Compile model\n",
    "    if 'bert_layer' not in hyperparams['ignore_layer']:\n",
    "        inputs=[tokens_features, numerical_features, sparse_features, \n",
    "                              in_id_bert, in_mask_bert, in_segment_bert,\n",
    "    #                           subjects\n",
    "                             ]\n",
    "    else:\n",
    "        inputs=[tokens_features, numerical_features, sparse_features]\n",
    "    model = Model(inputs=inputs, outputs=output_layer)\n",
    "        \n",
    "\n",
    "    metrics_class = Metrics(threshold=hyperparams['threshold'])\n",
    "    model.compile(hyperparams['optimizer'], binary_crossentropy_custom,\n",
    "                  metrics=[metrics_class.f1_m, metrics_class.precision_m, metrics_class.recall_m,\n",
    "                          metrics_class.auc, \n",
    "                           tf.keras.metrics.AUC(name=\"AUC_keras\"), \n",
    "                           tf.keras.metrics.FalsePositives(), \n",
    "                           tf.keras.metrics.FalseNegatives()])\n",
    "\n",
    "    return model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_tl_model(hyperparams, hyperparams_features, embedding_matrix, emotions, stopwords_list,\n",
    "                liwc_categories,\n",
    "               ignore_layer=[]):\n",
    "    def attention(xin):\n",
    "        return K.sum(xin, axis=1) \n",
    "    tokens_features = Input(shape=(hyperparams['maxlen'],), name='word_seq')\n",
    "    embedding_layer = Embedding(hyperparams_features['max_features'], \n",
    "                                hyperparams_features['embedding_dim'], \n",
    "                                input_length=hyperparams['maxlen'],\n",
    "                                embeddings_regularizer=regularizers.l2(hyperparams['l2_embeddings']),\n",
    "                                weights=[embedding_matrix], \n",
    "                                trainable=False,\n",
    "                               name='embeddings_layer')(\n",
    "        tokens_features)\n",
    "#     if 'batchnorm' not in ignore_layer:\n",
    "#         embedding_layer_norm = BatchNormalization(axis=1, momentum=hyperparams['norm_momentum'],\n",
    "#                                                      name='embeddings_layer_norm')(embedding_layer)\n",
    "    embedding_layer = Dropout(hyperparams['dropout'], name='embedding_dropout')(embedding_layer)\n",
    "\n",
    "    if 'lstm' not in ignore_layer:\n",
    "        if False: #tf.test.is_gpu_available():\n",
    "            lstm_layers = Bidirectional(CuDNNLSTM(hyperparams['lstm_units'], trainable=False,\n",
    "                                    return_sequences='attention' not in ignore_layer, # only True if using attention\n",
    "                          name='LSTM_layer'), name='bilstm')(embedding_layer)\n",
    "        else:\n",
    "            lstm_layers = Bidirectional(LSTM(hyperparams['lstm_units'], trainable=False,\n",
    "                               return_sequences='attention' not in ignore_layer,\n",
    "                          name='LSTM_layer'), name='bilstm')(embedding_layer)\n",
    "            \n",
    "    elif 'cnn' not in ignore_layer:\n",
    "        cnn_layers = Conv1D(hyperparams['filters'],\n",
    "                             hyperparams['kernel_size'],\n",
    "                             padding='valid',\n",
    "                             activation='relu',\n",
    "                             strides=1,\n",
    "                           trainable=False,\n",
    "                           name='convolution')(embedding_layer)\n",
    "        # we use max pooling:\n",
    "        cnn_layers = GlobalMaxPooling1D(trainable=False)(cnn_layers)\n",
    "    \n",
    "    # Attention\n",
    "    if 'attention' not in ignore_layer:\n",
    "        attention = Dense(1, activation='tanh', name='attention', trainable=False)(lstm_layers)\n",
    "        attention = Flatten()(attention)\n",
    "        attention = Activation('softmax')(attention)\n",
    "        attention = RepeatVector(hyperparams['lstm_units']*2)(attention)\n",
    "        attention = Permute([2, 1])(attention)\n",
    "\n",
    "        sent_representation = Multiply()([lstm_layers, attention])\n",
    "        sent_representation = Lambda(lambda xin: K.sum(xin, axis=1), \n",
    "                                     output_shape=(hyperparams['lstm_units'],)\n",
    "                                    )(sent_representation)\n",
    "#         sent_representation = Lambda(attention, \n",
    "#                                          output_shape=(hyperparams['lstm_units'],\n",
    "#                                         ))(sent_representation)\n",
    "\n",
    "        \n",
    "    elif 'lstm' not in ignore_layer:\n",
    "        sent_representation = lstm_layers\n",
    "    elif 'cnn' not in ignore_layer:\n",
    "        sent_representation = cnn_layers\n",
    "        \n",
    "    \n",
    "    sent_representation = Dropout(hyperparams['dropout'], name='lstm_att_dropout')(sent_representation)\n",
    "    if hyperparams['dense_sentence_units']:\n",
    "        sent_representation = Dense(units=hyperparams['dense_sentence_units'], activation='relu',\n",
    "                                   name='dense_sent_representation',\n",
    "                                   trainable=False)(sent_representation)\n",
    "    \n",
    "    # Other features\n",
    "    numerical_features = Input(shape=(len(emotions) + 1 + len(liwc_categories),), name='numeric_input') # emotions and pronouns\n",
    "    sparse_features = Input(shape=(len(stopwords_list),), name='sparse_input') # stopwords\n",
    "\n",
    "    dense_layer_sparse = Dense(units=hyperparams['dense_bow_units'],\n",
    "                              name='sparse_feat_dense_layer', activation='relu',\n",
    "                                kernel_regularizer=regularizers.l2(hyperparams['l2_dense']),\n",
    "                               trainable=False,\n",
    "                              )(sparse_features)\n",
    "    \n",
    "    # BERT encoder\n",
    "    if 'bert_layer' not in hyperparams['ignore_layer']:\n",
    "        in_id_bert = Input(shape=(hyperparams['maxlen'],), name=\"input_ids_bert\")\n",
    "        in_mask_bert = Input(shape=(hyperparams['maxlen'],), name=\"input_masks_bert\")\n",
    "        in_segment_bert = Input(shape=(hyperparams['maxlen'],), name=\"segment_ids_bert\")\n",
    "        bert_inputs = [in_id_bert, in_mask_bert, in_segment_bert]\n",
    "\n",
    "        bert_output = BertLayer(n_fine_tune_layers=hyperparams['bert_finetune_layers'], \n",
    "                                pooling=hyperparams['bert_pooling'],\n",
    "                               trainable=False,\n",
    "                               name='bert_layer')(bert_inputs)\n",
    "        dense_bert = Dense(hyperparams['bert_dense_units'], activation='relu',\n",
    "                           kernel_regularizer=regularizers.l2(hyperparams['l2_bert']),\n",
    "                          name='bert_dense_layer',\n",
    "                          trainable=False)(bert_output)\n",
    "    else:\n",
    "        dense_bert = None\n",
    "\n",
    "\n",
    "    \n",
    "    # Batch normalization\n",
    "    if 'batchnorm' not in ignore_layer:\n",
    "        numerical_features_norm = BatchNormalization(axis=1, momentum=hyperparams['norm_momentum'],\n",
    "                                                     name='numerical_features_norm')(numerical_features)\n",
    "        sent_representation_norm = BatchNormalization(axis=1, momentum=hyperparams['norm_momentum'],\n",
    "                                                      name='sent_repr_norm')(sent_representation)\n",
    "        dense_layer_sparse_norm = BatchNormalization(axis=1, momentum=hyperparams['norm_momentum'],\n",
    "                                                     name='sparse_features_norm')(dense_layer_sparse)\n",
    "        if 'bert_layer' not in hyperparams['ignore_layer']:\n",
    "            if hyperparams['bert_dense_units']:\n",
    "                dense_bert_norm = BatchNormalization(axis=1, momentum=hyperparams['norm_momentum'],\n",
    "                                                         name='bert_layer_norm')(dense_bert)\n",
    "            else:\n",
    "                dense_bert_norm = BatchNormalization(axis=1, momentum=hyperparams['norm_momentum'],\n",
    "                                                         name='bert_layer_norm')(bert_output)\n",
    "        else:\n",
    "            dense_bert_norm = None\n",
    "        \n",
    "#     subjects = Input(shape=(1,), name='subjects')\n",
    "    \n",
    "\n",
    "    all_layers = {\n",
    "        'user_encoded': sent_representation,\n",
    "        'numerical_dense_layer': numerical_features,\n",
    "        'sparse_feat_dense_layer': dense_layer_sparse,\n",
    "        'bert_layer': dense_bert if hyperparams['bert_dense_units'] else bert_output,\n",
    "    }\n",
    "    if 'batchnorm' not in ignore_layer:\n",
    "        all_layers = {\n",
    "            'user_encoded': sent_representation_norm,\n",
    "            'numerical_dense_layer': numerical_features_norm,\n",
    "            'sparse_feat_dense_layer': dense_layer_sparse_norm,\n",
    "            'bert_layer': dense_bert_norm\n",
    "        }\n",
    "    layers_to_merge = []\n",
    "    for n, l in all_layers.items():\n",
    "        if n in ignore_layer:\n",
    "            continue\n",
    "        layers_to_merge.append(l)\n",
    "        \n",
    "    if len(layers_to_merge) == 1:\n",
    "        merged_layers = layers_to_merge[0]\n",
    "    else:\n",
    "        merged_layers = concatenate(layers_to_merge)\n",
    "        \n",
    "    TL_layer = Dense(hyperparams['transfer_units'], activation='sigmoid',\n",
    "                         name='tl_layer',\n",
    "                        kernel_regularizer=regularizers.l2(hyperparams['l2_dense']),\n",
    "                         trainable=True\n",
    "                        )(merged_layers)\n",
    "    output_layer = Dense(1, activation='sigmoid',\n",
    "                         name='output_layer_tl',\n",
    "                        kernel_regularizer=regularizers.l2(hyperparams['l2_dense']),\n",
    "                         trainable=True,\n",
    "                        )(TL_layer)\n",
    "\n",
    "    # Compile model\n",
    "    if 'bert_layer' not in hyperparams['ignore_layer']:\n",
    "        inputs=[tokens_features, numerical_features, sparse_features, \n",
    "                              in_id_bert, in_mask_bert, in_segment_bert,\n",
    "    #                           subjects\n",
    "                             ]\n",
    "    else:\n",
    "        inputs=[tokens_features, numerical_features, sparse_features]\n",
    "    model = Model(inputs=inputs, outputs=output_layer)\n",
    "    model.summary()\n",
    "\n",
    "\n",
    "    if classes==1:\n",
    "        metrics_class = Metrics(threshold=hyperparams['threshold'])\n",
    "        model.compile(hyperparams['optimizer'], binary_crossentropy_custom,\n",
    "                      metrics=[metrics_class.f1_m, metrics_class.precision_m, metrics_class.recall_m,\n",
    "                              metrics_class.auc, \n",
    "                               tf.keras.metrics.AUC(name=\"AUC_keras\"), \n",
    "                               tf.keras.metrics.FalsePositives(), \n",
    "                               tf.keras.metrics.FalseNegatives()])\n",
    "    else:\n",
    "        model.compile(hyperparams['optimizer'], K.categorical_crossentropy,\n",
    "                     metrics=[tf.keras.metrics.CategoricalAccuracy(name='cat_acc'),\n",
    "#                              tf.keras.metrics.Precision(name='prec'), tf.keras.metrics.Recall(name='rec'), \n",
    "                              ])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_hierarchical_model(hyperparams, hyperparams_features, embedding_matrix, emotions, stopwords_list,\n",
    "                liwc_categories,\n",
    "               ignore_layer=[], activations=None, classes=1):\n",
    "    def attention(xin):\n",
    "        return K.sum(xin, axis=1) \n",
    "\n",
    "\n",
    "    # Post/sentence representation - word sequence\n",
    "    tokens_features = Input(shape=(hyperparams['maxlen'],), name='word_seq')\n",
    "    embedding_layer = Embedding(hyperparams_features['max_features'], \n",
    "                                hyperparams_features['embedding_dim'], \n",
    "                                input_length=hyperparams['maxlen'],\n",
    "                                embeddings_regularizer=regularizers.l2(hyperparams['l2_embeddings']),\n",
    "                                weights=[embedding_matrix], \n",
    "                                trainable=hyperparams['trainable_embeddings'],\n",
    "                               name='embeddings_layer')(\n",
    "        tokens_features)\n",
    "    embedding_layer = Dropout(hyperparams['dropout'], name='embedding_dropout')(embedding_layer)\n",
    "\n",
    "    \n",
    "    if 'lstm' not in ignore_layer:\n",
    "        if False: #tf.test.is_gpu_available():\n",
    "            lstm_layers = CuDNNLSTM(hyperparams['lstm_units'], \n",
    "                                    return_sequences='attention' not in ignore_layer, # only True if using attention\n",
    "                          name='LSTM_layer')(embedding_layer)\n",
    "        else:\n",
    "            lstm_layers = LSTM(hyperparams['lstm_units'], \n",
    "                               return_sequences='attention' not in ignore_layer,\n",
    "                          name='LSTM_layer')(embedding_layer)\n",
    "\n",
    "        # Attention\n",
    "        if 'attention' not in ignore_layer:\n",
    "            attention_layer = Dense(1, activation='tanh', name='attention')\n",
    "            attention = attention_layer(lstm_layers)\n",
    "            attention = Flatten()(attention)\n",
    "            attention_output = Activation('softmax')(attention)\n",
    "            attention = RepeatVector(hyperparams['lstm_units'])(attention_output)\n",
    "            attention = Permute([2, 1])(attention)\n",
    "\n",
    "            sent_representation = Multiply()([lstm_layers, attention])\n",
    "            sent_representation = Lambda(lambda xin: K.sum(xin, axis=1), \n",
    "                                     output_shape=(hyperparams['lstm_units'],)\n",
    "                                    )(sent_representation)\n",
    "\n",
    "#             sent_representation = Lambda(attention, \n",
    "#                                          output_shape=(hyperparams['lstm_units'],\n",
    "#                                         ))(sent_representation)\n",
    "        else:\n",
    "            sent_representation = lstm_layers\n",
    "\n",
    "    elif 'cnn' not in ignore_layer:\n",
    "        cnn_layers = Conv1D(hyperparams['filters'],\n",
    "                             hyperparams['kernel_size'],\n",
    "                             padding='valid',\n",
    "                             activation='relu',\n",
    "                             strides=1)(embedding_layer)\n",
    "        # we use max pooling:\n",
    "        sent_representation = GlobalMaxPooling1D()(cnn_layers)\n",
    "    \n",
    "    \n",
    "    if 'batchnorm' not in ignore_layer:\n",
    "        sent_representation = BatchNormalization(axis=1, momentum=hyperparams['norm_momentum'],\n",
    "                                                          name='sent_repr_norm')(sent_representation)\n",
    "    sent_representation = Dropout(hyperparams['dropout'], name='sent_repr_dropout')(sent_representation)\n",
    "\n",
    "            # Other features \n",
    "    numerical_features_history = Input(shape=(\n",
    "            hyperparams['posts_per_group'],\n",
    "            len(emotions) + 1 + len(liwc_categories)\n",
    "        ), name='numeric_input_hist') # emotions and pronouns\n",
    "    sparse_features_history = Input(shape=(\n",
    "            hyperparams['posts_per_group'],\n",
    "            len(stopwords_list)\n",
    "        ), name='sparse_input_hist') # stopwords\n",
    "\n",
    "\n",
    "\n",
    "    if activations == 'attention':\n",
    "#         sent_representation = Flatten()(attention_layer.output)\n",
    "        sent_representation = attention_output\n",
    "\n",
    "\n",
    "    posts_history_input = Input(shape=(hyperparams['posts_per_group'], \n",
    "                                     hyperparams['maxlen']\n",
    "                                          ), name='hierarchical_word_seq_input')\n",
    "\n",
    "    # Hierarchy\n",
    "    sentEncoder = Model(inputs=tokens_features, \n",
    "                        outputs=sent_representation)\n",
    "    sentEncoder.summary()\n",
    "\n",
    "    user_encoder = TimeDistributed(sentEncoder, name='user_encoder')(posts_history_input)\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    if activations != 'attention':\n",
    "        \n",
    "        \n",
    "        # BERT encoder\n",
    "        if 'bert_layer' not in hyperparams['ignore_layer']:\n",
    "            in_id_bert = Input(shape=(hyperparams['maxlen'],), name=\"input_ids_bert\")\n",
    "            in_mask_bert = Input(shape=(hyperparams['maxlen'],), name=\"input_masks_bert\")\n",
    "            in_segment_bert = Input(shape=(hyperparams['maxlen'],), name=\"segment_ids_bert\")\n",
    "            bert_inputs = [in_id_bert, in_mask_bert, in_segment_bert]\n",
    "\n",
    "            bert_output = BertLayer(n_fine_tune_layers=hyperparams['bert_finetune_layers'], \n",
    "                                    pooling=hyperparams['bert_pooling'],\n",
    "                                   trainable=hyperparams['bert_trainable'],\n",
    "                                   name='bert_layer')(bert_inputs)\n",
    "            dense_bert = Dense(hyperparams['bert_dense_units'], \n",
    "                               activation='relu',\n",
    "                              kernel_regularizer=regularizers.l2(hyperparams['l2_dense']),\n",
    "                              name='bert_dense_layer')(bert_output)\n",
    "\n",
    "            bertSentEncoder = Model(bert_inputs, dense_bert)\n",
    "\n",
    "\n",
    "            in_id_bert_history = Input(shape=(hyperparams['posts_per_group'],\n",
    "                                                              hyperparams['maxlen'],), name=\"input_ids_bert_hist\")\n",
    "            in_mask_bert_history = Input(shape=(hyperparams['posts_per_group'],\n",
    "                                                                hyperparams['maxlen'],), name=\"input_masks_bert_hist\")\n",
    "            in_segment_bert_history = Input(shape=(hyperparams['posts_per_group'],\n",
    "                                                                   hyperparams['maxlen'],), name=\"segment_ids_bert_hist\")\n",
    "            bert_inputs_history = [in_id_bert_history, in_mask_bert_history, in_segment_bert_history]\n",
    "            bert_inputs_concatenated = concatenate(bert_inputs_history)\n",
    "            inputs_indices = [hyperparams['maxlen']*i for i in range(3)]\n",
    "            # slice the input in equal slices on the last dimension\n",
    "            bert_encoder_layer = TimeDistributed(Lambda(lambda x: bertSentEncoder([x[:,inputs_indices[0]:inputs_indices[1]], \n",
    "                                                                          x[:,inputs_indices[1]:inputs_indices[2]],\n",
    "                                                                                  x[:,inputs_indices[2]:]])),\n",
    "                                                name='bert_distributed_layer')(\n",
    "                                bert_inputs_concatenated)\n",
    "            bertUserEncoder = Model(bert_inputs_history, bert_encoder_layer)\n",
    "            bertUserEncoder.summary()\n",
    "\n",
    "            bert_user_encoder = bertUserEncoder(bert_inputs_history)\n",
    "        else:\n",
    "            bert_user_encoder = None\n",
    "\n",
    "\n",
    "        dense_layer_sparse = Dense(units=hyperparams['dense_bow_units'],\n",
    "                                  name='sparse_feat_dense_layer', activation='relu',\n",
    "                                    kernel_regularizer=regularizers.l2(hyperparams['l2_dense']),\n",
    "                                  )\n",
    "        dense_layer_sparse_user = TimeDistributed(dense_layer_sparse,\n",
    "                                                 name='sparse_dense_layer_user')(sparse_features_history)\n",
    "        \n",
    "                \n",
    "        dense_layer_numerical = Dense(units=hyperparams['dense_numerical_units'],\n",
    "                                  name='numerical_feat_dense_layer', activation='relu',\n",
    "                                    kernel_regularizer=regularizers.l2(hyperparams['l2_dense']),\n",
    "                                  )\n",
    "        dense_layer_numerical_user = TimeDistributed(dense_layer_numerical,\n",
    "                                                 name='numerical_dense_layer_user')(numerical_features_history)\n",
    "\n",
    "\n",
    "        # Concatenate features\n",
    "        if 'batchnorm' not in ignore_layer:\n",
    "#             numerical_features_history_norm = BatchNormalization(axis=1, momentum=hyperparams['norm_momentum'],\n",
    "#                                                          name='numerical_features_norm')(numerical_features_history)\n",
    "            dense_layer_numerical_user = BatchNormalization(axis=1, momentum=hyperparams['norm_momentum'],\n",
    "                                                         name='numerical_features_norm')(dense_layer_numerical_user)\n",
    "            dense_layer_sparse_user = BatchNormalization(axis=1, momentum=hyperparams['norm_momentum'],\n",
    "                                                         name='sparse_features_norm')(dense_layer_sparse_user)\n",
    "        all_layers = {\n",
    "            'user_encoded': user_encoder,\n",
    "            'bert_layer': bert_user_encoder,\n",
    "#             'numerical_dense_layer': numerical_features_history if 'batchnorm' in ignore_layer \\\n",
    "#                         else numerical_features_history_norm\n",
    "            'numerical_dense_layer': dense_layer_numerical_user,\n",
    "\n",
    "            'sparse_feat_dense_layer': dense_layer_sparse_user,\n",
    "        }\n",
    "\n",
    "        layers_to_merge = [l for n,l in all_layers.items() if n not in ignore_layer]\n",
    "        if len(layers_to_merge) == 1:\n",
    "            merged_layers = layers_to_merge[0]\n",
    "        else:\n",
    "            merged_layers = concatenate(layers_to_merge)\n",
    "\n",
    "        if 'lstm_user' not in ignore_layer:\n",
    "\n",
    "            if False:#tf.test.is_gpu_available():\n",
    "                lstm_user_layers = CuDNNLSTM(hyperparams['lstm_units_user'], \n",
    "                                        return_sequences='attention_user' not in ignore_layer, # only True if using attention\n",
    "                              name='LSTM_layer_user')(merged_layers)\n",
    "            else:\n",
    "                lstm_user_layers = LSTM(hyperparams['lstm_units_user'], \n",
    "                                   return_sequences='attention_user' not in ignore_layer,\n",
    "                              name='LSTM_layer_user')(merged_layers)\n",
    "\n",
    "            # Attention\n",
    "            if 'attention_user' not in ignore_layer:\n",
    "                attention_user_layer = Dense(1, activation='tanh', name='attention_user')\n",
    "                attention_user = attention_user_layer(lstm_user_layers)\n",
    "                attention_user = Flatten()(attention_user)\n",
    "                attention_user_output = Activation('softmax')(attention_user)\n",
    "                attention_user = RepeatVector(hyperparams['lstm_units_user'])(attention_user_output)\n",
    "                attention_user = Permute([2, 1])(attention_user)\n",
    "\n",
    "                user_representation = Multiply()([lstm_user_layers, attention_user])\n",
    "                user_representation = Lambda(lambda xin: K.sum(xin, axis=1), \n",
    "                                             output_shape=(hyperparams['lstm_units_user'],))(user_representation)\n",
    "    #             user_representation = Lambda(attention, \n",
    "    #                                          output_shape=(hyperparams['lstm_units_user'],\n",
    "    #                                         ))(user_representation)\n",
    "            else:\n",
    "                user_representation = lstm_user_layers\n",
    "\n",
    "\n",
    "        elif 'cnn_user' not in ignore_layer:\n",
    "            cnn_layers_user = Conv1D(hyperparams['filters_user'],\n",
    "                                 hyperparams['kernel_size_user'],\n",
    "                                 padding='valid',\n",
    "                                 activation='relu',\n",
    "                                 strides=1)(merged_layers)\n",
    "            # we use max pooling:\n",
    "            user_representation = GlobalMaxPooling1D()(cnn_layers_user)\n",
    "    #         user_representation = Flatten()(user_representation)\n",
    "\n",
    "\n",
    "        user_representation = Dropout(hyperparams['dropout'], name='user_repr_dropout')(user_representation)\n",
    "\n",
    "\n",
    "        if hyperparams['dense_user_units']:\n",
    "            user_representation = Dense(units=hyperparams['dense_user_units'], activation='relu',\n",
    "                                       name='dense_user_representation')(user_representation)\n",
    "\n",
    "        output_layer = Dense(classes, activation='sigmoid' if classes==1 else 'softmax',\n",
    "                             name='output_layer',\n",
    "                            kernel_regularizer=regularizers.l2(hyperparams['l2_dense']),\n",
    "                             input_shape=(hyperparams['lstm_units_user'],),\n",
    "                            )(user_representation)\n",
    "\n",
    "    # Compile model\n",
    "\n",
    "#     elif activations == 'attention':\n",
    "#         outputs = attention_layer.output\n",
    "    if activations == 'attention':\n",
    "        outputs = user_encoder\n",
    "\n",
    "        \n",
    "    elif activations == 'attention_user':\n",
    "#         outputs = attention_user.output\n",
    "        outputs = attention_user_output\n",
    "    elif activations == 'output_layer':\n",
    "        outputs = user_representation\n",
    "\n",
    "    \n",
    "    else:\n",
    "        outputs = output_layer\n",
    "    if 'bert_layer' not in hyperparams['ignore_layer']:\n",
    "\n",
    "        hierarchical_model = Model(inputs=[posts_history_input, \n",
    "                                       numerical_features_history, sparse_features_history,\n",
    "                                      in_id_bert_history, in_mask_bert_history, in_segment_bert_history], \n",
    "                  outputs=outputs)\n",
    "    else:\n",
    "        hierarchical_model = Model(inputs=[posts_history_input, \n",
    "                                       numerical_features_history, sparse_features_history,\n",
    "                                      ], \n",
    "                  outputs=outputs)\n",
    "    hierarchical_model.summary()\n",
    "    \n",
    "    if classes==1:\n",
    "        metrics_class = Metrics(threshold=hyperparams['threshold'])\n",
    "        hierarchical_model.compile(hyperparams['optimizer'], binary_crossentropy_custom,\n",
    "                      metrics=[metrics_class.f1_m, metrics_class.precision_m, metrics_class.recall_m,\n",
    "                              metrics_class.auc])\n",
    "    else:\n",
    "        \n",
    "        hierarchical_model.compile(hyperparams['optimizer'], K.categorical_crossentropy,\n",
    "                     metrics=[ tf.keras.metrics.CategoricalAccuracy(name='cat_acc'),\n",
    "#                              tf.keras.metrics.Precision(name='prec'), tf.keras.metrics.Recall(name='rec'), \n",
    "                              ])\n",
    "    return hierarchical_model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def build_tl_model(pretrained_model, hyperparams, units=100,  emotions=emotions, stopwords_list=stopword_list,\n",
    "#                 liwc_categories=liwc_categories):\n",
    "#     tokens_features = Input(shape=(hyperparams['maxlen'],), name='word_seq_tl')\n",
    "#     numerical_features = Input(shape=(len(emotions) + 1 + len(liwc_categories),), name='numeric_input_tl') # emotions and pronouns\n",
    "#     sparse_features = Input(shape=(len(stopwords_list),), name='sparse_input_tl') # stopwords\n",
    "#     pretrained_model.summary()\n",
    "#     print(\"inputs\", tokens_features, numerical_features, sparse_features)\n",
    "#     pretrained_output = pretrained_model(inputs=[tokens_features, numerical_features, sparse_features])\n",
    "#     # TODO: set trainable to false\n",
    "#     tl_layer = Dense(units=units, activation='relu',\n",
    "#                                    name='tl_layer', trainable=False,\n",
    "#                         kernel_regularizer=regularizers.l2(hyperparams['l2_dense'])\n",
    "#                     )(pretrained_output)\n",
    "#     output_layer = Dense(1, activation='sigmoid',\n",
    "#                          name='tl_output_layer',\n",
    "#                         kernel_regularizer=regularizers.l2(hyperparams['l2_dense'])\n",
    "#                         )(tl_layer)\n",
    "# #     pretrained_model.outputs = output_layer ## I DUNNO\n",
    "#     tl_model = Model(inputs=[tokens_features, numerical_features, sparse_features], \n",
    "#           outputs=output_layer)\n",
    "#     metrics_class = Metrics(threshold=hyperparams['threshold'])\n",
    "#     tl_model.compile(hyperparams['optimizer'], binary_crossentropy_custom,\n",
    "#                   metrics=[metrics_class.f1_m, metrics_class.precision_m, metrics_class.recall_m,\n",
    "#                           metrics_class.auc, \n",
    "#                            tf.keras.metrics.AUC(name=\"AUC_keras\"), \n",
    "#                            tf.keras.metrics.FalsePositives(), \n",
    "#                            tf.keras.metrics.FalseNegatives()])\n",
    "\n",
    "#     return tl_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = build_model(hyperparams, hyperparams_features, embedding_matrix, emotions, stopword_list,\n",
    "#                     liwc_categories=[c for c in categories if c in writings_df.columns]\n",
    "# ,\n",
    "#                    ignore_layer=hyperparams['ignore_layer'])\n",
    "# model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hierarchical_model = build_hierarchical_model(hyperparams, hyperparams_features, embedding_matrix, emotions, stopword_list,\n",
    "#                     liwc_categories=[c for c in categories if c in writings_df.columns]\n",
    "# ,\n",
    "#                    ignore_layer=hyperparams['ignore_layer'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot_model(model, 'models/sequential_bert_model.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize_vars(sess)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WeightsHistory(callbacks.Callback):\n",
    "    def __init__(self, logs={}):\n",
    "        super(WeightsHistory, self).__init__()\n",
    "    def on_train_begin(self, logs={}):\n",
    "        self.log_weights(0)\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        if epoch % 10 == 0:\n",
    "            self.log_weights(epoch)\n",
    "    def log_weights(self, step):\n",
    "        for layer in self.model.layers:\n",
    "            try:\n",
    "                experiment.log_histogram_3d(layer.get_weights()[0], \n",
    "                                            name=layer.name + \"_weight\", step=step)\n",
    "            except Exception as e:\n",
    "#                 logger.debug(\"Logging weights error: \" + layer.name + \"; \" + str(e) + \"\\n\")\n",
    "                # Layer probably does not exist\n",
    "                pass\n",
    "\n",
    "class OutputsHistory(callbacks.Callback):\n",
    "    def __init__(self, logs={}, generator=None, generator_type=\"\"):\n",
    "        super(OutputsHistory, self).__init__()\n",
    "        self.generator_type = generator_type\n",
    "        if generator:\n",
    "            self.generator = generator\n",
    "        elif generator_type:\n",
    "            self.generator = DataGenerator(user_level_data, subjects_split, \n",
    "                                     set_type=generator_type, \n",
    "                                   hierarchical=hyperparams['hierarchical'],\n",
    "                                seq_len=hyperparams['maxlen'], batch_size=hyperparams['batch_size'],\n",
    "                                     max_posts_per_user=None,\n",
    "                                   pad_with_duplication=False,\n",
    "                                    posts_per_group=hyperparams['posts_per_group'],\n",
    "                                    post_groups_per_user=None, \n",
    "                                           liwc_words_for_categories=liwc_words_for_categories,\n",
    "                                           compute_liwc=True,\n",
    "                                         emotions=emotions, liwc_categories=liwc_categories,\n",
    "                                     sample_seqs=False, shuffle=False)\n",
    "    def on_train_begin(self, logs={}):\n",
    "        self.log_outputs(0)\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        if epoch % 2 == 0:\n",
    "            self.log_outputs(epoch)\n",
    "    def log_outputs(self, step):\n",
    "        try:\n",
    "            experiment.log_histogram_3d(self.model.predict(self.generator,  verbose=1, steps=2),\n",
    "                                        name='output_%s' % self.generator_type, step=step)\n",
    "        except Exception as e:\n",
    "            logger.debug(\"Logging outputs error: \" + str(e) + \"\\n\")\n",
    "#                 Layer probably does not exist\n",
    "            pass\n",
    "\n",
    "class ActivationsAttention(callbacks.Callback):\n",
    "    def __init__(self, logs={}, generator=None, generator_type=\"\"):\n",
    "        super(ActivationsAttention, self).__init__()\n",
    "        self.generator_type = generator_type\n",
    "        if generator:\n",
    "            self.generator = generator\n",
    "        elif generator_type:\n",
    "            self.generator = DataGenerator(user_level_data, subjects_split, \n",
    "                                     set_type=generator_type, \n",
    "                                   hierarchical=hyperparams['hierarchical'],\n",
    "                                seq_len=hyperparams['maxlen'], batch_size=hyperparams['batch_size'],\n",
    "                                     max_posts_per_user=None,\n",
    "                                   pad_with_duplication=False,\n",
    "                                    posts_per_group=hyperparams['posts_per_group'],\n",
    "                                    post_groups_per_user=None, \n",
    "                                     sample_seqs=False, shuffle=False)\n",
    "    def on_train_begin(self, logs={}):\n",
    "        self.log_outputs(0)\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        if epoch % 10 == 0:\n",
    "            self.log_outputs(epoch)\n",
    "    def log_outputs(self, step):\n",
    "        try:\n",
    "            experiment.log_histogram_3d(self.model.get_layer('attention_user').output.eval())\n",
    "        except Exception as e:\n",
    "            logger.debug(\"Logging activations error: \" + str(e) + \"\\n\")\n",
    "            pass\n",
    "\n",
    "class LRHistory(callbacks.Callback):\n",
    "    def __init__(self, logs={}):\n",
    "        super(LRHistory, self).__init__()\n",
    "    \n",
    "    def on_epoch_begin(self, epoch, logs={}):\n",
    "        self.log_lr()\n",
    "        \n",
    "    def log_lr(self):\n",
    "        lr = K.eval(self.model.optimizer.lr)\n",
    "        logger.debug(\"Learning rate is %f...\\n\" % lr)\n",
    "        experiment.log_parameter('lr', lr)\n",
    "\n",
    "class FreezeLayer(callbacks.Callback):\n",
    "    def __init__(self, logs={}, patience=5, layer={'user_encoder':'embeddings_layer'}, verbose=1, set_to=False):\n",
    "        super(FreezeLayer, self).__init__()\n",
    "        self.freeze_epoch = patience\n",
    "        self.freeze_layer = layer\n",
    "        self.verbose = verbose\n",
    "        self.set_to = set_to\n",
    "\n",
    "    def on_epoch_begin(self, epoch, logs={}):\n",
    "        if type(self.freeze_layer)==dict:\n",
    "            submodel = self.model.get_layer(list(self.freeze_layer.keys())[0])\n",
    "        else:\n",
    "            submodel = self.model\n",
    "        logging.debug(\"Trainable embeddings\", submodel.get_layer(self.freeze_layer).trainable)\n",
    "        if epoch == self.freeze_epoch:\n",
    "            try:\n",
    "                layer = submodel.get_layer(self.freeze_layer)\n",
    "                old_value = layer.trainable\n",
    "                layer.trainable = self.set_to\n",
    "                # TODO: does this reset the optimizer? should I also compile the top-level model?\n",
    "                self.model.compile(hyperparams['optimizer'], binary_crossentropy_custom,\n",
    "                  metrics=[metrics_class.f1_m, metrics_class.precision_m, metrics_class.recall_m])\n",
    "                if self.verbose:\n",
    "                    logging.debug(\"Setting %s layer from %s to trainable=%s...\\n\" % (layer.name, old_value,\n",
    "                                                                   submodel.get_layer(self.freeze_layer).trainable))\n",
    "            except Exception as e:\n",
    "                # layer probably does not exist\n",
    "                pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, hyperparams,\n",
    "                data_generator_train, data_generator_valid,\n",
    "                epochs, class_weight, start_epoch=0, workers=4,\n",
    "                callback_list = [],\n",
    "                \n",
    "                model_path='/tmp/model',\n",
    "                validation_set='valid',\n",
    "               verbose=1):\n",
    "    \n",
    "    logger.info(\"Initializing callbacks...\\n\")\n",
    "    # Initialize callbacks\n",
    "    freeze_layer = FreezeLayer(patience=hyperparams['freeze_patience'], set_to=not hyperparams['trainable_embeddings'])\n",
    "    weights_history = WeightsHistory()\n",
    "    outputs_history_valid = OutputsHistory(generator_type=validation_set)\n",
    "    outputs_history_train = OutputsHistory(generator_type='train')\n",
    "    activations_history_train = ActivationsAttention(generator_type='train')\n",
    "    lr_history = LRHistory()\n",
    "\n",
    "    reduce_lr = callbacks.ReduceLROnPlateau(monitor='val_loss', factor=hyperparams['reduce_lr_factor'],\n",
    "                              patience=hyperparams['reduce_lr_patience'], min_lr=0.000001, verbose=1)\n",
    "    lr_schedule = callbacks.LearningRateScheduler(lambda epoch, lr: \n",
    "                                                  lr if (epoch+1)%hyperparams['scheduled_reduce_lr_freq']!=0 else\n",
    "                                                  lr*hyperparams['scheduled_reduce_lr_factor'], verbose=1)\n",
    "    callbacks_dict = {'freeze_layer': freeze_layer, 'weights_history': weights_history,\n",
    "           'outputs_history_valid': outputs_history_valid, 'outputs_history_train': outputs_history_train,\n",
    "           'lr_history': lr_history,\n",
    "            'activations': activations_history_train,\n",
    "           'reduce_lr_plateau': reduce_lr,\n",
    "            'lr_schedule': lr_schedule}\n",
    "\n",
    "    \n",
    "    logging.info('Train...')\n",
    "\n",
    "\n",
    "    history = model.fit_generator(data_generator_train,\n",
    "                steps_per_epoch=100,\n",
    "              epochs=epochs, initial_epoch=start_epoch, \n",
    "              class_weight=class_weight,\n",
    "              validation_data=data_generator_valid,\n",
    "                        verbose=verbose,\n",
    "#               validation_split=0.3,\n",
    "                       workers=workers,\n",
    "            callbacks = [\n",
    "                callbacks.ModelCheckpoint(filepath='%s_best.h5' % model_path, verbose=1, \n",
    "                                          save_best_only=True, save_weights_only=True),\n",
    "#                 callbacks.EarlyStopping(patience=hyperparams['early_stopping_patience'],\n",
    "#                                        restore_best_weights=True)\n",
    "            ] + [\n",
    "                callbacks_dict[c] for c in [\n",
    "#                     'weights_history', \n",
    "                    'outputs_history_valid', \n",
    "#                     'outputs_history_train', \n",
    "#                     'reduce_lr_plateau', \n",
    "#                     'lr_schedule', \n",
    "#                     'activations'\n",
    "                ]])\n",
    "    return model, history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_network_type(hyperparams):\n",
    "    if 'lstm' in hyperparams['ignore_layer']:\n",
    "        network_type = 'cnn'\n",
    "    else:\n",
    "        network_type = 'lstm'\n",
    "    if 'user_encoded' in hyperparams['ignore_layer']:\n",
    "        if 'bert_layer' not in hyperparams['ignore_layer']:\n",
    "            network_type = 'bert'\n",
    "        else:\n",
    "            network_type = 'extfeatures'\n",
    "    if hyperparams['hierarchical']:\n",
    "        hierarch_type = 'hierarchical'\n",
    "    else:\n",
    "        hierarch_type = 'seq'\n",
    "    return network_type, hierarch_type\n",
    "\n",
    "def initialize_experiment(hyperparams, nrc_lexicon_path, emotions, pretrained_embeddings_path, \n",
    "                          dataset_type, transfer_type):\n",
    "\n",
    "    experiment = Experiment(api_key=\"eoBdVyznAhfg3bK9pZ58ZSXfv\",\n",
    "                            project_name=\"mental\", workspace=\"ananana\", disabled=False)\n",
    "\n",
    "    experiment.log_parameters(hyperparams_features)\n",
    "\n",
    "    experiment.log_parameter('emotion_lexicon', nrc_lexicon_path)\n",
    "    experiment.log_parameter('emotions', emotions)\n",
    "    experiment.log_parameter('embeddings_path', pretrained_embeddings_path)\n",
    "    experiment.log_parameter('dataset_type', dataset_type)\n",
    "    experiment.log_parameter('transfer_type', transfer_type)\n",
    "    experiment.add_tag(dataset_type)\n",
    "    experiment.log_parameters(hyperparams)\n",
    "    network_type, hierarch_type = get_network_type(hyperparams)\n",
    "    experiment.add_tag(network_type)\n",
    "    experiment.add_tag(hierarch_type)\n",
    "    \n",
    "    return experiment\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_datasets(user_level_data, subjects_split, hyperparams, hyperparams_features, \n",
    "                        validation_set, emotions, liwc_categories, session=None, classes=1):\n",
    "    liwc_words_for_categories = pickle.load(open(hyperparams_features['liwc_words_cached'], 'rb'))\n",
    "    if classes!=1 and 'class_weights' in hyperparams:\n",
    "        class_weights = hyperparams['class_weights']\n",
    "    else:\n",
    "        class_weights = None\n",
    "    data_generator_train = DataGenerator(user_level_data, subjects_split, set_type='train',\n",
    "                                        seq_len=hyperparams['maxlen'], batch_size=hyperparams['batch_size'],\n",
    "                                        sample_seqs=hyperparams['sample_seqs'], sampling_distr=hyperparams['sampling_distr'],\n",
    "                                        posts_per_group=hyperparams['posts_per_group'], post_groups_per_user=hyperparams['post_groups_per_user'],\n",
    "                                        max_posts_per_user=hyperparams['posts_per_user'], \n",
    "                                         hierarchical=hyperparams['hierarchical'], \n",
    "                                         use_bert='bert_layer' not in hyperparams['ignore_layer'],\n",
    "                                         compute_liwc=True, liwc_words_for_categories=liwc_words_for_categories,\n",
    "                                         emotions=emotions, liwc_categories=liwc_categories,\n",
    "                                        session=session, classes=classes, class_weights=class_weights)\n",
    "    data_generator_valid = DataGenerator(user_level_data, subjects_split, set_type=validation_set,\n",
    "                                        seq_len=hyperparams['maxlen'], batch_size=hyperparams['batch_size'],\n",
    "                                        posts_per_group=hyperparams['posts_per_group'], \n",
    "                                         post_groups_per_user=1,#hyperparams['post_groups_per_user'],\n",
    "                                        max_posts_per_user=None, \n",
    "                                        sample_seqs=False, shuffle=False, hierarchical=hyperparams['hierarchical'],\n",
    "                                         use_bert='bert_layer' not in hyperparams['ignore_layer'],\n",
    "                                         compute_liwc=True, liwc_words_for_categories=liwc_words_for_categories,\n",
    "                                        emotions=emotions, liwc_categories=liwc_categories,\n",
    "                                        session=session, classes=classes)\n",
    "\n",
    "    return data_generator_train, data_generator_valid\n",
    "\n",
    "def initialize_model(hyperparams, hyperparams_features, embedding_matrix, emotions, stopword_list,\n",
    "                    liwc_categories, session=None, transfer=False, classes=1):\n",
    "\n",
    "    logger.info(\"Initializing model...\\n\")\n",
    "    # Initialize model\n",
    "    if hyperparams['hierarchical']:\n",
    "        model = build_hierarchical_model(hyperparams, hyperparams_features, embedding_matrix, \n",
    "                                         emotions, stopword_list, liwc_categories,\n",
    "                       ignore_layer=hyperparams['ignore_layer'], classes=classes)\n",
    "    else:\n",
    "        model = build_model(hyperparams, hyperparams_features, embedding_matrix, \n",
    "                                        emotions, stopword_list, liwc_categories,\n",
    "                       ignore_layer=hyperparams['ignore_layer'], classes=classes)\n",
    "    if transfer:\n",
    "        model = build_tl_model(hyperparams, hyperparams_features, embedding_matrix, \n",
    "                                        emotions, stopword_list, liwc_categories,\n",
    "                       ignore_layer=hyperparams['ignore_layer'])\n",
    "        model.load_weights(hyperparams_features['pretrained_model_path'] + '_weights.h5', by_name=True)\n",
    "    # Needed just for bert\n",
    "    if 'bert_layer' not in hyperparams['ignore_layer']:\n",
    "        initialize_sess(session)                  \n",
    "    model.summary()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(user_level_data, subjects_split, \n",
    "          hyperparams, hyperparams_features, \n",
    "          embedding_matrix, emotions, stopword_list, liwc_categories,\n",
    "          experiment, validation_set='valid',\n",
    "          version=0, epochs=50, start_epoch=0,\n",
    "         session=None, model=None, transfer_layer=False,\n",
    "         classes=1):\n",
    "    network_type, hierarch_type = get_network_type(hyperparams)\n",
    "    for feature in ['LIWC', 'emotions', 'numerical_dense_layer', 'sparse_feat_dense_layer', 'user_encoded']:\n",
    "        if feature in hyperparams['ignore_layer']:\n",
    "            network_type += \"no%s\" % feature\n",
    "    if not transfer_layer:\n",
    "        model_path='models/%s_%s_%s%d' % (network_type, dataset_type, hierarch_type, version)\n",
    "    else:\n",
    "        model_path='models/%s_%s_%s_transfer_%s%d' % (network_type, dataset_type, hierarch_type, transfer_type, version)\n",
    "        \n",
    "    \n",
    "    # Ablate emotions or LIWC\n",
    "    if 'emotions' in hyperparams['ignore_layer']:\n",
    "        emotions = []\n",
    "    if 'LIWC' in hyperparams['ignore_layer']:\n",
    "        liwc_categories = []\n",
    "\n",
    "    logger.info(\"Initializing datasets...\\n\")\n",
    "    data_generator_train, data_generator_valid = initialize_datasets(user_level_data, subjects_split, \n",
    "                                                                     hyperparams,hyperparams_features,\n",
    "                                                                     validation_set=validation_set,\n",
    "                                                                     emotions=emotions, liwc_categories=liwc_categories, \n",
    "                                                                    session=session, classes=classes)\n",
    "    if not model:\n",
    "        if transfer_layer:\n",
    "            logger.info(\"Initializing pretrained model...\\n\")\n",
    "        else:\n",
    "            logger.info(\"Initializing model...\\n\")\n",
    "        model = initialize_model(hyperparams, hyperparams_features, embedding_matrix, \n",
    "                                 emotions, stopword_list, liwc_categories, session=session, transfer=transfer_layer,\n",
    "                                classes=classes)\n",
    "\n",
    "       \n",
    "    print(model_path)\n",
    "    logger.info(\"Training model...\\n\")\n",
    "    model, history = train_model(model, hyperparams,\n",
    "                                 data_generator_train, data_generator_valid,\n",
    "                       epochs=epochs, start_epoch=start_epoch,\n",
    "                      class_weight={0:1, 1:hyperparams['positive_class_weight']} if classes==1 else None,\n",
    "                      callback_list = [\n",
    "                          'weights_history',\n",
    "                          'lr_history',\n",
    "                          'outputs_history_valid',\n",
    "                          'outputs_history_train',\n",
    "                          'reduce_lr_plateau',\n",
    "                          'lr_schedule'\n",
    "                                      ],\n",
    "                      model_path=model_path, workers=4,\n",
    "                                validation_set=validation_set)\n",
    "    logger.info(\"Saving model...\\n\")\n",
    "    try:\n",
    "        save_model_and_params(model, model_path, hyperparams, hyperparams_features)\n",
    "        experiment.log_parameter(\"model_path\", model_path)\n",
    "    except:\n",
    "        logger.error(\"Could not save model.\\n\")\n",
    "\n",
    "    return model, history\n",
    "# except Exception as e:# tf.errors.ResourceExhaustedError:\n",
    "#     print(e)\n",
    "#     sess.close()\n",
    "#     sess = tf.Session(config=sess_config)\n",
    "#     initialize_vars(sess)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "key = 'lstm_seq'\n",
    "# # non-duplicate key\n",
    "# while key in models_collection.keys():\n",
    "#     key=key + \"1\"\n",
    "# # models_collection[key] = cur_model\n",
    "# # session.close()\n",
    "# session = initialize_sess()\n",
    "# # all_sessions.append(session)\n",
    "# session_collection[key] = session\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_collection = {}\n",
    "hyperparams_collection = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "64"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(liwc_categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "# writings_df.groupby('source').subject.nunique()\n",
    "# Counter(writings_df.label.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparams = {\n",
    "    # Network parmeters\n",
    "    \n",
    "    # Sequential + hierarchical layers\n",
    "    'trainable_embeddings': True,\n",
    "\n",
    "    'lstm_units': 128,\n",
    "#     'lstm_units': 256,\n",
    "    \n",
    "    'dense_bow_units': 20,\n",
    "    'dense_sentence_units': 0,\n",
    "    'dense_numerical_units': 20,\n",
    "\n",
    "    \n",
    "    # CNN\n",
    "    'filters': 100,\n",
    "    'kernel_size': 5,\n",
    "    \n",
    "    # Just hierarchical layers\n",
    "    'lstm_units_user': 32,\n",
    "    'dense_user_units': 0,\n",
    "    \n",
    "    'filters_user': 10,\n",
    "    'kernel_size_user': 3,\n",
    "        \n",
    "    # BERT layers\n",
    "    'bert_dense_units': 256,\n",
    "    'bert_finetune_layers': 0,\n",
    "    'bert_trainable': False ,\n",
    "    'bert_pooling': 'first', # mean, first\n",
    "    \n",
    "    'transfer_units': 20,\n",
    "\n",
    "    # Regularization etc\n",
    "    'dropout': 0.1,\n",
    "#     'dropout': 0,\n",
    "    'l2_dense': 0.00011,\n",
    "    'l2_embeddings': 0.0000001,\n",
    "    'l2_bert': 0.0001,\n",
    "    'norm_momentum': 0.1,\n",
    "    \n",
    "    'ignore_layer': [\n",
    "#         'lstm', 'attention', \n",
    "#         'cnn',\n",
    "#         'user_encoded',\n",
    "#         'lstm_user', 'attention_user', \n",
    "#                      'batchnorm',\n",
    "#                      'user_encoded', # remove LSTM/CNN\n",
    "                     'bert_layer',\n",
    "#                      'numerical_dense_layer', \n",
    "#         'sparse_feat_dense_layer', # remove extracted features\n",
    "#         'LIWC',\n",
    "#         'emotions'\n",
    "                    ],\n",
    "\n",
    "    # Learning parameters\n",
    "    'optimizer': None, #'adam',\n",
    "    'decay': 0.001,\n",
    "    'lr': 0.00005,\n",
    "#     'lr': 0.00005,#     'lr': 0.01,\n",
    "#     'lr': 0.00001,#     'lr': 0.01,\n",
    "#     'lr': 0.0001,\n",
    "    \"reduce_lr_factor\": 0.5,\n",
    "    \"reduce_lr_patience\": 55,\n",
    "    'scheduled_reduce_lr_freq': 95,\n",
    "    'scheduled_reduce_lr_factor': 0.5,\n",
    "    \"freeze_patience\": 2000,\n",
    "    'threshold': 0.5,\n",
    "    'early_stopping_patience': 5,\n",
    "    'positive_class_weight': 1,\n",
    "    # set this to None for uniform class sampling (only applies to multiclass setting)\n",
    "    'class_weights': {0:1304, 1:1287, 2:763},\n",
    "#     'positive_class_weight': 2,\n",
    "    \n",
    "    # Generator parameters\n",
    "    \n",
    "    # Note: average text length in eRisk: 300\n",
    "    #       average text length in CLPsych: 13\n",
    "#     \"maxlen\": 512,\n",
    "#     \"maxlen\": 128,\n",
    "#     \"maxlen\": 512,\n",
    "    \"maxlen\": 256,\n",
    "    \"posts_per_user\": None, # if you want to limit total nr of posts considered per user\n",
    "    \"post_groups_per_user\": None, # if you want a fixed number of post groups per user\n",
    "                                  # to even out user weights\n",
    "    \"posts_per_group\": 50, # how long are the \"batches\" of posts. maxlen/avglen~=posts_per_group\n",
    "    \"batch_size\": 32,\n",
    "    \"padding\": \"pre\",\n",
    "    \"hierarchical\": True,\n",
    "    'sample_seqs': False,\n",
    "    'sampling_distr': 'exp',\n",
    "\n",
    "}\n",
    "if not hyperparams['optimizer']:\n",
    "    hyperparams['optimizer'] = optimizers.Adam(lr=hyperparams['lr'], #beta_1=0.9, beta_2=0.999, epsilon=0.0001,\n",
    "                                   decay=hyperparams['decay'])\n",
    "    \n",
    "if transfer_type:\n",
    "#     hyperparams, _ = load_params(hyperparams_features['pretrained_model_path'])\n",
    "    if 'optimizer' not in hyperparams:\n",
    "        hyperparams['optimizer'] = optimizers.Adam(lr=hyperparams['lr'], #beta_1=0.9, beta_2=0.999, epsilon=0.0001,\n",
    "                                       decay=hyperparams['decay'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparams_collection[key] = hyperparams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'symanto'"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# session_collection['cnn_hierarch'].close()\n",
    "# K.clear_session()\n",
    "# transfer_type=None\n",
    "dataset_type\n",
    "# transfer_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.optimizer_v2.adam.Adam at 0x7feb8458a6d0>"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hyperparams['optimizer']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "COMET INFO: ---------------------------\n",
      "COMET INFO: Comet.ml Experiment Summary\n",
      "COMET INFO: ---------------------------\n",
      "COMET INFO:   Data:\n",
      "COMET INFO:     display_summary_level : 1\n",
      "COMET INFO:     url                   : https://www.comet.ml/ananana/mental/49b7cb9835ab435ba96a0962c6833ef8\n",
      "COMET INFO:   Others:\n",
      "COMET INFO:     trainable_params : 6252203\n",
      "COMET INFO:   Parameters:\n",
      "COMET INFO:     Adam_amsgrad               : 1\n",
      "COMET INFO:     Adam_beta_1                : 0.9\n",
      "COMET INFO:     Adam_beta_2                : 0.999\n",
      "COMET INFO:     Adam_decay                 : 0.001\n",
      "COMET INFO:     Adam_epsilon               : 1e-07\n",
      "COMET INFO:     Adam_learning_rate         : 5e-05\n",
      "COMET INFO:     Adam_name                  : Adam\n",
      "COMET INFO:     Optimizer                  : Adam\n",
      "COMET INFO:     batch_size                 : 32\n",
      "COMET INFO:     bert_dense_units           : 256\n",
      "COMET INFO:     bert_finetune_layers       : 1\n",
      "COMET INFO:     bert_pooling               : first\n",
      "COMET INFO:     bert_trainable             : 1\n",
      "COMET INFO:     class_weights              : {\"0\": 1304, \"1\": 1287, \"2\": 763}\n",
      "COMET INFO:     dataset_type               : symanto\n",
      "COMET INFO:     decay                      : 0.001\n",
      "COMET INFO:     dense_bow_units            : 20\n",
      "COMET INFO:     dense_numerical_units      : 20\n",
      "COMET INFO:     dense_sentence_units       : 1\n",
      "COMET INFO:     dense_user_units           : 1\n",
      "COMET INFO:     dropout                    : 0.1\n",
      "COMET INFO:     early_stopping_patience    : 5\n",
      "COMET INFO:     embedding_dim              : 300\n",
      "COMET INFO:     embeddings_path            : ../resources/glove.840B/glove.840B.300d.txt\n",
      "COMET INFO:     emotion_lexicon            : ../resources/NRC-Emotion-Lexicon-Wordlevel-v0.92.txt\n",
      "COMET INFO:     emotions                   : ['anger', 'anticipation', 'disgust', 'fear', 'joy', 'negative', 'positive', 'sadness', 'surprise', 'trust']\n",
      "COMET INFO:     epochs                     : 25\n",
      "COMET INFO:     filters                    : 100\n",
      "COMET INFO:     filters_user               : 10\n",
      "COMET INFO:     freeze_patience            : 2000\n",
      "COMET INFO:     hierarchical               : True\n",
      "COMET INFO:     ignore_layer               : ['bert_layer']\n",
      "COMET INFO:     kernel_size                : 5\n",
      "COMET INFO:     kernel_size_user           : 3\n",
      "COMET INFO:     l2_bert                    : 0.0001\n",
      "COMET INFO:     l2_dense                   : 0.00011\n",
      "COMET INFO:     l2_embeddings              : 1e-07\n",
      "COMET INFO:     liwc_words_cached          : ../data/liwc_categories_for_vocabulary_erisk_clpsych_stop_20K.pkl\n",
      "COMET INFO:     lr                         : 5e-05\n",
      "COMET INFO:     lstm_units                 : 128\n",
      "COMET INFO:     lstm_units_user            : 32\n",
      "COMET INFO:     max_features               : 20002\n",
      "COMET INFO:     maxlen                     : 256\n",
      "COMET INFO:     norm_momentum              : 0.1\n",
      "COMET INFO:     optimizer                  : <tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x7feb9a5a8490>\n",
      "COMET INFO:     padding                    : pre\n",
      "COMET INFO:     positive_class_weight      : 1\n",
      "COMET INFO:     post_groups_per_user       : 1\n",
      "COMET INFO:     posts_per_group            : 50\n",
      "COMET INFO:     posts_per_user             : 1\n",
      "COMET INFO:     pretrained_model_path      : models/lstm_symanto_hierarchical64\n",
      "COMET INFO:     reduce_lr_factor           : 0.5\n",
      "COMET INFO:     reduce_lr_patience         : 55\n",
      "COMET INFO:     sample_seqs                : 1\n",
      "COMET INFO:     sampling_distr             : exp\n",
      "COMET INFO:     scheduled_reduce_lr_factor : 0.5\n",
      "COMET INFO:     scheduled_reduce_lr_freq   : 95\n",
      "COMET INFO:     steps                      : 100\n",
      "COMET INFO:     threshold                  : 0.5\n",
      "COMET INFO:     trainable_embeddings       : True\n",
      "COMET INFO:     transfer                   : 1\n",
      "COMET INFO:     transfer_type              : 1\n",
      "COMET INFO:     transfer_units             : 20\n",
      "COMET INFO:     user_level                 : True\n",
      "COMET INFO:     vocabulary_path            : ../data/all_vocab_clpsych_erisk_stop_20000.pkl\n",
      "COMET INFO:   Uploads:\n",
      "COMET INFO:     environment details      : 1\n",
      "COMET INFO:     filename                 : 1\n",
      "COMET INFO:     git metadata             : 1\n",
      "COMET INFO:     git-patch (uncompressed) : 1 (146 KB)\n",
      "COMET INFO:     histogram3d              : 1\n",
      "COMET INFO:     installed packages       : 1\n",
      "COMET INFO:     model graph              : 1\n",
      "COMET INFO:     os packages              : 1\n",
      "COMET INFO: ---------------------------\n",
      "COMET WARNING: As you are running in a Jupyter environment, you will need to call `experiment.end()` when finished to ensure all metrics and code are logged before exiting.\n",
      "COMET INFO: Experiment is live on comet.ml https://www.comet.ml/ananana/mental/2e40aee3bdf54f6caabac7145648cf75\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-11-29 17:19:40,237;INFO;Initializing datasets...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:training:Initializing datasets...\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-11-29 17:19:40,249;WARNING;User Sbee6icreated_at-664370083.json has no posts in train set. Ignoring.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:training:User Sbee6icreated_at-664370083.json has no posts in train set. Ignoring.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-11-29 17:19:40,252;WARNING;User oSPW7CE3HXKsf4icreated_at309684088.json has no posts in train set. Ignoring.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:training:User oSPW7CE3HXKsf4icreated_at309684088.json has no posts in train set. Ignoring.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-11-29 17:19:40,254;WARNING;User pun1i_created_at-77564069.json has no posts in train set. Ignoring.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:training:User pun1i_created_at-77564069.json has no posts in train set. Ignoring.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-11-29 17:19:40,255;WARNING;User r7oooba25created_at110126231.json has no posts in train set. Ignoring.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:training:User r7oooba25created_at110126231.json has no posts in train set. Ignoring.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-11-29 17:19:40,257;WARNING;User xr_zhcreated_at274446519.json has no posts in train set. Ignoring.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:training:User xr_zhcreated_at274446519.json has no posts in train set. Ignoring.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-11-29 17:19:40,259;WARNING;User 3PXKJMBxLl7NVrIcreated_at-312359495.json has no posts in valid set. Ignoring.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:training:User 3PXKJMBxLl7NVrIcreated_at-312359495.json has no posts in valid set. Ignoring.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-11-29 17:19:40,261;WARNING;User 7iqs7uI3T3MwBflcreated_at110126231.json has no posts in valid set. Ignoring.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:training:User 7iqs7uI3T3MwBflcreated_at110126231.json has no posts in valid set. Ignoring.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-11-29 17:19:40,262;WARNING;User A3qKlV8I5O4bKOzcreated_at-793452802.json has no posts in valid set. Ignoring.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:training:User A3qKlV8I5O4bKOzcreated_at-793452802.json has no posts in valid set. Ignoring.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-11-29 17:19:40,263;WARNING;User EliThePotatocreated_at732169814.json has no posts in valid set. Ignoring.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:training:User EliThePotatocreated_at732169814.json has no posts in valid set. Ignoring.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-11-29 17:19:40,265;WARNING;User I5Pmucreated_at696932245.json has no posts in valid set. Ignoring.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:training:User I5Pmucreated_at696932245.json has no posts in valid set. Ignoring.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-11-29 17:19:40,266;INFO;Initializing model...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:training:Initializing model...\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-11-29 17:19:40,267;INFO;Initializing model...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:training:Initializing model...\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_5\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "word_seq (InputLayer)           [(None, 256)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embeddings_layer (Embedding)    (None, 256, 300)     6000600     word_seq[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "embedding_dropout (Dropout)     (None, 256, 300)     0           embeddings_layer[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "LSTM_layer (LSTM)               (None, 256, 128)     219648      embedding_dropout[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "attention (Dense)               (None, 256, 1)       129         LSTM_layer[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "flatten_2 (Flatten)             (None, 256)          0           attention[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 256)          0           flatten_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "repeat_vector_2 (RepeatVector)  (None, 128, 256)     0           activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "permute_2 (Permute)             (None, 256, 128)     0           repeat_vector_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "multiply_2 (Multiply)           (None, 256, 128)     0           LSTM_layer[0][0]                 \n",
      "                                                                 permute_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_2 (Lambda)               (None, 128)          0           multiply_2[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "sent_repr_norm (BatchNormalizat (None, 128)          512         lambda_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "sent_repr_dropout (Dropout)     (None, 128)          0           sent_repr_norm[0][0]             \n",
      "==================================================================================================\n",
      "Total params: 6,220,889\n",
      "Trainable params: 6,220,633\n",
      "Non-trainable params: 256\n",
      "__________________________________________________________________________________________________\n",
      "Model: \"functional_7\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "numeric_input_hist (InputLayer) [(None, 50, 75)]     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "sparse_input_hist (InputLayer)  [(None, 50, 179)]    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "hierarchical_word_seq_input (In [(None, 50, 256)]    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "numerical_dense_layer_user (Tim (None, 50, 20)       1520        numeric_input_hist[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "sparse_dense_layer_user (TimeDi (None, 50, 20)       3600        sparse_input_hist[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "user_encoder (TimeDistributed)  (None, 50, 128)      6220889     hierarchical_word_seq_input[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "numerical_features_norm (BatchN (None, 50, 20)       200         numerical_dense_layer_user[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "sparse_features_norm (BatchNorm (None, 50, 20)       200         sparse_dense_layer_user[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 50, 168)      0           user_encoder[0][0]               \n",
      "                                                                 numerical_features_norm[0][0]    \n",
      "                                                                 sparse_features_norm[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "LSTM_layer_user (LSTM)          (None, 50, 32)       25728       concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "attention_user (Dense)          (None, 50, 1)        33          LSTM_layer_user[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "flatten_3 (Flatten)             (None, 50)           0           attention_user[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 50)           0           flatten_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "repeat_vector_3 (RepeatVector)  (None, 32, 50)       0           activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "permute_3 (Permute)             (None, 50, 32)       0           repeat_vector_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "multiply_3 (Multiply)           (None, 50, 32)       0           LSTM_layer_user[0][0]            \n",
      "                                                                 permute_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_3 (Lambda)               (None, 32)           0           multiply_3[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "user_repr_dropout (Dropout)     (None, 32)           0           lambda_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "output_layer (Dense)            (None, 1)            33          user_repr_dropout[0][0]          \n",
      "==================================================================================================\n",
      "Total params: 6,252,203\n",
      "Trainable params: 6,251,747\n",
      "Non-trainable params: 456\n",
      "__________________________________________________________________________________________________\n",
      "Model: \"functional_7\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "numeric_input_hist (InputLayer) [(None, 50, 75)]     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "sparse_input_hist (InputLayer)  [(None, 50, 179)]    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "hierarchical_word_seq_input (In [(None, 50, 256)]    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "numerical_dense_layer_user (Tim (None, 50, 20)       1520        numeric_input_hist[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "sparse_dense_layer_user (TimeDi (None, 50, 20)       3600        sparse_input_hist[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "user_encoder (TimeDistributed)  (None, 50, 128)      6220889     hierarchical_word_seq_input[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "numerical_features_norm (BatchN (None, 50, 20)       200         numerical_dense_layer_user[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "sparse_features_norm (BatchNorm (None, 50, 20)       200         sparse_dense_layer_user[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 50, 168)      0           user_encoder[0][0]               \n",
      "                                                                 numerical_features_norm[0][0]    \n",
      "                                                                 sparse_features_norm[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "LSTM_layer_user (LSTM)          (None, 50, 32)       25728       concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "attention_user (Dense)          (None, 50, 1)        33          LSTM_layer_user[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "flatten_3 (Flatten)             (None, 50)           0           attention_user[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 50)           0           flatten_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "repeat_vector_3 (RepeatVector)  (None, 32, 50)       0           activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "permute_3 (Permute)             (None, 50, 32)       0           repeat_vector_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "multiply_3 (Multiply)           (None, 50, 32)       0           LSTM_layer_user[0][0]            \n",
      "                                                                 permute_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_3 (Lambda)               (None, 32)           0           multiply_3[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "user_repr_dropout (Dropout)     (None, 32)           0           lambda_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "output_layer (Dense)            (None, 1)            33          user_repr_dropout[0][0]          \n",
      "==================================================================================================\n",
      "Total params: 6,252,203\n",
      "Trainable params: 6,251,747\n",
      "Non-trainable params: 456\n",
      "__________________________________________________________________________________________________\n",
      "models/lstm_symanto_hierarchical102\n",
      "2021-11-29 17:19:41,511;INFO;Training model...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:training:Training model...\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-11-29 17:19:41,513;INFO;Initializing callbacks...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:training:Initializing callbacks...\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-11-29 17:19:41,516;WARNING;User 3PXKJMBxLl7NVrIcreated_at-312359495.json has no posts in valid set. Ignoring.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:training:User 3PXKJMBxLl7NVrIcreated_at-312359495.json has no posts in valid set. Ignoring.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-11-29 17:19:41,518;WARNING;User 7iqs7uI3T3MwBflcreated_at110126231.json has no posts in valid set. Ignoring.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:training:User 7iqs7uI3T3MwBflcreated_at110126231.json has no posts in valid set. Ignoring.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-11-29 17:19:41,520;WARNING;User A3qKlV8I5O4bKOzcreated_at-793452802.json has no posts in valid set. Ignoring.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:training:User A3qKlV8I5O4bKOzcreated_at-793452802.json has no posts in valid set. Ignoring.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-11-29 17:19:41,525;WARNING;User EliThePotatocreated_at732169814.json has no posts in valid set. Ignoring.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:training:User EliThePotatocreated_at732169814.json has no posts in valid set. Ignoring.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-11-29 17:19:41,526;WARNING;User I5Pmucreated_at696932245.json has no posts in valid set. Ignoring.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:training:User I5Pmucreated_at696932245.json has no posts in valid set. Ignoring.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-11-29 17:19:41,528;WARNING;User Sbee6icreated_at-664370083.json has no posts in train set. Ignoring.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:training:User Sbee6icreated_at-664370083.json has no posts in train set. Ignoring.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-11-29 17:19:41,529;WARNING;User oSPW7CE3HXKsf4icreated_at309684088.json has no posts in train set. Ignoring.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:training:User oSPW7CE3HXKsf4icreated_at309684088.json has no posts in train set. Ignoring.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-11-29 17:19:41,530;WARNING;User pun1i_created_at-77564069.json has no posts in train set. Ignoring.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:training:User pun1i_created_at-77564069.json has no posts in train set. Ignoring.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-11-29 17:19:41,532;WARNING;User r7oooba25created_at110126231.json has no posts in train set. Ignoring.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:training:User r7oooba25created_at110126231.json has no posts in train set. Ignoring.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-11-29 17:19:41,534;WARNING;User xr_zhcreated_at274446519.json has no posts in train set. Ignoring.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:training:User xr_zhcreated_at274446519.json has no posts in train set. Ignoring.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-11-29 17:19:41,536;WARNING;User Sbee6icreated_at-664370083.json has no posts in train set. Ignoring.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:training:User Sbee6icreated_at-664370083.json has no posts in train set. Ignoring.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-11-29 17:19:41,538;WARNING;User oSPW7CE3HXKsf4icreated_at309684088.json has no posts in train set. Ignoring.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:training:User oSPW7CE3HXKsf4icreated_at309684088.json has no posts in train set. Ignoring.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-11-29 17:19:41,539;WARNING;User pun1i_created_at-77564069.json has no posts in train set. Ignoring.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:training:User pun1i_created_at-77564069.json has no posts in train set. Ignoring.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-11-29 17:19:41,540;WARNING;User r7oooba25created_at110126231.json has no posts in train set. Ignoring.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:training:User r7oooba25created_at110126231.json has no posts in train set. Ignoring.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-11-29 17:19:41,542;WARNING;User xr_zhcreated_at274446519.json has no posts in train set. Ignoring.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:training:User xr_zhcreated_at274446519.json has no posts in train set. Ignoring.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 2s 926ms/step\n",
      "Epoch 1/25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ana/.local/lib/python3.7/site-packages/tensorflow/python/framework/indexed_slices.py:433: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100/100 [==============================] - ETA: 0s - loss: 0.7662 - f1_m: 0.6583 - precision_m: 0.5658 - recall_m: 0.8049 - auc: 0.0000e+00\n",
      "Epoch 00001: val_loss improved from inf to 0.73400, saving model to models/lstm_symanto_hierarchical102_best.h5\n",
      "2/2 [==============================] - 2s 896ms/step\n",
      "100/100 [==============================] - 925s 9s/step - loss: 0.7662 - f1_m: 0.6583 - precision_m: 0.5658 - recall_m: 0.8049 - auc: 0.0000e+00 - val_loss: 0.7340 - val_f1_m: 0.7385 - val_precision_m: 0.6848 - val_recall_m: 0.8023 - val_auc: 0.0000e+00\n",
      "Epoch 2/25\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.7168 - f1_m: 0.6979 - precision_m: 0.6190 - recall_m: 0.8155 - auc: 0.0000e+00\n",
      "Epoch 00002: val_loss improved from 0.73400 to 0.72687, saving model to models/lstm_symanto_hierarchical102_best.h5\n",
      "100/100 [==============================] - 792s 8s/step - loss: 0.7168 - f1_m: 0.6979 - precision_m: 0.6190 - recall_m: 0.8155 - auc: 0.0000e+00 - val_loss: 0.7269 - val_f1_m: 0.7196 - val_precision_m: 0.5716 - val_recall_m: 0.9714 - val_auc: 0.0000e+00\n",
      "Epoch 3/25\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.6746 - f1_m: 0.7131 - precision_m: 0.6553 - recall_m: 0.8068 - auc: 0.0000e+00\n",
      "Epoch 00003: val_loss improved from 0.72687 to 0.72246, saving model to models/lstm_symanto_hierarchical102_best.h5\n",
      "2/2 [==============================] - 2s 961ms/step\n",
      "100/100 [==============================] - 975s 10s/step - loss: 0.6746 - f1_m: 0.7131 - precision_m: 0.6553 - recall_m: 0.8068 - auc: 0.0000e+00 - val_loss: 0.7225 - val_f1_m: 0.7576 - val_precision_m: 0.6449 - val_recall_m: 0.9297 - val_auc: 0.0000e+00\n",
      "Epoch 4/25\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.6263 - f1_m: 0.7533 - precision_m: 0.7295 - recall_m: 0.7943 - auc: 0.0000e+00\n",
      "Epoch 00004: val_loss did not improve from 0.72246\n",
      "100/100 [==============================] - 859s 9s/step - loss: 0.6263 - f1_m: 0.7533 - precision_m: 0.7295 - recall_m: 0.7943 - auc: 0.0000e+00 - val_loss: 0.7282 - val_f1_m: 0.7504 - val_precision_m: 0.7177 - val_recall_m: 0.8256 - val_auc: 0.0000e+00\n",
      "Epoch 5/25\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.5850 - f1_m: 0.7881 - precision_m: 0.7780 - recall_m: 0.8199 - auc: 0.0000e+00\n",
      "Epoch 00005: val_loss did not improve from 0.72246\n",
      "2/2 [==============================] - 2s 1s/step\n",
      "100/100 [==============================] - 915s 9s/step - loss: 0.5850 - f1_m: 0.7881 - precision_m: 0.7780 - recall_m: 0.8199 - auc: 0.0000e+00 - val_loss: 0.7453 - val_f1_m: 0.6867 - val_precision_m: 0.7361 - val_recall_m: 0.6864 - val_auc: 0.0000e+00\n",
      "Epoch 6/25\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.5430 - f1_m: 0.8081 - precision_m: 0.8184 - recall_m: 0.8092 - auc: 0.0000e+00\n",
      "Epoch 00006: val_loss did not improve from 0.72246\n",
      "100/100 [==============================] - 972s 10s/step - loss: 0.5430 - f1_m: 0.8081 - precision_m: 0.8184 - recall_m: 0.8092 - auc: 0.0000e+00 - val_loss: 0.7251 - val_f1_m: 0.7399 - val_precision_m: 0.7752 - val_recall_m: 0.7176 - val_auc: 0.0000e+00\n",
      "Epoch 7/25\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.5148 - f1_m: 0.8218 - precision_m: 0.8362 - recall_m: 0.8197 - auc: 0.0000e+00\n",
      "Epoch 00007: val_loss did not improve from 0.72246\n",
      "2/2 [==============================] - 2s 1s/step\n",
      "100/100 [==============================] - 905s 9s/step - loss: 0.5148 - f1_m: 0.8218 - precision_m: 0.8362 - recall_m: 0.8197 - auc: 0.0000e+00 - val_loss: 0.8181 - val_f1_m: 0.6480 - val_precision_m: 0.7318 - val_recall_m: 0.6154 - val_auc: 0.0000e+00\n",
      "Epoch 8/25\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.4834 - f1_m: 0.8414 - precision_m: 0.8687 - recall_m: 0.8283 - auc: 0.0000e+00\n",
      "Epoch 00008: val_loss did not improve from 0.72246\n",
      "100/100 [==============================] - 936s 9s/step - loss: 0.4834 - f1_m: 0.8414 - precision_m: 0.8687 - recall_m: 0.8283 - auc: 0.0000e+00 - val_loss: 0.7934 - val_f1_m: 0.6684 - val_precision_m: 0.7639 - val_recall_m: 0.6292 - val_auc: 0.0000e+00\n",
      "Epoch 9/25\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.4549 - f1_m: 0.8644 - precision_m: 0.8868 - recall_m: 0.8548 - auc: 0.0000e+00\n",
      "Epoch 00009: val_loss did not improve from 0.72246\n",
      "2/2 [==============================] - 2s 917ms/step\n",
      "100/100 [==============================] - 878s 9s/step - loss: 0.4549 - f1_m: 0.8644 - precision_m: 0.8868 - recall_m: 0.8548 - auc: 0.0000e+00 - val_loss: 0.8004 - val_f1_m: 0.7230 - val_precision_m: 0.7582 - val_recall_m: 0.7037 - val_auc: 0.0000e+00\n",
      "Epoch 10/25\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.4231 - f1_m: 0.8729 - precision_m: 0.9066 - recall_m: 0.8584 - auc: 0.0000e+00\n",
      "Epoch 00010: val_loss did not improve from 0.72246\n",
      "100/100 [==============================] - 934s 9s/step - loss: 0.4231 - f1_m: 0.8729 - precision_m: 0.9066 - recall_m: 0.8584 - auc: 0.0000e+00 - val_loss: 0.8469 - val_f1_m: 0.6375 - val_precision_m: 0.7442 - val_recall_m: 0.5840 - val_auc: 0.0000e+00\n",
      "Epoch 11/25\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.4008 - f1_m: 0.8876 - precision_m: 0.9118 - recall_m: 0.8736 - auc: 0.0000e+00\n",
      "Epoch 00011: val_loss did not improve from 0.72246\n",
      "2/2 [==============================] - 2s 948ms/step\n",
      "100/100 [==============================] - 819s 8s/step - loss: 0.4008 - f1_m: 0.8876 - precision_m: 0.9118 - recall_m: 0.8736 - auc: 0.0000e+00 - val_loss: 0.8356 - val_f1_m: 0.6926 - val_precision_m: 0.7421 - val_recall_m: 0.6604 - val_auc: 0.0000e+00\n",
      "Epoch 12/25\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.3755 - f1_m: 0.8973 - precision_m: 0.9289 - recall_m: 0.8752 - auc: 0.0000e+00\n",
      "Epoch 00012: val_loss did not improve from 0.72246\n",
      "100/100 [==============================] - 781s 8s/step - loss: 0.3755 - f1_m: 0.8973 - precision_m: 0.9289 - recall_m: 0.8752 - auc: 0.0000e+00 - val_loss: 0.8370 - val_f1_m: 0.6851 - val_precision_m: 0.7442 - val_recall_m: 0.6465 - val_auc: 0.0000e+00\n",
      "Epoch 13/25\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.3521 - f1_m: 0.9218 - precision_m: 0.9493 - recall_m: 0.9013 - auc: 0.0000e+00\n",
      "Epoch 00013: val_loss did not improve from 0.72246\n",
      "2/2 [==============================] - 2s 947ms/step\n",
      "100/100 [==============================] - 808s 8s/step - loss: 0.3521 - f1_m: 0.9218 - precision_m: 0.9493 - recall_m: 0.9013 - auc: 0.0000e+00 - val_loss: 0.9123 - val_f1_m: 0.6771 - val_precision_m: 0.7462 - val_recall_m: 0.6326 - val_auc: 0.0000e+00\n",
      "Epoch 14/25\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.3344 - f1_m: 0.9216 - precision_m: 0.9541 - recall_m: 0.8967 - auc: 0.0000e+00\n",
      "Epoch 00014: val_loss did not improve from 0.72246\n",
      "100/100 [==============================] - 791s 8s/step - loss: 0.3344 - f1_m: 0.9216 - precision_m: 0.9541 - recall_m: 0.8967 - auc: 0.0000e+00 - val_loss: 0.8498 - val_f1_m: 0.7508 - val_precision_m: 0.6801 - val_recall_m: 0.8392 - val_auc: 0.0000e+00\n",
      "Epoch 15/25\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.3158 - f1_m: 0.9310 - precision_m: 0.9553 - recall_m: 0.9133 - auc: 0.0000e+00\n",
      "Epoch 00015: val_loss did not improve from 0.72246\n",
      "2/2 [==============================] - 2s 809ms/step\n",
      "100/100 [==============================] - 852s 9s/step - loss: 0.3158 - f1_m: 0.9310 - precision_m: 0.9553 - recall_m: 0.9133 - auc: 0.0000e+00 - val_loss: 0.8822 - val_f1_m: 0.7337 - val_precision_m: 0.7352 - val_recall_m: 0.7395 - val_auc: 0.0000e+00\n",
      "Epoch 16/25\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.3001 - f1_m: 0.9338 - precision_m: 0.9583 - recall_m: 0.9144 - auc: 0.0000e+00\n",
      "Epoch 00016: val_loss did not improve from 0.72246\n",
      "100/100 [==============================] - 805s 8s/step - loss: 0.3001 - f1_m: 0.9338 - precision_m: 0.9583 - recall_m: 0.9144 - auc: 0.0000e+00 - val_loss: 0.9173 - val_f1_m: 0.7369 - val_precision_m: 0.6673 - val_recall_m: 0.8245 - val_auc: 0.0000e+00\n",
      "Epoch 17/25\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.2834 - f1_m: 0.9415 - precision_m: 0.9698 - recall_m: 0.9190 - auc: 0.0000e+00\n",
      "Epoch 00017: val_loss did not improve from 0.72246\n",
      "2/2 [==============================] - 2s 996ms/step\n",
      "100/100 [==============================] - 807s 8s/step - loss: 0.2834 - f1_m: 0.9415 - precision_m: 0.9698 - recall_m: 0.9190 - auc: 0.0000e+00 - val_loss: 0.9375 - val_f1_m: 0.7565 - val_precision_m: 0.7237 - val_recall_m: 0.7959 - val_auc: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18/25\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.2670 - f1_m: 0.9507 - precision_m: 0.9740 - recall_m: 0.9317 - auc: 0.0000e+00\n",
      "Epoch 00018: val_loss did not improve from 0.72246\n",
      "100/100 [==============================] - 843s 8s/step - loss: 0.2670 - f1_m: 0.9507 - precision_m: 0.9740 - recall_m: 0.9317 - auc: 0.0000e+00 - val_loss: 0.8986 - val_f1_m: 0.7265 - val_precision_m: 0.7326 - val_recall_m: 0.7229 - val_auc: 0.0000e+00\n",
      "Epoch 19/25\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.2602 - f1_m: 0.9481 - precision_m: 0.9761 - recall_m: 0.9268 - auc: 0.0000e+00\n",
      "Epoch 00019: val_loss did not improve from 0.72246\n",
      "2/2 [==============================] - 2s 922ms/step\n",
      "100/100 [==============================] - 900s 9s/step - loss: 0.2602 - f1_m: 0.9481 - precision_m: 0.9761 - recall_m: 0.9268 - auc: 0.0000e+00 - val_loss: 0.9948 - val_f1_m: 0.7508 - val_precision_m: 0.6801 - val_recall_m: 0.8392 - val_auc: 0.0000e+00\n",
      "Epoch 20/25\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.2510 - f1_m: 0.9525 - precision_m: 0.9760 - recall_m: 0.9333 - auc: 0.0000e+00\n",
      "Epoch 00020: val_loss did not improve from 0.72246\n",
      "100/100 [==============================] - 922s 9s/step - loss: 0.2510 - f1_m: 0.9525 - precision_m: 0.9760 - recall_m: 0.9333 - auc: 0.0000e+00 - val_loss: 0.9852 - val_f1_m: 0.7377 - val_precision_m: 0.6783 - val_recall_m: 0.8106 - val_auc: 0.0000e+00\n",
      "Epoch 21/25\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.2401 - f1_m: 0.9555 - precision_m: 0.9795 - recall_m: 0.9353 - auc: 0.0000e+00\n",
      "Epoch 00021: val_loss did not improve from 0.72246\n",
      "2/2 [==============================] - 2s 991ms/step\n",
      "100/100 [==============================] - 915s 9s/step - loss: 0.2401 - f1_m: 0.9555 - precision_m: 0.9795 - recall_m: 0.9353 - auc: 0.0000e+00 - val_loss: 1.0132 - val_f1_m: 0.7508 - val_precision_m: 0.7378 - val_recall_m: 0.7681 - val_auc: 0.0000e+00\n",
      "Epoch 22/25\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.2383 - f1_m: 0.9528 - precision_m: 0.9744 - recall_m: 0.9354 - auc: 0.0000e+00\n",
      "Epoch 00022: val_loss did not improve from 0.72246\n",
      "100/100 [==============================] - 795s 8s/step - loss: 0.2383 - f1_m: 0.9528 - precision_m: 0.9744 - recall_m: 0.9354 - auc: 0.0000e+00 - val_loss: 1.0074 - val_f1_m: 0.7508 - val_precision_m: 0.7378 - val_recall_m: 0.7681 - val_auc: 0.0000e+00\n",
      "Epoch 23/25\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.2278 - f1_m: 0.9521 - precision_m: 0.9725 - recall_m: 0.9369 - auc: 0.0000e+00\n",
      "Epoch 00023: val_loss did not improve from 0.72246\n",
      "2/2 [==============================] - 3s 1s/step\n",
      "100/100 [==============================] - 828s 8s/step - loss: 0.2278 - f1_m: 0.9521 - precision_m: 0.9725 - recall_m: 0.9369 - auc: 0.0000e+00 - val_loss: 1.0207 - val_f1_m: 0.7280 - val_precision_m: 0.6724 - val_recall_m: 0.7967 - val_auc: 0.0000e+00\n",
      "Epoch 24/25\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.2207 - f1_m: 0.9618 - precision_m: 0.9841 - recall_m: 0.9433 - auc: 0.0000e+00\n",
      "Epoch 00024: val_loss did not improve from 0.72246\n",
      "100/100 [==============================] - 826s 8s/step - loss: 0.2207 - f1_m: 0.9618 - precision_m: 0.9841 - recall_m: 0.9433 - auc: 0.0000e+00 - val_loss: 0.9656 - val_f1_m: 0.7716 - val_precision_m: 0.7500 - val_recall_m: 0.7967 - val_auc: 0.0000e+00\n",
      "Epoch 25/25\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.2160 - f1_m: 0.9595 - precision_m: 0.9818 - recall_m: 0.9412 - auc: 0.0000e+00\n",
      "Epoch 00025: val_loss did not improve from 0.72246\n",
      "2/2 [==============================] - 2s 779ms/step\n",
      "100/100 [==============================] - 828s 8s/step - loss: 0.2160 - f1_m: 0.9595 - precision_m: 0.9818 - recall_m: 0.9412 - auc: 0.0000e+00 - val_loss: 1.0576 - val_f1_m: 0.7338 - val_precision_m: 0.6819 - val_recall_m: 0.7967 - val_auc: 0.0000e+00\n",
      "2021-11-29 23:24:59,467;INFO;Saving model...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:training:Saving model...\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-11-29 23:24:59,698;ERROR;Could not save model.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:training:Could not save model.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1d 10h 3min 2s, sys: 5h 3min 32s, total: 1d 15h 6min 34s\n",
      "Wall time: 6h 5min 26s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# transfer_type=\"depression\"\n",
    "transfer_type=None\n",
    "classes=1\n",
    "# transfer_type=\"depression\"\n",
    "# with session_collection[key].as_default():\n",
    "#     with session_collection[key].graph.as_default():\n",
    "hyperparams_collection[key] = hyperparams\n",
    "\n",
    "\n",
    "if transfer_type:\n",
    "    # TODO: try to compile? with proper optimizer?\n",
    "    hyperparams_collection[key]['trainable_embeddings'] = True\n",
    "    hyperparams_collection[key]['transfer_units'] = 20\n",
    "    hyperparams_collection[key]['positive_class_weight'] = 1\n",
    "#     hyperparams_collection[key]['positive_class_weight'] = 5\n",
    "    hyperparams_collection[key]['lr'] = 0.001\n",
    "    hyperparams_collection[key]['optimizer'] = optimizers.Adam(lr=hyperparams_collection[key]['lr'], #beta_1=0.9, beta_2=0.999, epsilon=0.0001,\n",
    "                                   decay=hyperparams_collection[key]['decay'])\n",
    "    hyperparams_features['pretrained_model_path'] = 'models/lstmnonumerical_dense_layer_clpsych_hierarchical62'\n",
    "\n",
    "#     hyperparams_collection[key]['lr'] = 0.01\n",
    "\n",
    "#     models_collection[key] = load_saved_model(hyperparams_features['pretrained_model_path'], \n",
    "#                                               hyperparams_collection[key])\n",
    "    models_collection[key] = load_saved_model_weights(hyperparams_features['pretrained_model_path'], \n",
    "                                                      hyperparams_collection[key], \n",
    "                                                      emotions, stopword_list, liwc_categories, classes, \n",
    "                                                      h5=True)\n",
    "\n",
    "#     metrics_class = Metrics(threshold=hyperparams_collection[key]['threshold'])\n",
    "#     models_collection[key].compile(hyperparams_collection[key]['optimizer'], binary_crossentropy_custom,\n",
    "#                   metrics=[metrics_class.f1_m, metrics_class.precision_m, metrics_class.recall_m,\n",
    "#                           metrics_class.auc, \n",
    "#                            tf.keras.metrics.AUC(name=\"AUC_keras\"), \n",
    "#                            tf.keras.metrics.FalsePositives(), \n",
    "#                            tf.keras.metrics.FalseNegatives()])\n",
    "\n",
    "\n",
    "    experiment = initialize_experiment(hyperparams_collection[key], nrc_lexicon_path, emotions, pretrained_embeddings_path, \n",
    "                                  dataset_type, transfer_type)\n",
    "    models_collection[key], history = train(user_level_data, subjects_split, \n",
    "              hyperparams_collection[key], hyperparams_features, \n",
    "              embedding_matrix, emotions, stopword_list, liwc_categories,\n",
    "                  experiment,\n",
    "                  validation_set='valid',\n",
    "              version=63, epochs=90, start_epoch=80, transfer_layer=False,\n",
    "#                     session=session_collection[key],\n",
    "                model=models_collection[key]                        # Remove this to use transfer layer(?)\n",
    "                                           )\n",
    "else:\n",
    "    experiment = initialize_experiment(hyperparams, nrc_lexicon_path, emotions, pretrained_embeddings_path, \n",
    "                          dataset_type, transfer_type)\n",
    "    models_collection[key], history = train(user_level_data, subjects_split, \n",
    "              hyperparams_collection[key], hyperparams_features, \n",
    "              embedding_matrix, emotions, stopword_list, liwc_categories,\n",
    "                  experiment,\n",
    "                  validation_set='valid',\n",
    "              version=102, epochs=25, start_epoch=0, classes=classes,\n",
    "#                     session=session_collection[key],\n",
    "#                     model=models_collection[key]\n",
    "                                           )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "64\n",
      "Model: \"functional_7\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "numeric_input_hist (InputLayer) [(None, 50, 75)]     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "sparse_input_hist (InputLayer)  [(None, 50, 179)]    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "hierarchical_word_seq_input (In [(None, 50, 256)]    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "numerical_dense_layer_user (Tim (None, 50, 20)       1520        numeric_input_hist[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "sparse_dense_layer_user (TimeDi (None, 50, 20)       3600        sparse_input_hist[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "user_encoder (TimeDistributed)  (None, 50, 128)      6220889     hierarchical_word_seq_input[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "numerical_features_norm (BatchN (None, 50, 20)       200         numerical_dense_layer_user[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "sparse_features_norm (BatchNorm (None, 50, 20)       200         sparse_dense_layer_user[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 50, 168)      0           user_encoder[0][0]               \n",
      "                                                                 numerical_features_norm[0][0]    \n",
      "                                                                 sparse_features_norm[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "LSTM_layer_user (LSTM)          (None, 50, 32)       25728       concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "attention_user (Dense)          (None, 50, 1)        33          LSTM_layer_user[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "flatten_3 (Flatten)             (None, 50)           0           attention_user[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 50)           0           flatten_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "repeat_vector_3 (RepeatVector)  (None, 32, 50)       0           activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "permute_3 (Permute)             (None, 50, 32)       0           repeat_vector_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "multiply_3 (Multiply)           (None, 50, 32)       0           LSTM_layer_user[0][0]            \n",
      "                                                                 permute_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_3 (Lambda)               (None, 32)           0           multiply_3[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "user_repr_dropout (Dropout)     (None, 32)           0           lambda_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "output_layer (Dense)            (None, 1)            33          user_repr_dropout[0][0]          \n",
      "==================================================================================================\n",
      "Total params: 6,252,203\n",
      "Trainable params: 6,251,747\n",
      "Non-trainable params: 456\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "print(len(emotions))\n",
    "print(len(liwc_categories))\n",
    "# models_collection[key].get_layer('LSTM_layer_user').weights\n",
    "models_collection[key].summary()\n",
    "# hyperparams_collection[key]['ignore_layer']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # model_path = \"models/lstm_%s_hierarchical53\" % dataset_type\n",
    "# models_collection[key] = initialize_model(hyperparams_collection[key], \n",
    "#                                           hyperparams_features, embedding_matrix, emotions, stopword_list,\n",
    "#                     liwc_categories)\n",
    "# # models_collection[key].load_weights(model_path + \"_weights\")\n",
    "\n",
    "\n",
    "# # embedding_matrix.shape\n",
    "# models_collection[key].load_weights(hyperparams_features['pretrained_model_path'] + \"_weights\")\n",
    "# metrics_class = Metrics(threshold=hyperparams_collection[key]['threshold'])\n",
    "# # models_collection[key].compile(hyperparams_collection[key]['optimizer'], binary_crossentropy_custom,\n",
    "# #               metrics=[metrics_class.f1_m, metrics_class.precision_m, metrics_class.recall_m,\n",
    "# #                       metrics_class.auc, \n",
    "# #                        tf.keras.metrics.AUC(name=\"AUC_keras\"), \n",
    "# #                        tf.keras.metrics.FalsePositives(), \n",
    "# #                        tf.keras.metrics.FalseNegatives()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "# models_collection[key] = initialize_model(hyperparams_collection[key], \n",
    "#                                           hyperparams_features, embedding_matrix, emotions, stopword_list,\n",
    "#                     liwc_categories)\n",
    "# models_collection[key] = load_weights(hyperparams_features['pretrained_model_path'] + \"_weights.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "# models_collection[key] = depression_model\n",
    "# hyperparams_collection[key]\n",
    "# classes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating only on last group (1)...\n",
      "2021-11-29 23:31:19,293;WARNING;User abo5401created_at180601369.json has no posts in test set. Ignoring.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:training:User abo5401created_at180601369.json has no posts in test set. Ignoring.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-11-29 23:31:19,294;WARNING;User i__f5rcreated_at-500049795.json has no posts in test set. Ignoring.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:training:User i__f5rcreated_at-500049795.json has no posts in test set. Ignoring.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating...\n",
      "WARNING:tensorflow:From <timed exec>:66: Model.evaluate_generator (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use Model.evaluate, which supports generators.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <timed exec>:66: Model.evaluate_generator (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use Model.evaluate, which supports generators.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 5s 1s/step - loss: 0.7994 - f1_m: 0.7378 - precision_m: 0.7268 - recall_m: 0.7566 - auc: 0.0000e+00 - AUC_keras: 0.7792 - false_positives: 18.0000 - false_negatives: 16.0000\n",
      "Finding optimal threshold...\n",
      "2021-11-29 23:31:29,790;WARNING;User 3PXKJMBxLl7NVrIcreated_at-312359495.json has no posts in valid set. Ignoring.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:training:User 3PXKJMBxLl7NVrIcreated_at-312359495.json has no posts in valid set. Ignoring.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-11-29 23:31:29,792;WARNING;User 7iqs7uI3T3MwBflcreated_at110126231.json has no posts in valid set. Ignoring.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:training:User 7iqs7uI3T3MwBflcreated_at110126231.json has no posts in valid set. Ignoring.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-11-29 23:31:29,793;WARNING;User A3qKlV8I5O4bKOzcreated_at-793452802.json has no posts in valid set. Ignoring.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:training:User A3qKlV8I5O4bKOzcreated_at-793452802.json has no posts in valid set. Ignoring.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-11-29 23:31:29,795;WARNING;User EliThePotatocreated_at732169814.json has no posts in valid set. Ignoring.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:training:User EliThePotatocreated_at732169814.json has no posts in valid set. Ignoring.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-11-29 23:31:29,796;WARNING;User I5Pmucreated_at696932245.json has no posts in valid set. Ignoring.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:training:User I5Pmucreated_at696932245.json has no posts in valid set. Ignoring.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "4/4 [==============================] - 4s 901ms/step - loss: 1.0576 - f1_m: 0.6949 - precision_m: 0.5335 - recall_m: 1.0000 - auc: 0.0000e+00 - AUC_keras: 0.6886 - false_positives_1: 21.0000 - false_negatives_1: 14.0000\n",
      "1\n",
      "4/4 [==============================] - 4s 918ms/step - loss: 1.0576 - f1_m: 0.7225 - precision_m: 0.5929 - recall_m: 0.9306 - auc: 0.0000e+00 - AUC_keras: 0.6886 - false_positives_2: 21.0000 - false_negatives_2: 14.0000\n",
      "2\n",
      "4/4 [==============================] - 4s 916ms/step - loss: 1.0576 - f1_m: 0.7116 - precision_m: 0.6067 - recall_m: 0.8725 - auc: 0.0000e+00 - AUC_keras: 0.6886 - false_positives_3: 21.0000 - false_negatives_3: 14.0000\n",
      "3\n",
      "4/4 [==============================] - 4s 898ms/step - loss: 1.0576 - f1_m: 0.6885 - precision_m: 0.5975 - recall_m: 0.8301 - auc: 0.0000e+00 - AUC_keras: 0.6886 - false_positives_4: 21.0000 - false_negatives_4: 14.0000\n",
      "4\n",
      "4/4 [==============================] - 4s 889ms/step - loss: 1.0576 - f1_m: 0.6898 - precision_m: 0.6055 - recall_m: 0.8134 - auc: 0.0000e+00 - AUC_keras: 0.6886 - false_positives_5: 21.0000 - false_negatives_5: 14.0000\n",
      "5\n",
      "4/4 [==============================] - 4s 893ms/step - loss: 1.0576 - f1_m: 0.7338 - precision_m: 0.6819 - recall_m: 0.7967 - auc: 0.0000e+00 - AUC_keras: 0.6886 - false_positives_6: 21.0000 - false_negatives_6: 14.0000\n",
      "6\n",
      "4/4 [==============================] - 4s 895ms/step - loss: 1.0576 - f1_m: 0.7726 - precision_m: 0.7511 - recall_m: 0.7967 - auc: 0.0000e+00 - AUC_keras: 0.6886 - false_positives_7: 21.0000 - false_negatives_7: 14.0000\n",
      "7\n",
      "4/4 [==============================] - 4s 908ms/step - loss: 1.0576 - f1_m: 0.7077 - precision_m: 0.7353 - recall_m: 0.6909 - auc: 0.0000e+00 - AUC_keras: 0.6886 - false_positives_8: 21.0000 - false_negatives_8: 14.0000\n",
      "8\n",
      "4/4 [==============================] - 4s 894ms/step - loss: 1.0576 - f1_m: 0.6916 - precision_m: 0.7544 - recall_m: 0.6484 - auc: 0.0000e+00 - AUC_keras: 0.6886 - false_positives_9: 21.0000 - false_negatives_9: 14.0000\n",
      "9\n",
      "4/4 [==============================] - 4s 888ms/step - loss: 1.0576 - f1_m: 0.6558 - precision_m: 0.7500 - recall_m: 0.5837 - auc: 0.0000e+00 - AUC_keras: 0.6886 - false_positives_10: 21.0000 - false_negatives_10: 14.0000\n",
      "{0: 0.6948620080947876, 1: 0.722471296787262, 2: 0.7115532755851746, 3: 0.6884823441505432, 4: 0.689765989780426, 5: 0.733756422996521, 6: 0.7725694179534912, 7: 0.7077467441558838, 8: 0.6916042566299438, 9: 0.6557602882385254} 6\n",
      "Computing with best threshold...\n",
      "2021-11-29 23:32:51,921;WARNING;User abo5401created_at180601369.json has no posts in test set. Ignoring.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:training:User abo5401created_at180601369.json has no posts in test set. Ignoring.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-11-29 23:32:51,923;WARNING;User i__f5rcreated_at-500049795.json has no posts in test set. Ignoring.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:training:User i__f5rcreated_at-500049795.json has no posts in test set. Ignoring.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 6s 1s/step - loss: 0.8388 - f1_m: 0.6884 - precision_m: 0.6941 - recall_m: 0.6901 - auc: 0.0000e+00 - AUC_keras: 0.7631 - false_positives_11: 22.0000 - false_negatives_11: 20.0000\n",
      "CPU times: user 6min 35s, sys: 49.1 s, total: 7min 24s\n",
      "Wall time: 1min 43s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:urllib3.connectionpool:Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'ReadTimeoutError(\"HTTPSConnectionPool(host='www.comet.ml', port=443): Read timed out. (read timeout=10)\")': /clientlib/status-report/update\n",
      "WARNING:urllib3.connectionpool:Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x7feb841dca10>: Failed to establish a new connection: [Errno -3] Temporary failure in name resolution')': /clientlib/status-report/update\n",
      "WARNING:urllib3.connectionpool:Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x7feb65cf9850>: Failed to establish a new connection: [Errno -3] Temporary failure in name resolution')': /clientlib/status-report/update\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import pickle\n",
    "\n",
    "# # Evaluate on entire posts history, final F1-score\n",
    "# print(\"Evaluating on same nr of groups as train (%d)...\" % hyperparams['post_groups_per_user'] if \n",
    "#       hyperparams['post_groups_per_user'] else 0)\n",
    "# cur_model.evaluate_generator(DataGenerator(user_level_data, subjects_split, \n",
    "#                                          set_type='test', \n",
    "#                                     seq_len=hyperparams['maxlen'], batch_size=hyperparams['batch_size'],\n",
    "#                                        hierarchical=hyperparams['hierarchical'],\n",
    "#                                          max_posts_per_user=None,\n",
    "#                                        pad_with_duplication=False,\n",
    "#                                         posts_per_group=hyperparams['posts_per_group'],\n",
    "#                                         post_groups_per_user=hyperparams['post_groups_per_user'], \n",
    "#                                          sample_seqs=False, shuffle=False), verbose=1)\n",
    "# print(\"Evaluating on entire posts history...\")\n",
    "# cur_model.evaluate_generator(DataGenerator(user_level_data, subjects_split, \n",
    "#                                          set_type='test', \n",
    "#                                     seq_len=hyperparams['maxlen'], batch_size=hyperparams['batch_size'],\n",
    "#                                        hierarchical=hyperparams['hierarchical'],\n",
    "#                                          max_posts_per_user=None,\n",
    "#                                        pad_with_duplication=False,\n",
    "#                                         posts_per_group=hyperparams['posts_per_group'],\n",
    "#                                         post_groups_per_user=hyperparams['post_groups_per_user'], \n",
    "#                                          sample_seqs=False, shuffle=False), verbose=1)\n",
    "# hyperparams_collection[key] = hyperparams\n",
    "\n",
    "\n",
    "liwc_words_for_categories = pickle.load(open(hyperparams_features['liwc_words_cached'], 'rb'))\n",
    "if 'emotions' in hyperparams_collection[key]['ignore_layer']:\n",
    "    emotions = []\n",
    "if 'LIWC' in hyperparams_collection[key]['ignore_layer']:\n",
    "    liwc_categories = []\n",
    "# # \n",
    "# with session_collection[key].as_default():\n",
    "#     with session_collection[key].graph.as_default():\n",
    "print(\"Evaluating only on last group (1)...\")\n",
    "if classes==1:\n",
    "    metrics_class = Metrics(threshold=0.5)\n",
    "    models_collection[key].compile(hyperparams_collection[key]['optimizer'], binary_crossentropy_custom,\n",
    "                      metrics=[metrics_class.f1_m, metrics_class.precision_m, metrics_class.recall_m,\n",
    "                              metrics_class.auc, \n",
    "                               tf.keras.metrics.AUC(name=\"AUC_keras\"), \n",
    "                               tf.keras.metrics.FalsePositives(), \n",
    "                               tf.keras.metrics.FalseNegatives()])\n",
    "else:\n",
    "    models_collection[key].compile(hyperparams_collection[key]['optimizer'], K.categorical_crossentropy,\n",
    "                     metrics=[tf.keras.metrics.CategoricalAccuracy(name='cat_acc'),\n",
    "                             tf.keras.metrics.Precision(name='prec'), tf.keras.metrics.Recall(name='rec'), \n",
    "                              ])\n",
    "\n",
    "test_generator = DataGenerator(user_level_data, subjects_split, \n",
    "                                         set_type='test', \n",
    "                                    seq_len=hyperparams_collection[key]['maxlen'],   \n",
    "#                                         batch_size=len(subjects_split['test']), # on all data at once\n",
    "                                        batch_size=hyperparams_collection[key]['batch_size'], # on all data at once\n",
    "                                       hierarchical=hyperparams_collection[key]['hierarchical'],\n",
    "                                         max_posts_per_user=None,\n",
    "                                       pad_with_duplication=False,\n",
    "                                        posts_per_group=hyperparams_collection[key]['posts_per_group'],\n",
    "                                        post_groups_per_user=1,  compute_liwc=True,\n",
    "                                        liwc_words_for_categories=liwc_words_for_categories,\n",
    "                                        emotions=emotions, liwc_categories=liwc_categories, keep_last_batch=False,\n",
    "                                         sample_seqs=False, shuffle=False, classes=classes,\n",
    "                              )\n",
    "print(\"Evaluating...\")\n",
    "results1 = models_collection[key].evaluate_generator(test_generator, verbose=1)\n",
    "\n",
    "if classes>1:\n",
    "    test_labels_sparse = list(test_generator.generated_labels) # need to get these after iterating\n",
    "    print(len(test_labels_sparse), len(test_generator.generated_labels))\n",
    "    print(\"Predicting\")\n",
    "    Y_pred = models_collection[key].predict_generator(test_generator)#, num_of_test_samples // batch_size+1)\n",
    "    y_pred = np.argmax(Y_pred, axis=1)\n",
    "    \n",
    "    test_labels_sparse = list(test_generator.generated_labels) # need to get these after iterating\n",
    "    print(len(test_labels_sparse), len(test_generator.generated_labels))\n",
    "    print('Confusion Matrix')\n",
    "    # TODO: check\n",
    "    # keeping as many batches as we have for predictions, hopefully they match... I got one more\n",
    "    # TODO: no, can't assume it, have to fix it\n",
    "\n",
    "    test_labels = np.argmax(test_generator.generated_labels, axis=1) \n",
    "    print(test_labels.shape, y_pred.shape)\n",
    "    print(confusion_matrix(test_labels, y_pred))\n",
    "    print('Classification Report')\n",
    "    target_names = ['selfharm', 'anorexia', 'depression']\n",
    "    print(classification_report(test_labels, y_pred, target_names=target_names))\n",
    "    # experiment.log_metric(\"test_f1\", results1[1])\n",
    "# experiment.log_metric(\"test_prec\", results1[2])\n",
    "# experiment.log_metric(\"test_recall\", results1[3])\n",
    "# experiment.log_metric(\"test_auc\", results1[4])\n",
    "\n",
    "\n",
    "#     Optimal thresh\n",
    "if classes==1:\n",
    "    print(\"Finding optimal threshold...\")\n",
    "    f1s = {}\n",
    "    eval_generator = DataGenerator(user_level_data, subjects_split, \n",
    "                                             set_type='valid', compute_liwc=True,\n",
    "                                            liwc_words_for_categories=liwc_words_for_categories,\n",
    "                                            emotions=emotions, liwc_categories=liwc_categories,\n",
    "                                        seq_len=hyperparams_collection[key]['maxlen'], \n",
    "                                            batch_size=hyperparams_collection[key]['batch_size'],\n",
    "                                           hierarchical=hyperparams_collection[key]['hierarchical'],\n",
    "                                             max_posts_per_user=None,\n",
    "                                           pad_with_duplication=False,\n",
    "                                            posts_per_group=hyperparams_collection[key]['posts_per_group'],\n",
    "                                            post_groups_per_user=1, \n",
    "                                                     sample_seqs=False, shuffle=False)\n",
    "    for thresh in range(0, 10, 1):\n",
    "        print(thresh)\n",
    "        # model1.load_weights(model_path + \"_weights\", by_name=True)\n",
    "        metrics_class = Metrics(threshold=thresh/10)\n",
    "        models_collection[key].compile(hyperparams_collection[key]['optimizer'], binary_crossentropy_custom,\n",
    "                          metrics=[metrics_class.f1_m, metrics_class.precision_m, metrics_class.recall_m,\n",
    "                                metrics_class.auc, \n",
    "                               tf.keras.metrics.AUC(name=\"AUC_keras\"), \n",
    "                               tf.keras.metrics.FalsePositives(), \n",
    "                               tf.keras.metrics.FalseNegatives()])\n",
    "    \n",
    "        results = models_collection[key].evaluate_generator(eval_generator, verbose=1)\n",
    "        f1s[thresh] = results[1]\n",
    "    best_f1 = 0\n",
    "    best_thresh = 0.5\n",
    "    for t, f1 in f1s.items():\n",
    "        if f1 >= best_f1:\n",
    "            best_thresh = t\n",
    "            best_f1 = f1\n",
    "    print(f1s, best_thresh)\n",
    "    hyperparams_features['best_thresh'] = best_thresh/10\n",
    "    # experiment.log_metric(\"best_thresh\", best_thresh/10)\n",
    "\n",
    "    print(\"Computing with best threshold...\")\n",
    "    metrics_class = Metrics(best_thresh/10)\n",
    "    models_collection[key].compile(hyperparams_collection[key]['optimizer'], binary_crossentropy_custom,\n",
    "                          metrics=[metrics_class.f1_m, metrics_class.precision_m, metrics_class.recall_m,\n",
    "                                metrics_class.auc, \n",
    "                               tf.keras.metrics.AUC(name=\"AUC_keras\"), \n",
    "                               tf.keras.metrics.FalsePositives(), \n",
    "                               tf.keras.metrics.FalseNegatives()])\n",
    "\n",
    "    results = models_collection[key].evaluate_generator(DataGenerator(user_level_data, subjects_split, \n",
    "                                             set_type='test', compute_liwc=True,\n",
    "                                            liwc_words_for_categories=liwc_words_for_categories,\n",
    "                                            emotions = emotions, liwc_categories=liwc_categories,\n",
    "\n",
    "                                        seq_len=hyperparams_collection[key]['maxlen'], \n",
    "                                           batch_size=hyperparams_collection[key]['batch_size'],\n",
    "                                           hierarchical=hyperparams_collection[key]['hierarchical'],\n",
    "                                             max_posts_per_user=None,\n",
    "                                           pad_with_duplication=False,\n",
    "                                            posts_per_group=hyperparams_collection[key]['posts_per_group'],\n",
    "                                            post_groups_per_user=1, \n",
    "                                                     sample_seqs=False, shuffle=False), verbose=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'test_generator' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-129-03e49e6d6f51>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# np.argmax(test_generator.generated_labels, axis=1)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtest_labels_sparse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_generator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerated_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_generator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerated_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'test_generator' is not defined"
     ]
    }
   ],
   "source": [
    "# np.argmax(test_generator.generated_labels, axis=1)\n",
    "test_labels_sparse = list(test_generator.generated_labels)\n",
    "len(test_generator.generated_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'source'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3079\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3080\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3081\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'source'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-130-2687d623e473>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m user_level_data2, subjects_split2, vocabulary = load_erisk_data(writings_df[writings_df['source']=='depression'], \n\u001b[0m\u001b[1;32m      2\u001b[0m                                                             \u001b[0mvoc_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhyperparams_features\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'max_features'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m                                                            \u001b[0memotion_lexicon\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnrc_lexicon\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m                                                            \u001b[0memotions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0memotions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m                                                            \u001b[0muser_level\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhyperparams_features\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'user_level'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3022\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3023\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3024\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3025\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3026\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3080\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3081\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3082\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3083\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3084\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtolerance\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'source'"
     ]
    }
   ],
   "source": [
    "user_level_data2, subjects_split2, vocabulary = load_erisk_data(writings_df[writings_df['source']=='depression'], \n",
    "                                                            voc_size=hyperparams_features['max_features'],\n",
    "                                                           emotion_lexicon=nrc_lexicon,\n",
    "                                                           emotions=emotions,\n",
    "                                                           user_level=hyperparams_features['user_level'],\n",
    "                                                                                logger=logger,\n",
    "#                                                            vocabulary=pickle.load(open('vocabulary_40K_all.pkl', 'rb')),\n",
    "#                                                            vocabulary=pickle.load(open('vocab_clpsych_10000.pkl', 'rb')),\n",
    "                                                              vocabulary=vocabulary_dict,\n",
    "                                                              by_subset=False\n",
    "                                                                               )\n",
    "results2 = models_collection[key].evaluate_generator(DataGenerator(user_level_data2, subjects_split2, \n",
    "                                         set_type='test', \n",
    "                                    seq_len=hyperparams_collection[key]['maxlen'],   \n",
    "#                                         batch_size=len(subjects_split['test']), # on all data at once\n",
    "                                        batch_size=hyperparams_collection[key]['batch_size'], # on all data at once\n",
    "                                       hierarchical=hyperparams_collection[key]['hierarchical'],\n",
    "                                         max_posts_per_user=None,\n",
    "                                       pad_with_duplication=False,\n",
    "                                        posts_per_group=hyperparams_collection[key]['posts_per_group'],\n",
    "                                        post_groups_per_user=1,  compute_liwc=True,\n",
    "                                        liwc_words_for_categories=liwc_words_for_categories,\n",
    "                                         sample_seqs=False, shuffle=False), verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating on partial posts history...\n",
      "Iteration 0\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'lstm_seq'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-131-9c4fd7f1570e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0miteration\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterations\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhyperparams_collection\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'posts_per_group'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Iteration\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miteration\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m     results = models_collection[key].evaluate_generator(DataGenerator(user_level_data, subjects_split, \n\u001b[0m\u001b[1;32m     15\u001b[0m                                          \u001b[0mset_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'test'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m                                        \u001b[0mhierarchical\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhyperparams_collection\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'hierarchical'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'lstm_seq'"
     ]
    }
   ],
   "source": [
    "iterations = 1500\n",
    "\n",
    "# Evaluate on partial post history, simulating stream\n",
    "print(\"Evaluating on partial posts history...\")\n",
    "cnt=0\n",
    "cnt+=1\n",
    "f1_per_iteration = []\n",
    "auc_per_iteration = []\n",
    "precision_per_iteration = []\n",
    "recall_per_iteration = []\n",
    "predictions_per_iteration = []\n",
    "for iteration in range(0, iterations, hyperparams_collection[key]['posts_per_group']):\n",
    "    print(\"Iteration\", iteration)\n",
    "    results = models_collection[key].evaluate_generator(DataGenerator(user_level_data, subjects_split, \n",
    "                                         set_type='test', \n",
    "                                       hierarchical=hyperparams_collection[key]['hierarchical'],\n",
    "                                        seq_len=hyperparams['maxlen'], \n",
    "#                                         batch_size=len(subjects_split['test'])//2, # on all data at once\n",
    "                                        batch_size=hyperparams_collection[key]['batch_size'], # on all data at once\n",
    "                                         max_posts_per_user=iteration,\n",
    "                                       pad_with_duplication=False,\n",
    "                                        posts_per_group=hyperparams_collection[key]['posts_per_group'],\n",
    "                                        post_groups_per_user=1, \n",
    "                                        post_offset=iteration,\n",
    "                                        compute_liwc=True,\n",
    "                                        liwc_words_for_categories=liwc_words_for_categories,\n",
    "                                        emotions=emotions, liwc_categories=liwc_categories,\n",
    "                                         sample_seqs=False, shuffle=False), verbose=1)\n",
    "    f1_per_iteration.append(results[1])\n",
    "    precision_per_iteration.append(results[2])\n",
    "    recall_per_iteration.append(results[3])\n",
    "    auc_per_iteration.append(results[5])\n",
    "    predictions = models_collection[key].predict(DataGenerator(user_level_data, subjects_split, \n",
    "                                         set_type='test', \n",
    "                                       hierarchical=hyperparams_collection[key]['hierarchical'],\n",
    "                                        seq_len=hyperparams['maxlen'], \n",
    "#                                         batch_size=len(subjects_split['test'])//2, # on all data at once\n",
    "                                        batch_size=hyperparams_collection[key]['batch_size'], # on all data at once\n",
    "                                         max_posts_per_user=iteration,\n",
    "                                       pad_with_duplication=False,\n",
    "                                        posts_per_group=hyperparams_collection[key]['posts_per_group'],\n",
    "                                        post_groups_per_user=1, \n",
    "                                        post_offset=iteration,\n",
    "                                        compute_liwc=True,\n",
    "                                        liwc_words_for_categories=liwc_words_for_categories,\n",
    "                                        emotions=emotions, liwc_categories=liwc_categories,\n",
    "                                         sample_seqs=False, shuffle=False), verbose=1)\n",
    "    predictions_per_iteration.extend(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions_per_iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average precision across 1500 iterations: nan;\n",
      "average recall across 1500 iterations: nan;\n",
      "average f1 across 1500 iterations: nan;\n",
      "average auc across 1500 iterations: nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ana/.local/lib/python3.7/site-packages/numpy/core/fromnumeric.py:3335: RuntimeWarning: Mean of empty slice.\n",
      "  out=out, **kwargs)\n",
      "/home/ana/.local/lib/python3.7/site-packages/numpy/core/_methods.py:161: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    }
   ],
   "source": [
    "print(\"\"\"average precision across %d iterations: %f;\n",
    "average recall across %d iterations: %f;\n",
    "average f1 across %d iterations: %f;\n",
    "average auc across %d iterations: %f\"\"\" % (\n",
    "    iterations, np.mean(precision_per_iteration[:iterations]),\n",
    "    iterations, np.mean(recall_per_iteration[:iterations]),\n",
    "    iterations, np.mean(f1_per_iteration[:iterations]),\n",
    "    iterations, np.mean(auc_per_iteration[:iterations])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.plot(range(0, len(auc_per_iteration)*hyperparams_collection[key]['posts_per_group'], hyperparams_collection[key]['posts_per_group']), \n",
    "#          auc_per_iteration)\n",
    "pd.Series(auc_per_iteration, \n",
    "          index=range(0, len(auc_per_iteration)*hyperparams_collection[key]['posts_per_group'], hyperparams_collection[key]['posts_per_group'])\n",
    "                                                                    ).rolling(20).mean().plot()\n",
    "plt.xlabel(\"Posts offset\")\n",
    "plt.ylabel(\"AUC\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Series([p[0] for p in predictions_per_iteration]).hist(bins=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.plot(range(0, iteration*hyperparams_collection[key]['posts_per_group'], \n",
    "#                hyperparams_collection[key]['posts_per_group']), \n",
    "#          predictions_per_iteration)\n",
    "pd.Series([p[0] for p in predictions_per_iteration]).rolling(5000).std().plot()\n",
    "plt.xlabel(\"Posts offset\")\n",
    "plt.ylabel(\"Predictions\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "attention_user = [v for v in models_collection[key].get_layer('attention_user').get_weights()[0].flatten()]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "attention_layer = models_collection[key].get_layer('user_encoder').get_weights()[-2]\n",
    "assert(attention_layer.shape == (128, 1))\n",
    "pd.Series([v for v in attention_layer]).rolling(30).mean().plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pickle.dump(auc_per_iteration, open(\"auc_per_iteration_selfharm53.pkl\", \"wb+\"))\n",
    "# pickle.dump(f1_per_iteration, open(\"f1_per_iteration_selfharm53.pkl\", \"wb+\"))\n",
    "# pickle.dump(predictions_per_iteration, open(\"predictions_per_iteration_selfharm53.pkl\", \"wb+\"))\n",
    "# pickle.dump(attention_user, open(\"attention_user_selfharm53.pkl\", \"wb+\"))\n",
    "# pickle.dump(attention_layer, open(\"attention_post_selfharm53.pkl\", \"wb+\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = load_saved_model(\"models/lstm_depression_hierarchical52\", hyperparams_collection[key])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(range(0, len(scores_per_iteration[:15])*hyperparams_collection[key]['posts_per_group'], hyperparams_collection[key]['posts_per_group']), \n",
    "         scores_per_iteration[:15])\n",
    "plt.xlabel(\"Posts offset\")\n",
    "plt.ylabel(\"AUC\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# attention_user = [v for v in models_collection[key].get_layer('attention_user').get_activations()[0].flatten()]\n",
    "l = models_collection[key].get_layer('attention_user')\n",
    "# l.activation(samplegenerator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_per_iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for e in nrc_lexicon:\n",
    "    print(e)\n",
    "    print(nrc_lexicon[e].intersection(set(tokenize(text.lower()))))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save_model_and_params(cur_model, 'models/lstm_selfharm_seq16_2', hyperparams, hyperparams_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# models_collection = {}\n",
    "# hyperparams_collection = {}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Series([v for v in models_collection[key].get_layer('attention_user').get_weights()[0].flatten()]).rolling(10\n",
    "                                                                                                             ).mean().plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Series([v for v in models_collection[key].get_layer('attention_user').get_weights()[0].flatten()]).abs().rolling(10\n",
    "                                                                                                             ).mean().plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.Series([v for v in models_collection[key].get_layer('attention_user').get_weights()[0].flatten()]).to_csv(\n",
    "#     'attention_user_weights_lstm_selfharm_erisk_all_1group.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Series([v for v in models_collection[key].get_layer('attention').get_weights()[0].flatten()]).rolling(5).mean().plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Series([abs(v) for v in models_collection[key].get_layer('output_layer').get_weights()[0].flatten()]).plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d1, d2 = initialize_datasets(user_level_data, subjects_split, hyperparams, hyperparams_features, \n",
    "                        validation_set='valid', session=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "writings_df.source"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Attention and predictions analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_nr = 56\n",
    "model_name = \"models/lstm_%s_hierarchical53\" % dataset_type\n",
    "hyperparams, _ = load_params(model_name)\n",
    "model = load_saved_model(model_name, hyperparams)\n",
    "auc_per_iteration = pickle.load(open(\"auc_per_iteration_depression53.pkl\", \"rb\"))\n",
    "f1_per_iteration = pickle.load(open(\"f1_per_iteration_depression53.pkl\", \"rb\"))\n",
    "predictions_per_iteration = pickle.load(open(\"predictions_per_iteration_depression53.pkl\", \"rb\"))\n",
    "attention_user = pickle.load(open(\"attention_user_depression53.pkl\", \"rb\"))\n",
    "attention_layer = pickle.load(open(\"attention_post_depression53.pkl\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Series(attention_user).rolling(10).mean().plot()\n",
    "plt.ylabel(\"Attention weight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Series([abs(l[0]) for l in attention_layer]).rolling(50).mean().plot()\n",
    "plt.ylabel(\"Attention weight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = range(0, min(len(auc_per_iteration)*hyperparams['posts_per_group'], 2000), \n",
    "                      hyperparams['posts_per_group'])\n",
    "pd.Series(auc_per_iteration, \n",
    "          index=index\n",
    "                                                                    ).rolling(5).mean().plot()\n",
    "plt.xlabel(\"Posts offset\")\n",
    "plt.ylabel(\"AUC\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[l.shape for l in model.get_layer('user_encoder').get_weights()]\n",
    "# hyperparams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(model.get_layer('attention_user').get_weights()[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[(l.name, len(l.get_weights()), len(l.get_weights()[0]) if len(l.get_weights()) else 0) for l in model.layers]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[(len(l), len(l[0]) if len(l) and type(l[0])==list else 0) for \n",
    " l in model.get_layer('user_encoder').get_weights()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "userl = model.get_layer('user_encoder').layer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "userl.get_layer('lstm_user').get_weights()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_weights = userl.get_layer(index=3).get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_weights[1].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Attention activations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_nr=101\n",
    "# dataset_type = \"anorexia\"\n",
    "\n",
    "hyperparams = json.load(open(\"models/lstm_%s_hierarchical%d.hp.json\" % (dataset_type, model_nr)))\n",
    "\n",
    "if 'optimizer' not in hyperparams:\n",
    "    hyperparams['optimizer'] = optimizers.Adam(lr=hyperparams['lr'], #beta_1=0.9, beta_2=0.999, epsilon=0.0001,\n",
    "                                   decay=hyperparams['decay'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_model = build_hierarchical_model(hyperparams, hyperparams_features, embedding_matrix, \n",
    "                                         emotions, stopword_list, liwc_categories,\n",
    "                       ignore_layer=hyperparams['ignore_layer'], activations=False)\n",
    "original_model.load_weights(\"models/lstm_%s_hierarchical%d\" % (dataset_type, model_nr) + '_weights.h5', by_name=True)\n",
    "\n",
    "activation_model_user = build_hierarchical_model(hyperparams, hyperparams_features, embedding_matrix, \n",
    "                                         emotions, stopword_list, liwc_categories,\n",
    "                       ignore_layer=hyperparams['ignore_layer'], activations='attention_user')\n",
    "# activation_model_user.load_weights(\"models/lstm_%s_hierarchical%d\"  % (dataset_type, model_nr) + '_weights.h5', by_name=True)\n",
    "\n",
    "user_representation_model = build_hierarchical_model(hyperparams, hyperparams_features, embedding_matrix, \n",
    "                                         emotions, stopword_list, liwc_categories,\n",
    "                       ignore_layer=hyperparams['ignore_layer'], activations='output_layer')\n",
    "user_representation_model.load_weights(\"models/lstm_%s_hierarchical%d\"  % (dataset_type, model_nr) + '_weights.h5', by_name=True)\n",
    "\n",
    "\n",
    "activation_model = build_hierarchical_model(hyperparams, hyperparams_features, embedding_matrix, \n",
    "                                         emotions, stopword_list, liwc_categories,\n",
    "                       ignore_layer=hyperparams['ignore_layer'], activations='attention')\n",
    "# activation_model.load_weights(\"models/lstm_%s_hierarchical%d\" % (dataset_type, model_nr) + '_weights.h5', by_name=True)\n",
    "\n",
    "\n",
    "\n",
    "# activation_outputs = [layer.output for layer in original_model.layers]\n",
    "# activation_model = tf.keras.Model(inputs, activation_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_representation_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_subjects = list(set(writings_df[writings_df['label']==1].subject))\n",
    "negative_subjects = list(set(writings_df[writings_df['label']==0].subject)) #[:len(positive_subjects)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(positive_subjects), len(negative_subjects))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# subji = 15\n",
    "subjects_split_test_positive = {'test':\n",
    "                                 [s for s in subjects_split['test'] if s in positive_subjects][:]}\n",
    "subjects_split_test_negative = {'test':\n",
    "                                 [s for s in subjects_split['test'] if s in negative_subjects][:]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samplegenerator_positive = DataGenerator(user_level_data, subjects_split_test_positive, \n",
    "                                     set_type='test', \n",
    "                                   hierarchical=True,\n",
    "                                seq_len=hyperparams['maxlen'], #batch_size=hyperparams['batch_size'],\n",
    "                                batch_size=1,\n",
    "                                max_posts_per_user=None,\n",
    "                                   pad_with_duplication=False,\n",
    "                                    posts_per_group=hyperparams['posts_per_group'],\n",
    "#                                     post_groups_per_user=None, \n",
    "                                    post_groups_per_user=1, \n",
    "                                     sample_seqs=False, shuffle=False)\n",
    "samplegenerator_negative = DataGenerator(user_level_data, subjects_split_test_negative, \n",
    "                                     set_type='test', \n",
    "                                   hierarchical=True,\n",
    "                                seq_len=hyperparams['maxlen'], #batch_size=hyperparams['batch_size'],\n",
    "                                batch_size=1,\n",
    "                                max_posts_per_user=None,\n",
    "                                   pad_with_duplication=False,\n",
    "                                    posts_per_group=hyperparams['posts_per_group'],\n",
    "#                                     post_groups_per_user=None, \n",
    "                                    post_groups_per_user=1, \n",
    "                                     sample_seqs=False, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(samplegenerator_positive), len(samplegenerator_negative))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### T2 encodings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "writings_df_t2=pickle.load(open('data/writings_df_T2_liwc.pkl', 'rb'))\n",
    "# writings_df_t2=pickle.load(open('data/writings_df_t2_test_liwc.pkl', 'rb'))\n",
    "user_level_data_t2, subjects_split_t2, vocabulary = load_erisk_data(writings_df_t2, \n",
    "                                                            voc_size=hyperparams_features['max_features'],\n",
    "                                                           emotion_lexicon=nrc_lexicon,\n",
    "                                                           emotions=emotions,\n",
    "                                                           user_level=hyperparams_features['user_level'],\n",
    "                                                                                logger=logger,\n",
    "#                                                            vocabulary=pickle.load(open('vocabulary_40K_all.pkl', 'rb')),\n",
    "#                                                            vocabulary=pickle.load(open('vocab_clpsych_10000.pkl', 'rb')),\n",
    "                                                              vocabulary=vocabulary_dict,\n",
    "                                                              by_subset=True,\n",
    "                                                              labelcol = 'anx',\n",
    "#                                                               label_index={'depression':1, \"ptsd\":0}\n",
    "                                                                               )\n",
    "subjects_split_t2['test'] += subjects_split_t2['train']+subjects_split_t2['valid']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_embeddings_per_subject = {}\n",
    "for subject in subjects_split_t2['test']:\n",
    "    samplegenerator_t2 = DataGenerator(user_level_data_t2, {'test':[subject]}, \n",
    "                                     set_type='test', \n",
    "                                   hierarchical=True,\n",
    "                                seq_len=hyperparams['maxlen'], #batch_size=hyperparams['batch_size'],\n",
    "                                batch_size=1,\n",
    "                                max_posts_per_user=None,\n",
    "                                   pad_with_duplication=False,\n",
    "                                    posts_per_group=hyperparams['posts_per_group'],\n",
    "#                                     post_groups_per_user=None, \n",
    "                                    post_groups_per_user=None, \n",
    "                                     sample_seqs=False, shuffle=False)\n",
    "    print(subject, len(samplegenerator_t2))\n",
    "    user_embeddings_per_subject[subject] = user_representation_model.predict(samplegenerator_t2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(user_embeddings_per_subject, open('user_embeddings_t2_2020_model101.pkl', 'wb+'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_representation_model.predict(samplegenerator_t2).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Attention analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "attention_words_positive = activation_model.predict(samplegenerator_positive)\n",
    "attention_words_negative = activation_model.predict(samplegenerator_negative)\n",
    "predictions_positive = original_model.predict(samplegenerator_positive)\n",
    "predictions_negative = original_model.predict(samplegenerator_negative)\n",
    "attention_positive_user = activation_model_user.predict(samplegenerator_positive)\n",
    "attention_negative_user = activation_model_user.predict(samplegenerator_negative)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_negative.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(samplegenerator_positive), len(samplegenerator_negative), \n",
    "      predictions_positive.shape, predictions_negative.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "writings_df[writings_df['subject']==subjects_split_test_positive['test'][0]][['text']].head()\n",
    "# writings_df[writings_df['subject']==subjects_split_test_negative['test'][0]][['text']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(predictions_negative.shape, attention_words_negative.shape, attention_negative_user.shape)\n",
    "print(predictions_negative.sum(), attention_words_negative.sum(axis=2), attention_negative_user.sum(axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "attention_positive_user.shape\n",
    "# len(writings_df[writings_df['subject']==subjects_split_test_positive['test'][2]])\n",
    "len(predictions_positive)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_word_scores(writings_df, subjects, generator, predictions, attention_user, attention_words, \n",
    "                      words_scores=None, nr_words=None, users=None):\n",
    "    unk = \" \"\n",
    "    if not words_scores:\n",
    "        words_scores = {t:0 for t in vocabulary_list}\n",
    "        words_scores_all = {t:[] for t in vocabulary_list}\n",
    "        nr_words = {t:0 for t in vocabulary_list}\n",
    "        words_scores[unk] = 0\n",
    "        words_scores_all[unk] = []\n",
    "        nr_words[unk] = 0\n",
    "    highlighted_texts = []\n",
    "    # NOTE: I am considering only first post group for each subject?\n",
    "    for i in range(len(predictions)):\n",
    "        if users and i not in users:\n",
    "            continue\n",
    "#         if predictions[i]<0.8:\n",
    "#             continue\n",
    "#         if i%57!=0:\n",
    "#             continue\n",
    "    #     if predictions_positive_user[i].mean() < 0.02:\n",
    "    #         continue\n",
    "#         sampletexts = writings_df[writings_df['subject']==subjects[i]][['tokenized_text']].values\n",
    "        post_lengths = []\n",
    "        for p in range(50):\n",
    "#             if  abs(attention_user[i][p]) < 0.05:\n",
    "#                 continue\n",
    "            print(i, p)\n",
    "            post_tokens = generator[i][0][0][0][p]\n",
    "            post_len = sum(post_tokens!=0)\n",
    "            post_lengths.append(post_len)\n",
    "            nr_posts = 50\n",
    "            if post_len == 0:\n",
    "                nr_posts -= 1\n",
    "                continue\n",
    "#             print(\"post len\", post_len, list(enumerate([vocabulary_list[j] if (j!=0 and j<len(vocabulary_list)) else \" \"\n",
    "#                           for j in post_tokens ])))\n",
    "            post_with_weights = [(k, tok, round(attention_words[i][p][k], 10)) \n",
    "                                 for (k, tok) in list(\n",
    "                enumerate([vocabulary_list[j] if (j!=0 and j<len(vocabulary_list)) else unk\n",
    "                          for j in post_tokens ]))]\n",
    "            highlighted_text = [(\">>>\", attention_user[i][p])]\n",
    "            for (pos, tok, att) in post_with_weights:\n",
    "                score = att * attention_user[i][p] * post_len\n",
    "                words_scores[tok] += score\n",
    "                words_scores_all[tok].append(score)\n",
    "                highlighted_text.append((tok,score))\n",
    "                nr_words[tok] += 1\n",
    "#             print(post_with_weights)\n",
    "            highlighted_texts.append(highlighted_text)\n",
    "            \n",
    "            print(\"post len\", post_len, \"nr posts\", nr_posts)\n",
    "        #     print([list(enumerate([t for t in sampletexts[-3:]])))\n",
    "            print(\"user attention\", attention_user[i][p], \"avg word attention\", attention_words[i][p].mean())\n",
    "            print(\"prediction\", predictions[i])\n",
    "            \n",
    "            pd.Series(attention_words[i][p]).plot(label=\"%d_%d\" %(i, p))\n",
    "#             pd.Series(attention_positive_user[i]).plot()\n",
    "#         plt.scatter(np.exp(attention_user[i]), post_lengths)\n",
    "#         plt.scatter(attention_words[i].mean(axis=1), post_lengths)\n",
    "    words_scores = {w: s/nr_words[tok] for (w,s) in words_scores.items()}\n",
    "    plt.legend()\n",
    "    return words_scores, words_scores_all, highlighted_texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "words_scores_positive, words_scores_positive_all, highlighted_texts = build_word_scores(writings_df, subjects_split_test_positive['test'], samplegenerator_positive,\n",
    "                                 predictions_positive, attention_positive_user, attention_words_positive,\n",
    "                                                            users=[2,3,5,7,88,99,44,66])\n",
    "\n",
    "words_scores_negative, words_scores_negative_all, highlighted_texts_negative = build_word_scores(writings_df, subjects_split_test_negative['test'], samplegenerator_negative,\n",
    "                                 predictions_negative, attention_negative_user, attention_words_negative,\n",
    "                                                                     users=[2,4,7])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_highlighted_html(texts):\n",
    "    htmltext = \"\"\"\"<html> \"\"\"\n",
    "    for text in texts:\n",
    "        for i, (tok, score) in enumerate(text):\n",
    "            if i==0:\n",
    "                htmltext += '<span style=\"background-color: rgba(200,0,0,%f)\"> %s </span>' % (20*abs(score), tok)\n",
    "            else:\n",
    "                htmltext += '<span style=\"background-color: rgba(0,0,200,%f)\"> %s </span>' % (10*abs(score), tok)\n",
    "        \n",
    "#         htmltext += \"</span>  <br> \\n\"\n",
    "        htmltext += \" <br> \\n\"\n",
    "    htmltext += \"\"\"</html>\"\"\"\n",
    "    return htmltext\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%html\n",
    "from IPython.display import display, Markdown\n",
    "display(Markdown(generate_highlighted_html(highlighted_texts)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted(words_scores_negative.items(), key=lambda i: -abs(i[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word = 'i'\n",
    "print(pd.Series(words_scores_positive_all[word]).describe(), pd.Series(words_scores_negative_all[word]).describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Series(words_scores_negative_all[word]).hist(bins=20, label=\"not self-harming\", alpha=0.7)\n",
    "pd.Series(words_scores_positive_all[word]).hist(bins=20, label=\"self-harming\", alpha=0.7)\n",
    "plt.xlabel('attention weights')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Series(np.concatenate([attention_positive_user,attention_negative_user]).mean(axis=0)).plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Series(np.concatenate([attention_positive_user]).mean(axis=0)).plot(label=\"depressed\")\n",
    "pd.Series(np.concatenate([attention_negative_user]).mean(axis=0)).plot(label=\"not depressed\")\n",
    "plt.ylabel(\"attention weights for user encoder\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Series(attention_words_positive.mean(axis=(1,0))).plot(label=\"depressed\")\n",
    "pd.Series(attention_words_negative.mean(axis=(1,0))).plot(label=\"not depressed\")\n",
    "plt.ylabel(\"attention weights for post encoder\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for word in vocabulary_list:\n",
    "    if not words_scores_negative[word]:\n",
    "#         if words_scores_positive[word]:\n",
    "#             print(word)\n",
    "        continue\n",
    "    if not words_scores_positive[word]:\n",
    "        continue\n",
    "    if pd.Series(words_scores_positive_all[word]).mean()/pd.Series(words_scores_negative_all[word]).mean() > 5:\n",
    "        print(word)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Output layer analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_representations = user_representation_model.predict(samplegenerator_positive)\n",
    "negative_representations = user_representation_model.predict(samplegenerator_negative)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(abs(positive_representations.mean(axis=0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components=2)\n",
    "# pca.fit_transform(positive_representations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(positive_representations.shape, negative_representations.shape,\n",
    "      np.concatenate([positive_representations, negative_representations[:len(positive_representations)]]).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_examples = np.concatenate([positive_representations, \n",
    "                                    negative_representations[:len(positive_representations)]])\n",
    "# making them balanced\n",
    "pca.fit_transform(training_examples)\n",
    "positive_reduced = pca.transform(positive_representations)\n",
    "negative_reduced = pca.transform(negative_representations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'axes.labelsize': 16,\n",
    "          'axes.titlesize': 16,\n",
    "          'legend.fontsize': 16,\n",
    "         'xtick.labelsize': 16,\n",
    "         'ytick.labelsize': 16}\n",
    "plt.rcParams.update(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter([x for x,y in negative_reduced], [y for x,y in negative_reduced], c='g', alpha=0.5, s=5, label='negative')\n",
    "\n",
    "plt.scatter([x for x,y in positive_reduced], [y for x,y in positive_reduced], c='r', alpha=0.5, s=5, label='positive')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "def plot_kde(positives, negatives):\n",
    "    graph = sns.jointplot([x for x,y in positives], [y for x,y in positives],\n",
    "                     cmap=\"Reds\", kind=\"kde\", marginal_kws={\"color\":\"r\", \"alpha\":.2}, shade=True, \n",
    "                          shade_lowest=False, alpha=.5)\n",
    "    graph.x = [x for x,y in negatives]\n",
    "    graph.y = [y for x,y in negatives]\n",
    "    graph.plot_joint(sns.kdeplot, cmap=\"Blues\", shade=True, shade_lowest=False, alpha=.5)\n",
    "    graph.plot_marginals(sns.kdeplot, color='b', shade=True, alpha=.2, legend=False)\n",
    "    ax = plt.gca()\n",
    "\n",
    "\n",
    "    ax.legend([\"positive\", \"negative\"])\n",
    "\n",
    "plot_kde(positive_reduced, negative_reduced)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<html> <mark> text </mark> more\n",
    "\n",
    "<span style=\"background-color: rgba(0,0,200,0.2)\">This text is highlighted in yellow.</span>\n",
    "</html>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plotting by LIWC features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "liwc_features_positive = []\n",
    "liwc_features_negative = []\n",
    "for i, subject in enumerate(subjects_split_test_positive['test']):\n",
    "    liwc_features_positive.extend(user_level_data[subject]['liwc'])\n",
    "for i, subject in enumerate(subjects_split_test_negative['test']):\n",
    "    liwc_features_negative.extend(user_level_data[subject]['liwc'])\n",
    "\n",
    "pcaliwc = PCA(n_components=2)\n",
    "pcaliwc.fit_transform(liwc_features_positive+liwc_features_negative)\n",
    "liwc_reduced_positive = pcaliwc.transform(liwc_features_positive)\n",
    "liwc_reduced_negative = pcaliwc.transform(liwc_features_negative)\n",
    "\n",
    "plot_kde(liwc_reduced_positive, liwc_reduced_negative)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "\n",
    "kmeans = KMeans(n_clusters=2, random_state=0).fit(training_examples)\n",
    "\n",
    "kmeans.predict(np.array(negative_representations[:10]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans = KMeans(n_clusters=2, random_state=0).fit(positive_representations)\n",
    "positive_clusters = kmeans.predict(np.array(positive_representations))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_clusters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes=1\n",
    "hyperparams_loaded = json.load(open('%s.hp.json' % hyperparams_features['pretrained_model_path']))\n",
    "if 'optimizer' not in hyperparams_loaded:\n",
    "    hyperparams_loaded['optimizer'] = optimizers.Adam(lr=hyperparams_loaded['lr'], #beta_1=0.9, beta_2=0.999, epsilon=0.0001,\n",
    "                                   decay=hyperparams_loaded['decay'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyperparams_loaded = hyperparams_collection[key]\n",
    "hyperparams_features['pretrained_model_path']\n",
    "# hyperparams_collection[key] = hyperparams_loaded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_collection = {}\n",
    "key='lstm_seq'\n",
    "# hyperparams_loaded['trainable_embeddings']=True\n",
    "models_collection[key] = load_saved_model_weights(hyperparams_features['pretrained_model_path'], \n",
    "                                                      hyperparams_loaded, \n",
    "                                                      emotions, stopword_list, liwc_categories, classes=classes, \n",
    "                                                      h5=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# models_collection[key].get_output_at?\n",
    "# combined_model = models_collection[key]\n",
    "writings_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%time\n",
    "all_predictions = {}\n",
    "# for subject in set(writings_df[writings_df['subset']=='test'].subject.values):\n",
    "for subject in set(subjects_split['test']):\n",
    "    all_predictions[subject] = {'true_label': None, 'predicted_label': None,\n",
    "                               'predicted_score': None, 'texts': None}\n",
    "    try:\n",
    "        user_level_data_subject = {subject: user_level_data[subject]}\n",
    "    except:\n",
    "        continue\n",
    "    if classes==1:\n",
    "        true_label = writings_df[writings_df['subject']==subject].label.values[0]\n",
    "    else:\n",
    "        true_label = user_level_data[subject]['label']\n",
    "#         true_label = label_index[user_level_data[subject]['condition']]\n",
    "    print(subject, \"Label\", true_label)\n",
    "    prediction = models_collection[key].predict(DataGenerator(user_level_data_subject, {'test':[subject]}, \n",
    "                                         set_type='test', \n",
    "                                    seq_len=hyperparams_loaded['maxlen'],   \n",
    "#                                         batch_size=len(subjects_split['test']), # on all data at once\n",
    "                                        batch_size=hyperparams_loaded['batch_size'], # on all data at once\n",
    "                                       hierarchical=hyperparams_loaded['hierarchical'],\n",
    "                                         max_posts_per_user=None,\n",
    "                                       pad_with_duplication=False,\n",
    "                                        posts_per_group=hyperparams_loaded['posts_per_group'],\n",
    "                                        post_groups_per_user=1,  compute_liwc=True,\n",
    "                                        liwc_words_for_categories=liwc_words_for_categories,\n",
    "                                         sample_seqs=False, shuffle=False), verbose=1)\n",
    "    if classes==1:\n",
    "        model_prediction = int(prediction[0][0]>=0.5)\n",
    "    else:\n",
    "        model_prediction = np.argmax(prediction[0])\n",
    "    print(\"Prediction: \", prediction[0], model_prediction)\n",
    "    # TODO: is this aggregation of texts correct?\n",
    "    if (true_label!=model_prediction):\n",
    "        print(\"Misclassification:\", len(\n",
    "            user_level_data_subject[subject]['raw']), \"words\")\n",
    "    all_predictions[subject]['true_label'] = true_label\n",
    "    all_predictions[subject]['predicted_label'] = model_prediction\n",
    "    all_predictions[subject]['predicted_score'] = prediction[0][0]\n",
    "    all_predictions[subject]['texts'] = \"\\n\".join(\n",
    "            user_level_data_subject[subject]['raw'][:hyperparams_loaded['posts_per_group']])\n",
    "    all_predictions[subject]['liwc'] = user_level_data_subject[subject]['liwc'][\n",
    "        :hyperparams_loaded['posts_per_group']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_df = pd.DataFrame.from_dict(all_predictions, orient='index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predictions_df = pickle.load(open('predictions_df_depression_erisk_lstmhierarch56.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_df['misclass'] = abs(predictions_df['true_label'] - predictions_df['predicted_label'])\n",
    "predictions_df['misclass'] = predictions_df['misclass'].apply(lambda x: 0 if x==0 else 1)\n",
    "predictions_df['misclass_signed'] = predictions_df['true_label'] - predictions_df['predicted_label']\n",
    "predictions_df[predictions_df['misclass']==1].predicted_score.describe()\n",
    "# predictions_df[predictions_df['misclass_signed']==-1].predicted_score.describe()\n",
    "# predictions_df[predictions_df['misclass']==0].predicted_score.describe()\n",
    "# predictions_df[predictions_df['misclass']==1].mean()\n",
    "# predictions_df[predictions_df['misclass']==0].mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_df.groupby(['misclass_signed', 'true_label']).count().predicted_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sorted(Counter(tokenize(\"\\n\".join(predictions_df[predictions_df['misclass']==1].texts.values))).items(), key=lambda t: -t[1])[:50])\n",
    "print(sorted(Counter(tokenize(\"\\n\".join(predictions_df[predictions_df['misclass']==0].texts.values))).items(), key=lambda t: -t[1])[:50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.feature_selection import SelectKBest, chi2\n",
    "col = 'misclass'\n",
    "target_val = 1\n",
    "counter_val = None\n",
    "\n",
    "misclassified_texts = \"\\n\".join(predictions_df[predictions_df[col]==target_val].texts.values)\n",
    "if counter_val is None:\n",
    "    correct_texts = \"\\n\".join(predictions_df[predictions_df[col]!=target_val].texts.values)\n",
    "else:\n",
    "    correct_texts = \"\\n\".join(predictions_df[predictions_df[col]==counter_val].texts.values)\n",
    "vectorizer = TfidfVectorizer(tokenizer=tokenize_tweets)\n",
    "term_doc=vectorizer.fit_transform([misclassified_texts, correct_texts])\n",
    "ch2 = SelectKBest(chi2, \"all\")\n",
    "X_train = ch2.fit_transform(term_doc, [1,0])\n",
    "\n",
    "scores = ch2.scores_\n",
    "pvalues = ch2.pvalues_\n",
    "words = vectorizer.get_feature_names()\n",
    "features_sorted = sorted([(words[i], scores[i]) for i in range(len(scores))], key=lambda t:t[1], reverse=True)\n",
    "\n",
    "print(features_sorted[:12])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_df['liwc_avg'] = predictions_df['liwc'].apply(lambda x: np.mean(x, axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, c in enumerate(categories):\n",
    "    predictions_df[c] = predictions_df['liwc_avg'].apply(lambda x: x[i])\n",
    "# TODO: compute emotions here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_df=predictions_df[~predictions_df.isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predictions_df = pickle.load(open('predictions_df_depression_clpsych.pkl','rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "liwc_words_for_categories = {}\n",
    "for categ in liwc_dict.keys():\n",
    "    liwc_words_for_categories[categ] = set()\n",
    "    for word in liwc_dict[categ]:\n",
    "        for t in vocabulary:\n",
    "            if t==word or (word[-1]=='*' and t.startswith(word[:-1])) \\\n",
    "                or (t==word.split(\"'\")[0]):\n",
    "                    liwc_words_for_categories[categ].add(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "liwc_words_for_categories.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_df['all_tokens'] = predictions_df['texts'].apply(tokenize)\n",
    "\n",
    "# TODO: include the title\n",
    "def extract_emotions(tokens, emotion, relative=True):\n",
    "    if not tokens:\n",
    "        return None\n",
    "    emotion_words = [t for t in tokens \n",
    "                     if t in nrc_lexicon[emotion]]\n",
    "    if relative and len(tokens):\n",
    "        return len(emotion_words) / len(tokens)\n",
    "    else:\n",
    "        return len(emotion_words)\n",
    "    \n",
    "    return encoded_emotions\n",
    "\n",
    "from functools import partial\n",
    "for emotion in emotions:\n",
    "    predictions_df[emotion] = predictions_df['all_tokens'].apply(partial(extract_emotions, emotion=emotion, \n",
    "                                                                   relative=True))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_liwc_categories(tokens, category_words, relative=True):\n",
    "    category_cnt = 0\n",
    "    if not tokens:\n",
    "        return None\n",
    "    text_len = len(tokens)\n",
    "    for t in tokens:\n",
    "        for word in category_words:\n",
    "            if t==word or (word[-1]=='*' and t.startswith(word[:-1])) \\\n",
    "            or (t==word.split(\"'\")[0]):\n",
    "                category_cnt += 1\n",
    "                break # one token cannot belong to more than one word in the category\n",
    "    if relative:\n",
    "        return category_cnt/text_len\n",
    "    else:\n",
    "        return category_cnt\n",
    "\n",
    "for categ in liwc_dict.keys():\n",
    "    if categ in predictions_df.columns:\n",
    "        continue\n",
    "    print(\"Encoding for category %s...\" % categ)\n",
    "    predictions_df[categ] = predictions_df['all_tokens'].apply(partial(encode_liwc_categories, \n",
    "                                                                   category_words=liwc_dict[categ], \n",
    "                                                                   relative=True))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def barplot_pvalues(categories_pscores, width=3, bar_width=None, yticks_freq=1, show_pval=False, \n",
    "                    yticks_start=1, angle=45, group_labels=None, logy=False, nr_bars=4):\n",
    "    \n",
    "    nr_bars = len(categories_pscores)\n",
    "    categories_pscores_aggregated = []\n",
    "    categories = set([t[0] for t in categories_pscores])\n",
    "#     for cat in categories:\n",
    "#         if aggreg=='mean':\n",
    "#             # Compute mean\n",
    "#             for c, v in categories_pscores:\n",
    "#                 s = 0\n",
    "#                 l = 0\n",
    "#                 if c==cat:\n",
    "#                     s += v\n",
    "#                     l += 1\n",
    "#             m = s/l\n",
    "#             categories_pscores_aggregated.append((cat, m))\n",
    "#         if aggreg=='group':\n",
    "#             for c, v in categories_pscores:\n",
    "#                 if c==cat:\n",
    "#                     categories_pscores_aggregated.append()\n",
    "    if type(categories_pscores) is list:\n",
    "        categories_pscores_aggregated = [categories_pscores]\n",
    "        labels = ['misclassif']\n",
    "    if type(categories_pscores) is dict:\n",
    "        labels = []\n",
    "        for group, scores in categories_pscores.items():\n",
    "            categories_pscores_aggregated.append(scores)\n",
    "            labels.append(group)\n",
    "#     if not bar_width:\n",
    "    bar_width = 1/(nr_bars+1) * width\n",
    "#         bar_width = 2/3 * width\n",
    " \n",
    "    positions = []\n",
    "    for i,scores in enumerate(categories_pscores_aggregated):\n",
    "        print(\"plotting\", labels[i], len(scores))\n",
    "        if len(positions)==0:\n",
    "            positions =  np.arange(0, len(scores) * width, width)\n",
    "        else:\n",
    "            positions = [x + bar_width for x in positions]\n",
    "        plt.bar(\n",
    "            positions,\n",
    "#            x = np.arange(0, len(scores) * width, width),\n",
    "            height=[s for (e,s) in scores], width=bar_width, align='edge', label=labels[i], edgecolor='white')\n",
    "    if show_pval:\n",
    "        plt.hlines(0.05, 0,width*nr_bars, linestyles=':', colors='red')\n",
    "    if logy:\n",
    "        plt.yscale('log')\n",
    "    plt.xticks(ticks=range(int(bar_width*2), width*len(scores), width), \n",
    "               labels=[e[:] for e,p in scores], rotation=angle)\n",
    "    if logy:\n",
    "#         plt.yticks(ticks=[10**i for i in range(-yticks_start,int(np.log10(min([p for (e,p) in scores])))\n",
    "#                                                ,-yticks_freq)] + [0.05],\n",
    "#             labels=[10**i for i in range(-yticks_start,int(np.log10(min([p for (e,p) in scores]))),\n",
    "#                                      -yticks_freq)],# + [0.05], \n",
    "#                )\n",
    "        plt.ylim(0,0.1)\n",
    "    else:\n",
    "#         plt.yticks(ticks=[10**i for i in range(-yticks_start,1,\n",
    "#                                                -yticks_freq)],\n",
    "#                    labels=[10**i for i in range(-yticks_start,1,\n",
    "#                                                -yticks_freq)]\n",
    "#                )\n",
    "        plt.ylim(0,0.1)\n",
    "#         plt.yticks(ticks=[10**i for i in range(-yticks_start,int(min([p for (e,p) in scores]))\n",
    "#                                                ,-yticks_freq)] + [0.05],\n",
    "#             labels=[10**i for i in range(-yticks_start,int(min([p for (e,p) in scores])),\n",
    "#                                      -yticks_freq)], # + [0.05], \n",
    "#                )\n",
    "    # Add xticks on the middle of the group bars\n",
    "#     plt.xlabel(group, fontweight='bold')\n",
    "#     plt.xticks([r + barWidth for r in range(len(bars1))], ['A', 'B', 'C', 'D', 'E'])\n",
    "    plt.legend()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "barplot_pvalues([(\"first\", 0.001), (\"seco\", 0.01), (\"third\", 0.00001)], bar_width=0.5, logy=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for c in categories:\n",
    "    print(c, 'misclass', predictions_df[predictions_df['misclass']==1][c].mean())\n",
    "    print(c, 'not misclass', predictions_df[predictions_df['misclass']==0][c].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for c in emotions:\n",
    "    print(c, 'misclass', predictions_df[predictions_df['misclass']==1][c].mean())\n",
    "    print(c, 'not misclass', predictions_df[predictions_df['misclass']==0][c].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import pearsonr, ttest_ind\n",
    "for c in categories:\n",
    "    print(c)\n",
    "    print('\\tmisclass', predictions_df[predictions_df['misclass']==1][c].mean())\n",
    "    print('\\tnot misclass', predictions_df[predictions_df['misclass']==0][c].mean())    \n",
    "    ttest = ttest_ind(predictions_df[predictions_df['misclass']==0][c],\n",
    "                                  predictions_df[predictions_df['misclass']==1][c])\n",
    "    print('\\tttest', ttest)\n",
    "    print('\\tpvalue', ttest[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'axes.labelsize': 25,\n",
    "          'axes.titlesize': 25,\n",
    "          'legend.fontsize': 25,\n",
    "         'xtick.labelsize': 25,\n",
    "         'ytick.labelsize': 25}\n",
    "plt.rcParams.update(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import pearsonr, ttest_ind\n",
    "\n",
    "def retrieve_differences_misclass_groups(predictions_df, categories, pval_thresh=0.05,\n",
    "                                        width=5, bar_width=1, angle=60, false_cat=None):\n",
    "    categories_pscores = {'FN': [], 'FP': []}\n",
    "#     categories_means = {'FN': [], 'FP': [], 'TN': [], 'TP': []}\n",
    "    if false_cat == 'FN':\n",
    "        categories_means = {'FN': [], 'TP': []}\n",
    "        cols_filters = {'misclass_signed': [('misclass_signed', 1), ('true_label', 1)]}\n",
    "    elif false_cat == 'FP':\n",
    "        categories_means = {'FP': [], 'TN': []}\n",
    "        cols_filters = {'misclass_signed': [('misclass_signed', -1), ('true_label', 0)]}\n",
    "\n",
    "    else:\n",
    "#         categories_means = {'FN': [], 'TN': [], 'TP': [], 'FP': []}\n",
    "        categories_means = {'FN': [], 'TN': [], 'TP': [], 'FP': []}\n",
    "        cols_filters = {'misclass': [('misclass', 1)]}\n",
    "\n",
    "    cols_values = {'FN': [('misclass_signed', 1)], 'FP': [('misclass_signed', -1)], \n",
    "                   'TN': [('misclass', 0), ('true_label', 0)], 'TP': [('misclass', 0), ('true_label', 1)]}\n",
    "    \n",
    "    for c in categories:\n",
    "        significant = True\n",
    "        for group in cols_filters:\n",
    "            cols_filter = cols_filters[group]\n",
    "            if len(cols_filter)==1:\n",
    "                col, val = cols_filter[0]\n",
    "                print(col,val)\n",
    "                groupdf = predictions_df.query('%s == %d' % (col, val))[c]\n",
    "                nongroupdf = predictions_df.query('%s != %d' % (col, val))[c]\n",
    "\n",
    "            if len(cols_filter)==2:\n",
    "                col1, val1 = cols_filter[0]\n",
    "                col2, val2 = cols_filter[1]\n",
    "                groupdf = predictions_df.query('%s == %d' % (col1, val1))[c]\n",
    "                nongroupdf = predictions_df.query('%s == %d' % (col2, val2))[c]\n",
    "\n",
    "            ttest = ttest_ind(groupdf, nongroupdf)\n",
    "            if ttest[1] >= pval_thresh:\n",
    "                print(\"Not significant\", c)\n",
    "                significant = False\n",
    "        if not significant:\n",
    "            continue\n",
    "#         for group in cols_values:\n",
    "        for group in categories_means:\n",
    "            print(group)\n",
    "            cols_value = cols_values[group]\n",
    "\n",
    "            print(c)\n",
    "            if len(cols_value)==1:\n",
    "                col, val = cols_value[0]\n",
    "                groupdf = predictions_df.query('%s == %d' % (col, val))[c]\n",
    "                nongroupdf = predictions_df.query('%s != %d' % (col, val))[c]\n",
    "\n",
    "            if len(cols_value)==2:\n",
    "                col1, val1 = cols_value[0]\n",
    "                col2, val2 = cols_value[1]\n",
    "                groupdf = predictions_df.query('%s == %d & %s == %d' % (col1, val1, col2, val2))[c]\n",
    "                nongroupdf = predictions_df.query('%s != %d | %s != %d' % (col1, val1, col2, val2))[c]\n",
    "\n",
    "            if len(groupdf)==0:\n",
    "                print(\"Group\", group, \"is empty. Skipping...\")\n",
    "                categories_pscores[group].append((c,0.99))\n",
    "                categories_means[group].append((c,0.0))\n",
    "                continue\n",
    "            print('\\t', col, val, groupdf.mean())\n",
    "            print('\\tnon', col, val, nongroupdf.mean())    \n",
    "            ttest = ttest_ind(groupdf, nongroupdf)\n",
    "            print('\\tttest', ttest)\n",
    "            print('\\tpvalue', ttest[1])\n",
    "#             if group in ('FN', 'FP'):\n",
    "#                 categories_pscores[group].append((c,ttest[1]))\n",
    "#             if ttest[1] < 0.05:\n",
    "#                 categories_means[group].append((c,groupdf.mean()))\n",
    "#             else:\n",
    "            categories_means[group].append((c,groupdf.mean()))\n",
    "\n",
    "    # emotion_pscores = sorted(emotion_pscores, key=lambda t:t[1])\n",
    "#     barplot_pvalues(categories_pscores, 3, yticks_start=2, bar_width=bar_width, show_pval=True)\n",
    "    print(categories_means)\n",
    "    barplot_pvalues(categories_means, bar_width=10, width=10, angle=angle, nr_bars=len(categories_means), logy=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[e for e in emotions if e in predictions_df.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "retrieve_differences_misclass_groups(predictions_df, [e for e in emotions if e not in ['negative', 'positive']])\n",
    "#                                     false_cat='FN')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "retrieve_differences_misclass_groups(predictions_df, categories, \n",
    "#                                      pval_thresh=0.000001, \n",
    "#                                      pval_thresh=0.001, \n",
    "                                     width=5, bar_width=0.5, angle=90, false_cat='FP')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import pearsonr, ttest_ind\n",
    "for c in categories:\n",
    "    print(c)\n",
    "    print('\\tpositive', predictions_df[predictions_df['true_label']==1][c].mean())\n",
    "    print('\\tnegative', predictions_df[predictions_df['true_label']==0][c].mean())    \n",
    "    ttest = ttest_ind(predictions_df[predictions_df['true_label']==0][c],\n",
    "                                  predictions_df[predictions_df['true_label']==1][c])\n",
    "    print('\\tttest', ttest)\n",
    "    print('\\tpvalue', ttest[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import pearsonr, ttest_ind\n",
    "for c in categories:\n",
    "    print(c)\n",
    "    print('\\tpredicted positive', predictions_df[predictions_df['predicted_label']==1][c].mean())\n",
    "    print('\\tpredicted_negative', predictions_df[predictions_df['predicted_label']==0][c].mean())    \n",
    "    ttest = ttest_ind(predictions_df[predictions_df['predicted_label']==0][c],\n",
    "                                  predictions_df[predictions_df['predicted_label']==1][c])\n",
    "    print('\\tttest', ttest)\n",
    "    print('\\tpvalue', ttest[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import pearsonr, ttest_ind\n",
    "categories_pscores = []\n",
    "for c in categories:\n",
    "    print(c)\n",
    "    print('\\tmisclassified', predictions_df[predictions_df['misclass']==1][c].mean())\n",
    "    print('\\tnot misclassified', predictions_df[predictions_df['misclass']==0][c].mean())    \n",
    "    ttest = ttest_ind(predictions_df[predictions_df['misclass']==0][c],\n",
    "                                  predictions_df[predictions_df['misclass']==1][c])\n",
    "    print('\\tttest', ttest)\n",
    "    print('\\tpvalue', ttest[1])\n",
    "    if ttest[1] < 0.05:\n",
    "        categories_pscores.append((c,ttest[1]))\n",
    "print(sorted(categories_pscores, key=lambda t:t[1]))        \n",
    "barplot_pvalues(categories_pscores, width=1, show_pval=False, yticks_start=1, yticks_freq=1, angle=90, \n",
    "               bar_width=0.5)\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pickle.dump(predictions_df, open('predictions_df_depression_symanto_lstmhierarch64.pkl', 'wb+'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predictions_df = pickle.load(open('predictions_df_depression_erisk.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ROC Curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_predictions\n",
    "predictions_df.columns\n",
    "y_test = predictions_df.true_label.values\n",
    "y_score = predictions_df.predicted_score.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, auc\n",
    "fpr = dict()\n",
    "tpr = dict()\n",
    "roc_auc = dict()\n",
    "\n",
    "fpr, tpr, _ = roc_curve(y_test, y_score)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "# Compute micro-average ROC curve and ROC area\n",
    "# fpr[\"micro\"], tpr[\"micro\"], _ = roc_curve(y_test.ravel(), y_score.ravel())\n",
    "# roc_auc[\"micro\"] = auc(fpr[\"micro\"], tpr[\"micro\"])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lw = 2\n",
    "plt.plot(fpr, tpr, color='darkorange',\n",
    "         lw=lw, \n",
    "#          label = dataset_type)\n",
    "         label='ROC curve (area = %0.2f)' % roc_auc)\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver operating characteristic example')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word Cloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from wordcloud import WordCloud\n",
    "# misclassified_users = set(predictions_df[predictions_df['misclass']==1].subject)\n",
    "text = \"\"\n",
    "for tokens in writings_df[writings_df['label']==1].tokenized_text.values:\n",
    "    text += \" \".join(tokens) + \" \"\n",
    "# text = \" \".join(predictions_df[predictions_df['misclass_signed']==-1].texts)\n",
    "# Create and generate a word cloud image:\n",
    "wordcloud = WordCloud( background_color='white', max_words=1000, max_font_size=70).generate(text)\n",
    "\n",
    "# Display the generated image:\n",
    "plt.imshow(wordcloud, interpolation='bilinear')\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_tokenizer?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_saliency(loaded_model, pure_txt, text_class, pred_labels, text_sequence):\n",
    "    text_class = 'Positive' if text_class==1 else 'Negative'\n",
    "    pred_labels = 'Positive' if pred_labels==1 else 'Negative'\n",
    "\n",
    "    input_tensors = [loaded_model.input, K.learning_phase()]\n",
    "    model_input = loaded_model.layers[2].input # the input for convolution layer\n",
    "    model_output = loaded_model.output[0][1]\n",
    "    gradients = loaded_model.optimizer.get_gradients(model_output,model_input)\n",
    "    compute_gradients = K.function(inputs=input_tensors, outputs=gradients)\n",
    "    matrix = compute_gradients([text_sequence.reshape(1,30), text_class])[0][0]\n",
    "    matrix = matrix[:len(pure_txt),:]\n",
    "\n",
    "    matrix_magnify=np.zeros((matrix.shape[0]*10,matrix.shape[1]))\n",
    "    for i in range(matrix.shape[0]):\n",
    "        for j in range(10):\n",
    "            matrix_magnify[i*10+j,:]=matrix[i,:]\n",
    "\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(111)\n",
    "    plt.imshow(normalize_array(np.absolute(matrix_magnify)), interpolation='nearest', cmap=plt.cm.Blues)\n",
    "    plt.yticks(np.arange(5, matrix.shape[0]*10, 10), pure_txt, weight='bold',fontsize=24)\n",
    "    plt.xticks(np.arange(0, matrix.shape[1], 50), weight='bold',fontsize=24)\n",
    "    plt.title('True Label: \"{}\" Predicted Label: \"{}\"'.format(text_class,pred_labels), weight='bold',fontsize=24)\n",
    "    plt.colorbar()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot_saliency(models_collection[key], \"this is some text to classify\", 0, 0, [\"this\", \"is\", \"some\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_level_data3, subjects_split2, vocabulary = load_erisk_data(writings_df, \n",
    "                                                            voc_size=hyperparams_features['max_features'],\n",
    "                                                           emotion_lexicon=nrc_lexicon,\n",
    "                                                           emotions=[],\n",
    "                                                                liwc_categories=[],\n",
    "                                                           user_level=hyperparams_features['user_level'],\n",
    "                                                                                logger=logger,\n",
    "#                                                            vocabulary=pickle.load(open('vocabulary_40K_all.pkl', 'rb')),\n",
    "#                                                            vocabulary=pickle.load(open('vocab_clpsych_10000.pkl', 'rb')),\n",
    "                                                              vocabulary=vocabulary_dict,\n",
    "                                                              by_subset=False\n",
    "                                                                               )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "import lime.lime_text as lt\n",
    "import keras\n",
    "# my self written library\n",
    "import numpy as np\n",
    "\n",
    "# This is the text that I want to explain\n",
    "\n",
    "\n",
    "#\n",
    "# recodeText = pl.generate_one_hot(text=inputText, alphabet=alphabet, maxChars=maxChars)\n",
    "\n",
    "model = models_collection[key]\n",
    "\n",
    "\n",
    "\n",
    "# subjects = ['subject14410000', 'subject68010000', 'test_subject315', 'test_subject2270', \n",
    "#             'test_subject9306', 'test_subject9359']\n",
    "subjects = [s for s in set(writings_df.subject.values) if s in user_level_data3]\n",
    "labels = [writings_df[writings_df['subject']==subject].label.values[0] for subject in subjects]\n",
    "overall_importance_vocabulary = {}\n",
    "\n",
    "def textForSubject(subject):\n",
    "    user_level_data_subject = user_level_data3[subject]\n",
    "    text = \"\\n\".join([\" \".join(t) for t in user_level_data_subject['texts'][\n",
    "        :hyperparams_collection[key]['posts_per_group']]])\n",
    "    return text\n",
    "    \n",
    "# pipeline-like function\n",
    "# takes raw text as input, converts it to one-hot character vectors via the alphabet\n",
    "# feeds it into keras' model.predict() function to receive predictions\n",
    "# works for lists of text as well as for single strings\n",
    "# TODO: need to make this actually work on the text input, not dummy. it needs to feed new things\n",
    "def predictFromText(inputTexts):\n",
    "    if type(inputTexts) != list:\n",
    "        inputTexts = [inputTexts]\n",
    "    \n",
    "    # list for predictions\n",
    "    predStorage = []\n",
    "    # loop through input list and predict\n",
    "\n",
    "    predictions = models_collection[key].predict(DataGeneratorFromText(inputTexts,\n",
    "                                        seq_len=hyperparams_collection[key]['maxlen'],\n",
    "                                        liwc_words_for_categories=liwc_words_for_categories,\n",
    "#                                         emotions=[], liwc_categories=[]\n",
    "                                                             ), verbose=1)\n",
    "    for i, prediction in enumerate(predictions):\n",
    "        pred = int(prediction>=0.5)\n",
    "\n",
    "#         recodeText = pl.generate_one_hot(text=textInput, alphabet=alphabet, maxChars=maxChars)\n",
    "#         pred = model.predict(recodeText.transpose())\n",
    "        # control output of function\n",
    "#         print(\"TEXT\", str(inputTexts[i][:100]), \"PRED\", prediction, \"\\n\")\n",
    "        predStorage.append((1-prediction[0], prediction[0]))\n",
    "    return(np.asarray(predStorage))\n",
    "\n",
    "inputTexts = [textForSubject(subject) for subject in subjects]\n",
    "\n",
    "print(len(inputTexts))\n",
    "print(labels)\n",
    "\n",
    "# print(inputTexts)\n",
    "# print(predictFromText(inputTexts))\n",
    "# Lime Explainer\n",
    "# bow controls if words are perturbed or overwritten with UNKWORDZ\n",
    "# False makes sense, if location of words is important as in this classifier\n",
    "explainer = lt.LimeTextExplainer(\n",
    "#     kernel_width=25, \n",
    "    verbose=False, class_names=['not depressed', 'depressed'],\n",
    "#                            feature_selection=\"auto\", split_expression=\" \", bow=False\n",
    ")\n",
    "for i, inputText in enumerate(inputTexts):\n",
    "    print(\"EXPLAINING...\", i)\n",
    "    exp = explainer.explain_instance(text_instance=inputText, labels=(0,1), \n",
    "#                                      labels=[labels[i]],\n",
    "                         classifier_fn=predictFromText, \n",
    "                                     num_features=100, num_samples=1000\n",
    "                                    )\n",
    "    for word, weight in exp.as_list():\n",
    "        if word not in overall_importance_vocabulary:\n",
    "            overall_importance_vocabulary[word] = []\n",
    "        overall_importance_vocabulary[word].append(weight)\n",
    "    # this works, yields an array with probabilities for both classes\n",
    "    # print(predictFromText(textInputList = listTexts))\n",
    "    # print(len(predictFromText(inputTexts[0])), len(inputTexts))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted(user_level_data3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp.as_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "explainer.explain_instance?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp.as_pyplot_figure()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp.show_in_notebook()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "explainer.explain_instance?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "overall_importance_vocabulary_averages = {word: np.mean(overall_importance_vocabulary[word]) \n",
    "                                          for word in overall_importance_vocabulary \n",
    "                                          if len(overall_importance_vocabulary[word])>=2}\n",
    "overall_importance_vocabulary_averages_abs = {word: np.abs(np.mean(overall_importance_vocabulary[word])) \n",
    "                                              for word in overall_importance_vocabulary\n",
    "                                             if len(overall_importance_vocabulary[word])>=2}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted(overall_importance_vocabulary_averages_abs.items(), key=lambda t: t[1], reverse=True)[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[(t[0], np.mean(t[1]), len(t[1])) for t in \n",
    " sorted(overall_importance_vocabulary.items(), key=lambda t: len(t[1]), reverse=True)[:20]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for word, weight in sorted(overall_importance_vocabulary_averages_abs.items(), key=lambda t: t[1], reverse=True)[:20]:\n",
    "    print(word, overall_importance_vocabulary[word])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pickle.dump(overall_importance_vocabulary, open('overall_importance_vocabulary_depression.pkl', 'wb+'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# overall_importance_vocabulary = pickle.load(open('overall_importance_vocabulary_selfharm.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Series([len(overall_importance_vocabulary[w]) for w in overall_importance_vocabulary]).hist(log=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "explainer.explain_instance?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in DataGenerator(user_level_data3, {'test':[subject]}, \n",
    "                                         set_type='test', \n",
    "                                    seq_len=hyperparams_collection[key]['maxlen'],   \n",
    "#                                         batch_size=len(subjects_split['test']), # on all data at once\n",
    "                                        batch_size=hyperparams_collection[key]['batch_size'], # on all data at once\n",
    "                                       hierarchical=hyperparams_collection[key]['hierarchical'],\n",
    "                                         max_posts_per_user=None,\n",
    "                                       pad_with_duplication=False,\n",
    "                                        posts_per_group=hyperparams_collection[key]['posts_per_group'],\n",
    "                                        post_groups_per_user=1,  compute_liwc=True,\n",
    "                                        liwc_words_for_categories=liwc_words_for_categories,\n",
    "                                         sample_seqs=False, shuffle=False,\n",
    "                                        emotions=[], liwc_categories=[]\n",
    "                                                             ):\n",
    "    print(x)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2D visualization of emotions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "def normalize_date(date):\n",
    "        return \" \".join(date.strip().split())\n",
    "writings_df['datetime'] = writings_df.date.apply(lambda d: datetime.datetime.strptime(\n",
    "            normalize_date(d), '%Y-%m-%d %H:%M:%S'))\n",
    "date_cutoff1 = datetime.datetime.strptime('2010','%Y').date()\n",
    "date_cutoff2 = datetime.datetime.strptime('2020','%Y').date()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "users_emotions = writings_df[\n",
    "    writings_df['datetime'].between(date_cutoff1, date_cutoff2)\n",
    "].groupby('subject').mean()[list(categories) + emotions + ['label']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "emotions_dict=users_emotions.dropna().to_dict(orient='index')\n",
    "subjects = list(emotions_dict.keys())\n",
    "emotions_matrix=[list(emotions_dict[s].values())[:-1] for s in subjects]\n",
    "emotions_labels=[emotions_dict[s]['label'] for s in subjects]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=2)\n",
    "pca.fit(np.array(emotions_matrix).transpose())\n",
    "col = plt.scatter(pca.components_[0], pca.components_[1], c=['r' if l==1 else 'b' for l in emotions_labels],\n",
    "           s=[0.5 for s in emotions_labels])\n",
    "\n",
    "ax = col.axes\n",
    "handles, labels = ax.get_legend_handles_labels()\n",
    "\n",
    "import matplotlib.patches as mpatches\n",
    "\n",
    "\n",
    "# manually define a new patch \n",
    "handles.append(mpatches.Patch(color='red', label='anorexic users'))\n",
    "handles.append(mpatches.Patch(color='blue', label='non anorexic users'))\n",
    "\n",
    "\n",
    "# plot the legend\n",
    "plt.legend(handles=handles, loc='upper center')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment = initialize_experiment(hyperparams, nrc_lexicon_path, emotions, pretrained_embeddings_path, \n",
    "                          dataset_type, transfer_type)\n",
    "experiment.add_tag(\"cross-validation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folds = 5\n",
    "\n",
    "f1_scores = []\n",
    "for test_slice in range(folds): \n",
    "    logger.info(\"Testing on slice %d, training on the rest...\\n\" % test_slice)\n",
    "    user_level_data, subjects_split, vocabulary = load_erisk_data(writings_df, \n",
    "                                                            voc_size=hyperparams_features['max_features'],\n",
    "                                                           emotion_lexicon=nrc_lexicon,\n",
    "                                                           emotions=emotions,\n",
    "                                                           user_level=hyperparams_features['user_level'],\n",
    "                                                                                logger=logger,\n",
    "                                                           vocabulary=pickle.load(open('all_vocab_clpsych_erisk_2000_dict.pkl', 'rb')),\n",
    "                                                              by_subset=False,\n",
    "                                                              nr_slices=folds,\n",
    "                                                                valid_prop=0.1,\n",
    "                                                                  test_slice=test_slice\n",
    "                                                                 )\n",
    "    model, history = train(user_level_data, subjects_split, \n",
    "              hyperparams, hyperparams_features, \n",
    "              embedding_matrix, emotions, stopword_list, liwc_categories,\n",
    "                  experiment,\n",
    "                validation_set='test',\n",
    "              version=8, epochs=50,\n",
    "    )\n",
    "    f1_scores.append(sum(history.history['val_f1_m'][-6:-1])/5)\n",
    "experiment.add_metric(\"average_f1\", sum(f1_scores)/5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict on server data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize_vars(sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_path = \"models/lstm_selfharm_seq16\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparams1, hyperparams_features1 = load_params(model_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyperparams_features1['embeddings_path']=[\n",
    "#     '/home/anasab//eRisk/embeddings/finetuned_glove_clpsych_erisk_stop_20000_2.pkl']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparams_features1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_model = load_saved_model(model_path, hyperparams1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocabulary_list = pickle.load(open(hyperparams_features1['vocabulary_path'], 'rb'))\n",
    "vocabulary_dict={}\n",
    "for i,w in enumerate(vocabulary_list):\n",
    "    vocabulary_dict[w] = i\n",
    "embedding_matrix = load_embeddings2(hyperparams_features1['embeddings_path'], \n",
    "                                    hyperparams_features1['embedding_dim'], vocabulary_dict)\n",
    "liwc_words_for_categories = pickle.load(open(hyperparams_features1['liwc_words_cached'], 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if 'optimizer' not in hyperparams1:\n",
    "#         hyperparams1['optimizer'] = optimizers.Adam(lr=hyperparams1['lr'], #beta_1=0.9, beta_2=0.999, epsilon=0.0001,\n",
    "#                                        decay=hyperparams1['decay'])\n",
    "# loaded_model = initialize_model(hyperparams1, hyperparams_features1, embedding_matrix, emotions, stopword_list,\n",
    "#                     liwc_categories)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_model.load_weights(model_path + \"_weights.h5\", by_name=True)\n",
    "# metrics_class = Metrics(threshold=0.5)\n",
    "# loaded_model.compile(hyperparams1['optimizer'], binary_crossentropy_custom,\n",
    "#                   metrics=[metrics_class.f1_m, metrics_class.precision_m, metrics_class.recall_m])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Server data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_runs = {\n",
    "    'bert': 0,\n",
    "    'lstm_seq': 1,\n",
    "    'cnn_hierarch': 2,\n",
    "    'transfer': 3,\n",
    "    'ensemble': 4,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_key = 'lstm_seq'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "def load_erisk_server_data(datarounds_json, voc_size, emotion_lexicon, tokenizer,\n",
    "                           liwc_words_for_categories,\n",
    "                           emotions =  \n",
    "                    ['anger', 'anticipation', 'disgust', 'fear', 'joy', \n",
    "                     'negative', 'positive', 'sadness', 'surprise', 'trust'],\n",
    "                    liwc_categories = liwc_categories, \n",
    "                    pronouns = [\"i\", \"me\", \"my\", \"mine\", \"myself\"],\n",
    "                    user_level=True, vocabulary=vocabulary_dict,\n",
    "                   logger=logger):\n",
    "    def __encode_liwc_categories(tokens, liwc_words_for_categories, relative=True):\n",
    "        categories_cnt = [0 for c in liwc_categories]\n",
    "        if not tokens:\n",
    "            return categories_cnt\n",
    "        text_len = len(tokens)\n",
    "        for i, category in enumerate(liwc_categories):\n",
    "            for t in tokens:\n",
    "                if t in liwc_words_for_categories[category]:\n",
    "                    categories_cnt[i] += 1\n",
    "            if relative and text_len:\n",
    "                categories_cnt[i] = categories_cnt[i]/text_len\n",
    "        return categories_cnt\n",
    "    logger.debug(\"Loading data...\\n\")\n",
    "     \n",
    "    subjects_split = {'test': []}\n",
    " \n",
    "    user_level_texts = {}\n",
    "    for datapoints_json in datarounds_json:\n",
    "        for datapoint in datapoints_json:\n",
    "            words = []\n",
    "            raw_text = \"\"\n",
    "            if \"title\" in datapoint:\n",
    "                tokenized_title = tokenizer.tokenize(datapoint[\"title\"])\n",
    "                words.extend(tokenized_title)\n",
    "                raw_text += datapoint[\"title\"]\n",
    "            if \"content\" in datapoint:\n",
    "                tokenized_text = tokenizer.tokenize(datapoint[\"content\"])\n",
    "                words.extend(tokenized_text)\n",
    "                raw_text += datapoint[\"content\"]\n",
    "            \n",
    "            liwc_categs = __encode_liwc_categories(words, liwc_words_for_categories)\n",
    "            if datapoint[\"nick\"] not in user_level_texts.keys():\n",
    "                user_level_texts[datapoint[\"nick\"]] = {}\n",
    "                user_level_texts[datapoint[\"nick\"]]['texts'] = [words]\n",
    "                user_level_texts[datapoint[\"nick\"]]['liwc'] = [liwc_categs]\n",
    "                user_level_texts[datapoint[\"nick\"]]['raw'] = [raw_text]\n",
    "                subjects_split['test'].append(datapoint['nick'])\n",
    "            else:\n",
    "                user_level_texts[datapoint[\"nick\"]]['texts'].append(words)\n",
    "                user_level_texts[datapoint[\"nick\"]]['liwc'].append(liwc_categs)\n",
    "                user_level_texts[datapoint[\"nick\"]]['raw'].append(raw_text)\n",
    "            \n",
    "    return user_level_texts, subjects_split, vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_json_datapoint(jlpath):\n",
    "    datapoints = []\n",
    "    with open(jlpath) as f:\n",
    "        for line in f:\n",
    "            datapoints.append(json.loads(line))\n",
    "    return datapoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# erisk_server_data, erisk_server_subjects_split, vocabulary = load_erisk_server_data(data,\n",
    "#                        tokenizer=regtokenizer,\n",
    "#                        liwc_words_for_categories=liwc_words_for_categories,\n",
    "#                     voc_size=hyperparams_features['max_features'],\n",
    "#                     emotion_lexicon=nrc_lexicon,\n",
    "#                     emotions=emotions,\n",
    "#                     user_level=hyperparams_features['user_level'],\n",
    "#                        vocabulary=vocabulary_dict,\n",
    "#     #                                                            vocabulary=pickle.load(open('vocabulary20K_selfharm.pkl', 'rb'))\n",
    "#                     logger=logger)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "erisk_server_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "#TODO: predict only on last 50 posts\n",
    "\n",
    "with session_collection[model_key].as_default():\n",
    "    with session_collection[model_key].graph.as_default():\n",
    "        server_erisk_predictions = models_collection[model_key].predict(DataGenerator(erisk_server_data, erisk_server_subjects_split, \n",
    "                                             set_type='test', vocabulary=vocabulary_dict, \n",
    "                                           hierarchical=hyperparams_collection[model_key]['hierarchical'],\n",
    "                                        seq_len=hyperparams['maxlen'], batch_size=hyperparams['batch_size'],\n",
    "                                             max_posts_per_user=None,\n",
    "                                           pad_with_duplication=False,\n",
    "                                            posts_per_group=hyperparams['posts_per_group'],\n",
    "                                            post_groups_per_user=None, \n",
    "                                             sample_seqs=False, shuffle=False,\n",
    "                                                    compute_liwc=False)\n",
    "                                                                       )\n",
    "        pd.Series(server_erisk_predictions.flatten()).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Series(server_erisk_predictions.flatten()).describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Seding results to server!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# subjects = [d['nick'] for d in read_json_datapoint(\"client/data0.jl\")]\n",
    "# results = {s: 0 for s in subjects}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_next_data(rnd, results):\n",
    "#     # TODO: send results to get data\n",
    "#     response = build_response(results)\n",
    "#     # Send response\n",
    "#     data = {\"...\"}\n",
    "#     # Make sure it's the correct round\n",
    "#     assert data['number'] == rnd\n",
    "#     serialize_data(data)\n",
    "#     return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_next_data_dummy(rnd, results):\n",
    "#     return read_json_datapoint(\"client/data0.jl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Results for round and model\n",
    "results = {key: {} for key in models_runs}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_chunk(rnds):\n",
    "    # Send same results for a chunk of rounds to get new posts\n",
    "    data = [read_json_datapoint(\"data_server/data%d.jl\" % i) for i in rnds]\n",
    "#     data_chunks = []\n",
    "#     for rnd in rnds:\n",
    "#         # TODO: REPLACE THIS WITH THE CORRECT ONE\n",
    "#         data = get_next_data_dummy(rnd, results)\n",
    "#         data_chunks.append(data)\n",
    "#         all_data[rnd] = data\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "def predict_for_round_chunk(model, hyperparams, hyperparams_features, vocabulary, data_chunk, subjects=[],\n",
    "                           model_key='', cache_round=None): \n",
    "    # preload for subjects not occurring in the round with results from previous round\n",
    "#     results = {s: 0 for s in subjects}\n",
    "    if cache_round:\n",
    "        results = load_results(model_key, cache_round)\n",
    "    else:\n",
    "        results = {s: 0 for s in subjects}\n",
    "        \n",
    "    \n",
    "    erisk_server_data, erisk_server_subjects_split, vocabulary = load_erisk_server_data(data_chunk,\n",
    "                       tokenizer=regtokenizer,\n",
    "                       liwc_words_for_categories=liwc_words_for_categories,\n",
    "                    voc_size=hyperparams_features['max_features'],\n",
    "                    emotion_lexicon=nrc_lexicon,\n",
    "                    emotions=emotions,\n",
    "                    user_level=1,\n",
    "                       vocabulary=vocabulary,\n",
    "                    logger=logger)\n",
    "\n",
    "    for features, subjects, _ in DataGenerator(erisk_server_data, erisk_server_subjects_split, \n",
    "                                         set_type='test', vocabulary=vocabulary, \n",
    "                                       hierarchical=hyperparams['hierarchical'],\n",
    "                                    seq_len=hyperparams['maxlen'], batch_size=hyperparams['batch_size'],\n",
    "                                         max_posts_per_user=None,\n",
    "                                       pad_with_duplication=False,\n",
    "                                        posts_per_group=hyperparams['posts_per_group'],\n",
    "                                        post_groups_per_user=None, \n",
    "                                         sample_seqs=False, shuffle=False,\n",
    "                                      return_subjects=True):\n",
    "        predictions = model.predict_on_batch(features)\n",
    "        print(len(features[0]), len(subjects), len(predictions), len(results))\n",
    "        for i,s in enumerate(subjects):\n",
    "            results[\"subject\" + str(s)] = predictions[i].item()\n",
    "    return(results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_response(results, decision_thresh=0.5, model_name='', rnd=0):\n",
    "    response = []\n",
    "    for subject, score in results.items():\n",
    "        prediction = 1 if score >= decision_thresh else 0\n",
    "        response.append({'nick': subject, 'score': score, 'decision': prediction})\n",
    "    json.dump(response, open(\"data_server/response_run%s_rnd%d.json\" % (model_name, rnd), 'w+'))\n",
    "    return response\n",
    "# build_response(results, 50000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_ensemble_results(rnd, all_results, model_keys_to_average=['lstm_seq', 'cnn_hierarch']):\n",
    "#     subjects = [s for s in all_results[model_keys_to_average[0]][rnd]]\n",
    "#     results_ensemble = {}\n",
    "#     for sub in subjects:\n",
    "#         s = 0\n",
    "#         for k in model_keys_to_average:\n",
    "#             s += all_results[k][rnd][sub]\n",
    "#         results_ensemble[sub] = s/len(model_keys_to_average)\n",
    "#     return results_ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ensemble_results(results_to_average):\n",
    "    subjects = [s for s in results_to_average[0]]\n",
    "    results_ensemble = {}\n",
    "    for sub in subjects:\n",
    "        s = 0\n",
    "        for res in results_to_average:\n",
    "            s += res[sub]\n",
    "        results_ensemble[sub] = s/len(results_to_average)\n",
    "    return results_ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_transfer_results(rnd, all_results, model_to_average='lstm_seq', rounds_back=100):\n",
    "    subjects = [s for s in all_results[model_to_average][rnd]]\n",
    "    results_ensemble = {}\n",
    "    for sub in subjects:\n",
    "        s = 0\n",
    "        existing_rounds = 0\n",
    "        for prev_rnd in range(rnd-rounds_back, rnd+1):\n",
    "#             print(\"rolling rnds\", prev_rnd)\n",
    "            if prev_rnd in all_results[model_to_average]:\n",
    "                s += all_results[model_to_average][prev_rnd][sub]\n",
    "                existing_rounds += 1\n",
    "        results_ensemble[sub] = s/existing_rounds\n",
    "#         print(\"Have found a rolling window of %d for the transfer model\" % existing_rounds)\n",
    "    return results_ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_results(model_key, rnd):\n",
    "    results = {}\n",
    "    with open(\"data_server/response_run%s_rnd%d.json\" % (models_runs[model_key], rnd)) as f:\n",
    "        response = json.loads(f.read())\n",
    "        for line in response:\n",
    "            results[line['nick']] = line['score']\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# results['lstm_seq'][20] = load_results('lstm_seq', 20)\n",
    "# results['lstm_seq'][40] = \n",
    "results# results['bert'][40] = load_results('bert', 40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnds = range(500,600)\n",
    "decision_thresh = 0.5\n",
    "data_chunks = get_data_chunk(rnds)\n",
    "subjects = [d['nick'] for d in read_json_datapoint(\"data_server/data0.jl\")]\n",
    "# for key in ['transfer', 'ensemble']:\n",
    "for model_key in [\n",
    "                  'lstm_seq',\n",
    "                    'bert',\n",
    "                  'cnn_hierarch', \n",
    "                  'transfer', \n",
    "                  'ensemble',\n",
    "                ]:\n",
    "    print(model_key)\n",
    "    end_rnd = rnds[-1]\n",
    "#     if model_key=='lstm_seq':\n",
    "#         results[model_key][end_rnd]=load_results('lstm_seq', 20)\n",
    "    if model_key=='cnn_hierarch':\n",
    "        results[model_key][end_rnd]=load_results('cnn_hierarch', 40)\n",
    "    elif model_key=='bert':\n",
    "        results[model_key][end_rnd]=load_results('bert', end_rnd)\n",
    "    elif model_key=='ensemble':\n",
    "        model_keys_to_average=['bert', 'cnn_hierarch', 'lstm_seq']\n",
    "        missing_models = [m for m in model_keys_to_average if not results[m]]\n",
    "        if len(missing_models)!=0:\n",
    "            print(\"Missing models! cannot compute ensemble results\", missing_models)\n",
    "            continue\n",
    "        results_to_average = [results[m][end_rnd] for m in model_keys_to_average]\n",
    "#         results[model_key][end_rnd] = get_ensemble_results(rnd, results, \n",
    "#                                                 model_keys_to_average)\n",
    "        results[model_key][end_rnd] = get_ensemble_results(results_to_average)\n",
    "    ## For now\n",
    "    elif model_key=='transfer':\n",
    "        results[model_key][end_rnd]=get_transfer_results(\n",
    "            end_rnd, results, model_to_average='lstm_seq', rounds_back=60)\n",
    "#         results[model_key][end_rnd]=results['lstm_seq'][end_rnd]\n",
    "    ##\n",
    "    else:\n",
    "        with session_collection[model_key].as_default():\n",
    "            with session_collection[model_key].graph.as_default():\n",
    "                results[model_key][end_rnd] = predict_for_round_chunk(models_collection[model_key], \n",
    "                                              hyperparams_collection[model_key], hyperparams_features, \n",
    "                                              vocabulary_dict, \n",
    "                                          data_chunks, subjects=subjects, model_key=model_key, cache_round=499)\n",
    "\n",
    "    \n",
    "    print(len(results[model_key][end_rnd].values()), \"positive:\", \n",
    "      len([r for r in results[model_key][end_rnd].values() if r >=0.5]))\n",
    "    response1 = build_response(results[model_key][end_rnd], rnd=end_rnd, \n",
    "                               model_name=models_runs[model_key], decision_thresh=decision_thresh)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results['lstm_seq'].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Series(list(results['transfer'][180].values())).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import pearsonr\n",
    "pearsonr(list(results['bert'][220].values()), list(results['bert'][180].values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Series(list(results['lstm_seq'][160].values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict on eRisk data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# results = {}\n",
    "# labels = {}\n",
    "# featuresall = {}\n",
    "# with session_collection['lstm_seq2'].as_default():\n",
    "#     with session_collection['lstm_seq2'].graph.as_default():\n",
    "        # for features, subjects, lbls in DataGenerator(user_level_data, subjects_split, \n",
    "        #                                          set_type='train', vocabulary=vocabulary_dict,\n",
    "        #                                        hierarchical=hyperparams1['hierarchical'],\n",
    "        #                                     seq_len=hyperparams1['maxlen'], batch_size=hyperparams1['batch_size'],\n",
    "        #                                          max_posts_per_user=None,\n",
    "        #                                        pad_with_duplication=False,\n",
    "        #                                         posts_per_group=hyperparams1['posts_per_group'],\n",
    "        #                                         post_groups_per_user=None, \n",
    "        #                                          sample_seqs=False, shuffle=False,\n",
    "        #                                                return_subjects=True):\n",
    "\n",
    "        #     predictions = loaded_model.predict_on_batch(features)\n",
    "        #     print(len(features[0]), len(subjects), len(predictions), len(labels), len(results))\n",
    "        #     for i,s in enumerate(subjects):\n",
    "        #         if s not in results:\n",
    "        #             results[s] = []\n",
    "        #             featuresall[s] = []\n",
    "        #         results[s].append(predictions[i].item())\n",
    "        #         featuresall[s].append([features[j][i] for j in range(len(features))])\n",
    "        #         labels[s] = lbls[i]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for subject in results:\n",
    "    if not labels[subject]:\n",
    "        if np.std(results[subject])>0.0:\n",
    "            print(subject), print(results[subject][0], results[subject][-1]-results[subject][0])\n",
    "            pd.Series(results[subject]).rolling(window=5).mean().plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[featuresall[4278][i][0].sum() for i in range(len(featuresall[4278]))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(user_level_data['subject4278']['raw'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x, s, y in DataGenerator(user_level_data, subjects_split, \n",
    "                                         set_type='test', vocabulary=vocabulary_dict,\n",
    "                                       hierarchical=hyperparams1['hierarchical'],\n",
    "                                    seq_len=hyperparams1['maxlen'], batch_size=hyperparams1['batch_size'],\n",
    "                                         max_posts_per_user=None,\n",
    "                                       pad_with_duplication=False,\n",
    "                                        posts_per_group=hyperparams1['posts_per_group'],\n",
    "                                        post_groups_per_user=None, \n",
    "                                         sample_seqs=False, shuffle=False,\n",
    "                                               return_subjects=True):\n",
    "    print(\"subject\", s, \"features\", x[0].sum(axis=1))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_key='lstm_seq'\n",
    "with session_collection[model_key].as_default():\n",
    "    with session_collection[model_key].graph.as_default():\n",
    "        res = models_collection[model_key].evaluate_generator(DataGenerator(user_level_data, subjects_split, \n",
    "                                              liwc_words_for_categories=liwc_words_for_categories,\n",
    "                                         set_type='test', vocabulary=vocabulary_dict,\n",
    "                                       hierarchical=hyperparams_collection[model_key]['hierarchical'],\n",
    "                                    seq_len=hyperparams_collection[model_key]['maxlen'], \n",
    "                                    batch_size=hyperparams['batch_size'],\n",
    "                                         max_posts_per_user=None,\n",
    "                                       pad_with_duplication=False,\n",
    "                                        posts_per_group=hyperparams_collection[model_key]['posts_per_group'],\n",
    "                                        post_groups_per_user=1,#None, \n",
    "                                         sample_seqs=False, shuffle=False,\n",
    "                                             compute_liwc=False))\n",
    "        print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sessions_collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyperparams_collection['cnn_bert'] = {'hierarchical': False, 'maxlen': 512, 'posts_per_group': 50}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyperparams_collection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Feature importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = [\n",
    "    (e, 'nrc') for e in emotions] + ['pers_pronouns'] + [\n",
    "    (c, 'liwc') for c in list(categories) if c in writings_df.columns] + [\n",
    "(st, 'stopword') for st in stopword_list]\n",
    "weights = model.get_layer('output_layer').get_weights()[0].tolist()[-(len(features)):]\n",
    "\n",
    "print(len(weights), len(features))\n",
    "feature_importance = {}\n",
    "for (i, f) in enumerate(features):\n",
    "    feature_importance[f] = weights[i][0]\n",
    "\n",
    "sorted(feature_importance.items(), key=lambda t: abs(t[1]), reverse=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate per user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_for_point(subject, voc, hyperparams_features=hyperparams_features, nrc_lexicon=nrc_lexicon,\n",
    "                      emotions=emotions):\n",
    "    eval_writings_df = writings_df[writings_df['subject']==subject]\n",
    "    correct_label = eval_writings_df.label.values[0]\n",
    "    (x_train, y_train), (x_valid, y_valid), (x_test, y_test), voc = load_erisk_data(eval_writings_df,\n",
    "                        seq_len=hyperparams_features['maxlen'],\n",
    "                        voc_size=hyperparams_features['max_features'],\n",
    "                        emotion_lexicon=nrc_lexicon,\n",
    "                        emotions=emotions, user_level=False,\n",
    "                        train_prop=0.0, vocabulary=voc)\n",
    "    return x_test, y_test, correct_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_per_user(writings_df, majority_prop=0.2, train_prop=0.7, majority_nr=0, validate=False, voc=None,\n",
    "                    random=False, nr_slices=5, test_slice=2):\n",
    "    all_predictions = []\n",
    "    all_labels = []\n",
    "    tp = 0\n",
    "    tn = 0\n",
    "    fp = 0\n",
    "    fn = 0\n",
    "    thresh=0.5\n",
    "    majority_proportion=majority_prop\n",
    "    valid_prop = 0.3\n",
    "    \n",
    "    if 'subset' in writings_df.columns:\n",
    "        training_subjects = list(set(writings_df[writings_df['subset']=='train'].subject))\n",
    "        test_subjects = list(set(writings_df[writings_df['subset']=='test'].subject))\n",
    "    else:\n",
    "        all_subjects = sorted(list(set(writings_df.subject)))\n",
    "        training_subjects_size = int(len(all_subjects) * train_prop)\n",
    "        test_subjects_size = len(all_subjects) - training_subjects_size\n",
    "        # Cross-validation, with fixed slice as input\n",
    "        test_prop = 1-train_prop\n",
    "        test_slice = min(test_slice, nr_slices)\n",
    "        logger.debug(\"start index: %f, from %f\\n\" % (\n",
    "            len(all_subjects)*(1/nr_slices)*test_slice, test_prop*test_slice))\n",
    "        start_slice = int(len(all_subjects)*(1/nr_slices)*test_slice)\n",
    "        test_subjects = all_subjects[start_slice: start_slice+test_subjects_size]\n",
    "        training_subjects = [s for s in all_subjects if s not in test_subjects]\n",
    "    training_subjects = sorted(training_subjects) # ensuring reproducibility\n",
    "    valid_subjects_size = int(len(training_subjects) * valid_prop)\n",
    "    valid_subjects = training_subjects[:valid_subjects_size]\n",
    "    training_subjects = training_subjects[valid_subjects_size:]\n",
    "    \n",
    "    if validate:\n",
    "        subjects = valid_subjects\n",
    "    else:\n",
    "        subjects = test_subjects\n",
    "    for subject in subjects:\n",
    "        x_test_user, y_test_user, label = get_data_for_point(subject, voc=voc)\n",
    "        outputs = model.predict(x_test_user)\n",
    "        if random:\n",
    "            sigma = np.std(outputs)\n",
    "            mu = np.mean(outputs)\n",
    "            print(\"generating random outputs with sigma\", sigma, \"and mu\", mu)\n",
    "            outputs = sigma*np.random.randn(len(outputs))+mu\n",
    "        positive_pred = sum(outputs>=thresh)\n",
    "        negative_pred = sum(outputs<thresh)\n",
    "        majority_pred = 0\n",
    "        if majority_proportion and positive_pred >= majority_proportion*negative_pred:\n",
    "            majority_pred = 1\n",
    "        if majority_nr and positive_pred>=majority_nr:\n",
    "            majority_pred = 1\n",
    "        if label == 1:\n",
    "            if majority_pred == 1:\n",
    "                tp+=1\n",
    "            else:\n",
    "                fn+=1\n",
    "        else:\n",
    "            if majority_pred == 0:\n",
    "                tn+=1\n",
    "            else:\n",
    "                fp+=1\n",
    "        print(negative_pred, positive_pred, majority_pred)\n",
    "        all_predictions.append(majority_pred)\n",
    "        all_labels.append(label)\n",
    "    def prec_recall_f1(tp, fp, tn, fn):\n",
    "        recall = tp/(tp+fn+0.0000001)\n",
    "        precision = tp/(tp+fp+0.0000001)\n",
    "        f1 = 2*precision*recall/(precision+recall+0.0000001)\n",
    "        print(\"Recall\", recall, \"Precision\", precision, \"F1\", f1)\n",
    "    if majority_prop:\n",
    "        print(\"Vote proportion\", majority_prop)\n",
    "    if majority_nr:\n",
    "        print(\"Vote points\", majority_nr)\n",
    "    prec_recall_f1(tp, fp, tn, fn)\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_per_user(writings_df=writings_df, voc=voc, majority_prop=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_per_slice = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nr_slices=5\n",
    "logger.setLevel(logging.INFO)\n",
    "for tslice in range(nr_slices): \n",
    "    (x_train, y_train), (x_valid, y_valid), (x_test, y_test), voc = load_erisk_data(writings_df, \n",
    "                                                                seq_len=hyperparams_features['maxlen'],\n",
    "                                                                voc_size=hyperparams_features['max_features'],\n",
    "                                                               emotion_lexicon=nrc_lexicon,\n",
    "                                                               emotions=emotions,\n",
    "                                                               user_level=hyperparams_features['user_level'],\n",
    "                                                                                    test_slice=tslice,\n",
    "                                                                                    nr_slices=nr_slices,\n",
    "    #                                                            vocabulary=pickle.load(open('vocabulary20K_selfharm.pkl', 'rb'))\n",
    "                                                                                   logger=logger)\n",
    "    model, history = train_model(model, x_train, y_train, x_valid, y_valid,\n",
    "           epochs=200, batch_size=hyperparams['batch_size'],\n",
    "                      class_weight={0:0.5, 1:5}, start_epoch=0,\n",
    "                      callback_list = [freeze_layer, weights_history, reduce_lr],\n",
    "                      workers=2, verbose=0)\n",
    "    results_per_slice[tslice] = model.evaluate(x_test, y_test)\n",
    "    logger.info(\"Results for slice %d: %s\\n\" % (tslice, results_per_slice[tslice]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Average F1 score: \", np.array([results_per_slice[s][1] for s in results_per_slice.keys()]).mean(),\n",
    "     \"all F1 scores: \", {s: v[1] for (s,v) in results_per_slice.items()} )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extra analysis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_tokens(row):\n",
    "    tokens = []\n",
    "    if row.tokenized_text:\n",
    "        tokens += row.tokenized_text\n",
    "    if row.tokenized_title:\n",
    "        tokens += row.tokenized_title\n",
    "    return tokens\n",
    "writings_df['all_tokens'] = writings_df.apply (lambda row: merge_tokens(row), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: include the title\n",
    "def extract_emotions(tokens, emotion, relative=True):\n",
    "    if not tokens:\n",
    "        return None\n",
    "    emotion_words = [t for t in tokens \n",
    "                     if t in nrc_lexicon[emotion]]\n",
    "    if relative and len(tokens):\n",
    "        return len(emotion_words) / len(tokens)\n",
    "    else:\n",
    "        return len(emotion_words)\n",
    "    \n",
    "    return encoded_emotions\n",
    "\n",
    "from functools import partial\n",
    "for emotion in emotions:\n",
    "    writings_df[emotion] = writings_df['all_tokens'].apply(partial(extract_emotions, emotion=emotion, \n",
    "                                                                   relative=True))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "writings_df['pronouns'] = writings_df['all_tokens'].apply(partial(encode_pronouns, relative=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "writings_df[['text', 'label', 'pronouns', 'text_len'] + emotions].corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "writings_df[['text', 'label', 'pronouns', 'text_len'] + emotions].groupby('label').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.sentiment import SentimentAnalyzer, SentimentIntensityAnalyzer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sid = SentimentIntensityAnalyzer()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sid.polarity_scores(\"We are here today happiness is all around\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "writings_df['neg_vader'] = writings_df.text.apply(lambda t: sid.polarity_scores(t)['neg']\n",
    "                                                 if type(t)==str else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "writings_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "writings_df['pos_vader'] = writings_df.text.apply(lambda t: sid.polarity_scores(t)['pos']\n",
    "                                                 if type(t)==str else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "writings_df[['text', 'label', 'pronouns', 'text_len', 'neg_vader', 'pos_vader'] + emotions].groupby('label').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "writings_df[['text', 'label', 'pronouns', 'text_len', 'neg_vader', 'pos_vader'] + emotions].corr('spearman')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LIWC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from liwc_readDict import readDict\n",
    "\n",
    "liwc = readDict('/home/ana/resources/FakeOrFact/features/LIWC/LIWC/liwc.dic')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = [c for (w,c) in liwc]\n",
    "set(categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "liwc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "liwc_dict = {}\n",
    "for (w, c) in liwc:\n",
    "    if c not in liwc_dict:\n",
    "        liwc_dict[c] = []\n",
    "    liwc_dict[c].append(w)\n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "liwc_dict['pronoun']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_liwc_categories(tokens, category_words, relative=True):\n",
    "    category_cnt = 0\n",
    "    if not tokens:\n",
    "        return None\n",
    "    text_len = len(tokens)\n",
    "    for t in tokens:\n",
    "        for word in category_words:\n",
    "            if t==word or (word[-1]=='*' and t.startswith(word[:-1])) \\\n",
    "            or (t==word.split(\"'\")[0]):\n",
    "                category_cnt += 1\n",
    "                break # one token cannot belong to more than one word in the category\n",
    "    if relative:\n",
    "        return category_cnt/text_len\n",
    "    else:\n",
    "        return category_cnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    def __encode_liwc_categories(self, tokens, relative=True):\n",
    "        categories_cnt = [0 for c in self.liwc_categories]\n",
    "        if not tokens:\n",
    "            return None\n",
    "        text_len = len(tokens)\n",
    "        for i, category in enumerate(self.liwc_categories):\n",
    "            for t in tokens:\n",
    "                print(\"token\", t)\n",
    "                if t in self.liwc_words_for_categories[category]:\n",
    "                    categories_cnt[i] += 1\n",
    "            if relative:\n",
    "                categories_cnt[i] = categories_cnt[i]/text_len\n",
    "        return categories_cnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "from functools import partial\n",
    "# for categ in ['negemo', 'posemo', 'affect', 'sad', 'anx', 'pronoun']:#liwc_dict.keys():\n",
    "for categ in liwc_dict.keys():\n",
    "    if categ in writings_df.columns:\n",
    "        continue\n",
    "    print(\"Encoding for category %s...\" % categ)\n",
    "    writings_df[categ] = writings_df['all_tokens'].apply(partial(encode_liwc_categories, \n",
    "                                                                   category_words=liwc_dict[categ], \n",
    "                                                                   relative=True))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# categories for all words in vocabulary\n",
    "# vocabulary = pickle.load(open(\"all_vocab_clpsych_erisk_50000.pkl\", \"rb\"))\n",
    "liwc_words_for_categories = {}\n",
    "for categ in liwc_dict.keys():\n",
    "    liwc_words_for_categories[categ] = set()\n",
    "    for word in liwc_dict[categ]:\n",
    "        for t in vocabulary:\n",
    "            if t==word or (word[-1]=='*' and t.startswith(word[:-1])) \\\n",
    "                or (t==word.split(\"'\")[0]):\n",
    "                    liwc_words_for_categories[categ].add(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(liwc_words_for_categories, open(\"data/liwc_categories_for_vocabulary_erisk_clpsych_stop_40K.pkl\", \"wb+\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "writings_df.groupby('subject').mean()[['label', 'negemo', 'posemo', 'affect', 'sad', 'anx', 'pronoun']].corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "writings_df[['label', 'negemo', 'posemo', 'affect', 'sad', 'anx', 'pronoun']].groupby('label').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "writings_df.groupby('subject').mean()[['label'] + categories].corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Declare your hyperparameters search:\n",
    "tune_epochs=150\n",
    "config = {\n",
    "      \"algorithm\": \"bayes\",\n",
    "      \"parameters\": {\n",
    "          \"lstm_units\": {\"type\": \"integer\", \"min\": 32, \"max\": 300},\n",
    "          \"lstm_units_user\": {\"type\": \"integer\", \"min\": 5, \"max\": 40},\n",
    "          \"dense_bow_units\": {\"type\": \"integer\", \"min\": 5, \"max\": 35},\n",
    "          \"filters\": {\"type\": \"integer\", \"min\": 30, \"max\": 250},\n",
    "          \"kernel_size\": {\"type\": \"integer\", \"min\": 3, \"max\": 7},\n",
    "          \"dense_sentence_units\": {\"type\": \"integer\", \"min\": 0, \"max\": 10},\n",
    "          \"dense_user_units\": {\"type\": \"integer\", \"min\": 0, \"max\": 0},\n",
    "          \"bert_dense_units\": {\"type\": \"integer\", \"min\": 10, \"max\": 200},\n",
    "          \"bert_finetune_layers\": {\"type\": \"integer\", \"min\": 0, \"max\": 2},\n",
    "          \"lr\": {\"type\": \"float\", \"min\": 0.0005, \"max\": 0.2, \"scalingType\": \"loguniform\"},\n",
    "          \"l2_dense\": {\"type\": \"float\", \"min\": 0.0000001, \"max\": 0.1, \"scalingType\": \"loguniform\"},\n",
    "          \"l2_embeddings\": {\"type\": \"float\", \"min\": 0.00000001, \"max\": 0.2, \"scalingType\": \"loguniform\"},\n",
    "          \"l2_bert\": {\"type\": \"float\", \"min\": 0.00000001, \"max\": 0.2, \"scalingType\": \"loguniform\"},\n",
    "          \"dropout\": {\"type\": \"float\", \"min\": 0, \"max\": 0.5, \"scalingType\": \"uniform\"},\n",
    "          \"norm_momentum\": {\"type\": \"float\", \"min\": 0, \"max\": 0.99, \"scalingType\": \"uniform\"},\n",
    "          \"optimizer\": {\"type\": \"categorical\", \"values\": [\"\"]},#\"adam\", \"adagrad\", \"\"]},\n",
    "          \"batch_size\": {\"type\": \"integer\", \"min\": 5, \"max\": 128, \"scalingType\": \"loguniform\"},\n",
    "          \"positive_class_weight\": {\"type\": \"integer\", \"min\": 3, \"max\": 10},\n",
    "          \"trainable_embeddings\": {\"type\": \"discrete\", \"values\": [True, False]},\n",
    "          \"sample_seqs\": {\"type\": \"discrete\", \"values\": [True, False]},\n",
    "          \"bert_trainable\": {\"type\": \"discrete\", \"values\": [True, False]},\n",
    "          \"bert_pooling\": {\"type\": \"categorical\", \"values\": ['first', 'mean']},\n",
    "#           \"hierarchical\": {\"type\": \"discrete\", \"values\": [True, False]},\n",
    "          \"freeze_patience\": {\"type\": \"integer\", \"min\": 2, \"max\": tune_epochs+1},\n",
    "          \"lr_reduce_factor\": {\"type\": \"float\", \"min\": 0.0001, \"max\": 0.8},\n",
    "          \"scheduled_lr_reduce_factor\": {\"type\": \"float\", \"min\": 0.0001, \"max\": 0.8},\n",
    "          \"lr_reduce_patience\": {\"type\": \"integer\", \"min\": 2, \"max\": tune_epochs+1},\n",
    "          \"scheduled_lr_reduce_patience\": {\"type\": \"integer\", \"min\": 2, \"max\": tune_epochs+1},\n",
    "          \"early_stopping_patience\": {\"type\": \"integer\", \"min\": 2, \"max\": tune_epochs+1},\n",
    "          \"decay\": {\"type\": \"float\", \"min\": 0.00000001, \"max\": 0.5, \"scalingType\": \"loguniform\"},\n",
    "#           \"ignore_layers_values\": {\"type\": \"categorical\", \"values\": [\"attention\", \"batchnorm\", \"bert_layer\"]},\n",
    "          \"sampling_distr\": {\"type\": \"categorical\", \"values\": [\"exp\", \"uniform\"]},\n",
    "          \"posts_per_group\": {\"type\": \"integer\", \"min\": 10, \"max\": 100},\n",
    "          \"post_groups_per_user\": {\"type\": \"integer\", \"min\": 1, \"max\": 50},\n",
    "#           \"posts_per_user\": {\"type\": \"integer\", \"min\": 0, \"max\": 1000},\n",
    "          \"maxlen\": {\"type\": \"integer\", \"min\":64, \"max\": 512},\n",
    "      },\n",
    "      \"spec\": {\n",
    "          \"metric\": \"loss\",\n",
    "          \"objective\": \"minimize\",\n",
    "      },\n",
    "  }\n",
    "optimizer = Optimizer(config, api_key=\"eoBdVyznAhfg3bK9pZ58ZSXfv\")\n",
    "\n",
    "hyperparams_config = hyperparams\n",
    "\n",
    "for experiment in optimizer.get_experiments(project_name=\"mental\"):\n",
    "    experiment.add_tag(\"tune\")\n",
    "    experiment.add_tag(dataset_type)\n",
    "    \n",
    "    print(hyperparams_config)\n",
    "    \n",
    "\n",
    "    data_generator_train = DataGenerator(user_level_data, subjects_split, set_type='train',\n",
    "                                         seq_len=hyperparams_config[\"maxlen\"],\n",
    "                                                     sample_seqs=hyperparams_config['sample_seqs'],\n",
    "                                                     sampling_distr=hyperparams_config['sampling_distr'],\n",
    "                                                    posts_per_group=hyperparams_config['posts_per_group'],\n",
    "                                                    post_groups_per_user=1,#hyperparams_config['post_groups_per_user'],\n",
    "                                                    max_posts_per_user=hyperparams_config['posts_per_user'],\n",
    "                                    hierarchical=hyperparams['hierarchical'])\n",
    "    data_generator_valid = DataGenerator(user_level_data, subjects_split, set_type='valid',\n",
    "                                         seq_len=hyperparams_config[\"maxlen\"],\n",
    "                                         \n",
    "                                                    posts_per_group=hyperparams_config['posts_per_group'],\n",
    "                                                    post_groups_per_user=hyperparams_config['post_groups_per_user'],\n",
    "                                                    max_posts_per_user=None,\n",
    "                                                    sample_seqs=False, \n",
    "                                                     shuffle=False,\n",
    "                                                hierarchical=hyperparams['hierarchical'])\n",
    "    try:\n",
    "        if hyperparams['hierarchical']:\n",
    "            model = build_hierarchical_model(hyperparams_config, hyperparams_features, embedding_matrix, emotions, stopword_list,\n",
    "                            liwc_categories=[c for c in categories if c in writings_df.columns]\n",
    "        ,\n",
    "                           ignore_layer=hyperparams_config['ignore_layer'])\n",
    "        else:\n",
    "            model = build_model(hyperparams_config, hyperparams_features, embedding_matrix, emotions, stopword_list,\n",
    "                            liwc_categories=[c for c in categories if c in writings_df.columns]\n",
    "        ,\n",
    "                           ignore_layer=hyperparams_config['ignore_layer'])\n",
    "        model.summary()\n",
    "\n",
    "        freeze_layer = FreezeLayer(model, patience=hyperparams['freeze_patience'], set_to=not hyperparams['trainable_embeddings'])\n",
    "        weights_history = WeightsHistory()\n",
    "        lr_history = LRHistory()\n",
    "        reduce_lr = callbacks.ReduceLROnPlateau(monitor='val_loss', factor=hyperparams['reduce_lr_factor'],\n",
    "                                  patience=hyperparams['reduce_lr_patience'], min_lr=0.000001, verbose=1)\n",
    "        lr_schedule = callbacks.LearningRateScheduler(lambda epoch, lr: \n",
    "                                                      lr if (epoch+1)%hyperparams['scheduled_reduce_lr_freq']!=0 else\n",
    "                                                      lr*hyperparams['scheduled_reduce_lr_factor'], verbose=1)\n",
    "\n",
    "        model, history = train_model(model, hyperparams, data_generator_train, data_generator_valid,\n",
    "                           epochs=tune_epochs,\n",
    "                          class_weight={0:1, 1:experiment.get_parameter('positive_class_weight')}, \n",
    "                                     start_epoch=0,\n",
    "                          callback_list = [\n",
    "    #                                  weights_history, \n",
    "                                           reduce_lr, \n",
    "    #                                        lr_history, \n",
    "                                           lr_schedule\n",
    "                                          ],\n",
    "                          model_path='models/experiment', workers=4)\n",
    "    except tf.errors.ResourceExhaustedError as e:\n",
    "        print(e)\n",
    "        sess.close()\n",
    "        sess = tf.Session(config=sess_config)\n",
    "        initialize_vars(sess)\n",
    "\n",
    "    \n",
    "    loss = history.history['loss'][-1]\n",
    "    \n",
    "    \n",
    "    # Test the model\n",
    "    for param in config['parameters'].keys():    \n",
    "        hyperparams_config[param] = experiment.get_parameter(param)\n",
    "    if not hyperparams_config['optimizer']:\n",
    "        hyperparams_config['optimizer'] = optimizers.Adam(lr=hyperparams_config['lr'], \n",
    "                                   decay=hyperparams_config['decay'])\n",
    "#     hyperparams_config[\"ignore_layer\"] = []\n",
    "#     if hyperparams_config[\"ignore_layers_values\"]:\n",
    "#         hyperparams_config[\"ignore_layer\"] = [hyperparams_config[\"ignore_layers_values\"]]\n",
    "    hyperparams_config[\"ignore_layer\"] = [\"bert_layer\", \"batchnorm\"]\n",
    "        \n",
    "#     freeze_layer = FreezeLayer(model, patience=experiment.get_parameter('freeze_patience'),\n",
    "#                               set_to=not experiment.get_parameter('trainable_embeddings'))\n",
    "    reduce_lr = callbacks.ReduceLROnPlateau(monitor='val_loss', \n",
    "                                            factor=experiment.get_parameter('lr_reduce_factor'),\n",
    "                                            patience=experiment.get_parameter('lr_reduce_patience'), \n",
    "                                            min_lr=0.00000001, verbose=1)\n",
    "    \n",
    "    # Report the loss, if not auto-logged:\n",
    "    experiment.log_metric(\"loss\", loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {
    "height": "362px",
    "width": "218px"
   },
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
