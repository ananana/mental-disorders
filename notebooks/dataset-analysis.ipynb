{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "oriented-football",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import xml.etree.ElementTree as ET\n",
    "import glob, os\n",
    "import numpy as np\n",
    "from comet_ml import Experiment, Optimizer\n",
    "import pickle\n",
    "import logging\n",
    "import sys\n",
    "from sklearn.utils import class_weight\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "import json\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "herbal-behalf",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['TF_KERAS'] = '1'\n",
    "from tensorflow.keras.preprocessing import sequence\n",
    "from tensorflow.keras.models import Sequential, Model, load_model\n",
    "from tensorflow.keras.layers import Dense, Dropout, Embedding, LSTM, Lambda, BatchNormalization, TimeDistributed, \\\n",
    "    Bidirectional, Input, InputLayer, concatenate, Flatten, RepeatVector, Activation, Multiply, Permute, \\\n",
    "    Conv1D, GlobalMaxPooling1D\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras import callbacks, optimizers\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.utils import plot_model, Sequence\n",
    "\n",
    "from keras.utils import np_utils\n",
    "\n",
    "from nltk.tokenize import RegexpTokenizer, TweetTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "acknowledged-battle",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial-authorization",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocabs = {\n",
    "    'erisk_depression': None,\n",
    "    'erisk_anorexia': None,\n",
    "    'erisk_selfharm': None,\n",
    "    'clpsych': None,\n",
    "    'symanto': None\n",
    "    \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "alternative-awareness",
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in vocabs:\n",
    "    with open(f'data/{k}_vocab.json') as f:\n",
    "        vocabs[k] = dict(Counter(json.loads(f.read())).most_common(20000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "subtle-trailer",
   "metadata": {},
   "outputs": [],
   "source": [
    "overlaps = {}\n",
    "for k in vocabs:\n",
    "    for k2 in vocabs:\n",
    "        if k==k2:\n",
    "            continue\n",
    "        overlap = len([vocabs[k][w] for w in vocabs[k] if w in vocabs[k2]])\n",
    "        overlapercent1 = overlap / len(vocabs[k])        \n",
    "        overlapercent2 = overlap / len(vocabs[k2])\n",
    "        overlaps[(k,k2)] = (overlapercent1, overlapercent2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "proved-veteran",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6778949999999998"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(sorted([t[1] for t in overlaps.values()]))/len(overlaps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "refined-polymer",
   "metadata": {},
   "outputs": [],
   "source": [
    "datadirs_clpsych = {\n",
    "    'train': [''],\n",
    "    'test': ['']\n",
    "}\n",
    "datadir_root_clpsych = {\n",
    "    'train':'../data/clpsych/shared_task_data/final_training_data/',\n",
    "    'test': '../data/clpsych/shared_task_data/final_testing_data/'\n",
    "}\n",
    "    \n",
    "labels_files_clpsych = ['../data/clpsych/anonymized_user_info_by_chunk.csv']\n",
    "def read_texts_clpsych(datadir_root_clpsych,\n",
    "                   datadirs_clpsych,\n",
    "                   labels_files_T1_2019,\n",
    "                      label_by=['depression']):\n",
    "    writings = {'train': [], 'test': []}\n",
    "    writings_df = pd.DataFrame()\n",
    "    labels_df = pd.DataFrame()\n",
    "\n",
    "    for subset in ('test',):#, 'test'):\n",
    "        for subdir in [os.path.join(datadir_root_clpsych[subset], subp) for subp in datadirs_clpsych[subset]]:\n",
    "            for subject_file in glob.glob(subdir + \"/*.tweets\"):\n",
    "#                 if subject_file.split(\"/\")[-1] != 'sZVVktDN8qqjA.tweets':\n",
    "#                     continue\n",
    "#                 writings[subset].extend(read_subject_data_clpsych(os.path.join(subdir, subject_file)))\n",
    "                writings[subset].extend(read_subject_data_clpsych(subject_file))\n",
    "        writings_df_part = pd.DataFrame(writings[subset])\n",
    "        writings_df_part['subset'] = subset\n",
    "        writings_df = pd.concat([writings_df, writings_df_part])\n",
    "        writings_df.reindex()\n",
    "\n",
    "    for label_file in labels_files_clpsych:\n",
    "        labels = pd.read_csv(label_file, names=['subject','age','num_tweets','gender','condition','chunk_index'])\n",
    "        labels['label'] = labels['condition'].apply(lambda c: 1 if c in label_by else 0)\n",
    "        \n",
    "        labels_df = pd.concat([labels_df, labels])\n",
    "        labels_df = labels_df.drop_duplicates()\n",
    "        labels_df = labels_df.set_index('subject')\n",
    "\n",
    "        # TODO: this deduplication throws some unicode, surrogates not allowed, exception\n",
    "#     writings_df = writings_df.drop_duplicates(subset=['id', 'subject', 'subset', 'created_at', 'text'])\n",
    "    \n",
    "    writings_df = writings_df.join(labels_df, on='subject')\n",
    "    writings_df['date'] = writings_df['created_at']\n",
    "    \n",
    "    return writings_df\n",
    "\n",
    "def read_subject_data_clpsych(subject_file):\n",
    "    writings = []\n",
    "    with open(subject_file, \"rt\", encoding=\"utf-8\") as sf:\n",
    "        user = subject_file.split(\"/\")[-1].split(\".\")[0]\n",
    "#         print(subject_file)\n",
    "\n",
    "        for line in sf:\n",
    "            data = json.loads(line)#.encode('utf-16','surrogatepass').decode('utf-16'))\n",
    "            data['subject'] = user\n",
    "            writings.append(data)\n",
    "    return writings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "compressed-soundtrack",
   "metadata": {},
   "outputs": [],
   "source": [
    "if dataset_type == \"combined\":\n",
    "    writings_df_selfharm = pickle.load(open('data/writings_df_selfharm_all', 'rb'))\n",
    "    writings_df_anorexia = pickle.load(open('data/writings_df_anorexia_liwc', 'rb'))\n",
    "    writings_df_depression = pickle.load(open('data/writings_df_depression_liwc', 'rb'))\n",
    "    writings_df_selfharm['source'] = 'selfharm'\n",
    "    writings_df_anorexia['source'] = 'anorexia'\n",
    "    writings_df_depression['source'] = 'depression'\n",
    "    writings_df = pd.DataFrame()\n",
    "    writings_df = pd.concat([writings_df, writings_df_depression])\n",
    "    writings_df = pd.concat([writings_df, writings_df_selfharm])\n",
    "    writings_df = pd.concat([writings_df, writings_df_anorexia])\n",
    "elif dataset_type == \"combined_depr\":\n",
    "    writings_df = pd.DataFrame.from_dict(json.load(open('data/writings_df_depression_all.json')))\n",
    "elif dataset_type == \"clpsych\":\n",
    "#     writings_df = pd.DataFrame.from_dict(json.load(open('data/writings_df_%s_liwc_affect.json' % dataset_type)))#read_texts_clpsych(datadir_root_clpsych, datadirs_clpsych, labels_files_clpsych)\n",
    "#     writings_df_test = pd.DataFrame.from_dict(json.load(open('writings_df_%s_test.json' % dataset_type)))#read_texts_clpsych(datadir_root_clpsych, datadirs_clpsych, labels_files_clpsych)\n",
    "    writings_df_test = read_texts_clpsych(datadir_root_clpsych, datadirs_clpsych, labels_files_clpsych)\n",
    "    label_by = ['depression', 'ptsd']\n",
    "    writings_df.drop(writings_df[writings_df['condition']=='depression'].index, inplace=True)\n",
    "    writings_df['label'] = writings_df['condition'].apply(lambda c: 1 if c in label_by else 0)\n",
    "#     writings_df['date'] = writings_df['created_at']\n",
    "elif dataset_type == \"symanto\":\n",
    "#     writings_df = read_texts_symanto()\n",
    "    writings_df = pickle.load(open('../data/%s/writings_df_%s_liwc' % (dataset_type,dataset_type), 'rb'))\n",
    "elif dataset_type == 'selfharm':\n",
    "    writings_df = pickle.load(open('data/writings_df_%s_all' % dataset_type, 'rb'))\n",
    "elif dataset_type in [\"depression\", \"anorexia\", \"selfharm\"]:\n",
    "    writings_df = pickle.load(open('data/writings_df_%s_liwc' % dataset_type, 'rb'))\n",
    "else:\n",
    "    logger.error(\"Unknown dataset %s\" % dataset_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "peaceful-testimony",
   "metadata": {},
   "outputs": [],
   "source": [
    "writings_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "whole-bottle",
   "metadata": {},
   "outputs": [],
   "source": [
    "writings_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "ethical-depression",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 133 ms, sys: 3.35 ms, total: 136 ms\n",
      "Wall time: 135 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "v = Counter()\n",
    "for text in writings_df.tokenized_text.values:\n",
    "    v.update(text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "actual-ticket",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('i', 15551),\n",
       " ('rt', 13897),\n",
       " ('the', 12888),\n",
       " ('to', 12363),\n",
       " ('a', 10429),\n",
       " ('you', 8716),\n",
       " ('and', 7642),\n",
       " ('my', 6223),\n",
       " ('is', 6022),\n",
       " ('of', 5945),\n",
       " ('in', 5461),\n",
       " ('for', 5089),\n",
       " ('me', 4683),\n",
       " ('it', 4583),\n",
       " ('this', 4064),\n",
       " ('that', 3688),\n",
       " ('on', 3671),\n",
       " ('so', 3453),\n",
       " ('be', 3157),\n",
       " ('with', 2903)]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v.most_common(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "outstanding-malawi",
   "metadata": {},
   "outputs": [],
   "source": [
    "# vocab_erisk_selfharm.most_common(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "responsible-cassette",
   "metadata": {},
   "outputs": [],
   "source": [
    "# vocab_erisk_anorexia.most_common(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "private-means",
   "metadata": {},
   "outputs": [],
   "source": [
    "# vocab_erisk_depr.most_common(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "stretch-option",
   "metadata": {},
   "outputs": [],
   "source": [
    "# vocab_symanto.most_common(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "amended-performer",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
