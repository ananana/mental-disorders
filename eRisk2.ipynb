{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import xml.etree.ElementTree as ET\n",
    "import glob, os\n",
    "import numpy as np\n",
    "from comet_ml import Experiment, Optimizer\n",
    "import pickle\n",
    "import logging\n",
    "import sys\n",
    "from sklearn.utils import class_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['TF_KERAS'] = '1'\n",
    "from tensorflow.keras.preprocessing import sequence\n",
    "from tensorflow.keras.models import Sequential, Model, load_model\n",
    "from tensorflow.keras.layers import Dense, Dropout, Embedding, LSTM, Lambda, BatchNormalization, TimeDistributed, \\\n",
    "    CuDNNLSTM, Bidirectional, Input, concatenate, Flatten, RepeatVector, Activation, Multiply, Permute\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras import callbacks, optimizers\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.utils import plot_model, Sequence\n",
    "\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_seed = 1234\n",
    "tf.set_random_seed(my_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger = logging.getLogger('training')\n",
    "logger.addHandler(logging.StreamHandler(sys.stdout))\n",
    "logger.setLevel(logging.DEBUG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_subject_writings(subject_file):\n",
    "    writings = []\n",
    "    with open(subject_file) as sf:\n",
    "        contents = sf.read()\n",
    "        root = ET.fromstring(contents)\n",
    "        try:\n",
    "            subject = root.findall('ID')[0].text.strip()\n",
    "        except Exception:\n",
    "            print('Cannot extract ID', contents[:500], '\\n-------\\n')        \n",
    "        for w in root.iter('WRITING'):\n",
    "            subject_writings = {'subject': subject}\n",
    "            for title in w.findall('TITLE'):\n",
    "                subject_writings['title'] = title.text\n",
    "            for text in w.findall('TEXT'):\n",
    "                subject_writings['text'] = text.text\n",
    "            for date in w.findall('DATE'):\n",
    "                subject_writings['date'] = date.text\n",
    "            writings.append(subject_writings)\n",
    "    return writings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# root_dir = '/home/anasab/' \n",
    "root_dir = '/home/ana/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "datadir_T2 = root_dir + '/eRisk/data/eRisk2020_T2/eRisk2020_T2_TRAINING_DATA/'\n",
    "labels_file_T2 = root_dir + '/eRisk/data/eRisk2020_T2/eRisk2020_T2_TRAINING_DATA/Depression Questionnaires_anon.txt'\n",
    "nr_questions = 21"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_texts(datadir_T2,\n",
    "                labels_file_T2):\n",
    "    writings = []\n",
    "    writings_df = pd.DataFrame()\n",
    "    labels_df = pd.DataFrame()\n",
    "\n",
    "        \n",
    "    for subject_file in os.listdir(datadir_T2):\n",
    "        if not subject_file.startswith('subject'):\n",
    "            continue\n",
    "        writings.extend(read_subject_writings(os.path.join(datadir_T2, subject_file)))\n",
    "    writings_df = pd.DataFrame(writings)\n",
    "    \n",
    "    labels_df = pd.read_csv(os.path.join(labels_file_T2), \n",
    "                                 delimiter='\\s+', names=['subject'] + ['label%i' % i for i in range(nr_questions)])\n",
    "\n",
    "    labels_df = labels_df.set_index('subject')\n",
    "    \n",
    "    writings_df = writings_df.join(labels_df, on='subject')\n",
    "    \n",
    "    return writings_df, labels_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# writings_df, labels_df = read_texts(datadir_T2, labels_file_T2)\n",
    "writings_df = pickle.load(open('writings_df_T2_liwc.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>date</th>\n",
       "      <th>label0</th>\n",
       "      <th>label1</th>\n",
       "      <th>label2</th>\n",
       "      <th>label3</th>\n",
       "      <th>label4</th>\n",
       "      <th>label5</th>\n",
       "      <th>label6</th>\n",
       "      <th>...</th>\n",
       "      <th>feel</th>\n",
       "      <th>excl</th>\n",
       "      <th>future</th>\n",
       "      <th>nonfl</th>\n",
       "      <th>ppron</th>\n",
       "      <th>shehe</th>\n",
       "      <th>i</th>\n",
       "      <th>we</th>\n",
       "      <th>you</th>\n",
       "      <th>they</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>subject</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>subject1272</th>\n",
       "      <td>120</td>\n",
       "      <td>120</td>\n",
       "      <td>120</td>\n",
       "      <td>120</td>\n",
       "      <td>120</td>\n",
       "      <td>120</td>\n",
       "      <td>120</td>\n",
       "      <td>120</td>\n",
       "      <td>120</td>\n",
       "      <td>120</td>\n",
       "      <td>...</td>\n",
       "      <td>120</td>\n",
       "      <td>120</td>\n",
       "      <td>120</td>\n",
       "      <td>120</td>\n",
       "      <td>120</td>\n",
       "      <td>120</td>\n",
       "      <td>120</td>\n",
       "      <td>120</td>\n",
       "      <td>120</td>\n",
       "      <td>120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>subject2341</th>\n",
       "      <td>129</td>\n",
       "      <td>129</td>\n",
       "      <td>129</td>\n",
       "      <td>129</td>\n",
       "      <td>129</td>\n",
       "      <td>129</td>\n",
       "      <td>129</td>\n",
       "      <td>129</td>\n",
       "      <td>129</td>\n",
       "      <td>129</td>\n",
       "      <td>...</td>\n",
       "      <td>129</td>\n",
       "      <td>129</td>\n",
       "      <td>129</td>\n",
       "      <td>129</td>\n",
       "      <td>129</td>\n",
       "      <td>129</td>\n",
       "      <td>129</td>\n",
       "      <td>129</td>\n",
       "      <td>129</td>\n",
       "      <td>129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>subject2432</th>\n",
       "      <td>332</td>\n",
       "      <td>332</td>\n",
       "      <td>332</td>\n",
       "      <td>332</td>\n",
       "      <td>332</td>\n",
       "      <td>332</td>\n",
       "      <td>332</td>\n",
       "      <td>332</td>\n",
       "      <td>332</td>\n",
       "      <td>332</td>\n",
       "      <td>...</td>\n",
       "      <td>332</td>\n",
       "      <td>332</td>\n",
       "      <td>332</td>\n",
       "      <td>332</td>\n",
       "      <td>332</td>\n",
       "      <td>332</td>\n",
       "      <td>332</td>\n",
       "      <td>332</td>\n",
       "      <td>332</td>\n",
       "      <td>332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>subject2827</th>\n",
       "      <td>663</td>\n",
       "      <td>663</td>\n",
       "      <td>663</td>\n",
       "      <td>663</td>\n",
       "      <td>663</td>\n",
       "      <td>663</td>\n",
       "      <td>663</td>\n",
       "      <td>663</td>\n",
       "      <td>663</td>\n",
       "      <td>663</td>\n",
       "      <td>...</td>\n",
       "      <td>659</td>\n",
       "      <td>659</td>\n",
       "      <td>659</td>\n",
       "      <td>659</td>\n",
       "      <td>659</td>\n",
       "      <td>659</td>\n",
       "      <td>659</td>\n",
       "      <td>659</td>\n",
       "      <td>659</td>\n",
       "      <td>659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>subject2903</th>\n",
       "      <td>313</td>\n",
       "      <td>313</td>\n",
       "      <td>313</td>\n",
       "      <td>313</td>\n",
       "      <td>313</td>\n",
       "      <td>313</td>\n",
       "      <td>313</td>\n",
       "      <td>313</td>\n",
       "      <td>313</td>\n",
       "      <td>313</td>\n",
       "      <td>...</td>\n",
       "      <td>313</td>\n",
       "      <td>313</td>\n",
       "      <td>313</td>\n",
       "      <td>313</td>\n",
       "      <td>313</td>\n",
       "      <td>313</td>\n",
       "      <td>313</td>\n",
       "      <td>313</td>\n",
       "      <td>313</td>\n",
       "      <td>313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>subject2961</th>\n",
       "      <td>180</td>\n",
       "      <td>180</td>\n",
       "      <td>180</td>\n",
       "      <td>180</td>\n",
       "      <td>180</td>\n",
       "      <td>180</td>\n",
       "      <td>180</td>\n",
       "      <td>180</td>\n",
       "      <td>180</td>\n",
       "      <td>180</td>\n",
       "      <td>...</td>\n",
       "      <td>180</td>\n",
       "      <td>180</td>\n",
       "      <td>180</td>\n",
       "      <td>180</td>\n",
       "      <td>180</td>\n",
       "      <td>180</td>\n",
       "      <td>180</td>\n",
       "      <td>180</td>\n",
       "      <td>180</td>\n",
       "      <td>180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>subject3707</th>\n",
       "      <td>1022</td>\n",
       "      <td>1022</td>\n",
       "      <td>1022</td>\n",
       "      <td>1022</td>\n",
       "      <td>1022</td>\n",
       "      <td>1022</td>\n",
       "      <td>1022</td>\n",
       "      <td>1022</td>\n",
       "      <td>1022</td>\n",
       "      <td>1022</td>\n",
       "      <td>...</td>\n",
       "      <td>1022</td>\n",
       "      <td>1022</td>\n",
       "      <td>1022</td>\n",
       "      <td>1022</td>\n",
       "      <td>1022</td>\n",
       "      <td>1022</td>\n",
       "      <td>1022</td>\n",
       "      <td>1022</td>\n",
       "      <td>1022</td>\n",
       "      <td>1022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>subject3993</th>\n",
       "      <td>1510</td>\n",
       "      <td>1510</td>\n",
       "      <td>1510</td>\n",
       "      <td>1510</td>\n",
       "      <td>1510</td>\n",
       "      <td>1510</td>\n",
       "      <td>1510</td>\n",
       "      <td>1510</td>\n",
       "      <td>1510</td>\n",
       "      <td>1510</td>\n",
       "      <td>...</td>\n",
       "      <td>1509</td>\n",
       "      <td>1509</td>\n",
       "      <td>1509</td>\n",
       "      <td>1509</td>\n",
       "      <td>1509</td>\n",
       "      <td>1509</td>\n",
       "      <td>1509</td>\n",
       "      <td>1509</td>\n",
       "      <td>1509</td>\n",
       "      <td>1509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>subject4058</th>\n",
       "      <td>1028</td>\n",
       "      <td>1028</td>\n",
       "      <td>1028</td>\n",
       "      <td>1028</td>\n",
       "      <td>1028</td>\n",
       "      <td>1028</td>\n",
       "      <td>1028</td>\n",
       "      <td>1028</td>\n",
       "      <td>1028</td>\n",
       "      <td>1028</td>\n",
       "      <td>...</td>\n",
       "      <td>1028</td>\n",
       "      <td>1028</td>\n",
       "      <td>1028</td>\n",
       "      <td>1028</td>\n",
       "      <td>1028</td>\n",
       "      <td>1028</td>\n",
       "      <td>1028</td>\n",
       "      <td>1028</td>\n",
       "      <td>1028</td>\n",
       "      <td>1028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>subject436</th>\n",
       "      <td>29</td>\n",
       "      <td>29</td>\n",
       "      <td>29</td>\n",
       "      <td>29</td>\n",
       "      <td>29</td>\n",
       "      <td>29</td>\n",
       "      <td>29</td>\n",
       "      <td>29</td>\n",
       "      <td>29</td>\n",
       "      <td>29</td>\n",
       "      <td>...</td>\n",
       "      <td>29</td>\n",
       "      <td>29</td>\n",
       "      <td>29</td>\n",
       "      <td>29</td>\n",
       "      <td>29</td>\n",
       "      <td>29</td>\n",
       "      <td>29</td>\n",
       "      <td>29</td>\n",
       "      <td>29</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>subject5791</th>\n",
       "      <td>303</td>\n",
       "      <td>303</td>\n",
       "      <td>303</td>\n",
       "      <td>303</td>\n",
       "      <td>303</td>\n",
       "      <td>303</td>\n",
       "      <td>303</td>\n",
       "      <td>303</td>\n",
       "      <td>303</td>\n",
       "      <td>303</td>\n",
       "      <td>...</td>\n",
       "      <td>303</td>\n",
       "      <td>303</td>\n",
       "      <td>303</td>\n",
       "      <td>303</td>\n",
       "      <td>303</td>\n",
       "      <td>303</td>\n",
       "      <td>303</td>\n",
       "      <td>303</td>\n",
       "      <td>303</td>\n",
       "      <td>303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>subject5897</th>\n",
       "      <td>82</td>\n",
       "      <td>82</td>\n",
       "      <td>82</td>\n",
       "      <td>82</td>\n",
       "      <td>82</td>\n",
       "      <td>82</td>\n",
       "      <td>82</td>\n",
       "      <td>82</td>\n",
       "      <td>82</td>\n",
       "      <td>82</td>\n",
       "      <td>...</td>\n",
       "      <td>82</td>\n",
       "      <td>82</td>\n",
       "      <td>82</td>\n",
       "      <td>82</td>\n",
       "      <td>82</td>\n",
       "      <td>82</td>\n",
       "      <td>82</td>\n",
       "      <td>82</td>\n",
       "      <td>82</td>\n",
       "      <td>82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>subject6619</th>\n",
       "      <td>514</td>\n",
       "      <td>514</td>\n",
       "      <td>514</td>\n",
       "      <td>514</td>\n",
       "      <td>514</td>\n",
       "      <td>514</td>\n",
       "      <td>514</td>\n",
       "      <td>514</td>\n",
       "      <td>514</td>\n",
       "      <td>514</td>\n",
       "      <td>...</td>\n",
       "      <td>514</td>\n",
       "      <td>514</td>\n",
       "      <td>514</td>\n",
       "      <td>514</td>\n",
       "      <td>514</td>\n",
       "      <td>514</td>\n",
       "      <td>514</td>\n",
       "      <td>514</td>\n",
       "      <td>514</td>\n",
       "      <td>514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>subject6635</th>\n",
       "      <td>1054</td>\n",
       "      <td>1054</td>\n",
       "      <td>1054</td>\n",
       "      <td>1054</td>\n",
       "      <td>1054</td>\n",
       "      <td>1054</td>\n",
       "      <td>1054</td>\n",
       "      <td>1054</td>\n",
       "      <td>1054</td>\n",
       "      <td>1054</td>\n",
       "      <td>...</td>\n",
       "      <td>1054</td>\n",
       "      <td>1054</td>\n",
       "      <td>1054</td>\n",
       "      <td>1054</td>\n",
       "      <td>1054</td>\n",
       "      <td>1054</td>\n",
       "      <td>1054</td>\n",
       "      <td>1054</td>\n",
       "      <td>1054</td>\n",
       "      <td>1054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>subject6900</th>\n",
       "      <td>313</td>\n",
       "      <td>313</td>\n",
       "      <td>313</td>\n",
       "      <td>313</td>\n",
       "      <td>313</td>\n",
       "      <td>313</td>\n",
       "      <td>313</td>\n",
       "      <td>313</td>\n",
       "      <td>313</td>\n",
       "      <td>313</td>\n",
       "      <td>...</td>\n",
       "      <td>313</td>\n",
       "      <td>313</td>\n",
       "      <td>313</td>\n",
       "      <td>313</td>\n",
       "      <td>313</td>\n",
       "      <td>313</td>\n",
       "      <td>313</td>\n",
       "      <td>313</td>\n",
       "      <td>313</td>\n",
       "      <td>313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>subject7039</th>\n",
       "      <td>561</td>\n",
       "      <td>561</td>\n",
       "      <td>561</td>\n",
       "      <td>561</td>\n",
       "      <td>561</td>\n",
       "      <td>561</td>\n",
       "      <td>561</td>\n",
       "      <td>561</td>\n",
       "      <td>561</td>\n",
       "      <td>561</td>\n",
       "      <td>...</td>\n",
       "      <td>560</td>\n",
       "      <td>560</td>\n",
       "      <td>560</td>\n",
       "      <td>560</td>\n",
       "      <td>560</td>\n",
       "      <td>560</td>\n",
       "      <td>560</td>\n",
       "      <td>560</td>\n",
       "      <td>560</td>\n",
       "      <td>560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>subject9218</th>\n",
       "      <td>323</td>\n",
       "      <td>323</td>\n",
       "      <td>323</td>\n",
       "      <td>323</td>\n",
       "      <td>323</td>\n",
       "      <td>323</td>\n",
       "      <td>323</td>\n",
       "      <td>323</td>\n",
       "      <td>323</td>\n",
       "      <td>323</td>\n",
       "      <td>...</td>\n",
       "      <td>323</td>\n",
       "      <td>323</td>\n",
       "      <td>323</td>\n",
       "      <td>323</td>\n",
       "      <td>323</td>\n",
       "      <td>323</td>\n",
       "      <td>323</td>\n",
       "      <td>323</td>\n",
       "      <td>323</td>\n",
       "      <td>323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>subject9454</th>\n",
       "      <td>180</td>\n",
       "      <td>180</td>\n",
       "      <td>180</td>\n",
       "      <td>180</td>\n",
       "      <td>180</td>\n",
       "      <td>180</td>\n",
       "      <td>180</td>\n",
       "      <td>180</td>\n",
       "      <td>180</td>\n",
       "      <td>180</td>\n",
       "      <td>...</td>\n",
       "      <td>180</td>\n",
       "      <td>180</td>\n",
       "      <td>180</td>\n",
       "      <td>180</td>\n",
       "      <td>180</td>\n",
       "      <td>180</td>\n",
       "      <td>180</td>\n",
       "      <td>180</td>\n",
       "      <td>180</td>\n",
       "      <td>180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>subject9694</th>\n",
       "      <td>1001</td>\n",
       "      <td>1001</td>\n",
       "      <td>1001</td>\n",
       "      <td>1001</td>\n",
       "      <td>1001</td>\n",
       "      <td>1001</td>\n",
       "      <td>1001</td>\n",
       "      <td>1001</td>\n",
       "      <td>1001</td>\n",
       "      <td>1001</td>\n",
       "      <td>...</td>\n",
       "      <td>995</td>\n",
       "      <td>995</td>\n",
       "      <td>995</td>\n",
       "      <td>995</td>\n",
       "      <td>995</td>\n",
       "      <td>995</td>\n",
       "      <td>995</td>\n",
       "      <td>995</td>\n",
       "      <td>995</td>\n",
       "      <td>995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>subject9798</th>\n",
       "      <td>1284</td>\n",
       "      <td>1284</td>\n",
       "      <td>1284</td>\n",
       "      <td>1284</td>\n",
       "      <td>1284</td>\n",
       "      <td>1284</td>\n",
       "      <td>1284</td>\n",
       "      <td>1284</td>\n",
       "      <td>1284</td>\n",
       "      <td>1284</td>\n",
       "      <td>...</td>\n",
       "      <td>1281</td>\n",
       "      <td>1281</td>\n",
       "      <td>1281</td>\n",
       "      <td>1281</td>\n",
       "      <td>1281</td>\n",
       "      <td>1281</td>\n",
       "      <td>1281</td>\n",
       "      <td>1281</td>\n",
       "      <td>1281</td>\n",
       "      <td>1281</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20 rows × 103 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             title  text  date  label0  label1  label2  label3  label4  \\\n",
       "subject                                                                  \n",
       "subject1272    120   120   120     120     120     120     120     120   \n",
       "subject2341    129   129   129     129     129     129     129     129   \n",
       "subject2432    332   332   332     332     332     332     332     332   \n",
       "subject2827    663   663   663     663     663     663     663     663   \n",
       "subject2903    313   313   313     313     313     313     313     313   \n",
       "subject2961    180   180   180     180     180     180     180     180   \n",
       "subject3707   1022  1022  1022    1022    1022    1022    1022    1022   \n",
       "subject3993   1510  1510  1510    1510    1510    1510    1510    1510   \n",
       "subject4058   1028  1028  1028    1028    1028    1028    1028    1028   \n",
       "subject436      29    29    29      29      29      29      29      29   \n",
       "subject5791    303   303   303     303     303     303     303     303   \n",
       "subject5897     82    82    82      82      82      82      82      82   \n",
       "subject6619    514   514   514     514     514     514     514     514   \n",
       "subject6635   1054  1054  1054    1054    1054    1054    1054    1054   \n",
       "subject6900    313   313   313     313     313     313     313     313   \n",
       "subject7039    561   561   561     561     561     561     561     561   \n",
       "subject9218    323   323   323     323     323     323     323     323   \n",
       "subject9454    180   180   180     180     180     180     180     180   \n",
       "subject9694   1001  1001  1001    1001    1001    1001    1001    1001   \n",
       "subject9798   1284  1284  1284    1284    1284    1284    1284    1284   \n",
       "\n",
       "             label5  label6  ...  feel  excl  future  nonfl  ppron  shehe  \\\n",
       "subject                      ...                                            \n",
       "subject1272     120     120  ...   120   120     120    120    120    120   \n",
       "subject2341     129     129  ...   129   129     129    129    129    129   \n",
       "subject2432     332     332  ...   332   332     332    332    332    332   \n",
       "subject2827     663     663  ...   659   659     659    659    659    659   \n",
       "subject2903     313     313  ...   313   313     313    313    313    313   \n",
       "subject2961     180     180  ...   180   180     180    180    180    180   \n",
       "subject3707    1022    1022  ...  1022  1022    1022   1022   1022   1022   \n",
       "subject3993    1510    1510  ...  1509  1509    1509   1509   1509   1509   \n",
       "subject4058    1028    1028  ...  1028  1028    1028   1028   1028   1028   \n",
       "subject436       29      29  ...    29    29      29     29     29     29   \n",
       "subject5791     303     303  ...   303   303     303    303    303    303   \n",
       "subject5897      82      82  ...    82    82      82     82     82     82   \n",
       "subject6619     514     514  ...   514   514     514    514    514    514   \n",
       "subject6635    1054    1054  ...  1054  1054    1054   1054   1054   1054   \n",
       "subject6900     313     313  ...   313   313     313    313    313    313   \n",
       "subject7039     561     561  ...   560   560     560    560    560    560   \n",
       "subject9218     323     323  ...   323   323     323    323    323    323   \n",
       "subject9454     180     180  ...   180   180     180    180    180    180   \n",
       "subject9694    1001    1001  ...   995   995     995    995    995    995   \n",
       "subject9798    1284    1284  ...  1281  1281    1281   1281   1281   1281   \n",
       "\n",
       "                i    we   you  they  \n",
       "subject                              \n",
       "subject1272   120   120   120   120  \n",
       "subject2341   129   129   129   129  \n",
       "subject2432   332   332   332   332  \n",
       "subject2827   659   659   659   659  \n",
       "subject2903   313   313   313   313  \n",
       "subject2961   180   180   180   180  \n",
       "subject3707  1022  1022  1022  1022  \n",
       "subject3993  1509  1509  1509  1509  \n",
       "subject4058  1028  1028  1028  1028  \n",
       "subject436     29    29    29    29  \n",
       "subject5791   303   303   303   303  \n",
       "subject5897    82    82    82    82  \n",
       "subject6619   514   514   514   514  \n",
       "subject6635  1054  1054  1054  1054  \n",
       "subject6900   313   313   313   313  \n",
       "subject7039   560   560   560   560  \n",
       "subject9218   323   323   323   323  \n",
       "subject9454   180   180   180   180  \n",
       "subject9694   995   995   995   995  \n",
       "subject9798  1281  1281  1281  1281  \n",
       "\n",
       "[20 rows x 103 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "writings_df.groupby('subject').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subject</th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>date</th>\n",
       "      <th>label0</th>\n",
       "      <th>label1</th>\n",
       "      <th>label2</th>\n",
       "      <th>label3</th>\n",
       "      <th>label4</th>\n",
       "      <th>label5</th>\n",
       "      <th>...</th>\n",
       "      <th>feel</th>\n",
       "      <th>excl</th>\n",
       "      <th>future</th>\n",
       "      <th>nonfl</th>\n",
       "      <th>ppron</th>\n",
       "      <th>shehe</th>\n",
       "      <th>i</th>\n",
       "      <th>we</th>\n",
       "      <th>you</th>\n",
       "      <th>they</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>subject5791</td>\n",
       "      <td></td>\n",
       "      <td>Great, thanks a ton!</td>\n",
       "      <td>2018-10-30 17:35:30</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>subject5791</td>\n",
       "      <td>The search button gives me a 404 error</td>\n",
       "      <td>Just downloaded GBA4ios 2.1 and when I go to ...</td>\n",
       "      <td>2018-10-30 17:19:41</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.074468</td>\n",
       "      <td>0.074468</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.063830</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.063830</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>subject5791</td>\n",
       "      <td></td>\n",
       "      <td>Remindme! 1 week</td>\n",
       "      <td>2018-10-30 14:33:49</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>subject5791</td>\n",
       "      <td></td>\n",
       "      <td>Me too please</td>\n",
       "      <td>2018-10-19 18:06:38</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>subject5791</td>\n",
       "      <td></td>\n",
       "      <td>Any chance you can pm me what this spoiler is...</td>\n",
       "      <td>2018-10-19 18:04:14</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.027778</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.138889</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.027778</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10936</th>\n",
       "      <td>subject3993</td>\n",
       "      <td>Alternative Currency Being Considered in Penn...</td>\n",
       "      <td></td>\n",
       "      <td>2009-01-07 18:41:30</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10937</th>\n",
       "      <td>subject3993</td>\n",
       "      <td>Asus' new keyboard. Oh wait... thats not a ke...</td>\n",
       "      <td></td>\n",
       "      <td>2009-01-07 17:13:53</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.076923</td>\n",
       "      <td>0.076923</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10938</th>\n",
       "      <td>subject3993</td>\n",
       "      <td>Homeland Security USA - tripe to entertain mo...</td>\n",
       "      <td></td>\n",
       "      <td>2009-01-07 07:09:19</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10939</th>\n",
       "      <td>subject3993</td>\n",
       "      <td>10 dead as Israeli missile hits near U.N. sch...</td>\n",
       "      <td></td>\n",
       "      <td>2009-01-06 17:15:24</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10940</th>\n",
       "      <td>subject3993</td>\n",
       "      <td>iPhone Apps: Helping People Get Rich Quick</td>\n",
       "      <td></td>\n",
       "      <td>2009-01-06 07:25:07</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10941 rows × 104 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           subject                                              title  \\\n",
       "0      subject5791                                                      \n",
       "1      subject5791            The search button gives me a 404 error    \n",
       "2      subject5791                                                      \n",
       "3      subject5791                                                      \n",
       "4      subject5791                                                      \n",
       "...            ...                                                ...   \n",
       "10936  subject3993   Alternative Currency Being Considered in Penn...   \n",
       "10937  subject3993   Asus' new keyboard. Oh wait... thats not a ke...   \n",
       "10938  subject3993   Homeland Security USA - tripe to entertain mo...   \n",
       "10939  subject3993   10 dead as Israeli missile hits near U.N. sch...   \n",
       "10940  subject3993        iPhone Apps: Helping People Get Rich Quick    \n",
       "\n",
       "                                                    text  \\\n",
       "0                                  Great, thanks a ton!    \n",
       "1       Just downloaded GBA4ios 2.1 and when I go to ...   \n",
       "2                                      Remindme! 1 week    \n",
       "3                                         Me too please    \n",
       "4       Any chance you can pm me what this spoiler is...   \n",
       "...                                                  ...   \n",
       "10936                                                      \n",
       "10937                                                      \n",
       "10938                                                      \n",
       "10939                                                      \n",
       "10940                                                      \n",
       "\n",
       "                        date  label0  label1  label2  label3  label4  label5  \\\n",
       "0       2018-10-30 17:35:30        1       0       1       1       0       0   \n",
       "1       2018-10-30 17:19:41        1       0       1       1       0       0   \n",
       "2       2018-10-30 14:33:49        1       0       1       1       0       0   \n",
       "3       2018-10-19 18:06:38        1       0       1       1       0       0   \n",
       "4       2018-10-19 18:04:14        1       0       1       1       0       0   \n",
       "...                      ...     ...     ...     ...     ...     ...     ...   \n",
       "10936   2009-01-07 18:41:30        0       0       0       0       0       0   \n",
       "10937   2009-01-07 17:13:53        0       0       0       0       0       0   \n",
       "10938   2009-01-07 07:09:19        0       0       0       0       0       0   \n",
       "10939   2009-01-06 17:15:24        0       0       0       0       0       0   \n",
       "10940   2009-01-06 07:25:07        0       0       0       0       0       0   \n",
       "\n",
       "       ...  feel      excl    future  nonfl     ppron  shehe         i   we  \\\n",
       "0      ...   0.0  0.000000  0.000000    0.0  0.000000    0.0  0.000000  0.0   \n",
       "1      ...   0.0  0.074468  0.074468    0.0  0.063830    0.0  0.063830  0.0   \n",
       "2      ...   0.0  0.000000  0.000000    0.0  0.000000    0.0  0.000000  0.0   \n",
       "3      ...   0.0  0.000000  0.000000    0.0  0.333333    0.0  0.333333  0.0   \n",
       "4      ...   0.0  0.027778  0.111111    0.0  0.138889    0.0  0.111111  0.0   \n",
       "...    ...   ...       ...       ...    ...       ...    ...       ...  ...   \n",
       "10936  ...   0.0  0.000000  0.000000    0.0  0.000000    0.0  0.000000  0.0   \n",
       "10937  ...   0.0  0.076923  0.076923    0.0  0.000000    0.0  0.000000  0.0   \n",
       "10938  ...   0.0  0.000000  0.000000    0.0  0.000000    0.0  0.000000  0.0   \n",
       "10939  ...   0.0  0.000000  0.000000    0.0  0.000000    0.0  0.000000  0.0   \n",
       "10940  ...   0.0  0.000000  0.000000    0.0  0.000000    0.0  0.000000  0.0   \n",
       "\n",
       "            you  they  \n",
       "0      0.000000   0.0  \n",
       "1      0.000000   0.0  \n",
       "2      0.000000   0.0  \n",
       "3      0.000000   0.0  \n",
       "4      0.027778   0.0  \n",
       "...         ...   ...  \n",
       "10936  0.000000   0.0  \n",
       "10937  0.000000   0.0  \n",
       "10938  0.000000   0.0  \n",
       "10939  0.000000   0.0  \n",
       "10940  0.000000   0.0  \n",
       "\n",
       "[10941 rows x 104 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "writings_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = RegexpTokenizer(r'\\w+')\n",
    "\n",
    "def tokenize(t):\n",
    "    return tokenizer.tokenize(t.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_fields(writings_df):\n",
    "    writings_df['tokenized_title'] = writings_df['title'].apply(lambda t: tokenize(t) \n",
    "                                                                if type(t)==str and t else None)\n",
    "    writings_df['title_len'] = writings_df['tokenized_title'].apply(lambda t: len(t) \n",
    "                                                                    if type(t)==list and t else None)\n",
    "    writings_df['tokenized_text'] = writings_df['text'].apply(lambda t: tokenize(t) \n",
    "                                                              if type(t)==str and t else None)\n",
    "    writings_df['text_len'] = writings_df['tokenized_text'].apply(lambda t: len(t) \n",
    "                                                                  if type(t)==list and t else None)\n",
    "    return writings_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "writings_df = tokenize_fields(writings_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    10409.000000\n",
       "mean        50.365069\n",
       "std         84.811676\n",
       "min          1.000000\n",
       "25%          9.000000\n",
       "50%         24.000000\n",
       "75%         54.000000\n",
       "max       1567.000000\n",
       "Name: text_len, dtype: float64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "writings_df.text_len.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    1119.000000\n",
       "mean       11.246649\n",
       "std         6.979392\n",
       "min         1.000000\n",
       "25%         6.000000\n",
       "50%        10.000000\n",
       "75%        15.000000\n",
       "max        51.000000\n",
       "Name: title_len, dtype: float64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "writings_df.title_len.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count      20.000000\n",
       "mean      547.050000\n",
       "std       446.144828\n",
       "min        29.000000\n",
       "25%       180.000000\n",
       "50%       327.500000\n",
       "75%      1006.250000\n",
       "max      1510.000000\n",
       "Name: title, dtype: float64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "writings_df.groupby('subject').count().title.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count      20.000000\n",
       "mean      547.050000\n",
       "std       446.144828\n",
       "min        29.000000\n",
       "25%       180.000000\n",
       "50%       327.500000\n",
       "75%      1006.250000\n",
       "max      1510.000000\n",
       "Name: text, dtype: float64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "writings_df.groupby('subject').count().text.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparams_features = {\n",
    "    \"max_features\": 20000,\n",
    "    # cut texts after this number of words\n",
    "    # (among top max_features most common words)\n",
    "    \"maxlen\": 100,\n",
    "    \"embedding_dim\": 50,\n",
    "    \"user_level\": True,\n",
    "    \"posts_per_user\": 10,\n",
    "    \"batch_size\": 20,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Emotions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_NRC(nrc_path):\n",
    "    word_emotions = {}\n",
    "    emotion_words = {}\n",
    "    with open(nrc_path) as in_f:\n",
    "        for line in in_f:\n",
    "            line = line.strip()\n",
    "            if not line:\n",
    "                continue\n",
    "            word, emotion, label = line.split()\n",
    "            if word not in word_emotions:\n",
    "                word_emotions[word] = set()\n",
    "            if emotion not in emotion_words:\n",
    "                emotion_words[emotion] = set()\n",
    "            label = int(label)\n",
    "            if label:\n",
    "                word_emotions[word].add(emotion)\n",
    "                emotion_words[emotion].add(word)\n",
    "    return emotion_words\n",
    "\n",
    "nrc_lexicon_path = root_dir + '/resources/NRC-Emotion-Lexicon-Wordlevel-v0.92.txt'\n",
    "nrc_lexicon = load_NRC(nrc_lexicon_path)\n",
    "emotions = list(nrc_lexicon.keys())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_emotions(tokens, emotion_lexicon, emotions, relative=True):\n",
    "    text_len = len(tokens)\n",
    "    encoded_emotions = [0 for e in emotions]\n",
    "    for i, emotion in enumerate(emotions):\n",
    "        try:\n",
    "            emotion_words = [t for t in tokens if t in emotion_lexicon[emotion]]\n",
    "            if relative:\n",
    "                encoded_emotions[i] = len(emotion_words) / len(tokens)\n",
    "            else:\n",
    "                encoded_emotions[i] = len(emotion_words)\n",
    "        except ValueError:\n",
    "            print(\"Emotion not found.\")\n",
    "    return encoded_emotions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "64"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from liwc_readDict import readDict\n",
    "\n",
    "liwc = readDict(root_dir + '/resources/liwc.dic')\n",
    "\n",
    "categories = set([c for (w,c) in liwc])\n",
    "len(categories)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Personal pronouns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_person_pronouns = {\"i\", \"me\", \"my\", \"mine\", \"myself\"}\n",
    "def encode_pronouns(tokens, pronouns={\"i\", \"me\", \"my\", \"mine\", \"myself\"}, relative=True):\n",
    "    if not tokens:\n",
    "        return np.nan\n",
    "    text_len = len(tokens)\n",
    "    nr_pronouns = len([t for t in tokens if t in pronouns])\n",
    "    if relative:\n",
    "        return nr_pronouns/text_len\n",
    "    else:\n",
    "        return nr_pronouns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopword_list = stopwords.words(\"english\")\n",
    "def encode_stopwords(tokens, stopwords=stopword_list):\n",
    "    encoded_stopwords = [0 for s in stopword_list]\n",
    "    if not tokens:\n",
    "        return encoded_stopwords\n",
    "    for i, stopword in enumerate(stopwords):\n",
    "        if stopword in tokens:\n",
    "            encoded_stopwords[i] += 1\n",
    "    return encoded_stopwords"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encode data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "def encode_labels(labels):\n",
    "    '''Convert ia to i and ib to -i'''\n",
    "    encoded_labels = []\n",
    "    for i, l in enumerate(labels):\n",
    "        try:\n",
    "            encoded_labels.append(int(l))\n",
    "        except Exception as e:\n",
    "            logger.debug(\"Encoding label %s\\n\" % l)\n",
    "        \n",
    "            if str(l)[-1] == 'a':\n",
    "                encoded_labels.append(int(l[0]))\n",
    "            elif str(l)[-1] == 'b':\n",
    "                encoded_labels.append(-int(l[0]))\n",
    "            else:\n",
    "                logger.warning(\"Coult not encode label %s\\n\" % l)\n",
    "    return encoded_labels\n",
    "\n",
    "def load_erisk_data(writings_df, voc_size, emotion_lexicon, seq_len, emotions =  \n",
    "                    ['anger', 'anticipation', 'disgust', 'fear', 'joy', \n",
    "                     'negative', 'positive', 'sadness', 'surprise', 'trust'],\n",
    "                    liwc_categories = categories, ignore_features=[],\n",
    "                    pronouns = [\"i\", \"me\", \"my\", \"mine\", \"myself\"],\n",
    "                    train_prop=0.7, valid_prop=0.3, test_slice=2,\n",
    "                    nr_slices=5,\n",
    "                    min_post_len=3, min_word_len=1, \n",
    "                    user_level=True, vocabulary=None,\n",
    "                   logger=logger):\n",
    "    logger.debug(\"Loading data...\\n\")\n",
    "    if not vocabulary:\n",
    "        vocabulary = {}\n",
    "        word_freqs = Counter()\n",
    "        for words in writings_df.tokenized_text:\n",
    "            word_freqs.update(words)\n",
    "        for words in writings_df.tokenized_title:\n",
    "            word_freqs.update(words)\n",
    "        i = 1\n",
    "        for w, f in word_freqs.most_common(voc_size-2): # keeping voc_size-1 for unk\n",
    "            if len(w) < min_word_len:\n",
    "                continue\n",
    "            vocabulary[w] = i\n",
    "            i += 1\n",
    "\n",
    "    if 'subset' in writings_df.columns:\n",
    "        training_subjects = list(set(writings_df[writings_df['subset']=='train'].subject))\n",
    "        test_subjects = list(set(writings_df[writings_df['subset']=='test'].subject))\n",
    "    else:\n",
    "        all_subjects = sorted(list(set(writings_df.subject)))\n",
    "        training_subjects_size = int(len(all_subjects) * train_prop)\n",
    "        test_subjects_size = len(all_subjects) - training_subjects_size\n",
    "        # Cross-validation, with fixed slice as input\n",
    "        test_prop = 1-train_prop\n",
    "        test_slice = min(test_slice, nr_slices)\n",
    "        logger.debug(\"start index: %f, from %f\\n\" % (\n",
    "            len(all_subjects)*(1/nr_slices)*test_slice, test_prop*test_slice))\n",
    "        start_slice = int(len(all_subjects)*(1/nr_slices)*test_slice)\n",
    "        test_subjects = all_subjects[start_slice: start_slice+test_subjects_size]\n",
    "        training_subjects = [s for s in all_subjects if s not in test_subjects]\n",
    "    training_subjects = sorted(training_subjects) # ensuring reproducibility\n",
    "    valid_subjects_size = int(len(training_subjects) * valid_prop)\n",
    "    valid_subjects = training_subjects[:valid_subjects_size]\n",
    "    training_subjects = training_subjects[valid_subjects_size:]\n",
    "    categories = [c for c in liwc_categories if c in writings_df.columns]\n",
    "    logger.debug(\"%d training users, %d validation users, %d test users.\" % (\n",
    "        len(training_subjects), \n",
    "          len(valid_subjects),\n",
    "          len(test_subjects)))\n",
    "    subjects_split = {'train': training_subjects, \n",
    "                      'valid': valid_subjects, \n",
    "                      'test': test_subjects}\n",
    "\n",
    "    user_level_texts = {}\n",
    "    for row in writings_df.sort_values(by='date').itertuples():\n",
    "        words = []\n",
    "        if row.tokenized_title:\n",
    "            words.extend(row.tokenized_title)\n",
    "        if row.tokenized_text:\n",
    "            words.extend(row.tokenized_text)\n",
    "        if not words or len(words)<min_post_len:\n",
    "            print(row.subject)\n",
    "            continue\n",
    "        labels = [getattr(row, 'label%d'%i) for i in range(nr_questions)]\n",
    "        liwc_categs = [getattr(row, categ) for categ in categories]\n",
    "        if row.subject not in user_level_texts.keys():\n",
    "            user_level_texts[row.subject] = {}\n",
    "            user_level_texts[row.subject]['texts'] = [words]\n",
    "            user_level_texts[row.subject]['labels'] = encode_labels(labels)\n",
    "            user_level_texts[row.subject]['liwc'] = [liwc_categs]\n",
    "        else:\n",
    "            user_level_texts[row.subject]['texts'].append(words)\n",
    "            user_level_texts[row.subject]['liwc'].append(liwc_categs)\n",
    "    return user_level_texts, subjects_split, vocabulary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:training:Loading data...\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start index: 8.000000, from 0.600000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:training:start index: 8.000000, from 0.600000\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 training users, 4 validation users, 6 test users.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:training:10 training users, 4 validation users, 6 test users.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "subject3993\n",
      "subject3993\n",
      "subject3993\n",
      "subject9798\n",
      "subject9798\n",
      "subject9798\n",
      "subject9798\n",
      "subject9798\n",
      "subject9798\n",
      "subject9798\n",
      "subject9798\n",
      "subject2903\n",
      "subject9798\n",
      "subject6619\n",
      "subject2903\n",
      "subject2903\n",
      "subject9798\n",
      "subject6619\n",
      "subject6619\n",
      "subject6619\n",
      "subject6619\n",
      "subject6619\n",
      "subject6619\n",
      "subject6619\n",
      "subject6619\n",
      "subject6619\n",
      "subject6619\n",
      "subject3993\n",
      "subject5791\n",
      "subject6619\n",
      "subject5791\n",
      "subject9798\n",
      "subject6619\n",
      "subject9798\n",
      "subject6619\n",
      "subject6619\n",
      "subject6619\n",
      "subject6619\n",
      "subject6619\n",
      "subject6619\n",
      "subject5791\n",
      "subject7039\n",
      "subject5791\n",
      "subject5791\n",
      "subject6619\n",
      "subject6619\n",
      "subject6619\n",
      "subject6619\n",
      "subject6619\n",
      "subject6635\n",
      "subject6619\n",
      "subject6635\n",
      "subject6619\n",
      "subject6635\n",
      "subject6635\n",
      "subject7039\n",
      "subject3993\n",
      "subject6635\n",
      "subject6619\n",
      "subject7039\n",
      "subject9694\n",
      "subject6619\n",
      "subject7039\n",
      "subject7039\n",
      "subject7039\n",
      "subject7039\n",
      "subject7039\n",
      "subject7039\n",
      "subject7039\n",
      "subject7039\n",
      "subject7039\n",
      "subject6619\n",
      "subject7039\n",
      "subject9694\n",
      "subject6635\n",
      "subject6635\n",
      "subject7039\n",
      "subject9694\n",
      "subject9694\n",
      "subject9694\n",
      "subject9694\n",
      "subject9694\n",
      "subject7039\n",
      "subject6619\n",
      "subject9694\n",
      "subject9694\n",
      "subject9694\n",
      "subject9694\n",
      "subject9694\n",
      "subject9694\n",
      "subject9694\n",
      "subject9694\n",
      "subject9694\n",
      "subject9694\n",
      "subject9694\n",
      "subject9694\n",
      "subject9694\n",
      "subject9694\n",
      "subject9694\n",
      "subject6635\n",
      "subject9694\n",
      "subject9694\n",
      "subject9694\n",
      "subject9694\n",
      "subject9694\n",
      "subject9694\n",
      "subject9694\n",
      "subject9694\n",
      "subject9694\n",
      "subject9694\n",
      "subject9694\n",
      "subject9694\n",
      "subject9694\n",
      "subject9694\n",
      "subject9694\n",
      "subject9694\n",
      "subject9694\n",
      "subject9694\n",
      "subject9694\n",
      "subject9694\n",
      "subject9694\n",
      "subject9694\n",
      "subject9694\n",
      "subject9694\n",
      "subject9694\n",
      "subject9694\n",
      "subject9694\n",
      "subject9694\n",
      "subject6635\n",
      "subject9694\n",
      "subject9694\n",
      "subject9694\n",
      "subject9694\n",
      "subject9694\n",
      "subject9694\n",
      "subject9694\n",
      "subject9694\n",
      "subject9694\n",
      "subject9694\n",
      "subject9694\n",
      "subject9694\n",
      "subject9694\n",
      "subject9694\n",
      "subject9694\n",
      "subject9694\n",
      "subject9694\n",
      "subject9694\n",
      "subject9694\n",
      "subject9694\n",
      "subject9694\n",
      "subject9694\n",
      "subject9798\n",
      "subject9694\n",
      "subject9694\n",
      "subject9694\n",
      "subject9694\n",
      "subject9694\n",
      "subject9694\n",
      "subject9694\n",
      "subject9694\n",
      "subject9694\n",
      "subject9694\n",
      "subject9694\n",
      "subject9694\n",
      "subject9694\n",
      "subject9694\n",
      "subject9694\n",
      "subject9694\n",
      "subject9694\n",
      "subject9694\n",
      "subject9694\n",
      "subject9694\n",
      "subject9694\n",
      "subject9694\n",
      "subject9694\n",
      "subject9694\n",
      "subject9694\n",
      "subject9694\n",
      "subject9694\n",
      "subject9694\n",
      "subject9694\n",
      "subject9694\n",
      "subject9694\n",
      "subject6635\n",
      "subject9694\n",
      "subject9694\n",
      "subject9694\n",
      "subject9694\n",
      "subject9694\n",
      "subject9694\n",
      "subject9694\n",
      "subject9694\n",
      "subject5791\n",
      "subject9694\n",
      "subject9694\n",
      "subject9694\n",
      "subject9694\n",
      "subject9694\n",
      "subject9694\n",
      "subject9694\n",
      "subject9694\n",
      "subject9694\n",
      "subject9694\n",
      "subject9694\n",
      "subject9694\n",
      "subject9694\n",
      "subject9694\n",
      "subject9694\n",
      "subject9694\n",
      "subject9694\n",
      "subject9694\n",
      "subject9694\n",
      "subject9694\n",
      "subject9694\n",
      "subject9694\n",
      "subject9694\n",
      "subject9694\n",
      "subject9694\n",
      "subject9694\n",
      "subject9694\n",
      "subject9694\n",
      "subject9694\n",
      "subject6635\n",
      "subject5791\n",
      "subject5791\n",
      "subject9694\n",
      "subject9694\n",
      "subject6619\n",
      "subject9694\n",
      "subject9694\n",
      "subject9694\n",
      "subject9694\n",
      "subject9694\n",
      "subject6619\n",
      "subject6619\n",
      "subject7039\n",
      "subject9694\n",
      "subject9694\n",
      "subject9694\n",
      "subject9694\n",
      "subject9694\n",
      "subject9694\n",
      "subject9694\n",
      "subject9694\n",
      "subject9694\n",
      "subject9694\n",
      "subject9694\n",
      "subject9694\n",
      "subject9694\n",
      "subject9694\n",
      "subject9694\n",
      "subject9694\n",
      "subject9798\n",
      "subject9694\n",
      "subject9694\n",
      "subject9694\n",
      "subject9694\n",
      "subject9694\n",
      "subject9694\n",
      "subject9694\n",
      "subject9694\n",
      "subject9694\n",
      "subject9694\n",
      "subject9694\n",
      "subject9694\n",
      "subject9694\n",
      "subject9694\n",
      "subject9694\n",
      "subject9694\n",
      "subject9694\n",
      "subject6619\n",
      "subject9694\n",
      "subject4058\n",
      "subject9694\n",
      "subject7039\n",
      "subject9694\n",
      "subject4058\n",
      "subject2903\n",
      "subject4058\n",
      "subject2903\n",
      "subject2903\n",
      "subject7039\n",
      "subject4058\n",
      "subject2903\n",
      "subject2903\n",
      "subject3993\n",
      "subject9694\n",
      "subject9694\n",
      "subject3993\n",
      "subject6635\n",
      "subject6635\n",
      "subject9694\n",
      "subject9694\n",
      "subject9694\n",
      "subject9694\n",
      "subject9694\n",
      "subject9694\n",
      "subject9694\n",
      "subject9694\n",
      "subject9694\n",
      "subject9694\n",
      "subject9694\n",
      "subject9694\n",
      "subject9694\n",
      "subject9694\n",
      "subject9694\n",
      "subject3993\n",
      "subject7039\n",
      "subject9694\n",
      "subject9694\n",
      "subject9694\n",
      "subject3993\n",
      "subject3993\n",
      "subject9694\n",
      "subject3993\n",
      "subject3993\n",
      "subject2903\n",
      "subject7039\n",
      "subject9694\n",
      "subject5791\n",
      "subject9694\n",
      "subject9694\n",
      "subject9694\n",
      "subject9694\n",
      "subject7039\n",
      "subject3993\n",
      "subject2903\n",
      "subject2903\n",
      "subject9694\n",
      "subject436\n",
      "subject9694\n",
      "subject9694\n",
      "subject9694\n",
      "subject9694\n",
      "subject9694\n",
      "subject9694\n",
      "subject9694\n",
      "subject9694\n",
      "subject9694\n",
      "subject9694\n",
      "subject9694\n",
      "subject4058\n",
      "subject9798\n",
      "subject4058\n",
      "subject9694\n",
      "subject9694\n",
      "subject9694\n",
      "subject3993\n",
      "subject4058\n",
      "subject9694\n",
      "subject9694\n",
      "subject9694\n",
      "subject4058\n",
      "subject4058\n",
      "subject4058\n",
      "subject4058\n",
      "subject3993\n",
      "subject4058\n",
      "subject4058\n",
      "subject4058\n",
      "subject4058\n",
      "subject4058\n",
      "subject9694\n",
      "subject3993\n",
      "subject9694\n",
      "subject3993\n",
      "subject4058\n",
      "subject3993\n",
      "subject9694\n",
      "subject4058\n",
      "subject3993\n",
      "subject3993\n",
      "subject5897\n",
      "subject9694\n",
      "subject9694\n",
      "subject4058\n",
      "subject2341\n",
      "subject9694\n",
      "subject9694\n",
      "subject4058\n",
      "subject9694\n",
      "subject9694\n",
      "subject9694\n",
      "subject9694\n",
      "subject9798\n",
      "subject9694\n",
      "subject9694\n",
      "subject9694\n",
      "subject9694\n",
      "subject9694\n",
      "subject9694\n",
      "subject9694\n",
      "subject9694\n",
      "subject9694\n",
      "subject9694\n",
      "subject3993\n",
      "subject9798\n",
      "subject4058\n",
      "subject3993\n",
      "subject9798\n",
      "subject9798\n",
      "subject4058\n",
      "subject4058\n",
      "subject4058\n",
      "subject9798\n",
      "subject9798\n",
      "subject9694\n",
      "subject9694\n",
      "subject2432\n",
      "subject9798\n",
      "subject4058\n",
      "subject3993\n",
      "subject3993\n",
      "subject3993\n",
      "subject3993\n",
      "subject9798\n",
      "subject3993\n",
      "subject4058\n",
      "subject3993\n",
      "subject4058\n",
      "subject9694\n",
      "subject9798\n",
      "subject9798\n",
      "subject9798\n",
      "subject3993\n",
      "subject3993\n",
      "subject9798\n",
      "subject9694\n",
      "subject9798\n",
      "subject9798\n",
      "subject9798\n",
      "subject9798\n",
      "subject9798\n",
      "subject9798\n",
      "subject9798\n",
      "subject9798\n",
      "subject9798\n",
      "subject9798\n",
      "subject3993\n",
      "subject9798\n",
      "subject9798\n",
      "subject7039\n",
      "subject9798\n",
      "subject9798\n",
      "subject9798\n",
      "subject9798\n",
      "subject3993\n",
      "subject9694\n",
      "subject3993\n",
      "subject3993\n",
      "subject3993\n",
      "subject9798\n",
      "subject9798\n",
      "subject3993\n",
      "subject3993\n",
      "subject3993\n",
      "subject3993\n",
      "subject9798\n",
      "subject9694\n",
      "subject9694\n",
      "subject9694\n",
      "subject9694\n",
      "subject9694\n",
      "subject9694\n",
      "subject9694\n",
      "subject9694\n",
      "subject9694\n",
      "subject9694\n",
      "subject9694\n",
      "subject9694\n",
      "subject9694\n",
      "subject9694\n",
      "subject9694\n",
      "subject9694\n",
      "subject9694\n",
      "subject2432\n",
      "subject3993\n",
      "subject9694\n",
      "subject3993\n",
      "subject3993\n",
      "subject3993\n",
      "subject4058\n",
      "subject3993\n",
      "subject3707\n",
      "subject9694\n",
      "subject9694\n",
      "subject9694\n",
      "subject9694\n",
      "subject3707\n",
      "subject4058\n",
      "subject4058\n",
      "subject9798\n",
      "subject9798\n",
      "subject9694\n",
      "subject7039\n",
      "subject9694\n",
      "subject9798\n",
      "subject9798\n",
      "subject3707\n",
      "subject9798\n",
      "subject9694\n",
      "subject9798\n",
      "subject4058\n",
      "subject9798\n",
      "subject3993\n",
      "subject9694\n",
      "subject9798\n",
      "subject9694\n",
      "subject9798\n",
      "subject9798\n",
      "subject3707\n",
      "subject9798\n",
      "subject9798\n",
      "subject7039\n",
      "subject9798\n",
      "subject2432\n",
      "subject2432\n",
      "subject9798\n",
      "subject9798\n",
      "subject9798\n",
      "subject9694\n",
      "subject9694\n",
      "subject9694\n",
      "subject3707\n",
      "subject2432\n",
      "subject2432\n",
      "subject9798\n",
      "subject9694\n",
      "subject9694\n",
      "subject2432\n",
      "subject2432\n",
      "subject2432\n",
      "subject9694\n",
      "subject9798\n",
      "subject9798\n",
      "subject9798\n",
      "subject3707\n",
      "subject9798\n",
      "subject9694\n",
      "subject2432\n",
      "subject2432\n",
      "subject3707\n",
      "subject9798\n",
      "subject2432\n",
      "subject2432\n",
      "subject9694\n",
      "subject2432\n",
      "subject9694\n",
      "subject9798\n",
      "subject7039\n",
      "subject9798\n",
      "subject9798\n",
      "subject9798\n",
      "subject9694\n",
      "subject2432\n",
      "subject9694\n",
      "subject3707\n",
      "subject2432\n",
      "subject2432\n",
      "subject2432\n",
      "subject9694\n",
      "subject9694\n",
      "subject2432\n",
      "subject1272\n",
      "subject9798\n",
      "subject9798\n",
      "subject1272\n",
      "subject1272\n",
      "subject1272\n",
      "subject1272\n",
      "subject1272\n",
      "subject1272\n",
      "subject1272\n",
      "subject1272\n",
      "subject1272\n",
      "subject1272\n",
      "subject1272\n",
      "subject1272\n",
      "subject1272\n",
      "subject1272\n",
      "subject1272\n",
      "subject1272\n",
      "subject9798\n",
      "subject3707\n",
      "subject3707\n",
      "subject1272\n",
      "subject1272\n",
      "subject1272\n",
      "subject1272\n",
      "subject2432\n",
      "subject1272\n",
      "subject2432\n",
      "subject1272\n",
      "subject1272\n",
      "subject3707\n",
      "subject2432\n",
      "subject2432\n",
      "subject2432\n",
      "subject9694\n",
      "subject9694\n",
      "subject9798\n",
      "subject9798\n",
      "subject9694\n",
      "subject9694\n",
      "subject9798\n",
      "subject9694\n",
      "subject2432\n",
      "subject2432\n",
      "subject9694\n",
      "subject9694\n",
      "subject2432\n",
      "subject9798\n",
      "subject2432\n",
      "subject3707\n",
      "subject9694\n",
      "subject9798\n",
      "subject2432\n",
      "subject9798\n",
      "subject9798\n",
      "subject2432\n",
      "subject9694\n",
      "subject2432\n",
      "subject9694\n",
      "subject9798\n",
      "subject3707\n",
      "subject9694\n",
      "subject2432\n",
      "subject2432\n",
      "subject9694\n",
      "subject1272\n",
      "subject3707\n",
      "subject9798\n",
      "subject9694\n",
      "subject2432\n",
      "subject9694\n",
      "subject2432\n",
      "subject2432\n",
      "subject2341\n",
      "subject2432\n",
      "subject9798\n",
      "subject2432\n",
      "subject9798\n",
      "subject9798\n",
      "subject9798\n",
      "subject3707\n",
      "subject2432\n",
      "subject2432\n",
      "subject2432\n",
      "subject2432\n",
      "subject9798\n",
      "subject4058\n",
      "subject9454\n",
      "subject9798\n",
      "subject2432\n",
      "subject9454\n",
      "subject9694\n",
      "subject9694\n",
      "subject3993\n",
      "subject9694\n",
      "subject9454\n",
      "subject9454\n",
      "subject9454\n",
      "subject9798\n",
      "subject2432\n",
      "subject3993\n",
      "subject9694\n",
      "subject9694\n",
      "subject9694\n",
      "subject3707\n",
      "subject9694\n",
      "subject9694\n",
      "subject9798\n",
      "subject9454\n",
      "subject9454\n",
      "subject3707\n",
      "subject9798\n",
      "subject2827\n",
      "subject9454\n",
      "subject9694\n",
      "subject9454\n",
      "subject9798\n",
      "subject9694\n",
      "subject9218\n",
      "subject9218\n",
      "subject9218\n",
      "subject2432\n",
      "subject9218\n",
      "subject9218\n",
      "subject9218\n",
      "subject9454\n",
      "subject3707\n",
      "subject2827\n",
      "subject9798\n",
      "subject9218\n",
      "subject2827\n",
      "subject2827\n",
      "subject9218\n",
      "subject2827\n",
      "subject2827\n",
      "subject2827\n",
      "subject2827\n",
      "subject9454\n",
      "subject9454\n",
      "subject2827\n",
      "subject2827\n",
      "subject9694\n",
      "subject9694\n",
      "subject3707\n",
      "subject2827\n",
      "subject2827\n",
      "subject9454\n",
      "subject9218\n",
      "subject2827\n",
      "subject9218\n",
      "subject9218\n",
      "subject3707\n",
      "subject9218\n",
      "subject3707\n",
      "subject9218\n",
      "subject9218\n",
      "subject2827\n",
      "subject9454\n",
      "subject2827\n",
      "subject9454\n",
      "subject3993\n",
      "subject2827\n",
      "subject9798\n",
      "subject9454\n",
      "subject9454\n",
      "subject9454\n",
      "subject2961\n",
      "subject2827\n",
      "subject9454\n",
      "subject9218\n",
      "subject9218\n",
      "subject9218\n",
      "subject9218\n",
      "subject2432\n",
      "subject9454\n",
      "subject9798\n",
      "subject6900\n",
      "subject2961\n",
      "subject2961\n",
      "subject2961\n",
      "subject9454\n",
      "subject2827\n",
      "subject2827\n",
      "subject9218\n",
      "subject2827\n",
      "subject2827\n",
      "subject9218\n",
      "subject2827\n",
      "subject2961\n",
      "subject9218\n",
      "subject9798\n",
      "subject5897\n",
      "subject9694\n",
      "subject9218\n",
      "subject2827\n",
      "subject9218\n",
      "subject2827\n",
      "subject9218\n",
      "subject9694\n",
      "subject2432\n",
      "subject2827\n",
      "subject9454\n",
      "subject2432\n",
      "subject2961\n",
      "subject9218\n",
      "subject9694\n",
      "subject2961\n",
      "subject2432\n",
      "subject9454\n",
      "subject2432\n",
      "subject9694\n",
      "subject9694\n",
      "subject9694\n",
      "subject9694\n",
      "subject9694\n",
      "subject9694\n",
      "subject9694\n",
      "subject9798\n",
      "subject2827\n",
      "subject2432\n",
      "subject9798\n",
      "subject9694\n",
      "subject6900\n",
      "subject9798\n",
      "subject3993\n",
      "subject9694\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "subject6900\n",
      "subject6900\n",
      "subject6900\n",
      "subject6900\n",
      "subject9798\n",
      "subject3993\n",
      "subject9694\n",
      "subject6900\n",
      "subject9694\n",
      "subject9694\n",
      "subject2903\n",
      "subject4058\n",
      "subject3707\n",
      "subject3707\n",
      "subject9694\n",
      "subject9694\n",
      "subject9694\n",
      "subject9798\n",
      "subject3993\n",
      "subject9694\n",
      "subject2903\n",
      "subject6900\n",
      "subject6900\n",
      "subject6900\n",
      "subject9798\n",
      "subject2903\n",
      "subject2903\n"
     ]
    }
   ],
   "source": [
    "user_level_data, subjects_split, vocabulary = load_erisk_data(writings_df, \n",
    "                                                            seq_len=hyperparams_features['maxlen'],\n",
    "                                                            voc_size=hyperparams_features['max_features'],\n",
    "                                                           emotion_lexicon=nrc_lexicon,\n",
    "                                                           emotions=emotions,\n",
    "                                                           user_level=hyperparams_features['user_level'],\n",
    "                                                                                logger=logger\n",
    "#                                                            vocabulary=pickle.load(open('vocabulary20K_selfharm.pkl', 'rb'))\n",
    "                                                                               )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total 20000 word vectors.\n"
     ]
    }
   ],
   "source": [
    "def load_embeddings(path, embedding_dim, voc):\n",
    "    # random matrix with mean value = 0\n",
    "    embedding_matrix = np.random.random((len(voc)+2, embedding_dim)) - 0.5 # voc + unk + pad value(0)\n",
    "\n",
    "    f = open(path)\n",
    "    for line in f:\n",
    "        values = line.split()\n",
    "        word = values[0]\n",
    "        coefs = np.asarray(values[1:], dtype='float32')\n",
    "        word_i = voc.get(word)\n",
    "        if word_i is not None:\n",
    "            embedding_matrix[word_i] = coefs\n",
    "    f.close()\n",
    "\n",
    "    print('Total %s word vectors.' % len(embedding_matrix))\n",
    "\n",
    " \n",
    "    return embedding_matrix\n",
    "\n",
    "pretrained_embeddings_path = root_dir + '/resources/glove.twitter.27B/glove.twitter.27B.%dd.txt' % hyperparams_features['embedding_dim']\n",
    "embedding_matrix = load_embeddings(pretrained_embeddings_path, hyperparams_features['embedding_dim'], vocabulary)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataGenerator(Sequence):\n",
    "    'Generates data for Keras'\n",
    "    def __init__(self, user_level_data, batch_size=hyperparams_features['batch_size'], \n",
    "                 seq_len=hyperparams_features['maxlen'], voc_size=hyperparams_features['max_features'], \n",
    "                 emotion_lexicon=nrc_lexicon, set_type='train', test_user_index=0,\n",
    "                 emotions=emotions, pronouns=[\"i\", \"me\", \"my\", \"mine\", \"myself\"], \n",
    "                 max_posts_per_user=hyperparams_features['posts_per_user'],\n",
    "                 shuffle=True):\n",
    "        'Initialization'\n",
    "        self.seq_len = seq_len\n",
    "        self.emotion_lexicon = emotion_lexicon\n",
    "        self.batch_size = batch_size\n",
    "        self.data = user_level_data\n",
    "        self.all_users = list(self.data.keys())\n",
    "        self.emotions = emotions\n",
    "        self.pronouns = pronouns\n",
    "        self.set = set_type\n",
    "        self.shuffle = shuffle\n",
    "        self.voc_size = voc_size\n",
    "        self.max_posts_per_user = max_posts_per_user\n",
    "        self.test_user_index = test_user_index\n",
    "        self.on_epoch_end()\n",
    "\n",
    "    def __encode_text(self, tokens):\n",
    "        # Using voc_size-1 value for OOV token\n",
    "        encoded_tokens = [vocabulary.get(w, self.voc_size-1) for w in tokens]\n",
    "        encoded_emotions = encode_emotions(tokens, self.emotion_lexicon, self.emotions)\n",
    "        encoded_pronouns = encode_pronouns(tokens, self.pronouns)\n",
    "        encoded_stopwords = encode_stopwords(tokens)\n",
    "        return (encoded_tokens, encoded_emotions, encoded_pronouns, encoded_stopwords)\n",
    "        \n",
    "    def __len__(self):\n",
    "        'Denotes the number of batches per epoch'\n",
    "        if self.set == 'test':\n",
    "            return 1\n",
    "        return int(np.floor(len(self.data) / self.batch_size))\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        'Generate one batch of data'\n",
    "        if self.set == 'test':\n",
    "            users = [self.all_users[self.test_user_index]]\n",
    "        else:\n",
    "            # Generate indexes of the batch\n",
    "            user_indexes = self.indexes[index*self.batch_size:(index+1)*self.batch_size]\n",
    "            # Find users\n",
    "\n",
    "            users = [self.all_users[i] for i in user_indexes\n",
    "                     if i!=self.test_user_index\n",
    "                    ]\n",
    "\n",
    "        post_indexes = {}\n",
    "        # Sample post ids\n",
    "        for subject in users:\n",
    "            posts_len = len(self.data[subject]['texts'])\n",
    "            posts_index_sample = sorted(np.random.choice(posts_len, \n",
    "                                                         min(self.max_posts_per_user, posts_len),\n",
    "                                                         replace=False))\n",
    "            post_indexes[subject] = posts_index_sample\n",
    "        # Generate data\n",
    "        X, y = self.__data_generation(users, post_indexes)\n",
    "\n",
    "        return X, y\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        'Updates indexes after each epoch'\n",
    "        self.indexes = np.arange(len(self.data))\n",
    "        if self.shuffle == True:\n",
    "            np.random.shuffle(self.indexes)\n",
    "\n",
    "    def __data_generation(self, users, post_indexes):\n",
    "        'Generates data containing batch_size samples' # X : (n_samples, *dim, n_channels)\n",
    "        tokens_data = []\n",
    "        categ_data = []\n",
    "        sparse_data = []\n",
    "        subjects = []\n",
    "        labels = []\n",
    "        for subject in users:\n",
    "            texts = self.data[subject]['texts']\n",
    "            label = self.data[subject]['labels']\n",
    "            \n",
    "            # Sample\n",
    "            texts = [texts[i] for i in post_indexes[subject]]\n",
    "            liwc_selection = [self.data[subject]['liwc'][i] for i in post_indexes[subject]]\n",
    "\n",
    "            all_words = [sum(texts, [])] # merge all texts in one list\n",
    "            liwc_aggreg = [np.array(liwc_selection).mean(axis=0).tolist()]\n",
    "\n",
    "            for i, words in enumerate(all_words):\n",
    "                encoded_tokens, encoded_emotions, encoded_pronouns, encoded_stopwords = self.__encode_text(words)\n",
    "                subject_id = int(subject.split('t')[1])\n",
    "                tokens_data.append(encoded_tokens)\n",
    "                categ_data.append(encoded_emotions + [encoded_pronouns] + liwc_aggreg[i])\n",
    "                sparse_data.append(encoded_stopwords)\n",
    "                labels.append(label)\n",
    "                subjects.append(subject_id)\n",
    "\n",
    "        \n",
    "        # using zeros for padding\n",
    "        tokens_data_padded = sequence.pad_sequences(tokens_data, maxlen=self.seq_len)\n",
    "\n",
    "        return ([np.array(tokens_data_padded), np.array(categ_data), np.array(sparse_data),\n",
    "                np.array(subjects)],\n",
    "                np.array(labels).reshape(-1, len(labels)).tolist()) # to have one array per output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Don't split into the 3 sets, do leave-one-out cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger.setLevel(logging.DEBUG)\n",
    "\n",
    "# TODO: it is skipping the last batch\n",
    "x_data = {'train': [], 'test': []}\n",
    "y_data = {'train': [], 'test': []}\n",
    "test_user_index = np.random.randint(len(user_level_data))\n",
    "for set_type in ['train', 'test']:\n",
    "    for x, y in DataGenerator(user_level_data, \n",
    "                                          set_type=set_type,\n",
    "                             test_user_index=test_user_index):\n",
    "        x_data[set_type].append(x)\n",
    "        y_data[set_type].append(y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [1.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [1.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [1.0],\n",
       " [-2.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [2.0],\n",
       " [1.0],\n",
       " [0.0]]"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_data['test'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 2],\n",
       "       [3, 4]])"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array([[1,2],[3,4]]).reshape(2,-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum([len(subjects_split[s]) for s in ['train', 'valid', 'test']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[array([[  206,   174,   399,    15,     2,   757, 11823,    14, 19060,\n",
       "              2,   214,     4,  8411,    18, 19061,   278,    15,     7,\n",
       "             14,    25,  1927,   969,  5554,   218,     2,   140,   720,\n",
       "              9,    52,    34,     1,   105,    59,  2011,  3078,    77,\n",
       "           5427,    12,  1180,  4866,  5428,     1,   806,   494,  5429,\n",
       "            495,  1826,  1461,  1180,   418,     5,  2876,  5430,     2,\n",
       "            119,   446,    19,  3078,    15,   253,    52,   365,    13,\n",
       "             57,   547,  3495,    34,    81,   322,     1,   161,  2712,\n",
       "             55,    91,  2881,  3425,   225,   164,  1080,    35,  3425,\n",
       "             10,  3495,   472,     3,  1691,     1,   708,     8,     1,\n",
       "            495,   803,   495,  1826,  1461,     5,  5431,     4,  4782,\n",
       "            744]], dtype=int32),\n",
       "  array([[0.02380952, 0.01984127, 0.01190476, 0.03174603, 0.02380952,\n",
       "          0.0515873 , 0.04365079, 0.02777778, 0.01587302, 0.02380952,\n",
       "          0.03571429, 0.14160664, 0.14298647, 0.01111111, 0.00842199,\n",
       "          0.01762766, 0.07404306, 0.44766312, 0.12079112, 0.00212766,\n",
       "          0.09492612, 0.16493338, 0.        , 0.00564421, 0.        ,\n",
       "          0.03114286, 0.00751655, 0.        , 0.00833333, 0.08671505,\n",
       "          0.0368254 , 0.05467663, 0.00357143, 0.12956299, 0.04825464,\n",
       "          0.08221437, 0.0409306 , 0.01936643, 0.02298219, 0.01011111,\n",
       "          0.        , 0.00357143, 0.13103588, 0.09631493, 0.00751655,\n",
       "          0.        , 0.00357143, 0.        , 0.        , 0.02799941,\n",
       "          0.00714286, 0.        , 0.        , 0.00833333, 0.01323286,\n",
       "          0.06689092, 0.00212766, 0.02      , 0.04432084, 0.00666667,\n",
       "          0.03590476, 0.        , 0.03890544, 0.01175532, 0.01589421,\n",
       "          0.04667199, 0.        , 0.03537698, 0.10165282, 0.0113433 ,\n",
       "          0.00351655, 0.00569909, 0.05887333, 0.        , 0.01046099]]),\n",
       "  array([[1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0,\n",
       "          0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0,\n",
       "          0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1,\n",
       "          0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0,\n",
       "          1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0,\n",
       "          0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0,\n",
       "          0, 0, 0]]),\n",
       "  array([6619])]]"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_data['test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'train': [[[1.0,\n",
       "    1.0,\n",
       "    0.0,\n",
       "    1.0,\n",
       "    0.0,\n",
       "    0.0,\n",
       "    2.0,\n",
       "    0.0,\n",
       "    0.0,\n",
       "    0.0,\n",
       "    0.0,\n",
       "    1.0,\n",
       "    0.0,\n",
       "    0.0,\n",
       "    0.0,\n",
       "    0.0,\n",
       "    2.0,\n",
       "    0.0,\n",
       "    0.0],\n",
       "   [0.0,\n",
       "    2.0,\n",
       "    1.0,\n",
       "    3.0,\n",
       "    3.0,\n",
       "    2.0,\n",
       "    3.0,\n",
       "    2.0,\n",
       "    2.0,\n",
       "    2.0,\n",
       "    2.0,\n",
       "    1.0,\n",
       "    1.0,\n",
       "    3.0,\n",
       "    1.0,\n",
       "    3.0,\n",
       "    2.0,\n",
       "    1.0,\n",
       "    2.0],\n",
       "   [1.0,\n",
       "    2.0,\n",
       "    1.0,\n",
       "    0.0,\n",
       "    1.0,\n",
       "    3.0,\n",
       "    3.0,\n",
       "    2.0,\n",
       "    1.0,\n",
       "    3.0,\n",
       "    3.0,\n",
       "    3.0,\n",
       "    2.0,\n",
       "    3.0,\n",
       "    2.0,\n",
       "    3.0,\n",
       "    3.0,\n",
       "    2.0,\n",
       "    2.0],\n",
       "   [-3.0,\n",
       "    1.0,\n",
       "    3.0,\n",
       "    3.0,\n",
       "    3.0,\n",
       "    0.0,\n",
       "    2.0,\n",
       "    2.0,\n",
       "    1.0,\n",
       "    2.0,\n",
       "    1.0,\n",
       "    0.0,\n",
       "    3.0,\n",
       "    2.0,\n",
       "    1.0,\n",
       "    2.0,\n",
       "    2.0,\n",
       "    3.0,\n",
       "    1.0],\n",
       "   [2.0,\n",
       "    2.0,\n",
       "    2.0,\n",
       "    0.0,\n",
       "    2.0,\n",
       "    2.0,\n",
       "    1.0,\n",
       "    1.0,\n",
       "    1.0,\n",
       "    3.0,\n",
       "    0.0,\n",
       "    1.0,\n",
       "    0.0,\n",
       "    0.0,\n",
       "    0.0,\n",
       "    1.0,\n",
       "    1.0,\n",
       "    2.0,\n",
       "    3.0],\n",
       "   [0.0,\n",
       "    0.0,\n",
       "    2.0,\n",
       "    2.0,\n",
       "    -3.0,\n",
       "    1.0,\n",
       "    -1.0,\n",
       "    2.0,\n",
       "    1.0,\n",
       "    3.0,\n",
       "    0.0,\n",
       "    0.0,\n",
       "    0.0,\n",
       "    1.0,\n",
       "    0.0,\n",
       "    0.0,\n",
       "    0.0,\n",
       "    0.0,\n",
       "    1.0],\n",
       "   [0.0,\n",
       "    0.0,\n",
       "    0.0,\n",
       "    0.0,\n",
       "    0.0,\n",
       "    3.0,\n",
       "    2.0,\n",
       "    1.0,\n",
       "    0.0,\n",
       "    0.0,\n",
       "    3.0,\n",
       "    0.0,\n",
       "    0.0,\n",
       "    0.0,\n",
       "    0.0,\n",
       "    0.0,\n",
       "    0.0,\n",
       "    0.0,\n",
       "    0.0],\n",
       "   [0.0,\n",
       "    0.0,\n",
       "    0.0,\n",
       "    0.0,\n",
       "    0.0,\n",
       "    0.0,\n",
       "    0.0,\n",
       "    0.0,\n",
       "    0.0,\n",
       "    0.0,\n",
       "    -1.0,\n",
       "    0.0,\n",
       "    0.0,\n",
       "    1.0,\n",
       "    1.0,\n",
       "    3.0,\n",
       "    3.0,\n",
       "    2.0,\n",
       "    3.0],\n",
       "   [2.0,\n",
       "    2.0,\n",
       "    3.0,\n",
       "    2.0,\n",
       "    2.0,\n",
       "    1.0,\n",
       "    1.0,\n",
       "    2.0,\n",
       "    3.0,\n",
       "    1.0,\n",
       "    -2.0,\n",
       "    1.0,\n",
       "    0.0,\n",
       "    2.0,\n",
       "    2.0,\n",
       "    1.0,\n",
       "    1.0,\n",
       "    1.0,\n",
       "    2.0],\n",
       "   [1.0,\n",
       "    3.0,\n",
       "    0.0,\n",
       "    1.0,\n",
       "    1.0,\n",
       "    0.0,\n",
       "    0.0,\n",
       "    2.0,\n",
       "    3.0,\n",
       "    0.0,\n",
       "    0.0,\n",
       "    2.0,\n",
       "    -2.0,\n",
       "    2.0,\n",
       "    0.0,\n",
       "    2.0,\n",
       "    1.0,\n",
       "    1.0,\n",
       "    0.0],\n",
       "   [0.0,\n",
       "    1.0,\n",
       "    1.0,\n",
       "    0.0,\n",
       "    0.0,\n",
       "    1.0,\n",
       "    0.0,\n",
       "    0.0,\n",
       "    0.0,\n",
       "    0.0,\n",
       "    0.0,\n",
       "    0.0,\n",
       "    0.0,\n",
       "    1.0,\n",
       "    0.0,\n",
       "    0.0,\n",
       "    -1.0,\n",
       "    0.0,\n",
       "    1.0],\n",
       "   [2.0,\n",
       "    0.0,\n",
       "    0.0,\n",
       "    2.0,\n",
       "    0.0,\n",
       "    1.0,\n",
       "    0.0,\n",
       "    0.0,\n",
       "    0.0,\n",
       "    0.0,\n",
       "    0.0,\n",
       "    1.0,\n",
       "    0.0,\n",
       "    0.0,\n",
       "    0.0,\n",
       "    0.0,\n",
       "    0.0,\n",
       "    0.0,\n",
       "    0.0],\n",
       "   [0.0,\n",
       "    0.0,\n",
       "    0.0,\n",
       "    1.0,\n",
       "    2.0,\n",
       "    2.0,\n",
       "    1.0,\n",
       "    0.0,\n",
       "    1.0,\n",
       "    3.0,\n",
       "    2.0,\n",
       "    1.0,\n",
       "    3.0,\n",
       "    3.0,\n",
       "    1.0,\n",
       "    2.0,\n",
       "    2.0,\n",
       "    2.0,\n",
       "    -3.0],\n",
       "   [0.0,\n",
       "    3.0,\n",
       "    1.0,\n",
       "    2.0,\n",
       "    2.0,\n",
       "    2.0,\n",
       "    1.0,\n",
       "    2.0,\n",
       "    3.0,\n",
       "    2.0,\n",
       "    0.0,\n",
       "    3.0,\n",
       "    3.0,\n",
       "    1.0,\n",
       "    2.0,\n",
       "    1.0,\n",
       "    3.0,\n",
       "    2.0,\n",
       "    2.0],\n",
       "   [3.0,\n",
       "    2.0,\n",
       "    1.0,\n",
       "    -2.0,\n",
       "    1.0,\n",
       "    3.0,\n",
       "    2.0,\n",
       "    2.0,\n",
       "    3.0,\n",
       "    3.0,\n",
       "    2.0,\n",
       "    1.0,\n",
       "    0.0,\n",
       "    2.0,\n",
       "    2.0,\n",
       "    1.0,\n",
       "    0.0,\n",
       "    0.0,\n",
       "    3.0],\n",
       "   [2.0,\n",
       "    2.0,\n",
       "    3.0,\n",
       "    1.0,\n",
       "    1.0,\n",
       "    -1.0,\n",
       "    3.0,\n",
       "    3.0,\n",
       "    1.0,\n",
       "    1.0,\n",
       "    1.0,\n",
       "    2.0,\n",
       "    1.0,\n",
       "    0.0,\n",
       "    0.0,\n",
       "    1.0,\n",
       "    1.0,\n",
       "    1.0,\n",
       "    1.0],\n",
       "   [1.0,\n",
       "    1.0,\n",
       "    0.0,\n",
       "    1.0,\n",
       "    2.0,\n",
       "    2.0,\n",
       "    0.0,\n",
       "    0.0,\n",
       "    0.0,\n",
       "    1.0,\n",
       "    0.0,\n",
       "    0.0,\n",
       "    1.0,\n",
       "    1.0,\n",
       "    1.0,\n",
       "    1.0,\n",
       "    0.0,\n",
       "    3.0,\n",
       "    1.0],\n",
       "   [1.0,\n",
       "    0.0,\n",
       "    2.0,\n",
       "    1.0,\n",
       "    3.0,\n",
       "    1.0,\n",
       "    2.0,\n",
       "    -3.0,\n",
       "    1.0,\n",
       "    1.0,\n",
       "    1.0,\n",
       "    1.0,\n",
       "    2.0,\n",
       "    1.0,\n",
       "    2.0,\n",
       "    3.0,\n",
       "    2.0,\n",
       "    3.0,\n",
       "    2.0],\n",
       "   [3.0,\n",
       "    3.0,\n",
       "    1.0,\n",
       "    0.0,\n",
       "    0.0,\n",
       "    2.0,\n",
       "    3.0,\n",
       "    3.0,\n",
       "    2.0,\n",
       "    -2.0,\n",
       "    2.0,\n",
       "    -3.0,\n",
       "    2.0,\n",
       "    2.0,\n",
       "    0.0,\n",
       "    1.0,\n",
       "    1.0,\n",
       "    1.0,\n",
       "    1.0],\n",
       "   [0.0,\n",
       "    0.0,\n",
       "    1.0,\n",
       "    1.0,\n",
       "    1.0,\n",
       "    1.0,\n",
       "    1.0,\n",
       "    1.0,\n",
       "    1.0,\n",
       "    0.0,\n",
       "    2.0,\n",
       "    -1.0,\n",
       "    0.0,\n",
       "    -3.0,\n",
       "    1.0,\n",
       "    1.0,\n",
       "    1.0,\n",
       "    1.0,\n",
       "    0.0],\n",
       "   [1.0,\n",
       "    1.0,\n",
       "    0.0,\n",
       "    0.0,\n",
       "    2.0,\n",
       "    1.0,\n",
       "    0.0,\n",
       "    0.0,\n",
       "    0.0,\n",
       "    1.0,\n",
       "    0.0,\n",
       "    1.0,\n",
       "    1.0,\n",
       "    -1.0,\n",
       "    1.0,\n",
       "    0.0,\n",
       "    1.0,\n",
       "    0.0,\n",
       "    0.0]]],\n",
       " 'test': [[[0.0],\n",
       "   [0.0],\n",
       "   [0.0],\n",
       "   [1.0],\n",
       "   [0.0],\n",
       "   [0.0],\n",
       "   [0.0],\n",
       "   [0.0],\n",
       "   [0.0],\n",
       "   [0.0],\n",
       "   [0.0],\n",
       "   [1.0],\n",
       "   [0.0],\n",
       "   [0.0],\n",
       "   [1.0],\n",
       "   [-2.0],\n",
       "   [0.0],\n",
       "   [0.0],\n",
       "   [2.0],\n",
       "   [1.0],\n",
       "   [0.0]]]}"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparams = {\n",
    "    'lstm_units': 0,\n",
    "    'dense_bow_units': 20,\n",
    "    'dropout': 0.0,\n",
    "    'l2_dense': 0.00000011,\n",
    "    'l2_embeddings': 0.000001,\n",
    "    'dense_sentence_units': 100,\n",
    "    'optimizer': 'adam',\n",
    "    'decay': 0.00001,\n",
    "    'lr': 0.001,\n",
    "    \"trainable_embeddings\": True,\n",
    "    \"reduce_lr_factor\": 0.0002,\n",
    "    \"reduce_lr_patience\": 1000,\n",
    "    \"freeze_patience\": 500,\n",
    "    'threshold': 0.5,\n",
    "    'ignore_layer': ['lstm_layers', 'batchnorm'],\n",
    "    'norm_momentum': 0.1,\n",
    "\n",
    "}\n",
    "if not hyperparams['optimizer']:\n",
    "    hyperparams['optimizer'] = optimizers.Adam(lr=hyperparams['lr'], #beta_1=0.9, beta_2=0.999, epsilon=0.0001,\n",
    "                                   decay=hyperparams['decay'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class Metrics():\n",
    "#     def __init__(self, threshold=0.5):\n",
    "#         self.threshold=threshold\n",
    "        \n",
    "#     def recall_m(self, y_true, y_pred):\n",
    "#             y_labels = y_true\n",
    "#             y_pred = K.cast(K.greater(K.clip(y_pred, 0, 1), self.threshold), K.floatx())        \n",
    "#             possible_positives = K.sum(K.round(K.clip(y_labels, 0, 1)))\n",
    "#             true_positives = K.sum(K.round(K.clip(y_labels * y_pred, 0, 1)))\n",
    "#             recall = true_positives / (possible_positives + K.epsilon())\n",
    "#             return recall\n",
    "\n",
    "#     def precision_m(self, y_true, y_pred):\n",
    "#             y_labels = y_true\n",
    "#             y_pred = K.cast(K.greater(K.clip(y_pred, 0, 1), self.threshold), K.floatx())        \n",
    "#             true_positives = K.sum(K.round(K.clip(y_labels * y_pred, 0, 1)))\n",
    "#             predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "#             precision = true_positives / (predicted_positives + K.epsilon())\n",
    "#             return precision\n",
    "\n",
    "#     def f1_m(self, y_true, y_pred):\n",
    "#         precision = self.precision_m(y_true, y_pred)\n",
    "#         recall = self.recall_m(y_true, y_pred)\n",
    "#         return 2*((precision*recall)/(precision+recall+K.epsilon()))\n",
    "\n",
    "# def binary_crossentropy_custom(y_true, y_pred):\n",
    "#     y_labels = y_true\n",
    "#     return K.binary_crossentropy(y_labels, \n",
    "#                                  y_pred)\n",
    "\n",
    "# metrics_class = Metrics(threshold=hyperparams['threshold'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(hyperparams, hyperparams_features, embedding_matrix, emotions, stopwords_list,\n",
    "                liwc_categories, nr_classes,\n",
    "               ignore_layer=[]):\n",
    "\n",
    "    tokens_features = Input(shape=(hyperparams_features['maxlen'],), name='word_seq')\n",
    "    embedding_layer = Embedding(hyperparams_features['max_features'], \n",
    "                                hyperparams_features['embedding_dim'], \n",
    "                                input_length=hyperparams_features['maxlen'],\n",
    "                                embeddings_regularizer=regularizers.l2(hyperparams['l2_embeddings']),\n",
    "                                weights=[embedding_matrix], \n",
    "                                trainable=hyperparams['trainable_embeddings'],\n",
    "                               name='embeddings_layer')(\n",
    "        tokens_features)\n",
    "#     if 'batchnorm' not in ignore_layer:\n",
    "#         embedding_layer_norm = BatchNormalization(axis=-1, momentum=hyperparams['norm_momentum'],\n",
    "#                                                      name='embeddings_layer_norm')(embedding_layer)\n",
    "#     lstm_layers = Bidirectional(LSTM(hyperparams['lstm_units']))(embedding_layer)\n",
    "\n",
    "    if tf.test.is_gpu_available():\n",
    "        lstm_layers = CuDNNLSTM(hyperparams['lstm_units'], \n",
    "                                return_sequences='attention' not in ignore_layer, # only True if using attention\n",
    "                      name='LSTM_layer')(embedding_layer)\n",
    "    else:\n",
    "        lstm_layers = LSTM(hyperparams['lstm_units'], \n",
    "                           return_sequences='attention' not in ignore_layer,\n",
    "                      name='LSTM_layer')(embedding_layer)\n",
    "    \n",
    "    # Attention\n",
    "    if 'attention' not in ignore_layer:\n",
    "        attention = Dense(1, activation='tanh', name='attention')(lstm_layers)\n",
    "        attention = Flatten()(attention)\n",
    "        attention = Activation('softmax')(attention)\n",
    "        attention = RepeatVector(hyperparams['lstm_units'])(attention)\n",
    "        attention = Permute([2, 1])(attention)\n",
    "\n",
    "        sent_representation = Multiply()([lstm_layers, attention])\n",
    "        sent_representation = Lambda(lambda xin: K.sum(xin, axis=1), \n",
    "                                     output_shape=(hyperparams['lstm_units'],)\n",
    "                                    )(sent_representation)\n",
    "\n",
    "        \n",
    "    else:\n",
    "        sent_representation = lstm_layers\n",
    "        \n",
    "    \n",
    "    sent_representation = Dropout(hyperparams['dropout'], name='lstm_att_dropout')(sent_representation)\n",
    "    if hyperparams['dense_sentence_units']:\n",
    "        sent_representation = Dense(units=hyperparams['dense_sentence_units'],\n",
    "                                   name='dense_sent_representation')(sent_representation)\n",
    "    numerical_features = Input(shape=(len(emotions) + 1 + len(liwc_categories),), name='numeric_input') # emotions and pronouns\n",
    "    dense_layer = Dense(units=1,\n",
    "                        kernel_regularizer=regularizers.l2(hyperparams['l2_dense']),\n",
    "                        name='numerical_dense_layer',\n",
    "                       )(numerical_features)\n",
    "    sparse_features = Input(shape=(len(stopwords_list),), name='sparse_input') # stopwords\n",
    "\n",
    "    if hyperparams['dense_bow_units']:\n",
    "        dense_layer_sparse = Dense(units=hyperparams['dense_bow_units'],\n",
    "                              name='sparse_feat_dense_layer',\n",
    "                                kernel_regularizer=regularizers.l2(hyperparams['l2_dense']),\n",
    "                              )(sparse_features)\n",
    "    else:\n",
    "        dense_layer_sparse = sparse_features\n",
    "    \n",
    "    if 'batchnorm' not in ignore_layer:\n",
    "        numerical_features_norm = BatchNormalization(axis=1, momentum=hyperparams['norm_momentum'],\n",
    "                                                     name='numerical_features_norm')(numerical_features)\n",
    "        sent_representation_norm = BatchNormalization(axis=1, momentum=hyperparams['norm_momentum'],\n",
    "                                                      name='sent_repr_norm')(sent_representation)\n",
    "\n",
    "        dense_layer_sparse_norm = BatchNormalization(axis=1, momentum=hyperparams['norm_momentum'],\n",
    "                                                         name='sparse_features_norm')(dense_layer_sparse)\n",
    "        \n",
    "    subjects = Input(shape=(1,), name='subjects')\n",
    "    \n",
    "\n",
    "    all_layers = {\n",
    "        'lstm_layers': sent_representation,\n",
    "        'numerical_dense_layer': numerical_features,\n",
    "        'sparse_feat_dense_layer': dense_layer_sparse\n",
    "    }\n",
    "    if 'batchnorm' not in ignore_layer:\n",
    "        all_layers = {\n",
    "            'lstm_layers': sent_representation_norm,\n",
    "            'numerical_dense_layer': numerical_features_norm,\n",
    "            'sparse_feat_dense_layer': dense_layer_sparse_norm\n",
    "        }\n",
    "    layers_to_merge = []\n",
    "    for n, l in all_layers.items():\n",
    "        if n in ignore_layer:\n",
    "            continue\n",
    "        layers_to_merge.append(l)\n",
    "        \n",
    "    if len(layers_to_merge) == 1:\n",
    "        merged_layers = layers_to_merge[0]\n",
    "    else:\n",
    "        merged_layers = concatenate(layers_to_merge)\n",
    "    output_layers = []\n",
    "    for label in range(nr_questions):\n",
    "        output_layer = Dense(1, activation='softmax',\n",
    "                         name='output_layer%d' % label,\n",
    "                        kernel_regularizer=regularizers.l2(hyperparams['l2_dense']))(merged_layers)\n",
    "        output_layers.append(output_layer)\n",
    "\n",
    "    # Compile model\n",
    "    model = Model(inputs=[tokens_features, numerical_features, sparse_features, subjects], \n",
    "                  outputs=output_layers)\n",
    "\n",
    "    model.compile(hyperparams['optimizer'], {'output_layer%d'%i: 'mean_squared_error' for i in range(nr_questions)},\n",
    "                  metrics={'output_layer%d' % label: ['accuracy', 'mean_squared_error'] for label in range(nr_questions)})\n",
    "    return model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "sparse_input (InputLayer)       (None, 179)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "numeric_input (InputLayer)      (None, 75)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "sparse_feat_dense_layer (Dense) (None, 20)           3600        sparse_input[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_10 (Concatenate)    (None, 95)           0           numeric_input[0][0]              \n",
      "                                                                 sparse_feat_dense_layer[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "output_layer0 (Dense)           (None, 1)            96          concatenate_10[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "output_layer1 (Dense)           (None, 1)            96          concatenate_10[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "output_layer2 (Dense)           (None, 1)            96          concatenate_10[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "output_layer3 (Dense)           (None, 1)            96          concatenate_10[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "output_layer4 (Dense)           (None, 1)            96          concatenate_10[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "output_layer5 (Dense)           (None, 1)            96          concatenate_10[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "output_layer6 (Dense)           (None, 1)            96          concatenate_10[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "output_layer7 (Dense)           (None, 1)            96          concatenate_10[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "output_layer8 (Dense)           (None, 1)            96          concatenate_10[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "output_layer9 (Dense)           (None, 1)            96          concatenate_10[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "output_layer10 (Dense)          (None, 1)            96          concatenate_10[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "output_layer11 (Dense)          (None, 1)            96          concatenate_10[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "output_layer12 (Dense)          (None, 1)            96          concatenate_10[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "output_layer13 (Dense)          (None, 1)            96          concatenate_10[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "output_layer14 (Dense)          (None, 1)            96          concatenate_10[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "output_layer15 (Dense)          (None, 1)            96          concatenate_10[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "output_layer16 (Dense)          (None, 1)            96          concatenate_10[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "output_layer17 (Dense)          (None, 1)            96          concatenate_10[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "output_layer18 (Dense)          (None, 1)            96          concatenate_10[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "output_layer19 (Dense)          (None, 1)            96          concatenate_10[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "output_layer20 (Dense)          (None, 1)            96          concatenate_10[0][0]             \n",
      "==================================================================================================\n",
      "Total params: 5,616\n",
      "Trainable params: 5,616\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = build_model(hyperparams, hyperparams_features, embedding_matrix, emotions, stopword_list,\n",
    "                    liwc_categories=[c for c in categories if c in writings_df.columns],\n",
    "                    nr_classes=nr_questions,\n",
    "                   ignore_layer=hyperparams['ignore_layer'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, \n",
    "                data_generator_train, data_generator_valid,\n",
    "                epochs, start_epoch=0, workers=4,\n",
    "                callback_list = [],\n",
    "                model_path='/tmp/model',\n",
    "               verbose=1):\n",
    "    logging.info('Train...')\n",
    "    experiment.log_parameter('callbacks', callbacks)\n",
    "\n",
    "    history = model.fit_generator(data_generator_train,\n",
    "#               batch_size=batch_size,\n",
    "#                 steps_per_epoch=steps_per_epoch,\n",
    "              epochs=epochs, initial_epoch=start_epoch, \n",
    "              validation_data=data_generator_valid,\n",
    "                        verbose=verbose,\n",
    "#               validation_split=0.3,\n",
    "                       workers=workers,\n",
    "            callbacks = [\n",
    "                callbacks.ModelCheckpoint(filepath='%s_best' % model_path, verbose=1, \n",
    "                                          save_best_only=True),\n",
    "                callbacks.EarlyStopping(patience=500), *callback_list\n",
    "            ])\n",
    "    model.save(model_path)\n",
    "    experiment.log_parameter('model_path', model_path)\n",
    "    return model, history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "COMET INFO: ----------------------------\n",
      "COMET INFO: Comet.ml Experiment Summary:\n",
      "COMET INFO:   Data:\n",
      "COMET INFO:     url: https://www.comet.ml/ananana/mental/e5cb467425c84e0cbd402308db11a519\n",
      "COMET INFO:   Metrics [count] (min, max):\n",
      "COMET INFO:     sys.cpu.percent.01 [11] : (33.4, 100.0)\n",
      "COMET INFO:     sys.cpu.percent.02 [11] : (25.4, 63.0)\n",
      "COMET INFO:     sys.cpu.percent.03 [11] : (31.9, 65.0)\n",
      "COMET INFO:     sys.cpu.percent.04 [11] : (30.0, 64.6)\n",
      "COMET INFO:     sys.cpu.percent.avg [11]: (31.799999999999997, 67.0)\n",
      "COMET INFO:     sys.gpu.0.total_memory  : (1073414144.0, 1073414144.0)\n",
      "COMET INFO:     sys.load.avg [11]       : (1.55, 3.55)\n",
      "COMET INFO:     sys.ram.total [11]      : (8277311488.0, 8277311488.0)\n",
      "COMET INFO:     sys.ram.used [11]       : (6389862400.0, 7427514368.0)\n",
      "COMET INFO:   Other [count]:\n",
      "COMET INFO:     trainable_params: 5616\n",
      "COMET INFO: ----------------------------\n",
      "COMET INFO: old comet version (3.0.2) detected. current: 3.1.0 please update your comet lib with command: `pip install --no-cache-dir --upgrade comet_ml`\n",
      "COMET INFO: Experiment is live on comet.ml https://www.comet.ml/ananana/mental/bc8a5a9ae60d431cb2ea58847b1e6564\n",
      "\n"
     ]
    }
   ],
   "source": [
    "experiment = Experiment(api_key=\"eoBdVyznAhfg3bK9pZ58ZSXfv\",\n",
    "                        project_name=\"mental\", workspace=\"ananana\", disabled=False)\n",
    "\n",
    "experiment.log_parameters(hyperparams_features)\n",
    "\n",
    "experiment.log_parameter('emotion_lexicon', nrc_lexicon_path)\n",
    "experiment.log_parameter('emotions', emotions)\n",
    "experiment.log_parameter('embeddings_path', pretrained_embeddings_path)\n",
    "\n",
    "experiment.add_tag('T2')\n",
    "experiment.log_parameters(hyperparams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_user_index = np.random.randint(len(user_level_data))\n",
    "data_generator_train = DataGenerator(user_level_data, set_type='train', test_user_index=test_user_index)\n",
    "data_generator_valid = DataGenerator(user_level_data, set_type='test',  test_user_index=test_user_index)\n",
    "model, history = train_model(model, data_generator_train, data_generator_valid,\n",
    "           epochs=1000, start_epoch=0,\n",
    "                      callback_list = [],\n",
    "                      model_path='models/mlp_t21', workers=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extra analysis\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract LIWC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_tokens(row):\n",
    "    tokens = []\n",
    "    if row.tokenized_text:\n",
    "        tokens += row.tokenized_text\n",
    "    if row.tokenized_title:\n",
    "        tokens += row.tokenized_title\n",
    "    return tokens\n",
    "writings_df['all_tokens'] = writings_df.apply (lambda row: merge_tokens(row), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: include the title\n",
    "def extract_emotions(tokens, emotion, relative=True):\n",
    "    if not tokens:\n",
    "        return None\n",
    "    emotion_words = [t for t in tokens \n",
    "                     if t in nrc_lexicon[emotion]]\n",
    "    if relative:\n",
    "        return len(emotion_words) / len(tokens)\n",
    "    else:\n",
    "        return len(emotion_words)\n",
    "    \n",
    "    return encoded_emotions\n",
    "\n",
    "from functools import partial\n",
    "for emotion in emotions:\n",
    "    writings_df[emotion] = writings_df['all_tokens'].apply(partial(extract_emotions, emotion=emotion, \n",
    "                                                                   relative=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "writings_df['pronouns'] = writings_df['all_tokens'].apply(partial(encode_pronouns, relative=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label0</th>\n",
       "      <th>label1</th>\n",
       "      <th>label2</th>\n",
       "      <th>label3</th>\n",
       "      <th>label4</th>\n",
       "      <th>label5</th>\n",
       "      <th>label6</th>\n",
       "      <th>label7</th>\n",
       "      <th>label8</th>\n",
       "      <th>label9</th>\n",
       "      <th>...</th>\n",
       "      <th>anger</th>\n",
       "      <th>anticipation</th>\n",
       "      <th>disgust</th>\n",
       "      <th>fear</th>\n",
       "      <th>joy</th>\n",
       "      <th>negative</th>\n",
       "      <th>positive</th>\n",
       "      <th>sadness</th>\n",
       "      <th>surprise</th>\n",
       "      <th>trust</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>label0</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.780066</td>\n",
       "      <td>0.394792</td>\n",
       "      <td>0.660577</td>\n",
       "      <td>0.327117</td>\n",
       "      <td>0.345621</td>\n",
       "      <td>0.455499</td>\n",
       "      <td>0.735686</td>\n",
       "      <td>0.309227</td>\n",
       "      <td>0.635479</td>\n",
       "      <td>...</td>\n",
       "      <td>0.034671</td>\n",
       "      <td>0.015535</td>\n",
       "      <td>0.017945</td>\n",
       "      <td>0.039971</td>\n",
       "      <td>0.004400</td>\n",
       "      <td>0.021333</td>\n",
       "      <td>-0.029398</td>\n",
       "      <td>0.049543</td>\n",
       "      <td>-0.004456</td>\n",
       "      <td>-0.027378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>label1</th>\n",
       "      <td>0.780066</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.400175</td>\n",
       "      <td>0.726685</td>\n",
       "      <td>0.425165</td>\n",
       "      <td>0.533214</td>\n",
       "      <td>0.535219</td>\n",
       "      <td>0.860917</td>\n",
       "      <td>0.664714</td>\n",
       "      <td>0.775183</td>\n",
       "      <td>...</td>\n",
       "      <td>0.074130</td>\n",
       "      <td>0.077976</td>\n",
       "      <td>0.064694</td>\n",
       "      <td>0.096350</td>\n",
       "      <td>0.070177</td>\n",
       "      <td>0.044671</td>\n",
       "      <td>0.011881</td>\n",
       "      <td>0.095107</td>\n",
       "      <td>0.053556</td>\n",
       "      <td>0.022792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>label2</th>\n",
       "      <td>0.394792</td>\n",
       "      <td>0.400175</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.422413</td>\n",
       "      <td>0.842698</td>\n",
       "      <td>0.596555</td>\n",
       "      <td>0.534411</td>\n",
       "      <td>0.641306</td>\n",
       "      <td>0.258487</td>\n",
       "      <td>0.236198</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.100216</td>\n",
       "      <td>-0.101196</td>\n",
       "      <td>-0.048849</td>\n",
       "      <td>-0.109288</td>\n",
       "      <td>-0.039814</td>\n",
       "      <td>-0.102508</td>\n",
       "      <td>-0.059662</td>\n",
       "      <td>-0.072564</td>\n",
       "      <td>-0.090881</td>\n",
       "      <td>-0.094225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>label3</th>\n",
       "      <td>0.660577</td>\n",
       "      <td>0.726685</td>\n",
       "      <td>0.422413</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.401902</td>\n",
       "      <td>0.601494</td>\n",
       "      <td>0.658633</td>\n",
       "      <td>0.779561</td>\n",
       "      <td>0.710596</td>\n",
       "      <td>0.562745</td>\n",
       "      <td>...</td>\n",
       "      <td>0.047958</td>\n",
       "      <td>0.025483</td>\n",
       "      <td>0.043743</td>\n",
       "      <td>0.052658</td>\n",
       "      <td>0.031434</td>\n",
       "      <td>0.024096</td>\n",
       "      <td>0.011029</td>\n",
       "      <td>0.052280</td>\n",
       "      <td>0.009147</td>\n",
       "      <td>0.012804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>label4</th>\n",
       "      <td>0.327117</td>\n",
       "      <td>0.425165</td>\n",
       "      <td>0.842698</td>\n",
       "      <td>0.401902</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.458988</td>\n",
       "      <td>0.506148</td>\n",
       "      <td>0.601865</td>\n",
       "      <td>0.190326</td>\n",
       "      <td>0.073146</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.092402</td>\n",
       "      <td>-0.097064</td>\n",
       "      <td>-0.041111</td>\n",
       "      <td>-0.094764</td>\n",
       "      <td>-0.042750</td>\n",
       "      <td>-0.086652</td>\n",
       "      <td>-0.035937</td>\n",
       "      <td>-0.060032</td>\n",
       "      <td>-0.083494</td>\n",
       "      <td>-0.061473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>label5</th>\n",
       "      <td>0.345621</td>\n",
       "      <td>0.533214</td>\n",
       "      <td>0.596555</td>\n",
       "      <td>0.601494</td>\n",
       "      <td>0.458988</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.421742</td>\n",
       "      <td>0.620465</td>\n",
       "      <td>0.601454</td>\n",
       "      <td>0.546038</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.026898</td>\n",
       "      <td>-0.012710</td>\n",
       "      <td>-0.028510</td>\n",
       "      <td>-0.026102</td>\n",
       "      <td>0.012030</td>\n",
       "      <td>-0.037177</td>\n",
       "      <td>-0.001477</td>\n",
       "      <td>-0.005002</td>\n",
       "      <td>-0.025430</td>\n",
       "      <td>-0.018877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>label6</th>\n",
       "      <td>0.455499</td>\n",
       "      <td>0.535219</td>\n",
       "      <td>0.534411</td>\n",
       "      <td>0.658633</td>\n",
       "      <td>0.506148</td>\n",
       "      <td>0.421742</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.691181</td>\n",
       "      <td>0.394583</td>\n",
       "      <td>0.205096</td>\n",
       "      <td>...</td>\n",
       "      <td>0.006807</td>\n",
       "      <td>0.005744</td>\n",
       "      <td>0.063409</td>\n",
       "      <td>-0.008144</td>\n",
       "      <td>0.067497</td>\n",
       "      <td>-0.003552</td>\n",
       "      <td>0.032044</td>\n",
       "      <td>0.026211</td>\n",
       "      <td>-0.005417</td>\n",
       "      <td>0.014680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>label7</th>\n",
       "      <td>0.735686</td>\n",
       "      <td>0.860917</td>\n",
       "      <td>0.641306</td>\n",
       "      <td>0.779561</td>\n",
       "      <td>0.601865</td>\n",
       "      <td>0.620465</td>\n",
       "      <td>0.691181</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.665261</td>\n",
       "      <td>0.682315</td>\n",
       "      <td>...</td>\n",
       "      <td>0.061217</td>\n",
       "      <td>0.041191</td>\n",
       "      <td>0.067184</td>\n",
       "      <td>0.065648</td>\n",
       "      <td>0.056784</td>\n",
       "      <td>0.039552</td>\n",
       "      <td>0.017343</td>\n",
       "      <td>0.080756</td>\n",
       "      <td>0.023736</td>\n",
       "      <td>0.014293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>label8</th>\n",
       "      <td>0.309227</td>\n",
       "      <td>0.664714</td>\n",
       "      <td>0.258487</td>\n",
       "      <td>0.710596</td>\n",
       "      <td>0.190326</td>\n",
       "      <td>0.601454</td>\n",
       "      <td>0.394583</td>\n",
       "      <td>0.665261</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.701349</td>\n",
       "      <td>...</td>\n",
       "      <td>0.098390</td>\n",
       "      <td>0.074703</td>\n",
       "      <td>0.075011</td>\n",
       "      <td>0.117817</td>\n",
       "      <td>0.074120</td>\n",
       "      <td>0.072291</td>\n",
       "      <td>0.043375</td>\n",
       "      <td>0.090285</td>\n",
       "      <td>0.062752</td>\n",
       "      <td>0.047916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>label9</th>\n",
       "      <td>0.635479</td>\n",
       "      <td>0.775183</td>\n",
       "      <td>0.236198</td>\n",
       "      <td>0.562745</td>\n",
       "      <td>0.073146</td>\n",
       "      <td>0.546038</td>\n",
       "      <td>0.205096</td>\n",
       "      <td>0.682315</td>\n",
       "      <td>0.701349</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.085899</td>\n",
       "      <td>0.075637</td>\n",
       "      <td>0.046980</td>\n",
       "      <td>0.099930</td>\n",
       "      <td>0.053006</td>\n",
       "      <td>0.055270</td>\n",
       "      <td>-0.003065</td>\n",
       "      <td>0.088706</td>\n",
       "      <td>0.046994</td>\n",
       "      <td>0.007802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>label10</th>\n",
       "      <td>0.459704</td>\n",
       "      <td>0.701332</td>\n",
       "      <td>0.352253</td>\n",
       "      <td>0.286177</td>\n",
       "      <td>0.460112</td>\n",
       "      <td>0.082250</td>\n",
       "      <td>0.301806</td>\n",
       "      <td>0.638963</td>\n",
       "      <td>0.358459</td>\n",
       "      <td>0.526836</td>\n",
       "      <td>...</td>\n",
       "      <td>0.047744</td>\n",
       "      <td>0.030960</td>\n",
       "      <td>0.064827</td>\n",
       "      <td>0.069267</td>\n",
       "      <td>0.022764</td>\n",
       "      <td>0.032688</td>\n",
       "      <td>-0.026439</td>\n",
       "      <td>0.058439</td>\n",
       "      <td>0.030895</td>\n",
       "      <td>-0.009633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>label11</th>\n",
       "      <td>0.628568</td>\n",
       "      <td>0.505014</td>\n",
       "      <td>0.597287</td>\n",
       "      <td>0.654263</td>\n",
       "      <td>0.659291</td>\n",
       "      <td>0.339975</td>\n",
       "      <td>0.746437</td>\n",
       "      <td>0.669808</td>\n",
       "      <td>0.157615</td>\n",
       "      <td>0.137873</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.050213</td>\n",
       "      <td>-0.064920</td>\n",
       "      <td>0.002818</td>\n",
       "      <td>-0.064325</td>\n",
       "      <td>-0.034898</td>\n",
       "      <td>-0.044867</td>\n",
       "      <td>-0.032289</td>\n",
       "      <td>-0.024332</td>\n",
       "      <td>-0.067913</td>\n",
       "      <td>-0.043655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>label12</th>\n",
       "      <td>0.164636</td>\n",
       "      <td>0.531277</td>\n",
       "      <td>0.477001</td>\n",
       "      <td>0.582302</td>\n",
       "      <td>0.482094</td>\n",
       "      <td>0.574122</td>\n",
       "      <td>0.786561</td>\n",
       "      <td>0.686534</td>\n",
       "      <td>0.678687</td>\n",
       "      <td>0.344248</td>\n",
       "      <td>...</td>\n",
       "      <td>0.037900</td>\n",
       "      <td>0.042836</td>\n",
       "      <td>0.076534</td>\n",
       "      <td>0.034683</td>\n",
       "      <td>0.091427</td>\n",
       "      <td>0.018494</td>\n",
       "      <td>0.054134</td>\n",
       "      <td>0.056891</td>\n",
       "      <td>0.028593</td>\n",
       "      <td>0.049682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>label13</th>\n",
       "      <td>0.544199</td>\n",
       "      <td>0.814437</td>\n",
       "      <td>0.378425</td>\n",
       "      <td>0.692994</td>\n",
       "      <td>0.284479</td>\n",
       "      <td>0.631891</td>\n",
       "      <td>0.523459</td>\n",
       "      <td>0.840749</td>\n",
       "      <td>0.799450</td>\n",
       "      <td>0.786047</td>\n",
       "      <td>...</td>\n",
       "      <td>0.108503</td>\n",
       "      <td>0.101072</td>\n",
       "      <td>0.088583</td>\n",
       "      <td>0.114899</td>\n",
       "      <td>0.104665</td>\n",
       "      <td>0.071454</td>\n",
       "      <td>0.047371</td>\n",
       "      <td>0.113024</td>\n",
       "      <td>0.079471</td>\n",
       "      <td>0.057166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>label14</th>\n",
       "      <td>0.274646</td>\n",
       "      <td>0.377549</td>\n",
       "      <td>0.082223</td>\n",
       "      <td>0.575610</td>\n",
       "      <td>0.144770</td>\n",
       "      <td>0.039729</td>\n",
       "      <td>0.225095</td>\n",
       "      <td>0.436992</td>\n",
       "      <td>0.601238</td>\n",
       "      <td>0.244600</td>\n",
       "      <td>...</td>\n",
       "      <td>0.078158</td>\n",
       "      <td>0.007197</td>\n",
       "      <td>0.063778</td>\n",
       "      <td>0.106205</td>\n",
       "      <td>-0.020653</td>\n",
       "      <td>0.081125</td>\n",
       "      <td>-0.005521</td>\n",
       "      <td>0.054418</td>\n",
       "      <td>0.026271</td>\n",
       "      <td>0.011917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>label16</th>\n",
       "      <td>0.502127</td>\n",
       "      <td>0.516570</td>\n",
       "      <td>0.238003</td>\n",
       "      <td>0.524278</td>\n",
       "      <td>0.462440</td>\n",
       "      <td>0.227976</td>\n",
       "      <td>0.418812</td>\n",
       "      <td>0.424979</td>\n",
       "      <td>0.219875</td>\n",
       "      <td>0.013030</td>\n",
       "      <td>...</td>\n",
       "      <td>0.006432</td>\n",
       "      <td>-0.002684</td>\n",
       "      <td>0.007985</td>\n",
       "      <td>0.027464</td>\n",
       "      <td>-0.006546</td>\n",
       "      <td>0.009910</td>\n",
       "      <td>0.001472</td>\n",
       "      <td>0.016633</td>\n",
       "      <td>-0.000784</td>\n",
       "      <td>0.002941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>label18</th>\n",
       "      <td>0.651036</td>\n",
       "      <td>0.745270</td>\n",
       "      <td>0.400979</td>\n",
       "      <td>0.689083</td>\n",
       "      <td>0.522102</td>\n",
       "      <td>0.419214</td>\n",
       "      <td>0.376297</td>\n",
       "      <td>0.782254</td>\n",
       "      <td>0.386414</td>\n",
       "      <td>0.527524</td>\n",
       "      <td>...</td>\n",
       "      <td>0.043467</td>\n",
       "      <td>0.034858</td>\n",
       "      <td>0.041382</td>\n",
       "      <td>0.053852</td>\n",
       "      <td>0.006957</td>\n",
       "      <td>0.022268</td>\n",
       "      <td>-0.015058</td>\n",
       "      <td>0.064196</td>\n",
       "      <td>0.014851</td>\n",
       "      <td>0.007481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>label19</th>\n",
       "      <td>0.227896</td>\n",
       "      <td>0.408780</td>\n",
       "      <td>0.220126</td>\n",
       "      <td>0.726042</td>\n",
       "      <td>0.214565</td>\n",
       "      <td>0.414304</td>\n",
       "      <td>0.245927</td>\n",
       "      <td>0.480619</td>\n",
       "      <td>0.726622</td>\n",
       "      <td>0.378050</td>\n",
       "      <td>...</td>\n",
       "      <td>0.052778</td>\n",
       "      <td>0.014365</td>\n",
       "      <td>0.033138</td>\n",
       "      <td>0.078467</td>\n",
       "      <td>-0.002834</td>\n",
       "      <td>0.042453</td>\n",
       "      <td>0.009529</td>\n",
       "      <td>0.042273</td>\n",
       "      <td>0.015148</td>\n",
       "      <td>0.012965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>label20</th>\n",
       "      <td>0.231011</td>\n",
       "      <td>0.480633</td>\n",
       "      <td>-0.256666</td>\n",
       "      <td>0.071909</td>\n",
       "      <td>-0.085771</td>\n",
       "      <td>-0.159404</td>\n",
       "      <td>0.251145</td>\n",
       "      <td>0.220222</td>\n",
       "      <td>0.085796</td>\n",
       "      <td>0.247006</td>\n",
       "      <td>...</td>\n",
       "      <td>0.113690</td>\n",
       "      <td>0.141385</td>\n",
       "      <td>0.105854</td>\n",
       "      <td>0.134780</td>\n",
       "      <td>0.133817</td>\n",
       "      <td>0.083735</td>\n",
       "      <td>0.073445</td>\n",
       "      <td>0.128884</td>\n",
       "      <td>0.111432</td>\n",
       "      <td>0.091392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pronouns</th>\n",
       "      <td>0.076549</td>\n",
       "      <td>0.070065</td>\n",
       "      <td>0.028113</td>\n",
       "      <td>0.087742</td>\n",
       "      <td>-0.013821</td>\n",
       "      <td>0.021491</td>\n",
       "      <td>0.153504</td>\n",
       "      <td>0.087449</td>\n",
       "      <td>0.050775</td>\n",
       "      <td>0.035564</td>\n",
       "      <td>...</td>\n",
       "      <td>0.084328</td>\n",
       "      <td>0.111393</td>\n",
       "      <td>0.113715</td>\n",
       "      <td>0.083542</td>\n",
       "      <td>0.136223</td>\n",
       "      <td>0.084382</td>\n",
       "      <td>0.093848</td>\n",
       "      <td>0.104020</td>\n",
       "      <td>0.087861</td>\n",
       "      <td>0.104572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>text_len</th>\n",
       "      <td>-0.017232</td>\n",
       "      <td>0.093892</td>\n",
       "      <td>-0.257020</td>\n",
       "      <td>-0.016537</td>\n",
       "      <td>-0.191989</td>\n",
       "      <td>-0.155616</td>\n",
       "      <td>0.043913</td>\n",
       "      <td>0.019745</td>\n",
       "      <td>0.043236</td>\n",
       "      <td>0.007720</td>\n",
       "      <td>...</td>\n",
       "      <td>0.383628</td>\n",
       "      <td>0.389005</td>\n",
       "      <td>0.367378</td>\n",
       "      <td>0.404550</td>\n",
       "      <td>0.346625</td>\n",
       "      <td>0.358336</td>\n",
       "      <td>0.266902</td>\n",
       "      <td>0.419985</td>\n",
       "      <td>0.370182</td>\n",
       "      <td>0.343421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>anger</th>\n",
       "      <td>0.034671</td>\n",
       "      <td>0.074130</td>\n",
       "      <td>-0.100216</td>\n",
       "      <td>0.047958</td>\n",
       "      <td>-0.092402</td>\n",
       "      <td>-0.026898</td>\n",
       "      <td>0.006807</td>\n",
       "      <td>0.061217</td>\n",
       "      <td>0.098390</td>\n",
       "      <td>0.085899</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.233073</td>\n",
       "      <td>0.598404</td>\n",
       "      <td>0.596535</td>\n",
       "      <td>0.184501</td>\n",
       "      <td>0.628173</td>\n",
       "      <td>0.112392</td>\n",
       "      <td>0.560066</td>\n",
       "      <td>0.294260</td>\n",
       "      <td>0.169573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>anticipation</th>\n",
       "      <td>0.015535</td>\n",
       "      <td>0.077976</td>\n",
       "      <td>-0.101196</td>\n",
       "      <td>0.025483</td>\n",
       "      <td>-0.097064</td>\n",
       "      <td>-0.012710</td>\n",
       "      <td>0.005744</td>\n",
       "      <td>0.041191</td>\n",
       "      <td>0.074703</td>\n",
       "      <td>0.075637</td>\n",
       "      <td>...</td>\n",
       "      <td>0.233073</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.186819</td>\n",
       "      <td>0.266229</td>\n",
       "      <td>0.623134</td>\n",
       "      <td>0.197712</td>\n",
       "      <td>0.465499</td>\n",
       "      <td>0.243630</td>\n",
       "      <td>0.533921</td>\n",
       "      <td>0.510201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>disgust</th>\n",
       "      <td>0.017945</td>\n",
       "      <td>0.064694</td>\n",
       "      <td>-0.048849</td>\n",
       "      <td>0.043743</td>\n",
       "      <td>-0.041111</td>\n",
       "      <td>-0.028510</td>\n",
       "      <td>0.063409</td>\n",
       "      <td>0.067184</td>\n",
       "      <td>0.075011</td>\n",
       "      <td>0.046980</td>\n",
       "      <td>...</td>\n",
       "      <td>0.598404</td>\n",
       "      <td>0.186819</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.490544</td>\n",
       "      <td>0.157177</td>\n",
       "      <td>0.535049</td>\n",
       "      <td>0.090759</td>\n",
       "      <td>0.533151</td>\n",
       "      <td>0.251695</td>\n",
       "      <td>0.137118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fear</th>\n",
       "      <td>0.039971</td>\n",
       "      <td>0.096350</td>\n",
       "      <td>-0.109288</td>\n",
       "      <td>0.052658</td>\n",
       "      <td>-0.094764</td>\n",
       "      <td>-0.026102</td>\n",
       "      <td>-0.008144</td>\n",
       "      <td>0.065648</td>\n",
       "      <td>0.117817</td>\n",
       "      <td>0.099930</td>\n",
       "      <td>...</td>\n",
       "      <td>0.596535</td>\n",
       "      <td>0.266229</td>\n",
       "      <td>0.490544</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.172740</td>\n",
       "      <td>0.604027</td>\n",
       "      <td>0.105705</td>\n",
       "      <td>0.637423</td>\n",
       "      <td>0.265159</td>\n",
       "      <td>0.179944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>joy</th>\n",
       "      <td>0.004400</td>\n",
       "      <td>0.070177</td>\n",
       "      <td>-0.039814</td>\n",
       "      <td>0.031434</td>\n",
       "      <td>-0.042750</td>\n",
       "      <td>0.012030</td>\n",
       "      <td>0.067497</td>\n",
       "      <td>0.056784</td>\n",
       "      <td>0.074120</td>\n",
       "      <td>0.053006</td>\n",
       "      <td>...</td>\n",
       "      <td>0.184501</td>\n",
       "      <td>0.623134</td>\n",
       "      <td>0.157177</td>\n",
       "      <td>0.172740</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.105985</td>\n",
       "      <td>0.658043</td>\n",
       "      <td>0.191563</td>\n",
       "      <td>0.538937</td>\n",
       "      <td>0.629691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>negative</th>\n",
       "      <td>0.021333</td>\n",
       "      <td>0.044671</td>\n",
       "      <td>-0.102508</td>\n",
       "      <td>0.024096</td>\n",
       "      <td>-0.086652</td>\n",
       "      <td>-0.037177</td>\n",
       "      <td>-0.003552</td>\n",
       "      <td>0.039552</td>\n",
       "      <td>0.072291</td>\n",
       "      <td>0.055270</td>\n",
       "      <td>...</td>\n",
       "      <td>0.628173</td>\n",
       "      <td>0.197712</td>\n",
       "      <td>0.535049</td>\n",
       "      <td>0.604027</td>\n",
       "      <td>0.105985</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.070418</td>\n",
       "      <td>0.657725</td>\n",
       "      <td>0.205551</td>\n",
       "      <td>0.126966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>positive</th>\n",
       "      <td>-0.029398</td>\n",
       "      <td>0.011881</td>\n",
       "      <td>-0.059662</td>\n",
       "      <td>0.011029</td>\n",
       "      <td>-0.035937</td>\n",
       "      <td>-0.001477</td>\n",
       "      <td>0.032044</td>\n",
       "      <td>0.017343</td>\n",
       "      <td>0.043375</td>\n",
       "      <td>-0.003065</td>\n",
       "      <td>...</td>\n",
       "      <td>0.112392</td>\n",
       "      <td>0.465499</td>\n",
       "      <td>0.090759</td>\n",
       "      <td>0.105705</td>\n",
       "      <td>0.658043</td>\n",
       "      <td>0.070418</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.121755</td>\n",
       "      <td>0.360460</td>\n",
       "      <td>0.666906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sadness</th>\n",
       "      <td>0.049543</td>\n",
       "      <td>0.095107</td>\n",
       "      <td>-0.072564</td>\n",
       "      <td>0.052280</td>\n",
       "      <td>-0.060032</td>\n",
       "      <td>-0.005002</td>\n",
       "      <td>0.026211</td>\n",
       "      <td>0.080756</td>\n",
       "      <td>0.090285</td>\n",
       "      <td>0.088706</td>\n",
       "      <td>...</td>\n",
       "      <td>0.560066</td>\n",
       "      <td>0.243630</td>\n",
       "      <td>0.533151</td>\n",
       "      <td>0.637423</td>\n",
       "      <td>0.191563</td>\n",
       "      <td>0.657725</td>\n",
       "      <td>0.121755</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.278066</td>\n",
       "      <td>0.172253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>surprise</th>\n",
       "      <td>-0.004456</td>\n",
       "      <td>0.053556</td>\n",
       "      <td>-0.090881</td>\n",
       "      <td>0.009147</td>\n",
       "      <td>-0.083494</td>\n",
       "      <td>-0.025430</td>\n",
       "      <td>-0.005417</td>\n",
       "      <td>0.023736</td>\n",
       "      <td>0.062752</td>\n",
       "      <td>0.046994</td>\n",
       "      <td>...</td>\n",
       "      <td>0.294260</td>\n",
       "      <td>0.533921</td>\n",
       "      <td>0.251695</td>\n",
       "      <td>0.265159</td>\n",
       "      <td>0.538937</td>\n",
       "      <td>0.205551</td>\n",
       "      <td>0.360460</td>\n",
       "      <td>0.278066</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.407579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>trust</th>\n",
       "      <td>-0.027378</td>\n",
       "      <td>0.022792</td>\n",
       "      <td>-0.094225</td>\n",
       "      <td>0.012804</td>\n",
       "      <td>-0.061473</td>\n",
       "      <td>-0.018877</td>\n",
       "      <td>0.014680</td>\n",
       "      <td>0.014293</td>\n",
       "      <td>0.047916</td>\n",
       "      <td>0.007802</td>\n",
       "      <td>...</td>\n",
       "      <td>0.169573</td>\n",
       "      <td>0.510201</td>\n",
       "      <td>0.137118</td>\n",
       "      <td>0.179944</td>\n",
       "      <td>0.629691</td>\n",
       "      <td>0.126966</td>\n",
       "      <td>0.666906</td>\n",
       "      <td>0.172253</td>\n",
       "      <td>0.407579</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>31 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                label0    label1    label2    label3    label4    label5  \\\n",
       "label0        1.000000  0.780066  0.394792  0.660577  0.327117  0.345621   \n",
       "label1        0.780066  1.000000  0.400175  0.726685  0.425165  0.533214   \n",
       "label2        0.394792  0.400175  1.000000  0.422413  0.842698  0.596555   \n",
       "label3        0.660577  0.726685  0.422413  1.000000  0.401902  0.601494   \n",
       "label4        0.327117  0.425165  0.842698  0.401902  1.000000  0.458988   \n",
       "label5        0.345621  0.533214  0.596555  0.601494  0.458988  1.000000   \n",
       "label6        0.455499  0.535219  0.534411  0.658633  0.506148  0.421742   \n",
       "label7        0.735686  0.860917  0.641306  0.779561  0.601865  0.620465   \n",
       "label8        0.309227  0.664714  0.258487  0.710596  0.190326  0.601454   \n",
       "label9        0.635479  0.775183  0.236198  0.562745  0.073146  0.546038   \n",
       "label10       0.459704  0.701332  0.352253  0.286177  0.460112  0.082250   \n",
       "label11       0.628568  0.505014  0.597287  0.654263  0.659291  0.339975   \n",
       "label12       0.164636  0.531277  0.477001  0.582302  0.482094  0.574122   \n",
       "label13       0.544199  0.814437  0.378425  0.692994  0.284479  0.631891   \n",
       "label14       0.274646  0.377549  0.082223  0.575610  0.144770  0.039729   \n",
       "label16       0.502127  0.516570  0.238003  0.524278  0.462440  0.227976   \n",
       "label18       0.651036  0.745270  0.400979  0.689083  0.522102  0.419214   \n",
       "label19       0.227896  0.408780  0.220126  0.726042  0.214565  0.414304   \n",
       "label20       0.231011  0.480633 -0.256666  0.071909 -0.085771 -0.159404   \n",
       "pronouns      0.076549  0.070065  0.028113  0.087742 -0.013821  0.021491   \n",
       "text_len     -0.017232  0.093892 -0.257020 -0.016537 -0.191989 -0.155616   \n",
       "anger         0.034671  0.074130 -0.100216  0.047958 -0.092402 -0.026898   \n",
       "anticipation  0.015535  0.077976 -0.101196  0.025483 -0.097064 -0.012710   \n",
       "disgust       0.017945  0.064694 -0.048849  0.043743 -0.041111 -0.028510   \n",
       "fear          0.039971  0.096350 -0.109288  0.052658 -0.094764 -0.026102   \n",
       "joy           0.004400  0.070177 -0.039814  0.031434 -0.042750  0.012030   \n",
       "negative      0.021333  0.044671 -0.102508  0.024096 -0.086652 -0.037177   \n",
       "positive     -0.029398  0.011881 -0.059662  0.011029 -0.035937 -0.001477   \n",
       "sadness       0.049543  0.095107 -0.072564  0.052280 -0.060032 -0.005002   \n",
       "surprise     -0.004456  0.053556 -0.090881  0.009147 -0.083494 -0.025430   \n",
       "trust        -0.027378  0.022792 -0.094225  0.012804 -0.061473 -0.018877   \n",
       "\n",
       "                label6    label7    label8    label9  ...     anger  \\\n",
       "label0        0.455499  0.735686  0.309227  0.635479  ...  0.034671   \n",
       "label1        0.535219  0.860917  0.664714  0.775183  ...  0.074130   \n",
       "label2        0.534411  0.641306  0.258487  0.236198  ... -0.100216   \n",
       "label3        0.658633  0.779561  0.710596  0.562745  ...  0.047958   \n",
       "label4        0.506148  0.601865  0.190326  0.073146  ... -0.092402   \n",
       "label5        0.421742  0.620465  0.601454  0.546038  ... -0.026898   \n",
       "label6        1.000000  0.691181  0.394583  0.205096  ...  0.006807   \n",
       "label7        0.691181  1.000000  0.665261  0.682315  ...  0.061217   \n",
       "label8        0.394583  0.665261  1.000000  0.701349  ...  0.098390   \n",
       "label9        0.205096  0.682315  0.701349  1.000000  ...  0.085899   \n",
       "label10       0.301806  0.638963  0.358459  0.526836  ...  0.047744   \n",
       "label11       0.746437  0.669808  0.157615  0.137873  ... -0.050213   \n",
       "label12       0.786561  0.686534  0.678687  0.344248  ...  0.037900   \n",
       "label13       0.523459  0.840749  0.799450  0.786047  ...  0.108503   \n",
       "label14       0.225095  0.436992  0.601238  0.244600  ...  0.078158   \n",
       "label16       0.418812  0.424979  0.219875  0.013030  ...  0.006432   \n",
       "label18       0.376297  0.782254  0.386414  0.527524  ...  0.043467   \n",
       "label19       0.245927  0.480619  0.726622  0.378050  ...  0.052778   \n",
       "label20       0.251145  0.220222  0.085796  0.247006  ...  0.113690   \n",
       "pronouns      0.153504  0.087449  0.050775  0.035564  ...  0.084328   \n",
       "text_len      0.043913  0.019745  0.043236  0.007720  ...  0.383628   \n",
       "anger         0.006807  0.061217  0.098390  0.085899  ...  1.000000   \n",
       "anticipation  0.005744  0.041191  0.074703  0.075637  ...  0.233073   \n",
       "disgust       0.063409  0.067184  0.075011  0.046980  ...  0.598404   \n",
       "fear         -0.008144  0.065648  0.117817  0.099930  ...  0.596535   \n",
       "joy           0.067497  0.056784  0.074120  0.053006  ...  0.184501   \n",
       "negative     -0.003552  0.039552  0.072291  0.055270  ...  0.628173   \n",
       "positive      0.032044  0.017343  0.043375 -0.003065  ...  0.112392   \n",
       "sadness       0.026211  0.080756  0.090285  0.088706  ...  0.560066   \n",
       "surprise     -0.005417  0.023736  0.062752  0.046994  ...  0.294260   \n",
       "trust         0.014680  0.014293  0.047916  0.007802  ...  0.169573   \n",
       "\n",
       "              anticipation   disgust      fear       joy  negative  positive  \\\n",
       "label0            0.015535  0.017945  0.039971  0.004400  0.021333 -0.029398   \n",
       "label1            0.077976  0.064694  0.096350  0.070177  0.044671  0.011881   \n",
       "label2           -0.101196 -0.048849 -0.109288 -0.039814 -0.102508 -0.059662   \n",
       "label3            0.025483  0.043743  0.052658  0.031434  0.024096  0.011029   \n",
       "label4           -0.097064 -0.041111 -0.094764 -0.042750 -0.086652 -0.035937   \n",
       "label5           -0.012710 -0.028510 -0.026102  0.012030 -0.037177 -0.001477   \n",
       "label6            0.005744  0.063409 -0.008144  0.067497 -0.003552  0.032044   \n",
       "label7            0.041191  0.067184  0.065648  0.056784  0.039552  0.017343   \n",
       "label8            0.074703  0.075011  0.117817  0.074120  0.072291  0.043375   \n",
       "label9            0.075637  0.046980  0.099930  0.053006  0.055270 -0.003065   \n",
       "label10           0.030960  0.064827  0.069267  0.022764  0.032688 -0.026439   \n",
       "label11          -0.064920  0.002818 -0.064325 -0.034898 -0.044867 -0.032289   \n",
       "label12           0.042836  0.076534  0.034683  0.091427  0.018494  0.054134   \n",
       "label13           0.101072  0.088583  0.114899  0.104665  0.071454  0.047371   \n",
       "label14           0.007197  0.063778  0.106205 -0.020653  0.081125 -0.005521   \n",
       "label16          -0.002684  0.007985  0.027464 -0.006546  0.009910  0.001472   \n",
       "label18           0.034858  0.041382  0.053852  0.006957  0.022268 -0.015058   \n",
       "label19           0.014365  0.033138  0.078467 -0.002834  0.042453  0.009529   \n",
       "label20           0.141385  0.105854  0.134780  0.133817  0.083735  0.073445   \n",
       "pronouns          0.111393  0.113715  0.083542  0.136223  0.084382  0.093848   \n",
       "text_len          0.389005  0.367378  0.404550  0.346625  0.358336  0.266902   \n",
       "anger             0.233073  0.598404  0.596535  0.184501  0.628173  0.112392   \n",
       "anticipation      1.000000  0.186819  0.266229  0.623134  0.197712  0.465499   \n",
       "disgust           0.186819  1.000000  0.490544  0.157177  0.535049  0.090759   \n",
       "fear              0.266229  0.490544  1.000000  0.172740  0.604027  0.105705   \n",
       "joy               0.623134  0.157177  0.172740  1.000000  0.105985  0.658043   \n",
       "negative          0.197712  0.535049  0.604027  0.105985  1.000000  0.070418   \n",
       "positive          0.465499  0.090759  0.105705  0.658043  0.070418  1.000000   \n",
       "sadness           0.243630  0.533151  0.637423  0.191563  0.657725  0.121755   \n",
       "surprise          0.533921  0.251695  0.265159  0.538937  0.205551  0.360460   \n",
       "trust             0.510201  0.137118  0.179944  0.629691  0.126966  0.666906   \n",
       "\n",
       "               sadness  surprise     trust  \n",
       "label0        0.049543 -0.004456 -0.027378  \n",
       "label1        0.095107  0.053556  0.022792  \n",
       "label2       -0.072564 -0.090881 -0.094225  \n",
       "label3        0.052280  0.009147  0.012804  \n",
       "label4       -0.060032 -0.083494 -0.061473  \n",
       "label5       -0.005002 -0.025430 -0.018877  \n",
       "label6        0.026211 -0.005417  0.014680  \n",
       "label7        0.080756  0.023736  0.014293  \n",
       "label8        0.090285  0.062752  0.047916  \n",
       "label9        0.088706  0.046994  0.007802  \n",
       "label10       0.058439  0.030895 -0.009633  \n",
       "label11      -0.024332 -0.067913 -0.043655  \n",
       "label12       0.056891  0.028593  0.049682  \n",
       "label13       0.113024  0.079471  0.057166  \n",
       "label14       0.054418  0.026271  0.011917  \n",
       "label16       0.016633 -0.000784  0.002941  \n",
       "label18       0.064196  0.014851  0.007481  \n",
       "label19       0.042273  0.015148  0.012965  \n",
       "label20       0.128884  0.111432  0.091392  \n",
       "pronouns      0.104020  0.087861  0.104572  \n",
       "text_len      0.419985  0.370182  0.343421  \n",
       "anger         0.560066  0.294260  0.169573  \n",
       "anticipation  0.243630  0.533921  0.510201  \n",
       "disgust       0.533151  0.251695  0.137118  \n",
       "fear          0.637423  0.265159  0.179944  \n",
       "joy           0.191563  0.538937  0.629691  \n",
       "negative      0.657725  0.205551  0.126966  \n",
       "positive      0.121755  0.360460  0.666906  \n",
       "sadness       1.000000  0.278066  0.172253  \n",
       "surprise      0.278066  1.000000  0.407579  \n",
       "trust         0.172253  0.407579  1.000000  \n",
       "\n",
       "[31 rows x 31 columns]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "writings_df[['label%i'%i for i in range(21)] + ['text', 'pronouns', 'text_len'] + emotions].corr('spearman')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# writings_df['label15'] = writings_df['label15'].apply(lambda l: encode_labels([l])[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# writings_df['label17'] = writings_df['label17'].apply(lambda l: encode_labels([l])[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pronouns</th>\n",
       "      <th>text_len</th>\n",
       "      <th>anger</th>\n",
       "      <th>anticipation</th>\n",
       "      <th>disgust</th>\n",
       "      <th>fear</th>\n",
       "      <th>joy</th>\n",
       "      <th>negative</th>\n",
       "      <th>positive</th>\n",
       "      <th>sadness</th>\n",
       "      <th>surprise</th>\n",
       "      <th>trust</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>label0</th>\n",
       "      <td>0.516969</td>\n",
       "      <td>-0.072057</td>\n",
       "      <td>0.342691</td>\n",
       "      <td>-0.045245</td>\n",
       "      <td>0.082950</td>\n",
       "      <td>0.571431</td>\n",
       "      <td>0.109762</td>\n",
       "      <td>0.276499</td>\n",
       "      <td>0.017595</td>\n",
       "      <td>0.567242</td>\n",
       "      <td>-0.173440</td>\n",
       "      <td>0.042732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>label1</th>\n",
       "      <td>0.258942</td>\n",
       "      <td>-0.184847</td>\n",
       "      <td>0.258162</td>\n",
       "      <td>0.078775</td>\n",
       "      <td>0.070195</td>\n",
       "      <td>0.502286</td>\n",
       "      <td>-0.001560</td>\n",
       "      <td>0.203566</td>\n",
       "      <td>-0.049917</td>\n",
       "      <td>0.474208</td>\n",
       "      <td>0.042897</td>\n",
       "      <td>-0.023398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>label2</th>\n",
       "      <td>0.418806</td>\n",
       "      <td>-0.465340</td>\n",
       "      <td>0.077557</td>\n",
       "      <td>0.155113</td>\n",
       "      <td>0.224914</td>\n",
       "      <td>0.349005</td>\n",
       "      <td>0.411050</td>\n",
       "      <td>0.124091</td>\n",
       "      <td>0.302471</td>\n",
       "      <td>0.449829</td>\n",
       "      <td>0.349005</td>\n",
       "      <td>0.232670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>label3</th>\n",
       "      <td>0.342212</td>\n",
       "      <td>-0.177381</td>\n",
       "      <td>0.251011</td>\n",
       "      <td>0.039325</td>\n",
       "      <td>-0.033468</td>\n",
       "      <td>0.621671</td>\n",
       "      <td>0.249338</td>\n",
       "      <td>0.223400</td>\n",
       "      <td>0.264399</td>\n",
       "      <td>0.628365</td>\n",
       "      <td>-0.025101</td>\n",
       "      <td>0.296193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>label4</th>\n",
       "      <td>0.018720</td>\n",
       "      <td>-0.243359</td>\n",
       "      <td>-0.003256</td>\n",
       "      <td>0.026045</td>\n",
       "      <td>0.013836</td>\n",
       "      <td>0.275101</td>\n",
       "      <td>0.241731</td>\n",
       "      <td>0.076508</td>\n",
       "      <td>0.354051</td>\n",
       "      <td>0.425675</td>\n",
       "      <td>0.132667</td>\n",
       "      <td>0.345098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>label5</th>\n",
       "      <td>0.156537</td>\n",
       "      <td>-0.437907</td>\n",
       "      <td>0.334870</td>\n",
       "      <td>0.295241</td>\n",
       "      <td>0.299204</td>\n",
       "      <td>0.426018</td>\n",
       "      <td>0.303167</td>\n",
       "      <td>0.382426</td>\n",
       "      <td>0.390352</td>\n",
       "      <td>0.536981</td>\n",
       "      <td>0.354685</td>\n",
       "      <td>0.330907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>label6</th>\n",
       "      <td>0.531552</td>\n",
       "      <td>-0.111129</td>\n",
       "      <td>0.285981</td>\n",
       "      <td>-0.073050</td>\n",
       "      <td>0.190395</td>\n",
       "      <td>0.442183</td>\n",
       "      <td>0.446068</td>\n",
       "      <td>0.335717</td>\n",
       "      <td>0.421200</td>\n",
       "      <td>0.520672</td>\n",
       "      <td>-0.086261</td>\n",
       "      <td>0.355922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>label7</th>\n",
       "      <td>0.464098</td>\n",
       "      <td>-0.210246</td>\n",
       "      <td>0.476557</td>\n",
       "      <td>0.247623</td>\n",
       "      <td>0.211803</td>\n",
       "      <td>0.728852</td>\n",
       "      <td>0.420491</td>\n",
       "      <td>0.445409</td>\n",
       "      <td>0.412705</td>\n",
       "      <td>0.806720</td>\n",
       "      <td>0.132377</td>\n",
       "      <td>0.395573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>label8</th>\n",
       "      <td>0.321705</td>\n",
       "      <td>-0.278811</td>\n",
       "      <td>0.385221</td>\n",
       "      <td>0.210345</td>\n",
       "      <td>0.164977</td>\n",
       "      <td>0.546898</td>\n",
       "      <td>0.168276</td>\n",
       "      <td>0.293659</td>\n",
       "      <td>0.158378</td>\n",
       "      <td>0.561746</td>\n",
       "      <td>0.115484</td>\n",
       "      <td>0.080014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>label9</th>\n",
       "      <td>0.459068</td>\n",
       "      <td>-0.293339</td>\n",
       "      <td>0.653799</td>\n",
       "      <td>0.301626</td>\n",
       "      <td>0.362945</td>\n",
       "      <td>0.626454</td>\n",
       "      <td>0.310741</td>\n",
       "      <td>0.489728</td>\n",
       "      <td>0.213790</td>\n",
       "      <td>0.628111</td>\n",
       "      <td>-0.008286</td>\n",
       "      <td>0.228705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>label10</th>\n",
       "      <td>0.183642</td>\n",
       "      <td>-0.202639</td>\n",
       "      <td>0.463854</td>\n",
       "      <td>0.090238</td>\n",
       "      <td>0.419527</td>\n",
       "      <td>0.357785</td>\n",
       "      <td>0.109235</td>\n",
       "      <td>0.406862</td>\n",
       "      <td>0.045910</td>\n",
       "      <td>0.356202</td>\n",
       "      <td>-0.042744</td>\n",
       "      <td>0.079156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>label11</th>\n",
       "      <td>0.398861</td>\n",
       "      <td>-0.243131</td>\n",
       "      <td>0.131100</td>\n",
       "      <td>-0.170033</td>\n",
       "      <td>0.229623</td>\n",
       "      <td>0.395683</td>\n",
       "      <td>0.135867</td>\n",
       "      <td>0.259022</td>\n",
       "      <td>0.164471</td>\n",
       "      <td>0.498179</td>\n",
       "      <td>-0.063564</td>\n",
       "      <td>0.143018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>label12</th>\n",
       "      <td>0.469592</td>\n",
       "      <td>-0.152213</td>\n",
       "      <td>0.204030</td>\n",
       "      <td>0.152213</td>\n",
       "      <td>0.099586</td>\n",
       "      <td>0.455828</td>\n",
       "      <td>0.406440</td>\n",
       "      <td>0.216984</td>\n",
       "      <td>0.369196</td>\n",
       "      <td>0.551365</td>\n",
       "      <td>0.114969</td>\n",
       "      <td>0.385389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>label13</th>\n",
       "      <td>0.200805</td>\n",
       "      <td>-0.158114</td>\n",
       "      <td>0.409516</td>\n",
       "      <td>0.218198</td>\n",
       "      <td>0.062455</td>\n",
       "      <td>0.612693</td>\n",
       "      <td>0.266423</td>\n",
       "      <td>0.362082</td>\n",
       "      <td>0.298836</td>\n",
       "      <td>0.615065</td>\n",
       "      <td>0.137560</td>\n",
       "      <td>0.275119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>label14</th>\n",
       "      <td>0.182169</td>\n",
       "      <td>-0.097967</td>\n",
       "      <td>0.293090</td>\n",
       "      <td>-0.145735</td>\n",
       "      <td>-0.028337</td>\n",
       "      <td>0.599944</td>\n",
       "      <td>-0.162738</td>\n",
       "      <td>0.339240</td>\n",
       "      <td>-0.168405</td>\n",
       "      <td>0.459066</td>\n",
       "      <td>-0.090680</td>\n",
       "      <td>-0.045340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>label15</th>\n",
       "      <td>0.055011</td>\n",
       "      <td>-0.074876</td>\n",
       "      <td>-0.192538</td>\n",
       "      <td>-0.314785</td>\n",
       "      <td>-0.235324</td>\n",
       "      <td>-0.116134</td>\n",
       "      <td>-0.087101</td>\n",
       "      <td>-0.187954</td>\n",
       "      <td>-0.106966</td>\n",
       "      <td>-0.160448</td>\n",
       "      <td>-0.209347</td>\n",
       "      <td>-0.195594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>label16</th>\n",
       "      <td>-0.219744</td>\n",
       "      <td>0.171271</td>\n",
       "      <td>-0.077557</td>\n",
       "      <td>-0.177734</td>\n",
       "      <td>-0.300532</td>\n",
       "      <td>0.197123</td>\n",
       "      <td>-0.245596</td>\n",
       "      <td>0.054936</td>\n",
       "      <td>-0.038778</td>\n",
       "      <td>0.190660</td>\n",
       "      <td>-0.174503</td>\n",
       "      <td>-0.067862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>label17</th>\n",
       "      <td>0.077309</td>\n",
       "      <td>-0.559902</td>\n",
       "      <td>0.265504</td>\n",
       "      <td>-0.102297</td>\n",
       "      <td>0.610660</td>\n",
       "      <td>-0.024208</td>\n",
       "      <td>0.131971</td>\n",
       "      <td>0.309234</td>\n",
       "      <td>0.207718</td>\n",
       "      <td>-0.032017</td>\n",
       "      <td>0.220993</td>\n",
       "      <td>0.108544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>label18</th>\n",
       "      <td>0.062855</td>\n",
       "      <td>-0.241206</td>\n",
       "      <td>0.256135</td>\n",
       "      <td>0.160281</td>\n",
       "      <td>0.216064</td>\n",
       "      <td>0.499698</td>\n",
       "      <td>-0.007071</td>\n",
       "      <td>0.271848</td>\n",
       "      <td>0.065998</td>\n",
       "      <td>0.491055</td>\n",
       "      <td>0.234135</td>\n",
       "      <td>0.205065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>label19</th>\n",
       "      <td>0.275491</td>\n",
       "      <td>-0.300174</td>\n",
       "      <td>0.317691</td>\n",
       "      <td>0.148893</td>\n",
       "      <td>-0.007962</td>\n",
       "      <td>0.683951</td>\n",
       "      <td>0.158447</td>\n",
       "      <td>0.293804</td>\n",
       "      <td>0.136949</td>\n",
       "      <td>0.569296</td>\n",
       "      <td>0.234088</td>\n",
       "      <td>0.328838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>label20</th>\n",
       "      <td>0.041316</td>\n",
       "      <td>0.417930</td>\n",
       "      <td>-0.081838</td>\n",
       "      <td>-0.360723</td>\n",
       "      <td>-0.401245</td>\n",
       "      <td>0.002384</td>\n",
       "      <td>-0.197842</td>\n",
       "      <td>-0.200225</td>\n",
       "      <td>-0.334503</td>\n",
       "      <td>-0.085016</td>\n",
       "      <td>-0.634841</td>\n",
       "      <td>-0.156525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pronouns</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.154887</td>\n",
       "      <td>0.126316</td>\n",
       "      <td>0.207519</td>\n",
       "      <td>0.309774</td>\n",
       "      <td>0.180451</td>\n",
       "      <td>0.575940</td>\n",
       "      <td>-0.010526</td>\n",
       "      <td>0.239098</td>\n",
       "      <td>0.302256</td>\n",
       "      <td>0.063158</td>\n",
       "      <td>0.109774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>text_len</th>\n",
       "      <td>-0.154887</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.266165</td>\n",
       "      <td>-0.015038</td>\n",
       "      <td>-0.610526</td>\n",
       "      <td>-0.156391</td>\n",
       "      <td>-0.130827</td>\n",
       "      <td>-0.257143</td>\n",
       "      <td>-0.108271</td>\n",
       "      <td>-0.165414</td>\n",
       "      <td>-0.469173</td>\n",
       "      <td>-0.221053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>anger</th>\n",
       "      <td>0.126316</td>\n",
       "      <td>-0.266165</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.401504</td>\n",
       "      <td>0.575940</td>\n",
       "      <td>0.807519</td>\n",
       "      <td>0.264662</td>\n",
       "      <td>0.905263</td>\n",
       "      <td>0.421053</td>\n",
       "      <td>0.789474</td>\n",
       "      <td>0.228571</td>\n",
       "      <td>0.448120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>anticipation</th>\n",
       "      <td>0.207519</td>\n",
       "      <td>-0.015038</td>\n",
       "      <td>0.401504</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.178947</td>\n",
       "      <td>0.365414</td>\n",
       "      <td>0.636090</td>\n",
       "      <td>0.243609</td>\n",
       "      <td>0.613534</td>\n",
       "      <td>0.389474</td>\n",
       "      <td>0.670677</td>\n",
       "      <td>0.603008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>disgust</th>\n",
       "      <td>0.309774</td>\n",
       "      <td>-0.610526</td>\n",
       "      <td>0.575940</td>\n",
       "      <td>0.178947</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.215038</td>\n",
       "      <td>0.281203</td>\n",
       "      <td>0.562406</td>\n",
       "      <td>0.305263</td>\n",
       "      <td>0.371429</td>\n",
       "      <td>0.424060</td>\n",
       "      <td>0.174436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fear</th>\n",
       "      <td>0.180451</td>\n",
       "      <td>-0.156391</td>\n",
       "      <td>0.807519</td>\n",
       "      <td>0.365414</td>\n",
       "      <td>0.215038</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.263158</td>\n",
       "      <td>0.772932</td>\n",
       "      <td>0.363910</td>\n",
       "      <td>0.894737</td>\n",
       "      <td>0.189474</td>\n",
       "      <td>0.487218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>joy</th>\n",
       "      <td>0.575940</td>\n",
       "      <td>-0.130827</td>\n",
       "      <td>0.264662</td>\n",
       "      <td>0.636090</td>\n",
       "      <td>0.281203</td>\n",
       "      <td>0.263158</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.163910</td>\n",
       "      <td>0.869173</td>\n",
       "      <td>0.374436</td>\n",
       "      <td>0.469173</td>\n",
       "      <td>0.727820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>negative</th>\n",
       "      <td>-0.010526</td>\n",
       "      <td>-0.257143</td>\n",
       "      <td>0.905263</td>\n",
       "      <td>0.243609</td>\n",
       "      <td>0.562406</td>\n",
       "      <td>0.772932</td>\n",
       "      <td>0.163910</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.410526</td>\n",
       "      <td>0.754887</td>\n",
       "      <td>0.215038</td>\n",
       "      <td>0.419549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>positive</th>\n",
       "      <td>0.239098</td>\n",
       "      <td>-0.108271</td>\n",
       "      <td>0.421053</td>\n",
       "      <td>0.613534</td>\n",
       "      <td>0.305263</td>\n",
       "      <td>0.363910</td>\n",
       "      <td>0.869173</td>\n",
       "      <td>0.410526</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.500752</td>\n",
       "      <td>0.481203</td>\n",
       "      <td>0.855639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sadness</th>\n",
       "      <td>0.302256</td>\n",
       "      <td>-0.165414</td>\n",
       "      <td>0.789474</td>\n",
       "      <td>0.389474</td>\n",
       "      <td>0.371429</td>\n",
       "      <td>0.894737</td>\n",
       "      <td>0.374436</td>\n",
       "      <td>0.754887</td>\n",
       "      <td>0.500752</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.163910</td>\n",
       "      <td>0.520301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>surprise</th>\n",
       "      <td>0.063158</td>\n",
       "      <td>-0.469173</td>\n",
       "      <td>0.228571</td>\n",
       "      <td>0.670677</td>\n",
       "      <td>0.424060</td>\n",
       "      <td>0.189474</td>\n",
       "      <td>0.469173</td>\n",
       "      <td>0.215038</td>\n",
       "      <td>0.481203</td>\n",
       "      <td>0.163910</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.497744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>trust</th>\n",
       "      <td>0.109774</td>\n",
       "      <td>-0.221053</td>\n",
       "      <td>0.448120</td>\n",
       "      <td>0.603008</td>\n",
       "      <td>0.174436</td>\n",
       "      <td>0.487218</td>\n",
       "      <td>0.727820</td>\n",
       "      <td>0.419549</td>\n",
       "      <td>0.855639</td>\n",
       "      <td>0.520301</td>\n",
       "      <td>0.497744</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              pronouns  text_len     anger  anticipation   disgust      fear  \\\n",
       "label0        0.516969 -0.072057  0.342691     -0.045245  0.082950  0.571431   \n",
       "label1        0.258942 -0.184847  0.258162      0.078775  0.070195  0.502286   \n",
       "label2        0.418806 -0.465340  0.077557      0.155113  0.224914  0.349005   \n",
       "label3        0.342212 -0.177381  0.251011      0.039325 -0.033468  0.621671   \n",
       "label4        0.018720 -0.243359 -0.003256      0.026045  0.013836  0.275101   \n",
       "label5        0.156537 -0.437907  0.334870      0.295241  0.299204  0.426018   \n",
       "label6        0.531552 -0.111129  0.285981     -0.073050  0.190395  0.442183   \n",
       "label7        0.464098 -0.210246  0.476557      0.247623  0.211803  0.728852   \n",
       "label8        0.321705 -0.278811  0.385221      0.210345  0.164977  0.546898   \n",
       "label9        0.459068 -0.293339  0.653799      0.301626  0.362945  0.626454   \n",
       "label10       0.183642 -0.202639  0.463854      0.090238  0.419527  0.357785   \n",
       "label11       0.398861 -0.243131  0.131100     -0.170033  0.229623  0.395683   \n",
       "label12       0.469592 -0.152213  0.204030      0.152213  0.099586  0.455828   \n",
       "label13       0.200805 -0.158114  0.409516      0.218198  0.062455  0.612693   \n",
       "label14       0.182169 -0.097967  0.293090     -0.145735 -0.028337  0.599944   \n",
       "label15       0.055011 -0.074876 -0.192538     -0.314785 -0.235324 -0.116134   \n",
       "label16      -0.219744  0.171271 -0.077557     -0.177734 -0.300532  0.197123   \n",
       "label17       0.077309 -0.559902  0.265504     -0.102297  0.610660 -0.024208   \n",
       "label18       0.062855 -0.241206  0.256135      0.160281  0.216064  0.499698   \n",
       "label19       0.275491 -0.300174  0.317691      0.148893 -0.007962  0.683951   \n",
       "label20       0.041316  0.417930 -0.081838     -0.360723 -0.401245  0.002384   \n",
       "pronouns      1.000000 -0.154887  0.126316      0.207519  0.309774  0.180451   \n",
       "text_len     -0.154887  1.000000 -0.266165     -0.015038 -0.610526 -0.156391   \n",
       "anger         0.126316 -0.266165  1.000000      0.401504  0.575940  0.807519   \n",
       "anticipation  0.207519 -0.015038  0.401504      1.000000  0.178947  0.365414   \n",
       "disgust       0.309774 -0.610526  0.575940      0.178947  1.000000  0.215038   \n",
       "fear          0.180451 -0.156391  0.807519      0.365414  0.215038  1.000000   \n",
       "joy           0.575940 -0.130827  0.264662      0.636090  0.281203  0.263158   \n",
       "negative     -0.010526 -0.257143  0.905263      0.243609  0.562406  0.772932   \n",
       "positive      0.239098 -0.108271  0.421053      0.613534  0.305263  0.363910   \n",
       "sadness       0.302256 -0.165414  0.789474      0.389474  0.371429  0.894737   \n",
       "surprise      0.063158 -0.469173  0.228571      0.670677  0.424060  0.189474   \n",
       "trust         0.109774 -0.221053  0.448120      0.603008  0.174436  0.487218   \n",
       "\n",
       "                   joy  negative  positive   sadness  surprise     trust  \n",
       "label0        0.109762  0.276499  0.017595  0.567242 -0.173440  0.042732  \n",
       "label1       -0.001560  0.203566 -0.049917  0.474208  0.042897 -0.023398  \n",
       "label2        0.411050  0.124091  0.302471  0.449829  0.349005  0.232670  \n",
       "label3        0.249338  0.223400  0.264399  0.628365 -0.025101  0.296193  \n",
       "label4        0.241731  0.076508  0.354051  0.425675  0.132667  0.345098  \n",
       "label5        0.303167  0.382426  0.390352  0.536981  0.354685  0.330907  \n",
       "label6        0.446068  0.335717  0.421200  0.520672 -0.086261  0.355922  \n",
       "label7        0.420491  0.445409  0.412705  0.806720  0.132377  0.395573  \n",
       "label8        0.168276  0.293659  0.158378  0.561746  0.115484  0.080014  \n",
       "label9        0.310741  0.489728  0.213790  0.628111 -0.008286  0.228705  \n",
       "label10       0.109235  0.406862  0.045910  0.356202 -0.042744  0.079156  \n",
       "label11       0.135867  0.259022  0.164471  0.498179 -0.063564  0.143018  \n",
       "label12       0.406440  0.216984  0.369196  0.551365  0.114969  0.385389  \n",
       "label13       0.266423  0.362082  0.298836  0.615065  0.137560  0.275119  \n",
       "label14      -0.162738  0.339240 -0.168405  0.459066 -0.090680 -0.045340  \n",
       "label15      -0.087101 -0.187954 -0.106966 -0.160448 -0.209347 -0.195594  \n",
       "label16      -0.245596  0.054936 -0.038778  0.190660 -0.174503 -0.067862  \n",
       "label17       0.131971  0.309234  0.207718 -0.032017  0.220993  0.108544  \n",
       "label18      -0.007071  0.271848  0.065998  0.491055  0.234135  0.205065  \n",
       "label19       0.158447  0.293804  0.136949  0.569296  0.234088  0.328838  \n",
       "label20      -0.197842 -0.200225 -0.334503 -0.085016 -0.634841 -0.156525  \n",
       "pronouns      0.575940 -0.010526  0.239098  0.302256  0.063158  0.109774  \n",
       "text_len     -0.130827 -0.257143 -0.108271 -0.165414 -0.469173 -0.221053  \n",
       "anger         0.264662  0.905263  0.421053  0.789474  0.228571  0.448120  \n",
       "anticipation  0.636090  0.243609  0.613534  0.389474  0.670677  0.603008  \n",
       "disgust       0.281203  0.562406  0.305263  0.371429  0.424060  0.174436  \n",
       "fear          0.263158  0.772932  0.363910  0.894737  0.189474  0.487218  \n",
       "joy           1.000000  0.163910  0.869173  0.374436  0.469173  0.727820  \n",
       "negative      0.163910  1.000000  0.410526  0.754887  0.215038  0.419549  \n",
       "positive      0.869173  0.410526  1.000000  0.500752  0.481203  0.855639  \n",
       "sadness       0.374436  0.754887  0.500752  1.000000  0.163910  0.520301  \n",
       "surprise      0.469173  0.215038  0.481203  0.163910  1.000000  0.497744  \n",
       "trust         0.727820  0.419549  0.855639  0.520301  0.497744  1.000000  "
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "writings_df.groupby('subject').mean()[\n",
    "    ['label%i'%i for i in range(21)] + ['pronouns', 'text_len'] + emotions].corr(\n",
    "    'spearman')[['pronouns', 'text_len'] + emotions]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label0</th>\n",
       "      <th>label1</th>\n",
       "      <th>label2</th>\n",
       "      <th>label3</th>\n",
       "      <th>label4</th>\n",
       "      <th>label5</th>\n",
       "      <th>label6</th>\n",
       "      <th>label7</th>\n",
       "      <th>label8</th>\n",
       "      <th>label9</th>\n",
       "      <th>...</th>\n",
       "      <th>label11</th>\n",
       "      <th>label12</th>\n",
       "      <th>label13</th>\n",
       "      <th>label14</th>\n",
       "      <th>label15</th>\n",
       "      <th>label16</th>\n",
       "      <th>label17</th>\n",
       "      <th>label18</th>\n",
       "      <th>label19</th>\n",
       "      <th>label20</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>subject</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>subject1272</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>-3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>subject2341</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>-2</td>\n",
       "      <td>2</td>\n",
       "      <td>-3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>subject2432</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>subject2827</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>-2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>subject2903</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>subject2961</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>-3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>subject3707</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>-3</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>subject3993</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>subject4058</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>subject436</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>-2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>subject5791</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>subject5897</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>subject6619</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>subject6635</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>-3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>subject6900</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>subject7039</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>subject9218</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>subject9454</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>-3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>subject9694</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>subject9798</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>-2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             label0  label1  label2  label3  label4  label5  label6  label7  \\\n",
       "subject                                                                       \n",
       "subject1272       1       2       2       1       0       1       3       2   \n",
       "subject2341       1       2       3       2       3       2       3       3   \n",
       "subject2432       1       3       3       2       3       2       2       2   \n",
       "subject2827       1       3       3       2       3       2       2       3   \n",
       "subject2903       0       0       1       1       0       0       1       0   \n",
       "subject2961       1       1       1       1       0       0       1       1   \n",
       "subject3707       1       3       0       1       0       0       0       1   \n",
       "subject3993       0       0       0       0       0       0       0       0   \n",
       "subject4058       0       0       0       1       0       0       0       0   \n",
       "subject436        2       1       2       3       2       0       3       3   \n",
       "subject5791       1       0       1       1       0       0       2       1   \n",
       "subject5897       2       3       3       2       1       0       2       2   \n",
       "subject6619       0       0       0       1       0       0       0       0   \n",
       "subject6635       0       1       1       1       1       0       3       1   \n",
       "subject6900       1       1       2       1       0       0       1       1   \n",
       "subject7039       1       1       0       1       0       0       2       0   \n",
       "subject9218       2       2       1       2       1       0       3       2   \n",
       "subject9454       1       3       3       2       1       3       3       3   \n",
       "subject9694       0       0       2       0       1       0       0       0   \n",
       "subject9798       1       1       2       1       3       0       1       1   \n",
       "\n",
       "             label8  label9  ...  label11  label12  label13  label14  label15  \\\n",
       "subject                      ...                                                \n",
       "subject1272       1       3  ...        1        2        2        2       -3   \n",
       "subject2341       1       0  ...        2        3        3        2       -2   \n",
       "subject2432       2       1  ...        3        1        3        2        1   \n",
       "subject2827       2       2  ...        1        2        3        1       -2   \n",
       "subject2903       0       0  ...        0        0        0        1        0   \n",
       "subject2961       1       1  ...        1        1        0        2       -1   \n",
       "subject3707       1       2  ...        0        0        2        2       -3   \n",
       "subject3993       0       0  ...        0        0        0        0        0   \n",
       "subject4058       1       0  ...        0        0        0        3        2   \n",
       "subject436        1       2  ...        3        2        2        3        2   \n",
       "subject5791       0       0  ...        1        0        1        1       -1   \n",
       "subject5897       1       0  ...        3        2        2        3        1   \n",
       "subject6619       0       0  ...        1        0        0        1       -2   \n",
       "subject6635       1       0  ...        1        3        1        2       -3   \n",
       "subject6900       1       1  ...        1        0        1        2        2   \n",
       "subject7039       0       0  ...        1        0        0        0        0   \n",
       "subject9218       1       2  ...        3        1        2        2        2   \n",
       "subject9454       2       3  ...        3        3        2        2       -3   \n",
       "subject9694       0       0  ...        0        0        0        0        0   \n",
       "subject9798       0       0  ...        3        0        0        2       -2   \n",
       "\n",
       "             label16  label17  label18  label19  label20  \n",
       "subject                                                   \n",
       "subject1272        0        3        1        2        2  \n",
       "subject2341        2       -3        2        2        0  \n",
       "subject2432        2        1        2        1        0  \n",
       "subject2827        1        0        2        2        1  \n",
       "subject2903        0       -1        0        1        2  \n",
       "subject2961        0       -3        1        1        1  \n",
       "subject3707        1       -1        2        1        3  \n",
       "subject3993        0       -1        0        0        1  \n",
       "subject4058        1        0        0        3        0  \n",
       "subject436         1       -2        1        3        2  \n",
       "subject5791        1        0        1        0        0  \n",
       "subject5897        1       -1        3        3        1  \n",
       "subject6619        0        0        2        1        0  \n",
       "subject6635        1        1        1        1        2  \n",
       "subject6900        0        0        0        1        0  \n",
       "subject7039        2        0        0        0        2  \n",
       "subject9218        0        2        2        1        1  \n",
       "subject9454        1        3        3        3        0  \n",
       "subject9694        0        0        0        0        0  \n",
       "subject9798        2        0        2        1        1  \n",
       "\n",
       "[20 rows x 21 columns]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "writings_df.corrwith?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "from liwc_readDict import readDict\n",
    "\n",
    "liwc = readDict('/home/ana/resources/FakeOrFact/features/LIWC/LIWC/liwc.dic')\n",
    "categories = [c for (w,c) in liwc]\n",
    "set(categories)\n",
    "liwc_dict = {}\n",
    "for (w, c) in liwc:\n",
    "    if c not in liwc_dict:\n",
    "        liwc_dict[c] = []\n",
    "    liwc_dict[c].append(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_liwc_categories(tokens, category_words, relative=True):\n",
    "    category_cnt = 0\n",
    "    if not tokens:\n",
    "        return None\n",
    "    text_len = len(tokens)\n",
    "    for t in tokens:\n",
    "        for word in category_words:\n",
    "            if t==word or (word[-1]=='*' and t.startswith(word[:-1])) \\\n",
    "            or (t==word.split(\"'\")[0]):\n",
    "                category_cnt += 1\n",
    "                break # one token cannot belong to more than one word in the category\n",
    "    if relative:\n",
    "        return category_cnt/text_len\n",
    "    else:\n",
    "        return category_cnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoding for category funct...\n",
      "Encoding for category article...\n",
      "Encoding for category affect...\n",
      "Encoding for category negemo...\n",
      "Encoding for category sad...\n",
      "Encoding for category cogmech...\n",
      "Encoding for category inhib...\n",
      "Encoding for category bio...\n",
      "Encoding for category body...\n",
      "Encoding for category achieve...\n",
      "Encoding for category health...\n",
      "Encoding for category sexual...\n",
      "Encoding for category adverb...\n",
      "Encoding for category preps...\n",
      "Encoding for category space...\n",
      "Encoding for category relativ...\n",
      "Encoding for category time...\n",
      "Encoding for category work...\n",
      "Encoding for category certain...\n",
      "Encoding for category assent...\n",
      "Encoding for category posemo...\n",
      "Encoding for category insight...\n",
      "Encoding for category verb...\n",
      "Encoding for category past...\n",
      "Encoding for category money...\n",
      "Encoding for category percept...\n",
      "Encoding for category social...\n",
      "Encoding for category friend...\n",
      "Encoding for category motion...\n",
      "Encoding for category cause...\n",
      "Encoding for category leisure...\n",
      "Encoding for category incl...\n",
      "Encoding for category home...\n",
      "Encoding for category present...\n",
      "Encoding for category humans...\n",
      "Encoding for category anx...\n",
      "Encoding for category relig...\n",
      "Encoding for category auxverb...\n",
      "Encoding for category negate...\n",
      "Encoding for category ingest...\n",
      "Encoding for category death...\n",
      "Encoding for category quant...\n",
      "Encoding for category tentat...\n",
      "Encoding for category conj...\n",
      "Encoding for category pronoun...\n",
      "Encoding for category ipron...\n",
      "Encoding for category swear...\n",
      "Encoding for category hear...\n",
      "Encoding for category family...\n",
      "Encoding for category see...\n",
      "Encoding for category discrep...\n",
      "Encoding for category number...\n",
      "Encoding for category filler...\n",
      "Encoding for category feel...\n",
      "Encoding for category excl...\n",
      "Encoding for category future...\n",
      "Encoding for category nonfl...\n",
      "Encoding for category ppron...\n",
      "Encoding for category shehe...\n",
      "Encoding for category i...\n",
      "Encoding for category we...\n",
      "Encoding for category you...\n",
      "Encoding for category they...\n",
      "CPU times: user 40min 30s, sys: 1.28 s, total: 40min 31s\n",
      "Wall time: 40min 32s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from functools import partial\n",
    "# for categ in ['negemo', 'posemo', 'affect', 'sad', 'anx', 'pronoun']:#liwc_dict.keys():\n",
    "for categ in liwc_dict.keys():\n",
    "    if categ in writings_df.columns:\n",
    "        continue\n",
    "    print(\"Encoding for category %s...\" % categ)\n",
    "    writings_df[categ] = writings_df['all_tokens'].apply(partial(encode_liwc_categories, \n",
    "                                                                   category_words=liwc_dict[categ], \n",
    "                                                                   relative=True))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>posemo</th>\n",
       "      <th>negemo</th>\n",
       "      <th>anx</th>\n",
       "      <th>sad</th>\n",
       "      <th>affect</th>\n",
       "      <th>feel</th>\n",
       "      <th>social</th>\n",
       "      <th>health</th>\n",
       "      <th>sexual</th>\n",
       "      <th>present</th>\n",
       "      <th>cogmech</th>\n",
       "      <th>inhib</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>label0</th>\n",
       "      <td>0.011730</td>\n",
       "      <td>0.326771</td>\n",
       "      <td>0.217010</td>\n",
       "      <td>0.172602</td>\n",
       "      <td>0.222875</td>\n",
       "      <td>0.238794</td>\n",
       "      <td>-0.268958</td>\n",
       "      <td>0.483454</td>\n",
       "      <td>0.266444</td>\n",
       "      <td>0.366152</td>\n",
       "      <td>0.279850</td>\n",
       "      <td>0.073733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>label1</th>\n",
       "      <td>0.035878</td>\n",
       "      <td>0.316658</td>\n",
       "      <td>0.159109</td>\n",
       "      <td>0.258942</td>\n",
       "      <td>0.209026</td>\n",
       "      <td>0.372815</td>\n",
       "      <td>0.253483</td>\n",
       "      <td>0.513205</td>\n",
       "      <td>0.281561</td>\n",
       "      <td>0.443010</td>\n",
       "      <td>0.209806</td>\n",
       "      <td>0.145850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>label2</th>\n",
       "      <td>0.426562</td>\n",
       "      <td>0.240426</td>\n",
       "      <td>0.023267</td>\n",
       "      <td>0.085312</td>\n",
       "      <td>0.465340</td>\n",
       "      <td>0.294715</td>\n",
       "      <td>-0.046534</td>\n",
       "      <td>0.224914</td>\n",
       "      <td>0.434317</td>\n",
       "      <td>0.255937</td>\n",
       "      <td>0.124091</td>\n",
       "      <td>-0.062045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>label3</th>\n",
       "      <td>0.153954</td>\n",
       "      <td>0.291173</td>\n",
       "      <td>0.250175</td>\n",
       "      <td>0.188258</td>\n",
       "      <td>0.278623</td>\n",
       "      <td>0.114628</td>\n",
       "      <td>0.039325</td>\n",
       "      <td>0.355599</td>\n",
       "      <td>0.058569</td>\n",
       "      <td>0.459351</td>\n",
       "      <td>0.371497</td>\n",
       "      <td>0.118812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>label4</th>\n",
       "      <td>0.174177</td>\n",
       "      <td>0.157085</td>\n",
       "      <td>0.022789</td>\n",
       "      <td>0.097669</td>\n",
       "      <td>0.290566</td>\n",
       "      <td>0.109878</td>\n",
       "      <td>-0.100111</td>\n",
       "      <td>0.035812</td>\n",
       "      <td>0.109064</td>\n",
       "      <td>0.139992</td>\n",
       "      <td>0.153015</td>\n",
       "      <td>0.048021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>label5</th>\n",
       "      <td>0.354685</td>\n",
       "      <td>0.453759</td>\n",
       "      <td>-0.017833</td>\n",
       "      <td>0.215981</td>\n",
       "      <td>0.517166</td>\n",
       "      <td>0.247685</td>\n",
       "      <td>0.481500</td>\n",
       "      <td>0.156537</td>\n",
       "      <td>0.219944</td>\n",
       "      <td>0.358648</td>\n",
       "      <td>0.001981</td>\n",
       "      <td>-0.105018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>label6</th>\n",
       "      <td>0.124340</td>\n",
       "      <td>0.404104</td>\n",
       "      <td>0.207492</td>\n",
       "      <td>0.125117</td>\n",
       "      <td>0.384676</td>\n",
       "      <td>0.364470</td>\n",
       "      <td>0.156979</td>\n",
       "      <td>0.334940</td>\n",
       "      <td>0.254119</td>\n",
       "      <td>0.399441</td>\n",
       "      <td>0.319397</td>\n",
       "      <td>-0.246348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>label7</th>\n",
       "      <td>0.267869</td>\n",
       "      <td>0.524836</td>\n",
       "      <td>0.327049</td>\n",
       "      <td>0.308360</td>\n",
       "      <td>0.534180</td>\n",
       "      <td>0.404918</td>\n",
       "      <td>0.101229</td>\n",
       "      <td>0.543524</td>\n",
       "      <td>0.255410</td>\n",
       "      <td>0.576229</td>\n",
       "      <td>0.378442</td>\n",
       "      <td>0.101229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>label8</th>\n",
       "      <td>0.190548</td>\n",
       "      <td>0.332428</td>\n",
       "      <td>0.300258</td>\n",
       "      <td>0.128682</td>\n",
       "      <td>0.358825</td>\n",
       "      <td>0.345627</td>\n",
       "      <td>0.308507</td>\n",
       "      <td>0.478433</td>\n",
       "      <td>0.179000</td>\n",
       "      <td>0.623613</td>\n",
       "      <td>0.284585</td>\n",
       "      <td>0.118783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>label9</th>\n",
       "      <td>0.043918</td>\n",
       "      <td>0.543589</td>\n",
       "      <td>0.365431</td>\n",
       "      <td>0.081207</td>\n",
       "      <td>0.461554</td>\n",
       "      <td>0.265166</td>\n",
       "      <td>0.189759</td>\n",
       "      <td>0.635569</td>\n",
       "      <td>0.339743</td>\n",
       "      <td>0.503815</td>\n",
       "      <td>0.030660</td>\n",
       "      <td>0.031488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>label10</th>\n",
       "      <td>-0.229552</td>\n",
       "      <td>0.482851</td>\n",
       "      <td>0.275463</td>\n",
       "      <td>0.047494</td>\n",
       "      <td>0.272296</td>\n",
       "      <td>0.280212</td>\n",
       "      <td>0.123483</td>\n",
       "      <td>0.410028</td>\n",
       "      <td>0.414777</td>\n",
       "      <td>0.291294</td>\n",
       "      <td>-0.031662</td>\n",
       "      <td>-0.012665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>label11</th>\n",
       "      <td>0.092962</td>\n",
       "      <td>0.212143</td>\n",
       "      <td>0.003973</td>\n",
       "      <td>0.100113</td>\n",
       "      <td>0.222472</td>\n",
       "      <td>-0.000795</td>\n",
       "      <td>-0.324174</td>\n",
       "      <td>0.100113</td>\n",
       "      <td>0.332914</td>\n",
       "      <td>0.203403</td>\n",
       "      <td>0.110442</td>\n",
       "      <td>-0.007151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>label12</th>\n",
       "      <td>0.327905</td>\n",
       "      <td>0.302806</td>\n",
       "      <td>0.263133</td>\n",
       "      <td>0.233986</td>\n",
       "      <td>0.427490</td>\n",
       "      <td>0.433158</td>\n",
       "      <td>0.259085</td>\n",
       "      <td>0.525457</td>\n",
       "      <td>0.191075</td>\n",
       "      <td>0.536792</td>\n",
       "      <td>0.395105</td>\n",
       "      <td>-0.012145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>label13</th>\n",
       "      <td>0.128863</td>\n",
       "      <td>0.426118</td>\n",
       "      <td>0.135978</td>\n",
       "      <td>0.229266</td>\n",
       "      <td>0.378684</td>\n",
       "      <td>0.403982</td>\n",
       "      <td>0.268794</td>\n",
       "      <td>0.422165</td>\n",
       "      <td>0.092497</td>\n",
       "      <td>0.452207</td>\n",
       "      <td>0.323344</td>\n",
       "      <td>0.099612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>label14</th>\n",
       "      <td>-0.225890</td>\n",
       "      <td>0.259895</td>\n",
       "      <td>0.267182</td>\n",
       "      <td>-0.042911</td>\n",
       "      <td>-0.081774</td>\n",
       "      <td>-0.018622</td>\n",
       "      <td>-0.104444</td>\n",
       "      <td>0.398343</td>\n",
       "      <td>0.028337</td>\n",
       "      <td>0.442874</td>\n",
       "      <td>0.333572</td>\n",
       "      <td>0.133591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>label15</th>\n",
       "      <td>-0.172673</td>\n",
       "      <td>-0.348402</td>\n",
       "      <td>-0.197122</td>\n",
       "      <td>-0.476761</td>\n",
       "      <td>-0.307144</td>\n",
       "      <td>-0.284223</td>\n",
       "      <td>-0.539412</td>\n",
       "      <td>-0.183370</td>\n",
       "      <td>-0.091685</td>\n",
       "      <td>-0.184898</td>\n",
       "      <td>-0.055011</td>\n",
       "      <td>-0.169617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>label16</th>\n",
       "      <td>-0.022621</td>\n",
       "      <td>0.061399</td>\n",
       "      <td>0.067862</td>\n",
       "      <td>0.035547</td>\n",
       "      <td>-0.067862</td>\n",
       "      <td>-0.155113</td>\n",
       "      <td>0.093714</td>\n",
       "      <td>-0.164808</td>\n",
       "      <td>-0.323153</td>\n",
       "      <td>-0.006463</td>\n",
       "      <td>0.016158</td>\n",
       "      <td>0.100177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>label17</th>\n",
       "      <td>-0.169454</td>\n",
       "      <td>0.179606</td>\n",
       "      <td>-0.340470</td>\n",
       "      <td>-0.180387</td>\n",
       "      <td>0.087460</td>\n",
       "      <td>-0.016399</td>\n",
       "      <td>0.124162</td>\n",
       "      <td>-0.314701</td>\n",
       "      <td>0.527885</td>\n",
       "      <td>0.010152</td>\n",
       "      <td>-0.299083</td>\n",
       "      <td>-0.101516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>label18</th>\n",
       "      <td>0.102925</td>\n",
       "      <td>0.322132</td>\n",
       "      <td>0.040856</td>\n",
       "      <td>0.520912</td>\n",
       "      <td>0.211350</td>\n",
       "      <td>0.146924</td>\n",
       "      <td>0.046356</td>\n",
       "      <td>0.208993</td>\n",
       "      <td>0.259277</td>\n",
       "      <td>0.337060</td>\n",
       "      <td>0.255349</td>\n",
       "      <td>0.439200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>label19</th>\n",
       "      <td>0.073252</td>\n",
       "      <td>0.296193</td>\n",
       "      <td>0.276288</td>\n",
       "      <td>0.090769</td>\n",
       "      <td>0.116248</td>\n",
       "      <td>0.010351</td>\n",
       "      <td>0.191888</td>\n",
       "      <td>0.506394</td>\n",
       "      <td>0.089973</td>\n",
       "      <td>0.575665</td>\n",
       "      <td>0.330430</td>\n",
       "      <td>0.241254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>label20</th>\n",
       "      <td>-0.440178</td>\n",
       "      <td>-0.040522</td>\n",
       "      <td>0.344832</td>\n",
       "      <td>-0.071509</td>\n",
       "      <td>-0.313051</td>\n",
       "      <td>0.074687</td>\n",
       "      <td>0.179567</td>\n",
       "      <td>0.509303</td>\n",
       "      <td>-0.102496</td>\n",
       "      <td>-0.062769</td>\n",
       "      <td>0.123154</td>\n",
       "      <td>-0.099318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>posemo</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.058647</td>\n",
       "      <td>0.210526</td>\n",
       "      <td>0.233083</td>\n",
       "      <td>0.715789</td>\n",
       "      <td>0.299248</td>\n",
       "      <td>0.022556</td>\n",
       "      <td>0.159398</td>\n",
       "      <td>0.034586</td>\n",
       "      <td>0.282707</td>\n",
       "      <td>0.088722</td>\n",
       "      <td>0.148872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>negemo</th>\n",
       "      <td>-0.058647</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.330827</td>\n",
       "      <td>0.530827</td>\n",
       "      <td>0.566917</td>\n",
       "      <td>0.416541</td>\n",
       "      <td>0.378947</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.267669</td>\n",
       "      <td>0.598496</td>\n",
       "      <td>0.363910</td>\n",
       "      <td>-0.105263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>anx</th>\n",
       "      <td>0.210526</td>\n",
       "      <td>0.330827</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.359398</td>\n",
       "      <td>0.333835</td>\n",
       "      <td>0.333835</td>\n",
       "      <td>0.171429</td>\n",
       "      <td>0.604511</td>\n",
       "      <td>-0.147368</td>\n",
       "      <td>0.521805</td>\n",
       "      <td>0.484211</td>\n",
       "      <td>0.236090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sad</th>\n",
       "      <td>0.233083</td>\n",
       "      <td>0.530827</td>\n",
       "      <td>0.359398</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.413534</td>\n",
       "      <td>0.618045</td>\n",
       "      <td>0.360902</td>\n",
       "      <td>0.219549</td>\n",
       "      <td>0.198496</td>\n",
       "      <td>0.590977</td>\n",
       "      <td>0.705263</td>\n",
       "      <td>0.317293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>affect</th>\n",
       "      <td>0.715789</td>\n",
       "      <td>0.566917</td>\n",
       "      <td>0.333835</td>\n",
       "      <td>0.413534</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.535338</td>\n",
       "      <td>0.228571</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.227068</td>\n",
       "      <td>0.568421</td>\n",
       "      <td>0.254135</td>\n",
       "      <td>-0.084211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feel</th>\n",
       "      <td>0.299248</td>\n",
       "      <td>0.416541</td>\n",
       "      <td>0.333835</td>\n",
       "      <td>0.618045</td>\n",
       "      <td>0.535338</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.406015</td>\n",
       "      <td>0.461654</td>\n",
       "      <td>0.363910</td>\n",
       "      <td>0.657143</td>\n",
       "      <td>0.696241</td>\n",
       "      <td>-0.090226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>social</th>\n",
       "      <td>0.022556</td>\n",
       "      <td>0.378947</td>\n",
       "      <td>0.171429</td>\n",
       "      <td>0.360902</td>\n",
       "      <td>0.228571</td>\n",
       "      <td>0.406015</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.193985</td>\n",
       "      <td>-0.129323</td>\n",
       "      <td>0.467669</td>\n",
       "      <td>0.330827</td>\n",
       "      <td>-0.187970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>health</th>\n",
       "      <td>0.159398</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.604511</td>\n",
       "      <td>0.219549</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.461654</td>\n",
       "      <td>0.193985</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.066165</td>\n",
       "      <td>0.587970</td>\n",
       "      <td>0.380451</td>\n",
       "      <td>0.147368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sexual</th>\n",
       "      <td>0.034586</td>\n",
       "      <td>0.267669</td>\n",
       "      <td>-0.147368</td>\n",
       "      <td>0.198496</td>\n",
       "      <td>0.227068</td>\n",
       "      <td>0.363910</td>\n",
       "      <td>-0.129323</td>\n",
       "      <td>0.066165</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.190977</td>\n",
       "      <td>0.058647</td>\n",
       "      <td>-0.126316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>present</th>\n",
       "      <td>0.282707</td>\n",
       "      <td>0.598496</td>\n",
       "      <td>0.521805</td>\n",
       "      <td>0.590977</td>\n",
       "      <td>0.568421</td>\n",
       "      <td>0.657143</td>\n",
       "      <td>0.467669</td>\n",
       "      <td>0.587970</td>\n",
       "      <td>0.190977</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.708271</td>\n",
       "      <td>0.150376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cogmech</th>\n",
       "      <td>0.088722</td>\n",
       "      <td>0.363910</td>\n",
       "      <td>0.484211</td>\n",
       "      <td>0.705263</td>\n",
       "      <td>0.254135</td>\n",
       "      <td>0.696241</td>\n",
       "      <td>0.330827</td>\n",
       "      <td>0.380451</td>\n",
       "      <td>0.058647</td>\n",
       "      <td>0.708271</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.127820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>inhib</th>\n",
       "      <td>0.148872</td>\n",
       "      <td>-0.105263</td>\n",
       "      <td>0.236090</td>\n",
       "      <td>0.317293</td>\n",
       "      <td>-0.084211</td>\n",
       "      <td>-0.090226</td>\n",
       "      <td>-0.187970</td>\n",
       "      <td>0.147368</td>\n",
       "      <td>-0.126316</td>\n",
       "      <td>0.150376</td>\n",
       "      <td>0.127820</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           posemo    negemo       anx       sad    affect      feel    social  \\\n",
       "label0   0.011730  0.326771  0.217010  0.172602  0.222875  0.238794 -0.268958   \n",
       "label1   0.035878  0.316658  0.159109  0.258942  0.209026  0.372815  0.253483   \n",
       "label2   0.426562  0.240426  0.023267  0.085312  0.465340  0.294715 -0.046534   \n",
       "label3   0.153954  0.291173  0.250175  0.188258  0.278623  0.114628  0.039325   \n",
       "label4   0.174177  0.157085  0.022789  0.097669  0.290566  0.109878 -0.100111   \n",
       "label5   0.354685  0.453759 -0.017833  0.215981  0.517166  0.247685  0.481500   \n",
       "label6   0.124340  0.404104  0.207492  0.125117  0.384676  0.364470  0.156979   \n",
       "label7   0.267869  0.524836  0.327049  0.308360  0.534180  0.404918  0.101229   \n",
       "label8   0.190548  0.332428  0.300258  0.128682  0.358825  0.345627  0.308507   \n",
       "label9   0.043918  0.543589  0.365431  0.081207  0.461554  0.265166  0.189759   \n",
       "label10 -0.229552  0.482851  0.275463  0.047494  0.272296  0.280212  0.123483   \n",
       "label11  0.092962  0.212143  0.003973  0.100113  0.222472 -0.000795 -0.324174   \n",
       "label12  0.327905  0.302806  0.263133  0.233986  0.427490  0.433158  0.259085   \n",
       "label13  0.128863  0.426118  0.135978  0.229266  0.378684  0.403982  0.268794   \n",
       "label14 -0.225890  0.259895  0.267182 -0.042911 -0.081774 -0.018622 -0.104444   \n",
       "label15 -0.172673 -0.348402 -0.197122 -0.476761 -0.307144 -0.284223 -0.539412   \n",
       "label16 -0.022621  0.061399  0.067862  0.035547 -0.067862 -0.155113  0.093714   \n",
       "label17 -0.169454  0.179606 -0.340470 -0.180387  0.087460 -0.016399  0.124162   \n",
       "label18  0.102925  0.322132  0.040856  0.520912  0.211350  0.146924  0.046356   \n",
       "label19  0.073252  0.296193  0.276288  0.090769  0.116248  0.010351  0.191888   \n",
       "label20 -0.440178 -0.040522  0.344832 -0.071509 -0.313051  0.074687  0.179567   \n",
       "posemo   1.000000 -0.058647  0.210526  0.233083  0.715789  0.299248  0.022556   \n",
       "negemo  -0.058647  1.000000  0.330827  0.530827  0.566917  0.416541  0.378947   \n",
       "anx      0.210526  0.330827  1.000000  0.359398  0.333835  0.333835  0.171429   \n",
       "sad      0.233083  0.530827  0.359398  1.000000  0.413534  0.618045  0.360902   \n",
       "affect   0.715789  0.566917  0.333835  0.413534  1.000000  0.535338  0.228571   \n",
       "feel     0.299248  0.416541  0.333835  0.618045  0.535338  1.000000  0.406015   \n",
       "social   0.022556  0.378947  0.171429  0.360902  0.228571  0.406015  1.000000   \n",
       "health   0.159398  0.285714  0.604511  0.219549  0.285714  0.461654  0.193985   \n",
       "sexual   0.034586  0.267669 -0.147368  0.198496  0.227068  0.363910 -0.129323   \n",
       "present  0.282707  0.598496  0.521805  0.590977  0.568421  0.657143  0.467669   \n",
       "cogmech  0.088722  0.363910  0.484211  0.705263  0.254135  0.696241  0.330827   \n",
       "inhib    0.148872 -0.105263  0.236090  0.317293 -0.084211 -0.090226 -0.187970   \n",
       "\n",
       "           health    sexual   present   cogmech     inhib  \n",
       "label0   0.483454  0.266444  0.366152  0.279850  0.073733  \n",
       "label1   0.513205  0.281561  0.443010  0.209806  0.145850  \n",
       "label2   0.224914  0.434317  0.255937  0.124091 -0.062045  \n",
       "label3   0.355599  0.058569  0.459351  0.371497  0.118812  \n",
       "label4   0.035812  0.109064  0.139992  0.153015  0.048021  \n",
       "label5   0.156537  0.219944  0.358648  0.001981 -0.105018  \n",
       "label6   0.334940  0.254119  0.399441  0.319397 -0.246348  \n",
       "label7   0.543524  0.255410  0.576229  0.378442  0.101229  \n",
       "label8   0.478433  0.179000  0.623613  0.284585  0.118783  \n",
       "label9   0.635569  0.339743  0.503815  0.030660  0.031488  \n",
       "label10  0.410028  0.414777  0.291294 -0.031662 -0.012665  \n",
       "label11  0.100113  0.332914  0.203403  0.110442 -0.007151  \n",
       "label12  0.525457  0.191075  0.536792  0.395105 -0.012145  \n",
       "label13  0.422165  0.092497  0.452207  0.323344  0.099612  \n",
       "label14  0.398343  0.028337  0.442874  0.333572  0.133591  \n",
       "label15 -0.183370 -0.091685 -0.184898 -0.055011 -0.169617  \n",
       "label16 -0.164808 -0.323153 -0.006463  0.016158  0.100177  \n",
       "label17 -0.314701  0.527885  0.010152 -0.299083 -0.101516  \n",
       "label18  0.208993  0.259277  0.337060  0.255349  0.439200  \n",
       "label19  0.506394  0.089973  0.575665  0.330430  0.241254  \n",
       "label20  0.509303 -0.102496 -0.062769  0.123154 -0.099318  \n",
       "posemo   0.159398  0.034586  0.282707  0.088722  0.148872  \n",
       "negemo   0.285714  0.267669  0.598496  0.363910 -0.105263  \n",
       "anx      0.604511 -0.147368  0.521805  0.484211  0.236090  \n",
       "sad      0.219549  0.198496  0.590977  0.705263  0.317293  \n",
       "affect   0.285714  0.227068  0.568421  0.254135 -0.084211  \n",
       "feel     0.461654  0.363910  0.657143  0.696241 -0.090226  \n",
       "social   0.193985 -0.129323  0.467669  0.330827 -0.187970  \n",
       "health   1.000000  0.066165  0.587970  0.380451  0.147368  \n",
       "sexual   0.066165  1.000000  0.190977  0.058647 -0.126316  \n",
       "present  0.587970  0.190977  1.000000  0.708271  0.150376  \n",
       "cogmech  0.380451  0.058647  0.708271  1.000000  0.127820  \n",
       "inhib    0.147368 -0.126316  0.150376  0.127820  1.000000  "
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "relevant_categs = ['posemo', 'negemo', 'anx', 'sad', 'affect', 'feel', 'social', 'health', \n",
    "                   'sexual', 'present', 'cogmech', 'inhib']\n",
    "writings_df.groupby('subject').mean()[\n",
    "    ['label%i'%i for i in range(21)] + relevant_categs].corr(\n",
    "    'spearman')[relevant_categs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['funct',\n",
       " 'article',\n",
       " 'affect',\n",
       " 'negemo',\n",
       " 'sad',\n",
       " 'cogmech',\n",
       " 'inhib',\n",
       " 'bio',\n",
       " 'body',\n",
       " 'achieve',\n",
       " 'health',\n",
       " 'sexual',\n",
       " 'adverb',\n",
       " 'preps',\n",
       " 'space',\n",
       " 'relativ',\n",
       " 'time',\n",
       " 'work',\n",
       " 'certain',\n",
       " 'assent',\n",
       " 'anger',\n",
       " 'posemo',\n",
       " 'insight',\n",
       " 'verb',\n",
       " 'past',\n",
       " 'money',\n",
       " 'percept',\n",
       " 'social',\n",
       " 'friend',\n",
       " 'motion',\n",
       " 'cause',\n",
       " 'leisure',\n",
       " 'incl',\n",
       " 'home',\n",
       " 'present',\n",
       " 'humans',\n",
       " 'anx',\n",
       " 'relig',\n",
       " 'auxverb',\n",
       " 'negate',\n",
       " 'ingest',\n",
       " 'death',\n",
       " 'quant',\n",
       " 'tentat',\n",
       " 'conj',\n",
       " 'pronoun',\n",
       " 'ipron',\n",
       " 'swear',\n",
       " 'hear',\n",
       " 'family',\n",
       " 'see',\n",
       " 'discrep',\n",
       " 'number',\n",
       " 'filler',\n",
       " 'feel',\n",
       " 'excl',\n",
       " 'future',\n",
       " 'nonfl',\n",
       " 'ppron',\n",
       " 'shehe',\n",
       " 'i',\n",
       " 'we',\n",
       " 'you',\n",
       " 'they']"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(writings_df.groupby('subject').min()[\n",
    "    ['label%i'%i for i in range(21)] + list(liwc_dict.keys())].corr()[list(liwc_dict.keys())].mean().sort_values().index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(writings_df, open('writings_df_T2_liwc.pkl', 'wb+'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
