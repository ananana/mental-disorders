{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import xml.etree.ElementTree as ET\n",
    "import glob, os\n",
    "import numpy as np\n",
    "from comet_ml import Experiment, Optimizer\n",
    "import pickle\n",
    "import logging\n",
    "import sys\n",
    "from sklearn.utils import class_weight\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\n",
    "os.environ['TF_KERAS'] = '1'\n",
    "\n",
    "# only reserve 1 GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "# tf.version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing import sequence\n",
    "from tensorflow.keras.models import Sequential, Model, load_model\n",
    "from tensorflow.keras.layers import Dense, Dropout, Embedding, LSTM, Lambda, BatchNormalization, TimeDistributed, \\\n",
    "     Bidirectional, Input, concatenate, Flatten, RepeatVector, Activation, Multiply, Permute#, CuDNNLSTM\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras import callbacks, optimizers\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.utils import plot_model, Sequence\n",
    "\n",
    "from nltk.tokenize import RegexpTokenizer, TweetTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "tf.test.is_gpu_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_seed = 1234\n",
    "# tf.set_random_seed(my_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger = logging.getLogger('training')\n",
    "logger.addHandler(logging.StreamHandler(sys.stdout))\n",
    "logger.setLevel(logging.DEBUG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_subject_writings(subject_file):\n",
    "    writings = []\n",
    "    with open(subject_file) as sf:\n",
    "        contents = sf.read()\n",
    "        root = ET.fromstring(contents)\n",
    "        try:\n",
    "            subject = root.findall('ID')[0].text.strip()\n",
    "        except Exception:\n",
    "            print('Cannot extract ID', contents[:500], '\\n-------\\n')        \n",
    "        for w in root.iter('WRITING'):\n",
    "            subject_writings = {'subject': subject}\n",
    "            for title in w.findall('TITLE'):\n",
    "                subject_writings['title'] = title.text\n",
    "            for text in w.findall('TEXT'):\n",
    "                subject_writings['text'] = text.text\n",
    "            for date in w.findall('DATE'):\n",
    "                subject_writings['date'] = date.text\n",
    "            writings.append(subject_writings)\n",
    "    return writings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# root_dir = '/home/anasab/' \n",
    "root_dir = '/home/anasab/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datadir_T2 = root_dir + '/eRisk/data/eRisk2020_T2/eRisk2020_T2_TEST_DATA/'\n",
    "# labels_file_T2 = root_dir + '/eRisk/data/eRisk2020_T2/eRisk2020_T2_TRAINING_DATA/Depression Questionnaires_anon.txt'\n",
    "nr_questions = 21"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_texts(datadir_T2,\n",
    "                labels_file_T2=None):\n",
    "    writings = []\n",
    "    writings_df = pd.DataFrame()\n",
    "    labels_df = pd.DataFrame()\n",
    "\n",
    "        \n",
    "    for subject_file in os.listdir(datadir_T2):\n",
    "        if not subject_file.startswith('subject'):\n",
    "            continue\n",
    "        writings.extend(read_subject_writings(os.path.join(datadir_T2, subject_file)))\n",
    "    writings_df = pd.DataFrame(writings)\n",
    "    if labels_file_T2:\n",
    "        labels_df = pd.read_csv(os.path.join(labels_file_T2), \n",
    "                                     delimiter='\\s+', names=['subject'] + ['label%i' % i for i in range(nr_questions)])\n",
    "\n",
    "        labels_df = labels_df.set_index('subject')\n",
    "\n",
    "        writings_df = writings_df.join(labels_df, on='subject')\n",
    "    \n",
    "    return writings_df, labels_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "writings_df, labels_df = read_texts(datadir_T2)#, labels_file_T2)\n",
    "# writings_df = pickle.load(open('writings_df_T2_liwc.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "writings_df.groupby('subject').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "writings_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = RegexpTokenizer(r'\\w+')\n",
    "\n",
    "def tokenize(t):\n",
    "    return tokenizer.tokenize(t.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "tt = TweetTokenizer()\n",
    "sw = stopwords.words(\"english\")\n",
    "def tokenize_tweets(t, tokenizer=tt, stop=True):\n",
    "    tokens = tokenizer.tokenize(t.lower())\n",
    "    tokens_clean = [token for token in tokens if \n",
    "                            re.match(\"^[a-z]*$\", token)]\n",
    "    if not stop:\n",
    "        tokens_clean = [token for token in tokens_clean \n",
    "                        if token not in sw]\n",
    "    return tokens_clean\n",
    "\n",
    "def tokenize_fields(writings_df):\n",
    "    writings_df['tokenized_title'] = writings_df['title'].apply(lambda t: tokenize_tweets(t) \n",
    "                                                                if type(t)==str and t else None)\n",
    "    writings_df['title_len'] = writings_df['tokenized_title'].apply(lambda t: len(t) \n",
    "                                                                    if type(t)==list and t else None)\n",
    "    writings_df['tokenized_text'] = writings_df['text'].apply(lambda t: tokenize_tweets(t) \n",
    "                                                              if type(t)==str and t else None)\n",
    "    writings_df['text_len'] = writings_df['tokenized_text'].apply(lambda t: len(t) \n",
    "                                                                  if type(t)==list and t else None)\n",
    "    return writings_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "writings_df = tokenize_fields(writings_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "writings_df.text_len.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "writings_df.title_len.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "writings_df.groupby('subject').count().title.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "writings_df.groupby('subject').count().text.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RoBERTa & co"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from simpletransformers.classification import MultiLabelClassificationModel\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_len = 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aggregate by users\n",
    "writings_df = writings_df.fillna(value={'text': '', 'title':''})\n",
    "column_functions = {'text': lambda t: \" \".join(t), \n",
    "                                        'title': lambda t: \" \".join(t),\n",
    "                                        'tokenized_text': 'sum',\n",
    "                                        'tokenized_title': 'sum',\n",
    "                                        'text_len': 'sum',\n",
    "                                        'title_len': 'sum'}\n",
    "if 'label1' in writings_df.columns:\n",
    "    column_functions.update({'label%i'%i: 'min' for i in range(21)})\n",
    "writings_per_user_df = writings_df.groupby('subject').aggregate(column_functions)\n",
    "#                                          'subset': 'min'})\n",
    "# writings_per_user_df = writings_per_user_df.fillna(\"\")\n",
    "writings_per_user_df['text'] = writings_per_user_df['text'] + \" \" +  writings_per_user_df['title']\n",
    "writings_per_user_df['text_len'] = writings_per_user_df['text_len'] + writings_per_user_df['title_len']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "writings_per_user_df.text_len.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reverse_text(text):\n",
    "    return \" \".join(text.split()[::-1])\n",
    "def truncate_text_beginning(text, seq_len=seq_len, epsilon=20):\n",
    "    truncated_tokenized = text.split()[-seq_len-epsilon:]\n",
    "    return \" \".join(truncated_tokenized)\n",
    "# writings_per_user_df['text'] = writings_per_user_df['text'].apply(truncate_text_beginning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_subjects_split(writings_df, train_prop=0.8, test_slice=2, nr_slices=5, valid_prop=0):\n",
    "    if 'subset' in writings_df.columns:\n",
    "        training_subjects = list(set(writings_df[writings_df['subset']=='train'].subject))\n",
    "        test_subjects = list(set(writings_df[writings_df['subset']=='test'].subject))\n",
    "    else:\n",
    "        all_subjects = sorted(list(set(writings_df.subject)))\n",
    "        training_subjects_size = int(len(all_subjects) * train_prop)\n",
    "        test_subjects_size = len(all_subjects) - training_subjects_size\n",
    "        # Cross-validation, with fixed slice as input\n",
    "        test_prop = 1-train_prop\n",
    "        test_slice = min(test_slice, nr_slices)\n",
    "        logger.debug(\"start index: %f, from %f\\n\" % (\n",
    "            len(all_subjects)*(1/nr_slices)*test_slice, test_prop*test_slice))\n",
    "        start_slice = int(len(all_subjects)*(1/nr_slices)*test_slice)\n",
    "        test_subjects = all_subjects[start_slice: start_slice+test_subjects_size]\n",
    "        training_subjects = [s for s in all_subjects if s not in test_subjects]\n",
    "    training_subjects = sorted(training_subjects) # ensuring reproducibility\n",
    "    valid_subjects_size = int(len(training_subjects) * valid_prop)\n",
    "    valid_subjects = training_subjects[:valid_subjects_size]\n",
    "    training_subjects = training_subjects[valid_subjects_size:]\n",
    "    logger.debug(\"%d training users, %d validation users, %d test users.\" % (\n",
    "        len(training_subjects), \n",
    "          len(valid_subjects),\n",
    "          len(test_subjects)))\n",
    "    subjects_split = {'train': training_subjects, \n",
    "                      'valid': valid_subjects, \n",
    "                      'test': test_subjects}\n",
    "    return subjects_split\n",
    "\n",
    "subjects_split = get_subjects_split(writings_df, nr_slices=5, test_slice=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = writings_per_user_df[writings_per_user_df.index.isin(subjects_split['train'])]#[['text', 'labels']]\n",
    "test_df = writings_per_user_df[writings_per_user_df.index.isin(subjects_split['test'])]#[['text', 'labels']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MultiLabelBinarizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['labels'] = train_df[['label%d'%i for i in range(21)]].values.tolist()\n",
    "binarizer = MultiLabelBinarizer()\n",
    "binarizer.fit([range(-3,3,1)])\n",
    "# TODO: this is not the right way. it's not multilabel...?\n",
    "train_df['labels'] = train_df['labels'].apply(lambda l: binarizer.transform((l,)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = {\n",
    "#    'model_type':  'roberta',\n",
    "#    'model_name': 'roberta-base',\n",
    "   'output_dir': 'outputs/',\n",
    "   'cache_dir': 'cache/',\n",
    "    'fp16': True,\n",
    "   'fp16_opt_level': 'O1',\n",
    "   'max_seq_length': seq_len,#256, #128,\n",
    "   'train_batch_size': 8,\n",
    "   'eval_batch_size': 8,\n",
    "   'gradient_accumulation_steps': 1,\n",
    "   'num_train_epochs': 2,\n",
    "   'weight_decay': 0,\n",
    "   'learning_rate': 4e-6,\n",
    "   'adam_epsilon': 1e-8,\n",
    "   'warmup_ratio': 0.06,\n",
    "   'warmup_steps': 0,\n",
    "   'max_grad_norm': 1.0,\n",
    "    'logging_steps': 50,\n",
    "   'evaluate_during_training': True,\n",
    "   'save_steps': 2000,\n",
    "   'eval_all_checkpoints': False,\n",
    "    'evaluate_during_training': True,\n",
    "    'evaluate_during_training_verbose': True,\n",
    "    'evaluate_during_training_steps': 3,\n",
    "   'use_tensorboard': True,\n",
    "#     'tensorboard_dir': 'tensorboard/',\n",
    "    'overwrite_output_dir': True,\n",
    "   'reprocess_input_data': False,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a TransformerModel\n",
    "model = MultiLabelClassificationModel('roberta', 'roberta-base', args=args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "model.train_model(train_df=train_df, eval_df=test_df, text_ #acc=accuracy_score,\n",
    "                                                          prec=precision_score,\n",
    "                                                           f1=f1_score)#auto_weights=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparams_features = {\n",
    "    \"max_features\": 40000,\n",
    "    # cut texts after this number of words\n",
    "    # (among top max_features most common words)\n",
    "    \"maxlen\": 512,\n",
    "    \"embedding_dim\": 50,\n",
    "    \"user_level\": True,\n",
    "    \"posts_per_user\": 10,\n",
    "    \"batch_size\": 2,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Emotions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_NRC(nrc_path):\n",
    "    word_emotions = {}\n",
    "    emotion_words = {}\n",
    "    with open(nrc_path) as in_f:\n",
    "        for line in in_f:\n",
    "            line = line.strip()\n",
    "            if not line:\n",
    "                continue\n",
    "            word, emotion, label = line.split()\n",
    "            if word not in word_emotions:\n",
    "                word_emotions[word] = set()\n",
    "            if emotion not in emotion_words:\n",
    "                emotion_words[emotion] = set()\n",
    "            label = int(label)\n",
    "            if label:\n",
    "                word_emotions[word].add(emotion)\n",
    "                emotion_words[emotion].add(word)\n",
    "    return emotion_words\n",
    "\n",
    "nrc_lexicon_path = root_dir + '/resources/NRC-Emotion-Lexicon-Wordlevel-v0.92.txt'\n",
    "nrc_lexicon = load_NRC(nrc_lexicon_path)\n",
    "emotions = list(nrc_lexicon.keys())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_emotions(tokens, emotion_lexicon, emotions, relative=True):\n",
    "    text_len = len(tokens)\n",
    "    encoded_emotions = [0 for e in emotions]\n",
    "    for i, emotion in enumerate(emotions):\n",
    "        try:\n",
    "            emotion_words = [t for t in tokens if t in emotion_lexicon[emotion]]\n",
    "            if relative:\n",
    "                encoded_emotions[i] = len(emotion_words) / len(tokens)\n",
    "            else:\n",
    "                encoded_emotions[i] = len(emotion_words)\n",
    "        except ValueError:\n",
    "            print(\"Emotion not found.\")\n",
    "    return encoded_emotions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from liwc_readDict import readDict\n",
    "\n",
    "liwc = readDict(root_dir + '/resources/liwc.dic')\n",
    "\n",
    "categories = set([c for (w,c) in liwc])\n",
    "len(categories)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Personal pronouns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_person_pronouns = {\"i\", \"me\", \"my\", \"mine\", \"myself\"}\n",
    "def encode_pronouns(tokens, pronouns={\"i\", \"me\", \"my\", \"mine\", \"myself\"}, relative=True):\n",
    "    if not tokens:\n",
    "        return np.nan\n",
    "    text_len = len(tokens)\n",
    "    nr_pronouns = len([t for t in tokens if t in pronouns])\n",
    "    if relative:\n",
    "        return nr_pronouns/text_len\n",
    "    else:\n",
    "        return nr_pronouns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopword_list = stopwords.words(\"english\")\n",
    "def encode_stopwords(tokens, stopwords=stopword_list):\n",
    "    encoded_stopwords = [0 for s in stopwords]\n",
    "    if not tokens:\n",
    "        return encoded_stopwords\n",
    "    for i, stopword in enumerate(stopwords):\n",
    "        if stopword in tokens:\n",
    "            encoded_stopwords[i] += 1\n",
    "    return encoded_stopwords"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from easybert import Bert\n",
    "# bert = Bert(\"https://tfhub.dev/google/bert_uncased_L-12_H-768_A-12/1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x = bert.embed(\"A sequence of words is a sequebce.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def encode_bert(sequence):\n",
    "#     return bert.embed(sequence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple transformers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import simpletransformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prefix='/home/anasab/eRisk/data/'\n",
    "# train_df = pd.read_csv(prefix + 'train.csv', header=None)\n",
    "# train_df.head()\n",
    "\n",
    "# eval_df = pd.read_csv(prefix + 'test.csv', header=None)\n",
    "# eval_df.head()\n",
    "\n",
    "# train_df[0] = (train_df[0] == 2).astype(int)\n",
    "# eval_df[0] = (eval_df[0] == 2).astype(int)\n",
    "\n",
    "# train_df = pd.DataFrame({\n",
    "#     'text': train_df[1].replace(r'\\n', ' ', regex=True),\n",
    "#     'label':train_df[0]\n",
    "# })\n",
    "\n",
    "# print(train_df.head())\n",
    "\n",
    "# eval_df = pd.DataFrame({\n",
    "#     'text': eval_df[1].replace(r'\\n', ' ', regex=True),\n",
    "#     'label':eval_df[0]\n",
    "# })\n",
    "\n",
    "# print(eval_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from simpletransformers.classification import ClassificationModel\n",
    "\n",
    "\n",
    "# # Create a TransformerModel\n",
    "# model = ClassificationModel('roberta', 'roberta-base')\n",
    "\n",
    "# # Train the model\n",
    "# model.train_model(train_df)\n",
    "\n",
    "# # Evaluate the model\n",
    "# result, model_outputs, wrong_predictions = model.eval_model(eval_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from bert import albert_tokenization\n",
    "# from bert import bert_tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow_hub as hub\n",
    "# bert_path = \"https://tfhub.dev/google/bert_uncased_L-12_H-768_A-12/1\"\n",
    "# bert_path = \"https://tfhub.dev/tensorflow/bert_en_uncased_L-12_H-768_A-12/1\"\n",
    "bert_path = \"https://tfhub.dev/google/bert_uncased_L-12_H-768_A-12/1\"\n",
    "\n",
    "import bert\n",
    "# from bert.tokenization.bert_tokenization import FullTokenizer\n",
    "from bert.tokenization import FullTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_layer = hub.KerasLayer(bert_path,# signature='tokens' , signature_outputs_as_dict=True,\n",
    "                            trainable=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class InputExample(object):\n",
    "    \"\"\"A single training/test example for simple sequence classification.\"\"\"\n",
    "\n",
    "    def __init__(self, guid, text_a, text_b=None, label=None):\n",
    "        \"\"\"Constructs a InputExample.\n",
    "    Args:\n",
    "      guid: Unique id for the example.\n",
    "      text_a: string. The untokenized text of the first sequence. For single\n",
    "        sequence tasks, only this sequence must be specified.\n",
    "      text_b: (Optional) string. The untokenized text of the second sequence.\n",
    "        Only must be specified for sequence pair tasks.\n",
    "      label: (Optional) string. The label of the example. This should be\n",
    "        specified for train and dev examples, but not for test examples.\n",
    "    \"\"\"\n",
    "        self.guid = guid\n",
    "        self.text_a = text_a\n",
    "        self.text_b = text_b\n",
    "        self.label = label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_text_for_bert(tokenizer, example, max_seq_length=512):\n",
    "    \"\"\"Converts a single `InputExample` into a single `InputFeatures`.\"\"\"\n",
    "\n",
    "#     if isinstance(example, PaddingInputExample):\n",
    "#         input_ids = [0] * max_seq_length\n",
    "#         input_mask = [0] * max_seq_length\n",
    "#         segment_ids = [0] * max_seq_length\n",
    "#         label = 0\n",
    "#         return input_ids, input_mask, segment_ids, label\n",
    "\n",
    "    tokens_a = tokenizer.tokenize(example.text_a)\n",
    "    if len(tokens_a) > max_seq_length - 2:\n",
    "        tokens_a = tokens_a[0 : (max_seq_length - 2)]\n",
    "\n",
    "    tokens = []\n",
    "    segment_ids = []\n",
    "    tokens.append(\"[CLS]\")\n",
    "    segment_ids.append(0)\n",
    "    for token in tokens_a:\n",
    "        tokens.append(token)\n",
    "        segment_ids.append(0)\n",
    "    tokens.append(\"[SEP]\")\n",
    "    segment_ids.append(0)\n",
    "\n",
    "    input_ids = tokenizer.convert_tokens_to_ids(tokens)\n",
    "\n",
    "    # The mask has 1 for real tokens and 0 for padding tokens. Only real\n",
    "    # tokens are attended to.\n",
    "    input_mask = [1] * len(input_ids)\n",
    "\n",
    "    # Zero-pad up to the sequence length.\n",
    "    while len(input_ids) < max_seq_length:\n",
    "        input_ids.append(0)\n",
    "        input_mask.append(0)\n",
    "        segment_ids.append(0)\n",
    "\n",
    "    assert len(input_ids) == max_seq_length\n",
    "    assert len(input_mask) == max_seq_length\n",
    "    assert len(segment_ids) == max_seq_length\n",
    "\n",
    "    return input_ids, input_mask, segment_ids, example.label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_tokenizer_from_hub_module():\n",
    "    \"\"\"Get the vocab file and casing info from the Hub module.\"\"\"\n",
    "#     bert_module =  hub.Module(bert_path)\n",
    "#     tokenization_info = bert_module(signature=\"tokenization_info\", as_dict=True)\n",
    "    vocab_file = bert_layer.resolved_object.vocab_file.asset_path.numpy()\n",
    "    do_lower_case = bert_layer.resolved_object.do_lower_case.numpy()\n",
    "\n",
    "#     vocab_file, do_lower_case = sess.run(\n",
    "#         [\n",
    "#             tokenization_info[\"vocab_file\"],\n",
    "#             tokenization_info[\"do_lower_case\"],\n",
    "#         ]\n",
    "#     )\n",
    "\n",
    "    return FullTokenizer(vocab_file=vocab_file, do_lower_case=do_lower_case)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate tokenizer\n",
    "# bert_tokenizer = FullTokenizer()\n",
    "bert_tokenizer = create_tokenizer_from_hub_module()\n",
    "\n",
    "encode_text_for_bert(bert_tokenizer, InputExample(None, \n",
    "                                               \"Ana are mere\"), \n",
    "                       hyperparams_features['maxlen'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### tfhub albert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input_ids = tf.keras.layers.Input(shape=[None], dtype=tf.int32)\n",
    "# input_mask = tf.keras.layers.Input(shape=[None], dtype=tf.int32)\n",
    "# sequence_mask = tf.keras.layers.Input(shape=[None], dtype=tf.int32)\n",
    "\n",
    "# albert = hub.KerasLayer(\n",
    "#     \"https://tfhub.dev/google/albert_xlarge/3\",\n",
    "#     trainable=True,\n",
    "#     signature=\"tokens\",\n",
    "#     output_key=\"pooled_output\",\n",
    "# )\n",
    "\n",
    "# features = {\n",
    "#     \"input_ids\": input_ids,\n",
    "#     \"input_mask\": input_mask,\n",
    "#     \"segment_ids\": sequence_mask,\n",
    "# }\n",
    "# out = albert(features)\n",
    "# model = tf.keras.Model(inputs=[input_ids, input_mask, sequence_mask], outputs=out)\n",
    "# model.compile(\"adam\", loss=\"sparse_categorical_crossentropy\")\n",
    "# model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encode data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "def encode_labels(labels):\n",
    "    '''Convert ia to i and ib to -i'''\n",
    "    encoded_labels = []\n",
    "    for i, l in enumerate(labels):\n",
    "        try:\n",
    "            encoded_labels.append(int(l))\n",
    "        except Exception as e:\n",
    "            logger.debug(\"Encoding label %s\\n\" % l)\n",
    "        \n",
    "            if str(l)[-1] == 'a':\n",
    "                encoded_labels.append(int(l[0]))\n",
    "            elif str(l)[-1] == 'b':\n",
    "                encoded_labels.append(-int(l[0]))\n",
    "            else:\n",
    "                logger.warning(\"Coult not encode label %s\\n\" % l)\n",
    "    return encoded_labels\n",
    "\n",
    "def load_erisk_data(writings_df, voc_size, emotion_lexicon, seq_len, emotions =  \n",
    "                    ['anger', 'anticipation', 'disgust', 'fear', 'joy', \n",
    "                     'negative', 'positive', 'sadness', 'surprise', 'trust'],\n",
    "                    liwc_categories = categories, ignore_features=[],\n",
    "                    pronouns = [\"i\", \"me\", \"my\", \"mine\", \"myself\"],\n",
    "                    train_prop=0.7, valid_prop=0.3, test_slice=2,\n",
    "                    nr_slices=5,\n",
    "                    min_post_len=3, min_word_len=1, \n",
    "                    user_level=True, vocabulary=None,\n",
    "                   logger=logger):\n",
    "    logger.debug(\"Loading data...\\n\")\n",
    "    if not vocabulary:\n",
    "        vocabulary = {}\n",
    "        word_freqs = Counter()\n",
    "        for words in writings_df.tokenized_text:\n",
    "            word_freqs.update(words)\n",
    "        for words in writings_df.tokenized_title:\n",
    "            word_freqs.update(words)\n",
    "        i = 1\n",
    "        for w, f in word_freqs.most_common(voc_size-2): # keeping voc_size-1 for unk\n",
    "            if len(w) < min_word_len:\n",
    "                continue\n",
    "            vocabulary[w] = i\n",
    "            i += 1\n",
    "\n",
    "    if 'subset' in writings_df.columns:\n",
    "        training_subjects = list(set(writings_df[writings_df['subset']=='train'].subject))\n",
    "        test_subjects = list(set(writings_df[writings_df['subset']=='test'].subject))\n",
    "    else:\n",
    "        all_subjects = sorted(list(set(writings_df.subject)))\n",
    "        training_subjects_size = int(len(all_subjects) * train_prop)\n",
    "        test_subjects_size = len(all_subjects) - training_subjects_size\n",
    "        # Cross-validation, with fixed slice as input\n",
    "        test_prop = 1-train_prop\n",
    "        test_slice = min(test_slice, nr_slices)\n",
    "        logger.debug(\"start index: %f, from %f\\n\" % (\n",
    "            len(all_subjects)*(1/nr_slices)*test_slice, test_prop*test_slice))\n",
    "        start_slice = int(len(all_subjects)*(1/nr_slices)*test_slice)\n",
    "        test_subjects = all_subjects[start_slice: start_slice+test_subjects_size]\n",
    "        training_subjects = [s for s in all_subjects if s not in test_subjects]\n",
    "    training_subjects = sorted(training_subjects) # ensuring reproducibility\n",
    "    valid_subjects_size = int(len(training_subjects) * valid_prop)\n",
    "    valid_subjects = training_subjects[:valid_subjects_size]\n",
    "    training_subjects = training_subjects[valid_subjects_size:]\n",
    "    categories = [c for c in liwc_categories if c in writings_df.columns]\n",
    "    logger.debug(\"%d training users, %d validation users, %d test users.\" % (\n",
    "        len(training_subjects), \n",
    "          len(valid_subjects),\n",
    "          len(test_subjects)))\n",
    "    subjects_split = {'train': training_subjects, \n",
    "                      'valid': valid_subjects, \n",
    "                      'test': test_subjects}\n",
    "\n",
    "    user_level_texts = {}\n",
    "    for row in writings_df.sort_values(by='date').itertuples():\n",
    "        words = []\n",
    "        raw_text = \"\"\n",
    "        if row.tokenized_title:\n",
    "            words.extend(row.tokenized_title)\n",
    "            raw_text += row.title\n",
    "        if row.tokenized_text:\n",
    "            words.extend(row.tokenized_text)\n",
    "            raw_text += row.text\n",
    "        if not words or len(words)<min_post_len:\n",
    "            print(row.subject)\n",
    "            continue\n",
    "        labels = [getattr(row, 'label%d'%i) for i in range(nr_questions)]\n",
    "        liwc_categs = [getattr(row, categ) for categ in categories]\n",
    "        if row.subject not in user_level_texts.keys():\n",
    "            user_level_texts[row.subject] = {}\n",
    "            user_level_texts[row.subject]['texts'] = [words]\n",
    "            user_level_texts[row.subject]['labels'] = encode_labels(labels)\n",
    "            user_level_texts[row.subject]['liwc'] = [liwc_categs]\n",
    "            user_level_texts[row.subject]['raw'] = [raw_text]\n",
    "        else:\n",
    "            user_level_texts[row.subject]['texts'].append(words)\n",
    "            user_level_texts[row.subject]['liwc'].append(liwc_categs)\n",
    "            user_level_texts[row.subject]['raw'].append(raw_text)\n",
    "\n",
    "    return user_level_texts, subjects_split, vocabulary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocabulary_list = pickle.load(open('all_vocab_clpsych_erisk_20000.pkl', 'rb'))\n",
    "vocabulary_dict={}\n",
    "for i,w in enumerate(vocabulary_list):\n",
    "    vocabulary_dict[w] = i\n",
    "user_level_data, subjects_split, vocabulary = load_erisk_data(writings_df, \n",
    "                                                            seq_len=hyperparams_features['maxlen'],\n",
    "                                                            voc_size=hyperparams_features['max_features'],\n",
    "                                                           emotion_lexicon=nrc_lexicon,\n",
    "                                                           emotions=emotions,\n",
    "                                                           user_level=hyperparams_features['user_level'],\n",
    "                                                                                logger=logger,\n",
    "#                                                            vocabulary=pickle.load(open('vocabulary_40K_all.pkl', 'rb'))\n",
    "                                                             vocabulary=vocabulary_dict,           \n",
    "                                                             )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_level_data['subject6900']['labels']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_embeddings(path, embedding_dim, voc):\n",
    "    # random matrix with mean value = 0\n",
    "    embedding_matrix = np.random.random((len(voc)+2, embedding_dim)) - 0.5 # voc + unk + pad value(0)\n",
    "\n",
    "    f = open(path)\n",
    "    for line in f:\n",
    "        values = line.split()\n",
    "        word = values[0]\n",
    "        coefs = np.asarray(values[1:], dtype='float32')\n",
    "        word_i = voc.get(word)\n",
    "        if word_i is not None:\n",
    "            embedding_matrix[word_i] = coefs\n",
    "    f.close()\n",
    "\n",
    "    print('Total %s word vectors.' % len(embedding_matrix))\n",
    "\n",
    " \n",
    "    return embedding_matrix\n",
    "\n",
    "pretrained_embeddings_path = root_dir + '/resources/glove.twitter.27B/glove.twitter.27B.%dd.txt' % hyperparams_features['embedding_dim']\n",
    "embedding_matrix = load_embeddings(pretrained_embeddings_path, hyperparams_features['embedding_dim'], vocabulary)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataGenerator(Sequence):\n",
    "    'Generates data for Keras'\n",
    "    def __init__(self, user_level_data, subjects_split, set_type='train', bert_tokenizer=bert_tokenizer,\n",
    "                 batch_size=hyperparams_features['batch_size'], seq_len=hyperparams_features['maxlen'], \n",
    "                 voc_size=hyperparams_features['max_features'], emotion_lexicon=nrc_lexicon, sparse_words=stopwords,\n",
    "                 emotions=emotions, pronouns=[\"i\", \"me\", \"my\", \"mine\", \"myself\"], \n",
    "                 max_posts_per_user=hyperparams_features['posts_per_user'],\n",
    "                 shuffle=True):\n",
    "        'Initialization'\n",
    "        self.seq_len = seq_len\n",
    "        self.bert_tokenizer = bert_tokenizer\n",
    "        self.subjects_split = subjects_split\n",
    "        self.set = set_type\n",
    "        self.emotion_lexicon = emotion_lexicon\n",
    "        self.batch_size = batch_size\n",
    "        self.data = user_level_data\n",
    "        self.emotions = emotions\n",
    "        self.pronouns = pronouns\n",
    "        self.shuffle = shuffle\n",
    "        self.sparse_words = sparse_words\n",
    "        self.voc_size = voc_size\n",
    "        self.max_posts_per_user = max_posts_per_user\n",
    "        self.on_epoch_end()\n",
    "\n",
    "    def __encode_text(self, tokens, raw_text):\n",
    "        # Using voc_size-1 value for OOV token\n",
    "        encoded_tokens = [vocabulary.get(w, self.voc_size-1) for w in tokens]\n",
    "        encoded_emotions = encode_emotions(tokens, self.emotion_lexicon, self.emotions)\n",
    "        encoded_pronouns = encode_pronouns(tokens, self.pronouns)\n",
    "        encoded_stopwords = encode_stopwords(tokens, self.sparse_words)\n",
    "        bert_ids, bert_masks, bert_segments, label = encode_text_for_bert(self.bert_tokenizer, InputExample(None, \n",
    "                                               raw_text), self.seq_len)\n",
    "        return (encoded_tokens, encoded_emotions, encoded_pronouns, encoded_stopwords,\n",
    "               bert_ids, bert_masks, bert_segments)\n",
    "        \n",
    "    def __len__(self):\n",
    "        'Denotes the number of batches per epoch'\n",
    "        return int(np.floor(len(self.subjects_split[self.set]) / self.batch_size))\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        'Generate one batch of data'\n",
    "        # Generate indexes of the batch\n",
    "        user_indexes = self.indexes[index*self.batch_size:(index+1)*self.batch_size]\n",
    "        # Find users\n",
    "        users = [self.subjects_split[self.set][i] for i in user_indexes\n",
    "                    if self.subjects_split[self.set][i] in self.data.keys()] # TODO: maybe needs a warning that user is missing\n",
    "\n",
    "        post_indexes = {}\n",
    "        # Sample post ids\n",
    "        for subject in users:\n",
    "            posts_len = len(self.data[subject]['texts'])\n",
    "            posts_index_sample = sorted(np.random.choice(posts_len, \n",
    "                                                         min(self.max_posts_per_user, posts_len),\n",
    "                                                         replace=False))\n",
    "            post_indexes[subject] = posts_index_sample\n",
    "        # Generate data\n",
    "        X, y = self.__data_generation(users, post_indexes)\n",
    "\n",
    "        return X, y\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        'Updates indexes after each epoch'\n",
    "        self.indexes = np.arange(len(self.subjects_split[self.set]))\n",
    "        if self.shuffle == True:\n",
    "            np.random.shuffle(self.indexes)\n",
    "\n",
    "    def __data_generation(self, users, post_indexes):\n",
    "        'Generates data containing batch_size samples' # X : (n_samples, *dim, n_channels)\n",
    "        tokens_data = []\n",
    "        categ_data = []\n",
    "        sparse_data = []\n",
    "        subjects = []\n",
    "        bert_ids_data = []\n",
    "        bert_masks_data = []\n",
    "        bert_segments_data = []\n",
    "        labels = []\n",
    "\n",
    "        for subject in users:\n",
    "            texts = self.data[subject]['texts']\n",
    "            raw_texts = self.data[subject]['raw']\n",
    "            label = self.data[subject]['label']\n",
    "            liwc_scores = self.data[subject]['liwc']\n",
    "            \n",
    "            # Sample\n",
    "            texts = [texts[i] for i in post_indexes[subject]]\n",
    "            liwc_selection = [liwc_scores[i] for i in post_indexes[subject]]\n",
    "            raw_texts = [raw_texts[i] for i in post_indexes[subject]]\n",
    "            \n",
    "            all_words = [sum(texts, [])] # merge all texts in one list -- Ok, why sum?? this is wrong!!\n",
    "            liwc_mean = [np.array(liwc_selection).mean(axis=0).tolist()]\n",
    "            liwc_std = [np.array(liwc_selection).std(axis=0).tolist()]\n",
    "            all_raw_texts = [\" \".join(raw_texts)]\n",
    "            \n",
    "            for i, words in enumerate(all_words):\n",
    "                encoded_tokens, encoded_emotions, encoded_pronouns, encoded_stopwords, \\\n",
    "                    bert_ids, bert_masks, bert_segments = self.__encode_text(words, all_raw_texts[i])\n",
    "                subject_id = int(subject.split('t')[1])\n",
    "                tokens_data.append(encoded_tokens)\n",
    "                categ_data.append(encoded_emotions + [encoded_pronouns] + liwc_mean[i] + liwc_std[i])\n",
    "                sparse_data.append(encoded_stopwords)\n",
    "                bert_ids_data.append(bert_ids)\n",
    "                bert_masks_data.append(bert_masks)\n",
    "                bert_segments_data.append(bert_segments)\n",
    "                \n",
    "                labels.append(label)\n",
    "                subjects.append(subject_id)\n",
    "\n",
    "        \n",
    "        # using zeros for padding\n",
    "        tokens_data_padded = sequence.pad_sequences(tokens_data, maxlen=self.seq_len)\n",
    "\n",
    "        return ([np.array(tokens_data_padded), np.array(categ_data), np.array(sparse_data),\n",
    "                 np.array(bert_ids_data), np.array(bert_masks_data), np.array(bert_segments_data),\n",
    "                np.array(subjects)],\n",
    "                np.array(labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataGenerator(Sequence):\n",
    "    'Generates data for Keras'\n",
    "    def __init__(self, user_level_data, subjects_split, batch_size=hyperparams_features['batch_size'], \n",
    "                 seq_len=hyperparams_features['maxlen'], voc_size=hyperparams_features['max_features'], \n",
    "                 emotion_lexicon=nrc_lexicon, set_type='train', test_user_indexes=[0],\n",
    "                 emotions=emotions, pronouns=[\"i\", \"me\", \"my\", \"mine\", \"myself\"], \n",
    "                 max_posts_per_user=hyperparams_features['posts_per_user'],\n",
    "                 bert_tokenizer=bert_tokenizer,\n",
    "                 shuffle=True):\n",
    "        'Initialization'\n",
    "        self.seq_len = seq_len\n",
    "        self.emotion_lexicon = emotion_lexicon\n",
    "        self.bert_tokenizer = bert_tokenizer\n",
    "        self.batch_size = batch_size\n",
    "        self.data = user_level_data\n",
    "        self.all_users = list(self.data.keys())\n",
    "        self.emotions = emotions\n",
    "        self.pronouns = pronouns\n",
    "        self.set = set_type\n",
    "        self.subjects_split = subjects_split\n",
    "        self.shuffle = shuffle\n",
    "        self.voc_size = voc_size\n",
    "        self.max_posts_per_user = max_posts_per_user\n",
    "        self.test_user_indexes = test_user_indexes\n",
    "        self.on_epoch_end()\n",
    "\n",
    "\n",
    "    def __encode_text(self, tokens, raw_text):\n",
    "        # Using voc_size-1 value for OOV token\n",
    "        encoded_tokens = [vocabulary.get(w, self.voc_size-1) for w in tokens]\n",
    "        encoded_emotions = encode_emotions(tokens, self.emotion_lexicon, self.emotions)\n",
    "        encoded_pronouns = encode_pronouns(tokens, self.pronouns)\n",
    "        encoded_stopwords = encode_stopwords(tokens)\n",
    "        bert_ids, bert_masks, bert_segments, label = encode_text_for_bert(self.bert_tokenizer, InputExample(None, \n",
    "                                               raw_text), self.seq_len)\n",
    "        return (encoded_tokens, encoded_emotions, encoded_pronouns, encoded_stopwords,\n",
    "               bert_ids, bert_masks, bert_segments)\n",
    "        \n",
    "    def __len__(self):\n",
    "        'Denotes the number of batches per epoch'\n",
    "        return int(np.floor(len(self.subjects_split[self.set]) / self.batch_size))\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        'Generate one batch of data'\n",
    "        # Generate indexes of the batch\n",
    "        user_indexes = self.indexes[index*self.batch_size:(index+1)*self.batch_size]\n",
    "        # Find users\n",
    "        users = [self.subjects_split[self.set][i] for i in user_indexes\n",
    "                    if self.subjects_split[self.set][i] in self.data.keys()] # TODO: maybe needs a warning that user is missing\n",
    "\n",
    "        post_indexes = {}\n",
    "        # Sample post ids\n",
    "        for subject in users:\n",
    "            posts_len = len(self.data[subject]['texts'])\n",
    "            posts_index_sample = sorted(np.random.choice(posts_len, \n",
    "                                                         min(self.max_posts_per_user, posts_len),\n",
    "                                                         replace=False))\n",
    "            post_indexes[subject] = posts_index_sample\n",
    "        # Generate data\n",
    "        X, y = self.__data_generation(users, post_indexes)\n",
    "\n",
    "        return X, y\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        'Updates indexes after each epoch'\n",
    "        self.indexes = np.arange(len(self.subjects_split[self.set]))\n",
    "        if self.shuffle == True:\n",
    "            np.random.shuffle(self.indexes)\n",
    "\n",
    "    def __data_generation(self, users, post_indexes):\n",
    "        'Generates data containing batch_size samples' # X : (n_samples, *dim, n_channels)\n",
    "        tokens_data = []\n",
    "        categ_data = []\n",
    "        sparse_data = []\n",
    "        subjects = []\n",
    "        bert_ids_data = []\n",
    "        bert_masks_data = []\n",
    "        bert_segments_data = []\n",
    "        labels = []\n",
    "        for subject in users:\n",
    "            texts = self.data[subject]['texts']\n",
    "            label = self.data[subject]['labels']\n",
    "            raw_texts = self.data[subject]['raw']\n",
    "\n",
    "            # Sample\n",
    "            texts = [texts[i] for i in post_indexes[subject]]\n",
    "            liwc_selection = [self.data[subject]['liwc'][i] for i in post_indexes[subject]]\n",
    "            raw_texts = [raw_texts[i] for i in post_indexes[subject]]\n",
    "\n",
    "            all_words = [sum(texts, [])] # merge all texts in one list\n",
    "            liwc_aggreg = [np.array(liwc_selection).mean(axis=0).tolist()]\n",
    "            all_raw_texts = [\" \".join(raw_texts)]\n",
    "\n",
    "            \n",
    "            for i, words in enumerate(all_words):\n",
    "                encoded_tokens, encoded_emotions, encoded_pronouns, encoded_stopwords, \\\n",
    "                    bert_ids, bert_masks, bert_segments = self.__encode_text(words, all_raw_texts[i])\n",
    "                subject_id = int(subject.split('t')[1])\n",
    "                tokens_data.append(encoded_tokens)\n",
    "                categ_data.append(encoded_emotions + [encoded_pronouns] + liwc_aggreg[i])\n",
    "                sparse_data.append(encoded_stopwords)\n",
    "                labels.append(label)\n",
    "                bert_ids_data.append(bert_ids)\n",
    "                bert_masks_data.append(bert_masks)\n",
    "                bert_segments_data.append(bert_segments)\n",
    "                \n",
    "                subjects.append(subject_id)\n",
    "\n",
    "        \n",
    "        # using zeros for padding\n",
    "        tokens_data_padded = sequence.pad_sequences(tokens_data, maxlen=self.seq_len)\n",
    "\n",
    "        return ([np.array(tokens_data_padded), np.array(categ_data), np.array(sparse_data),\n",
    "#                 np.array(subjects),\n",
    "                np.array(bert_ids_data, dtype=np.int32), \n",
    "                 np.array(bert_masks_data, dtype=np.int32), \n",
    "                 np.array(bert_segments_data, dtype=np.int32),],\n",
    "                np.array(labels))\n",
    "#                 np.array(labels).reshape(self.batch_size, -1, len(labels)).tolist()) # to have one array per output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Don't split into the 3 sets, do leave-one-out cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_subjects_split(test_size=hyperparams_features['batch_size']):\n",
    "    test_user_indexes = [np.random.randint(len(user_level_data)) for i in range(test_size)]\n",
    "\n",
    "    subjects_split = {'test': [u for i,u in \n",
    "                               enumerate(user_level_data.keys()) if i in test_user_indexes],\n",
    "                     'train': [u for i,u in \n",
    "                               enumerate(user_level_data.keys()) if i not in test_user_indexes],}\n",
    "    return subjects_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger.setLevel(logging.DEBUG)\n",
    "\n",
    "# TODO: it is skipping the last batch\n",
    "x_data = {'train': [], 'test': []}\n",
    "y_data = {'train': [], 'test': []}\n",
    "subjects_split = get_subjects_split()\n",
    "for set_type in ['train', 'test']:\n",
    "    for x, y in DataGenerator(user_level_data, batch_size=hyperparams_features['batch_size'],\n",
    "                            set_type=set_type,\n",
    "                             subjects_split=subjects_split):\n",
    "        print(x)\n",
    "        x_data[set_type].append(x)\n",
    "        y_data[set_type].append(y)\n",
    "#         break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_data['test'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_data['train'][0][5].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array([[1,2],[3,4]]).reshape(2,-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum([len(subjects_split[s]) for s in ['train', 'test']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_data['train']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparams = {\n",
    "    'lstm_units': 10,\n",
    "    'dense_bow_units': 20,\n",
    "    'dropout': 0.0,\n",
    "    'l2_dense': 0.00000011,\n",
    "    'l2_embeddings': 0.000001,\n",
    "    'dense_sentence_units': 100,\n",
    "    'optimizer': 'adam',\n",
    "    'bert_dense_units': 256,\n",
    "    'decay': 0.00001,\n",
    "    'lr': 0.01,\n",
    "    \"trainable_embeddings\": False,\n",
    "    \"reduce_lr_factor\": 0.0002,\n",
    "    \"reduce_lr_patience\": 1000,\n",
    "    \"freeze_patience\": 500,\n",
    "    'threshold': 0.5,\n",
    "    'bert_len': 768,\n",
    "    'ignore_layer': ['batchnorm', 'lstm_layers', 'numerical_dense_layer', 'sparse_feat_dense_layer'],\n",
    "    'norm_momentum': 0.1,\n",
    "\n",
    "}\n",
    "if not hyperparams['optimizer']:\n",
    "    hyperparams['optimizer'] = optimizers.Adam(lr=hyperparams['lr'], #beta_1=0.9, beta_2=0.999, epsilon=0.0001,\n",
    "                                   decay=hyperparams['decay'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class Metrics():\n",
    "#     def __init__(self, threshold=0.5):\n",
    "#         self.threshold=threshold\n",
    "        \n",
    "#     def recall_m(self, y_true, y_pred):\n",
    "#             y_labels = y_true\n",
    "#             y_pred = K.cast(K.greater(K.clip(y_pred, 0, 1), self.threshold), K.floatx())        \n",
    "#             possible_positives = K.sum(K.round(K.clip(y_labels, 0, 1)))\n",
    "#             true_positives = K.sum(K.round(K.clip(y_labels * y_pred, 0, 1)))\n",
    "#             recall = true_positives / (possible_positives + K.epsilon())\n",
    "#             return recall\n",
    "\n",
    "#     def precision_m(self, y_true, y_pred):\n",
    "#             y_labels = y_true\n",
    "#             y_pred = K.cast(K.greater(K.clip(y_pred, 0, 1), self.threshold), K.floatx())        \n",
    "#             true_positives = K.sum(K.round(K.clip(y_labels * y_pred, 0, 1)))\n",
    "#             predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "#             precision = true_positives / (predicted_positives + K.epsilon())\n",
    "#             return precision\n",
    "\n",
    "#     def f1_m(self, y_true, y_pred):\n",
    "#         precision = self.precision_m(y_true, y_pred)\n",
    "#         recall = self.recall_m(y_true, y_pred)\n",
    "#         return 2*((precision*recall)/(precision+recall+K.epsilon()))\n",
    "\n",
    "# def binary_crossentropy_custom(y_true, y_pred):\n",
    "#     y_labels = y_true\n",
    "#     return K.binary_crossentropy(y_labels, \n",
    "#                                  y_pred)\n",
    "\n",
    "# metrics_class = Metrics(threshold=hyperparams['threshold'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(hyperparams, hyperparams_features, embedding_matrix, emotions, stopwords_list,\n",
    "                liwc_categories, nr_classes,\n",
    "               ignore_layer=[]):\n",
    "\n",
    "    tokens_features = Input(shape=(hyperparams_features['maxlen'],), name='word_seq')\n",
    "    embedding_layer = Embedding(hyperparams_features['max_features'], \n",
    "                                hyperparams_features['embedding_dim'], \n",
    "                                input_length=hyperparams_features['maxlen'],\n",
    "                                embeddings_regularizer=regularizers.l2(hyperparams['l2_embeddings']),\n",
    "                                weights=[embedding_matrix], \n",
    "                                trainable=hyperparams['trainable_embeddings'],\n",
    "                               name='embeddings_layer')(\n",
    "        tokens_features)\n",
    "#     if 'batchnorm' not in ignore_layer:\n",
    "#         embedding_layer_norm = BatchNormalization(axis=-1, momentum=hyperparams['norm_momentum'],\n",
    "#                                                      name='embeddings_layer_norm')(embedding_layer)\n",
    "#     lstm_layers = Bidirectional(LSTM(hyperparams['lstm_units']))(embedding_layer)\n",
    "\n",
    "\n",
    "    lstm_layers = LSTM(hyperparams['lstm_units'], \n",
    "                           return_sequences='attention' not in ignore_layer,\n",
    "                      name='LSTM_layer')(embedding_layer)\n",
    "    \n",
    "    # Attention\n",
    "    if 'attention' not in ignore_layer:\n",
    "        attention = Dense(1, activation='tanh', name='attention')(lstm_layers)\n",
    "        attention = Flatten()(attention)\n",
    "        attention = Activation('softmax')(attention)\n",
    "        attention = RepeatVector(hyperparams['lstm_units'])(attention)\n",
    "        attention = Permute([2, 1])(attention)\n",
    "\n",
    "        sent_representation = Multiply()([lstm_layers, attention])\n",
    "        sent_representation = Lambda(lambda xin: K.sum(xin, axis=1), \n",
    "                                     output_shape=(hyperparams['lstm_units'],)\n",
    "                                    )(sent_representation)\n",
    "\n",
    "        \n",
    "    else:\n",
    "        sent_representation = lstm_layers\n",
    "        \n",
    "    \n",
    "    sent_representation = Dropout(hyperparams['dropout'], name='lstm_att_dropout')(sent_representation)\n",
    "    if hyperparams['dense_sentence_units']:\n",
    "        sent_representation = Dense(units=hyperparams['dense_sentence_units'],\n",
    "                                   name='dense_sent_representation')(sent_representation)\n",
    "    numerical_features = Input(shape=(len(emotions) + 1 + len(liwc_categories),), name='numeric_input') # emotions and pronouns\n",
    "    \n",
    "    in_id_bert = Input(shape=(hyperparams_features['maxlen'],), dtype='int32', name=\"input_ids_bert\")\n",
    "    in_mask_bert = Input(shape=(hyperparams_features['maxlen'],), dtype='int32', name=\"input_masks_bert\")\n",
    "    in_segment_bert = Input(shape=(hyperparams_features['maxlen'],), dtype='int32', name=\"segment_ids_bert\")\n",
    "#     bert_layer = hub.Module(\n",
    "#         \"https://tfhub.dev/google/albert_xlarge/3\",\n",
    "#         bert_path, trainable=True,\n",
    "#         trainable=False,\n",
    "#         signature=\"tokens\",\n",
    "#         signature_outputs_as_dict=True,\n",
    "#         output_key=\"pooled_output\",\n",
    "#     )\n",
    "\n",
    "#     bert_layer = hub.Module(\n",
    "# #         \"https://tfhub.dev/google/albert_xlarge/3\",\n",
    "#         bert_path, trainable=True,\n",
    "# #         trainable=False,\n",
    "# #         signature=\"tokens\",\n",
    "# #         signature_outputs_as_dict=True,\n",
    "#         output_key=\"pooled_output\",\n",
    "#     )\n",
    "\n",
    "    albert = hub.KerasLayer(\n",
    "        \"https://tfhub.dev/google/albert_base/3\",\n",
    "        trainable=False,\n",
    "        signature=\"tokens\",\n",
    "        output_key=\"pooled_output\",\n",
    "    )\n",
    "\n",
    "    bert_features = {\n",
    "        \"input_ids\": in_id_bert,\n",
    "        \"input_mask\": in_mask_bert,\n",
    "        \"segment_ids\": in_segment_bert,\n",
    "    }\n",
    "    bert_output = albert(bert_features)\n",
    "#     bert_output = albert([in_id_bert, in_mask_bert, in_segment_bert])['pooled_output']  # TODO: can also be 'mean'. Check BertLayer\n",
    "    dense_layer_bert = Dense(units=hyperparams['bert_dense_units'],\n",
    "                        kernel_regularizer=regularizers.l2(hyperparams['l2_dense']),\n",
    "                        name='bert_dense_layer',\n",
    "                       )(bert_output)\n",
    "    sparse_features = Input(shape=(len(stopwords_list),), name='sparse_input') # stopwords\n",
    "\n",
    "    if hyperparams['dense_bow_units']:\n",
    "        dense_layer_sparse = Dense(units=hyperparams['dense_bow_units'],\n",
    "                              name='sparse_feat_dense_layer',\n",
    "                                kernel_regularizer=regularizers.l2(hyperparams['l2_dense']),\n",
    "                              )(sparse_features)\n",
    "    else:\n",
    "        dense_layer_sparse = sparse_features\n",
    "    \n",
    "    if 'batchnorm' not in ignore_layer:\n",
    "        numerical_features_norm = BatchNormalization(axis=1, momentum=hyperparams['norm_momentum'],\n",
    "                                                     name='numerical_features_norm')(numerical_features)\n",
    "        sent_representation_norm = BatchNormalization(axis=1, momentum=hyperparams['norm_momentum'],\n",
    "                                                      name='sent_repr_norm')(sent_representation)\n",
    "\n",
    "        dense_layer_sparse_norm = BatchNormalization(axis=1, momentum=hyperparams['norm_momentum'],\n",
    "                                                         name='sparse_features_norm')(dense_layer_sparse)\n",
    "        dense_layer_bert_norm = BatchNormalization(axis=1, momentum=hyperparams['norm_momentum'],\n",
    "                                                         name='bert_features_norm')(dense_layer_bert)\n",
    "        \n",
    "    subjects = Input(shape=(1,), name='subjects')\n",
    "    \n",
    "\n",
    "    all_layers = {\n",
    "        'lstm_layers': sent_representation,\n",
    "        'numerical_dense_layer': numerical_features,\n",
    "        'sparse_feat_dense_layer': dense_layer_sparse,\n",
    "        'bert_layer': dense_layer_bert\n",
    "    }\n",
    "    if 'batchnorm' not in ignore_layer:\n",
    "        all_layers = {\n",
    "            'lstm_layers': sent_representation_norm,\n",
    "            'numerical_dense_layer': numerical_features_norm,\n",
    "            'sparse_feat_dense_layer': dense_layer_sparse_norm,\n",
    "            'bert_layer': dense_layer_bert_norm\n",
    "        }\n",
    "    layers_to_merge = []\n",
    "    for n, l in all_layers.items():\n",
    "        if n in ignore_layer:\n",
    "            continue\n",
    "        layers_to_merge.append(l)\n",
    "        \n",
    "    if len(layers_to_merge) == 1:\n",
    "        merged_layers = layers_to_merge[0]\n",
    "    else:\n",
    "        merged_layers = concatenate(layers_to_merge)\n",
    "    output_layers = []\n",
    "    for label in range(nr_classes):\n",
    "        output_layer = Dense(1, activation='softmax',\n",
    "                         name='output_layer%d' % label,\n",
    "                        kernel_regularizer=regularizers.l2(hyperparams['l2_dense']))(merged_layers)\n",
    "        output_layers.append(output_layer)\n",
    "\n",
    "    # Compile model\n",
    "    model = Model(inputs=[tokens_features, numerical_features, sparse_features,\n",
    "                         in_id_bert, in_mask_bert, in_segment_bert], \n",
    "                  outputs=output_layers)\n",
    "\n",
    "    model.compile(hyperparams['optimizer'], {'output_layer%d'%i: \n",
    "                                             'mean_squared_error' for i in range(nr_classes)},\n",
    "                  metrics={'output_layer%d' % label: \n",
    "                           ['accuracy', 'mean_squared_error'] for label in range(nr_classes)})\n",
    "    return model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hub.KerasLayer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = build_model(hyperparams, hyperparams_features, embedding_matrix, emotions, stopword_list,\n",
    "                    liwc_categories=[c for c in categories if c in writings_df.columns],\n",
    "                    nr_classes=nr_questions,\n",
    "                   ignore_layer=hyperparams['ignore_layer'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, \n",
    "                data_generator_train, data_generator_valid,\n",
    "                epochs, start_epoch=0, workers=4,\n",
    "                callback_list = [],\n",
    "                model_path='/tmp/model',\n",
    "               verbose=1):\n",
    "    logging.info('Train...')\n",
    "    experiment.log_parameter('callbacks', callbacks)\n",
    "\n",
    "    history = model.fit_generator(data_generator_train,\n",
    "#               batch_size=batch_size,\n",
    "#                 steps_per_epoch=steps_per_epoch,\n",
    "              epochs=epochs, initial_epoch=start_epoch, \n",
    "              validation_data=data_generator_valid,\n",
    "                        verbose=verbose,\n",
    "#               validation_split=0.3,\n",
    "                       workers=workers,\n",
    "            callbacks = [\n",
    "                callbacks.ModelCheckpoint(filepath='%s_best' % model_path, verbose=1, \n",
    "                                          save_best_only=True),\n",
    "                callbacks.EarlyStopping(patience=500), *callback_list\n",
    "            ])\n",
    "    model.save(model_path)\n",
    "    experiment.log_parameter('model_path', model_path)\n",
    "    return model, history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment = Experiment(api_key=\"eoBdVyznAhfg3bK9pZ58ZSXfv\",\n",
    "                        project_name=\"mental\", workspace=\"ananana\", disabled=False)\n",
    "\n",
    "experiment.log_parameters(hyperparams_features)\n",
    "\n",
    "experiment.log_parameter('emotion_lexicon', nrc_lexicon_path)\n",
    "experiment.log_parameter('emotions', emotions)\n",
    "experiment.log_parameter('embeddings_path', pretrained_embeddings_path)\n",
    "\n",
    "experiment.add_tag('T2')\n",
    "experiment.log_parameters(hyperparams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subjects_split = get_subjects_split(test_size=10)\n",
    "data_generator_train = DataGenerator(user_level_data, set_type='train', \n",
    "                                     subjects_split=subjects_split)\n",
    "data_generator_valid = DataGenerator(user_level_data, set_type='test',  \n",
    "                                     subjects_split=subjects_split)\n",
    "model, history = train_model(model, data_generator_train, data_generator_valid,\n",
    "           epochs=1000, start_epoch=0,\n",
    "                      callback_list = [],\n",
    "                      model_path='models/bert_t21', workers=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subjects_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for d in DataGenerator(user_level_data, set_type='train', \n",
    "                                     subjects_split=subjects_split):\n",
    "    print(d[0])\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.test.is_gpu_available()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import cross_val_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "writings_df = writings_df.fillna(value={'text': '', 'title':''})\n",
    "column_functions = {'text': lambda t: \" \".join(t), \n",
    "                                        'title': lambda t: \" \".join(t),\n",
    "                                        'text_len': 'sum',\n",
    "                                        'title_len': 'sum',\n",
    "                                        'tokenized_text': 'sum',\n",
    "                                        'tokenized_title': 'sum',\n",
    "                     }\n",
    "column_functions.update({'label%i'%i: 'min' for i in range(21)})\n",
    "column_functions.update({c: 'mean' for c in list(categories) + emotions + [\"pronouns\"]})\n",
    "writings_per_user_df = writings_df.groupby('subject').aggregate(column_functions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "writings_df.groupby('subject').mean().columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_avg_embedding(writings_df, subject, column):\n",
    "    return writings_df[writings_df['subject']==subject][column].apply(lambda l: np.array(l)).values.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_embeddings_text = {s: get_avg_embedding(writings_df, s, 'use_embeddings_text') \n",
    "                       for s in set(writings_df.subject.values)}\n",
    "avg_embeddings_title = {s: get_avg_embedding(writings_df, s, 'use_embeddings_title') \n",
    "                       for s in set(writings_df.subject.values)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "series_embeddings_text = pd.Series(avg_embeddings_text)\n",
    "series_embeddings_text.name = 'avg_embeddings_text'\n",
    "series_embeddings_title = pd.Series(avg_embeddings_title)\n",
    "series_embeddings_title.name = 'avg_embeddings_title'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "writings_per_user_df = writings_per_user_df.join(series_embeddings_text, on='subject')\n",
    "writings_per_user_df = writings_per_user_df.join(series_embeddings_title, on='subject')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "writings_per_user_df.columns.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "writings_per_user_df.join?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Universal sentence encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "# import sentencepiece\n",
    "# import tensorflow_text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "os.environ['TFHUB_CACHE_DIR'] = '/home/anasab/tf_cache'\n",
    "\n",
    "import tensorflow_hub as hub\n",
    "module_url = \"https://tfhub.dev/google/universal-sentence-encoder-large/3\"\n",
    "# Import the Universal Sentence Encoder's TF Hub module\n",
    "embed = hub.Module(module_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# embed_layer = hub.KerasLayer(\"https://tfhub.dev/google/universal-sentence-encoder-large/4\",input_shape=[],dtype=tf.string,trainable=True)\n",
    "\n",
    "# model = tf.keras.Sequential()\n",
    "# model.add(embed_layer)\n",
    "# model.add(tf.keras.layers.Dense(16, activation='relu'))\n",
    "# model.add(tf.keras.layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "# model.summary()\n",
    "\n",
    "# model.compile(optimizer='adam',\n",
    "#           loss='binary_crossentropy',\n",
    "#           metrics=['accuracy'])\n",
    "\n",
    "# history = model.fit(train_dataset,\n",
    "#                 validation_data=validation_dataset,\n",
    "#                 epochs=30,\n",
    "#                 verbose=1\n",
    "#                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tf.version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# g = tf.Graph()\n",
    "# with g.as_default():\n",
    "#     use = hub.load(\"https://tfhub.dev/google/universal-sentence-encoder/4\")\n",
    "#     # use = tf.saved_model.load(\"https://tfhub.dev/google/universal-sentence-encoder-multilingual/3\")\n",
    "#     # hub.Module(\"https://tfhub.dev/google/universal-sentence-encoder-multilingual-large/3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tf.compat.v1.disable_eager_execution()\n",
    "\n",
    "# module_url = \"https://tfhub.dev/google/universal-sentence-encoder/4\" #@param [\"https://tfhub.dev/google/universal-sentence-encoder/4\", \"https://tfhub.dev/google/universal-sentence-encoder-large/5\"]\n",
    "# model = hub.load(module_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with tf.compat.v1.Session() as session:\n",
    "#     session.run([tf.compat.v1.global_variables_initializer(), tf.compat.v1.tables_initializer()])\n",
    "#     message_embeddings = session.run(embed([\"The cat is on the may\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess.close()\n",
    "sess_config = tf.ConfigProto(\n",
    "        device_count={ 'GPU' : 1, 'CPU': 4 },\n",
    "        intra_op_parallelism_threads = 0,\n",
    "        inter_op_parallelism_threads = 4,\n",
    "        allow_soft_placement=True\n",
    "    )\n",
    "sess_config.gpu_options.allow_growth = True\n",
    "sess_config.gpu_options.per_process_gpu_memory_fraction = 1\n",
    "sess = tf.Session(config=sess_config)\n",
    "\n",
    "def initialize_vars(sess):\n",
    "    sess.run(tf.local_variables_initializer())\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    sess.run(tf.tables_initializer())\n",
    "    K.set_session(sess)\n",
    "initialize_vars(sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = embed([\"hello world\", \"good morning\"])\n",
    "\n",
    "embeddings.eval(session=sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_use(texts):\n",
    "    embeddings=embed(texts)\n",
    "    return embeddings.eval(session=sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_use([\"Come on, man!\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "writings_df['use_embedding_text'] = writings_df['text'].apply(lambda t: get_use([t])[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_texts = writings_df.text.values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "all_embeddings_dict = {}\n",
    "for i in range(0, int(len(all_texts)/2000)+1):\n",
    "    all_embeddings_dict[i] = get_use(all_texts[2000*i:min(2000*(i+1), len(all_texts))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[len(all_embeddings_dict[i]) for i in all_embeddings_dict]\n",
    "# len(all_embeddings_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_embeddings_texts = np.concatenate([all_embeddings_dict[i] for i in range(18)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[all_embeddings_dict[i] for i in range(18)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_embeddings.tolist()\n",
    "writings_df['use_embeddings_text'] = all_embeddings_texts.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "writings_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pickle.dump(writings_df, open(\"writings_df_t2_test_wuse.pkl\", \"wb+\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "writings_embeddings = writings_df[['subject', 'text', 'title', 'use_embeddings_text', 'use_embeddings_title']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "# writings_embeddings['use_similarity'] = writings_embeddings['use_embeddings_text'].apply()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cosine_similarity(writings_embeddings['use_embeddings_text'], writings_embeddings['use_embeddings_title'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# embed = hub.Module(\"../resources/sentence_wise_email/module/module_useT\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with tf.compat.v1.Session() as sess:\n",
    "#     model([\"The cat is on the mat\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# features = [np.random.rand(75) for i in range(20)]\n",
    "# features = writings_per_user_df[list(categories) + emotions + [\"pronouns\"]]\n",
    "features = writings_per_user_df['avg_embeddings_title'].values.tolist()\n",
    "\n",
    "def cross_validation(folds=2):\n",
    "    svmmodels= {}\n",
    "    total_score = 0\n",
    "    for l in range(21):\n",
    "#         print(\"Classifier for label\", l)\n",
    "        labels = writings_per_user_df['label%d' % l].values\n",
    "        svmmodels[l] = SVC(kernel='rbf', C=5)\n",
    "        cvscores = cross_val_score(svmmodels[l], features, labels, cv=folds)\n",
    "#         print(sum(cvscores)/folds, cvscores)\n",
    "        total_score += sum(cvscores)/folds\n",
    "    return total_score/21\n",
    "\n",
    "print(cross_validation())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def results_for_label(features, l, train_examples=16):\n",
    "    labels = writings_per_user_df['label%d' % l].values\n",
    "    svmmodel=SVC()\n",
    "    svmmodel.fit(features[:train_examples], labels[:train_examples])\n",
    "    predictions = svmmodel.predict(features[train_examples:])\n",
    "    print(l, predictions, labels[train_examples:], labels[:train_examples])\n",
    "    return labels[train_examples:]==predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cumresults = []\n",
    "for l in range(21):\n",
    "    results = results_for_label(features, l)\n",
    "    cumresults.append(results)\n",
    "\n",
    "nrusers = len(cumresults[0])\n",
    "nrques = 21\n",
    "correct_per_user = {u: 0 for u in range(nrusers)}\n",
    "for q, ques in enumerate(cumresults):\n",
    "    for u, answ in enumerate(cumresults[q]):\n",
    "        if answ:\n",
    "            correct_per_user[u] += 1\n",
    "\n",
    "for u in correct_per_user:\n",
    "    print(\"u\", u, correct_per_user[u]/nrques)\n",
    "print(\"AHR\", sum(correct_per_user.values())/nrusers/nrques)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.naive_bayes import GaussianNB, MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression, LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparams_features = {\n",
    "    \"max_features\": 20002,\n",
    "    # cut texts after this number of words\n",
    "    # (among top max_features most common words)\n",
    "    \"maxlen\": 512,\n",
    "    \"embedding_dim\": 100,\n",
    "    \"user_level\": True,\n",
    "    \"posts_per_user\": 10,\n",
    "    \"batch_size\": 1,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "def encode_labels(labels):\n",
    "    '''Convert ia to i and ib to -i'''\n",
    "    encoded_labels = []\n",
    "    for i, l in enumerate(labels):\n",
    "        try:\n",
    "            encoded_labels.append(int(l))\n",
    "        except Exception as e:\n",
    "            logger.debug(\"Encoding label %s\\n\" % l)\n",
    "        \n",
    "            if str(l)[-1] == 'a':\n",
    "                encoded_labels.append(int(l[0]))\n",
    "            elif str(l)[-1] == 'b':\n",
    "                encoded_labels.append(-int(l[0]))\n",
    "            else:\n",
    "                logger.warning(\"Coult not encode label %s\\n\" % l)\n",
    "    return encoded_labels\n",
    "\n",
    "def load_erisk_data(writings_df, voc_size, emotion_lexicon, emotions =  \n",
    "                    ['anger', 'anticipation', 'disgust', 'fear', 'joy', \n",
    "                     'negative', 'positive', 'sadness', 'surprise', 'trust'],\n",
    "                    liwc_categories = categories, ignore_features=[],\n",
    "                    pronouns = [\"i\", \"me\", \"my\", \"mine\", \"myself\"],\n",
    "                    train_prop=0.7, valid_prop=0.0, test_slice=2,\n",
    "                    nr_slices=5,\n",
    "                    min_post_len=3, min_word_len=1, \n",
    "                    user_level=True, vocabulary=None,\n",
    "                   logger=logger):\n",
    "    logger.debug(\"Loading data...\\n\")\n",
    "    if not vocabulary:\n",
    "        vocabulary = {}\n",
    "        word_freqs = Counter()\n",
    "        for words in writings_df.tokenized_text:\n",
    "            word_freqs.update(words)\n",
    "        for words in writings_df.tokenized_title:\n",
    "            word_freqs.update(words)\n",
    "        i = 1\n",
    "        for w, f in word_freqs.most_common(voc_size-2): # keeping voc_size-1 for unk\n",
    "            if len(w) < min_word_len:\n",
    "                continue\n",
    "            vocabulary[w] = i\n",
    "            i += 1\n",
    "\n",
    "    if 'subset' in writings_df.columns:\n",
    "        training_subjects = list(set(writings_df[writings_df['subset']=='train'].subject))\n",
    "        test_subjects = list(set(writings_df[writings_df['subset']=='test'].subject))\n",
    "    else:\n",
    "        all_subjects = sorted(list(set(writings_df.subject)))\n",
    "        training_subjects_size = int(len(all_subjects) * train_prop)\n",
    "        test_subjects_size = len(all_subjects) - training_subjects_size\n",
    "        # Cross-validation, with fixed slice as input\n",
    "        test_prop = 1-train_prop\n",
    "        test_slice = min(test_slice, nr_slices)\n",
    "        logger.debug(\"start index: %f, from %f\\n\" % (\n",
    "            len(all_subjects)*(1/nr_slices)*test_slice, test_prop*test_slice))\n",
    "        start_slice = int(len(all_subjects)*(1/nr_slices)*test_slice)\n",
    "        test_subjects = all_subjects[start_slice: start_slice+test_subjects_size]\n",
    "        training_subjects = [s for s in all_subjects if s not in test_subjects]\n",
    "    training_subjects = sorted(training_subjects) # ensuring reproducibility\n",
    "    valid_subjects_size = int(len(training_subjects) * valid_prop)\n",
    "    valid_subjects = training_subjects[:valid_subjects_size]\n",
    "    training_subjects = training_subjects[valid_subjects_size:]\n",
    "    categories = [c for c in liwc_categories if c in writings_df.columns]\n",
    "    logger.debug(\"%d training users, %d validation users, %d test users.\" % (\n",
    "        len(training_subjects), \n",
    "          len(valid_subjects),\n",
    "          len(test_subjects)))\n",
    "    subjects_split = {'train': training_subjects, \n",
    "                      'valid': valid_subjects, \n",
    "                      'test': test_subjects}\n",
    "\n",
    "    user_level_texts = {}\n",
    "    for row in writings_df.sort_values(by='date').itertuples():\n",
    "        words = []\n",
    "        raw_text = \"\"\n",
    "        if row.tokenized_title:\n",
    "            words.extend(row.tokenized_title)\n",
    "            raw_text += row.title\n",
    "        if row.tokenized_text:\n",
    "            words.extend(row.tokenized_text)\n",
    "            raw_text += row.text\n",
    "        if not words or len(words)<min_post_len:\n",
    "            print(row.subject)\n",
    "            continue\n",
    "        labels = [getattr(row, 'label%d'%i) for i in range(nr_questions)]\n",
    "        liwc_categs = [getattr(row, categ) for categ in categories]\n",
    "        if row.subject not in user_level_texts.keys():\n",
    "            user_level_texts[row.subject] = {}\n",
    "            user_level_texts[row.subject]['texts'] = [words]\n",
    "            user_level_texts[row.subject]['labels'] = encode_labels(labels)\n",
    "            user_level_texts[row.subject]['liwc'] = [liwc_categs]\n",
    "            user_level_texts[row.subject]['raw'] = [raw_text]\n",
    "        else:\n",
    "            user_level_texts[row.subject]['texts'].append(words)\n",
    "            user_level_texts[row.subject]['liwc'].append(liwc_categs)\n",
    "            user_level_texts[row.subject]['raw'].append(raw_text)\n",
    "\n",
    "    return user_level_texts, subjects_split, vocabulary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocabulary_list = pickle.load(open('all_vocab_clpsych_erisk_%d.pkl' % (\n",
    "    hyperparams_features['max_features']-2), 'rb'))\n",
    "vocabulary_dict={}\n",
    "for i,w in enumerate(vocabulary_list):\n",
    "    vocabulary_dict[w] = i\n",
    "user_level_data, subjects_split, vocabulary = load_erisk_data(writings_df, \n",
    "                                                            voc_size=hyperparams_features['max_features'],\n",
    "                                                           emotion_lexicon=nrc_lexicon,\n",
    "                                                           emotions=emotions,\n",
    "                                                           user_level=hyperparams_features['user_level'],\n",
    "                                                                                logger=logger,\n",
    "#                                                            vocabulary=pickle.load(open('vocabulary_40K_all.pkl', 'rb')),\n",
    "#                                                            vocabulary=pickle.load(open('vocab_clpsych_10000.pkl', 'rb')),\n",
    "                                                              vocabulary=vocabulary_dict,\n",
    "#                                                               by_subset=True\n",
    "                                                                               )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "writings_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataGenerator(Sequence):\n",
    "    'Generates data for Keras'\n",
    "    def __init__(self, user_level_data, subjects_split, set_type='train', #bert_tokenizer=bert_tokenizer,\n",
    "                 batch_size=1, seq_len=50, \n",
    "                 voc_size=hyperparams_features['max_features'], emotion_lexicon=nrc_lexicon,\n",
    "                 hierarchical=False, pad_value=0, padding='pre', sparse_words=stopword_list,\n",
    "                 post_groups_per_user=1, posts_per_group=10,\n",
    "                 sampling_distr_alfa=0.1, sampling_distr='exp', # 'exp', 'uniform'\n",
    "                 emotions=emotions, pronouns=[\"i\", \"me\", \"my\", \"mine\", \"myself\"], pad_with_duplication=False,\n",
    "                 max_posts_per_user=None, sample_seqs=False,\n",
    "                 shuffle=True):\n",
    "        'Initialization'\n",
    "        self.seq_len = seq_len\n",
    "#         self.bert_tokenizer = bert_tokenizer\n",
    "        self.subjects_split = subjects_split\n",
    "        self.set = set_type\n",
    "        self.emotion_lexicon = emotion_lexicon\n",
    "        self.batch_size = batch_size\n",
    "        self.hierarchical = hierarchical\n",
    "        self.data = user_level_data\n",
    "        self.pad_value = pad_value\n",
    "        self.sampling_distr_alfa = sampling_distr_alfa\n",
    "        self.sampling_distr = sampling_distr\n",
    "        self.emotions = emotions\n",
    "        self.pronouns = pronouns\n",
    "        self.sparse_words = sparse_words\n",
    "        self.sample_seqs = sample_seqs\n",
    "        self.pad_with_duplication = pad_with_duplication\n",
    "        self.padding = padding\n",
    "        self.shuffle = shuffle\n",
    "        self.voc_size = voc_size\n",
    "        self.max_posts_per_user = max_posts_per_user\n",
    "        self.post_groups_per_user = post_groups_per_user\n",
    "        self.posts_per_group = posts_per_group\n",
    "        self.__post_indexes_per_user()\n",
    "        self.on_epoch_end()\n",
    "        \n",
    "    @staticmethod\n",
    "    def _random_sample(population_size, sample_size, sampling_distr, alfa=0.1, replacement=False):\n",
    "        if sampling_distr == 'exp':\n",
    "            # Exponential sampling\n",
    "            sample = sorted(np.random.choice(population_size, \n",
    "                            min(sample_size, population_size),\n",
    "                            p = DataGenerator.__generate_reverse_exponential_indices(population_size, alfa),\n",
    "                            replace=replacement))\n",
    "                                                                # if pad_with_duplication, \n",
    "                                                                # pad by adding the same post multiple times\n",
    "                                                                # if there are not enough posts\n",
    "        elif sampling_distr == 'uniform':\n",
    "            # Uniform sampling\n",
    "            sample = sorted(np.random.choice(population_size,\n",
    "                            min(sample_size, population_size),\n",
    "                            replace=replacement))\n",
    "        return sample\n",
    "    \n",
    "    @staticmethod\n",
    "    def __generate_reverse_exponential_indices(max_index, alfa=1):\n",
    "        probabilities = []\n",
    "        for x in range(max_index):\n",
    "            probabilities.append(alfa * (np.exp(alfa*x)))\n",
    "        reverse_probabilities = [p for p in probabilities]\n",
    "        sump = sum(reverse_probabilities)\n",
    "        normalized_probabilities = [p/sump for p in reverse_probabilities]\n",
    "        return normalized_probabilities\n",
    "    \n",
    "    def __post_indexes_per_user(self):\n",
    "        self.indexes_per_user = {u: [] for u in range(len(self.subjects_split[self.set]))}\n",
    "        self.indexes_with_user = []\n",
    "        for u in range(len(self.subjects_split[self.set])):\n",
    "            if self.subjects_split[self.set][u] not in self.data:\n",
    "                logger.warning(\"User %s has no posts in %s set. Ignoring.\\n\" % (\n",
    "                    self.subjects_split[self.set][u], self.set))\n",
    "                continue\n",
    "            user_posts = self.data[self.subjects_split[self.set][u]]['texts']\n",
    "            if self.max_posts_per_user:\n",
    "                user_posts = user_posts[:self.max_posts_per_user]\n",
    "            nr_post_groups = int(np.ceil(len(user_posts) / self.posts_per_group))\n",
    "            \n",
    "            if self.post_groups_per_user:\n",
    "#                 Limit total number of posts generated for a user to his total nr of posts\n",
    "                if not self.sample_seqs:\n",
    "                    nr_post_groups = min(self.post_groups_per_user, nr_post_groups)\n",
    "                else:\n",
    "                    nr_post_groups = self.post_groups_per_user\n",
    "            for i in range(nr_post_groups):\n",
    "                # Generate random ordered samples of the posts\n",
    "                if self.sample_seqs:\n",
    "                    indexes_sample = DataGenerator._random_sample(population_size=len(user_posts),\n",
    "                                                         sample_size=self.posts_per_group,\n",
    "                                                         sampling_distr=self.sampling_distr,\n",
    "                                                         alfa=self.sampling_distr_alfa,\n",
    "                                                         replacement=self.pad_with_duplication)\n",
    "                    self.indexes_per_user[u].append(indexes_sample)\n",
    "                    self.indexes_with_user.append((u, indexes_sample))\n",
    "                    # break # just generate one?\n",
    "                # Generate all subsets of the posts in order\n",
    "                else:\n",
    "                    self.indexes_per_user[u].append(range(i*self.posts_per_group ,\n",
    "                                                        min((i+1)*self.posts_per_group, len(user_posts))))\n",
    "                    self.indexes_with_user.append((u, range(i*self.posts_per_group ,\n",
    "                                                        min((i+1)*self.posts_per_group, len(user_posts)))))\n",
    "\n",
    "    def __encode_text(self, tokens, raw_text):\n",
    "        # Using voc_size-1 value for OOV token\n",
    "        encoded_tokens = [vocabulary.get(w, self.voc_size-1) for w in tokens]\n",
    "        encoded_emotions = encode_emotions(tokens, self.emotion_lexicon, self.emotions)\n",
    "        encoded_pronouns = encode_pronouns(tokens, self.pronouns)\n",
    "        encoded_stopwords = encode_stopwords(tokens, self.sparse_words)\n",
    "#         bert_ids, bert_masks, bert_segments, label = encode_text_for_bert(self.bert_tokenizer, InputExample(None, \n",
    "#                                                raw_text), self.seq_len)\n",
    "        return (encoded_tokens, encoded_emotions, encoded_pronouns, encoded_stopwords,)\n",
    "#                bert_ids, bert_masks, bert_segments)\n",
    "        \n",
    "    def __len__(self):\n",
    "        'Denotes the number of batches per epoch'\n",
    "        return int(np.ceil(len(self.indexes) / self.batch_size)) # + 1 to not discard last batch\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        'Generate one batch of data'\n",
    "        # Generate indexes of the batch\n",
    "        indexes = self.indexes[index*self.batch_size:(index+1)*self.batch_size]\n",
    "        # Find users\n",
    "        user_indexes = [t[0] for t in indexes]\n",
    "        users = [self.subjects_split[self.set][i] for i in user_indexes\n",
    "                    if self.subjects_split[self.set][i] in self.data.keys()] # TODO: maybe needs a warning that user is missing\n",
    "\n",
    "        post_indexes_per_user = {}\n",
    "        # Sample post ids\n",
    "        for u, post_indexes in indexes:\n",
    "            user = self.subjects_split[self.set][u]\n",
    "            post_indexes_per_user[user] = post_indexes\n",
    "  \n",
    "        # Generate data\n",
    "        if self.hierarchical:\n",
    "            X, y, g = self.__data_generation_hierarchical(users, post_indexes_per_user)\n",
    "        else:\n",
    "            X, y, g = self.__data_generation(users, post_indexes_per_user)\n",
    "\n",
    "        return X, y, g\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        'Updates indexes after each epoch'\n",
    "        self.indexes = self.indexes_with_user\n",
    "#         np.arange(len(self.subjects_split[self.set]))\n",
    "        if self.shuffle == True:\n",
    "            np.random.shuffle(self.indexes)\n",
    "\n",
    "    def __data_generation(self, users, post_indexes):\n",
    "        'Generates data containing batch_size samples' # X : (n_samples, *dim, n_channels)\n",
    "        tokens_data = []\n",
    "        categ_data = []\n",
    "        sparse_data = []\n",
    "        subjects = []\n",
    "#         bert_ids_data = []\n",
    "#         bert_masks_data = []\n",
    "#         bert_segments_data = []\n",
    "        labels = []\n",
    "\n",
    "        for subject in users:\n",
    "            texts = self.data[subject]['texts']\n",
    "            raw_texts = self.data[subject]['raw']\n",
    "            label = self.data[subject]['labels']\n",
    "            liwc_scores = self.data[subject]['liwc']\n",
    "            \n",
    "            # Sample\n",
    "            texts = [texts[i] for i in post_indexes[subject]]\n",
    "            liwc_selection = [liwc_scores[i] for i in post_indexes[subject]]\n",
    "            raw_texts = [raw_texts[i] for i in post_indexes[subject]]\n",
    "            \n",
    "            all_words = [sum(texts, [])] # merge all texts in one list\n",
    "            liwc_mean = [np.array(liwc_selection).mean(axis=0).tolist()]\n",
    "            liwc_std = [np.array(liwc_selection).mean(axis=0).tolist()]\n",
    "            all_raw_texts = [\" \".join(raw_texts)]\n",
    "\n",
    "            #                     bert_ids, bert_masks, bert_segments \n",
    "            for i, words in enumerate(all_words):\n",
    "                encoded_tokens, encoded_emotions, encoded_pronouns, encoded_stopwords, \\\n",
    "                        = self.__encode_text(words, all_raw_texts[i])\n",
    "                try:\n",
    "                    subject_id = int(re.findall('[0-9]+', subject)[0])\n",
    "                except IndexError:\n",
    "                    subject_id = subject\n",
    "                tokens_data.append(encoded_tokens)\n",
    "                categ_data.append(encoded_emotions + [encoded_pronouns] + liwc_mean[i] + liwc_std[i])\n",
    "                sparse_data.append(encoded_stopwords)\n",
    "#                 bert_ids_data.append(bert_ids)\n",
    "#                 bert_masks_data.append(bert_masks)\n",
    "#                 bert_segments_data.append(bert_segments)\n",
    "                \n",
    "                labels.append(label)\n",
    "                subjects.append(subject_id)\n",
    "\n",
    "        \n",
    "        # using zeros for padding\n",
    "        tokens_data_padded = sequence.pad_sequences(tokens_data, maxlen=self.seq_len, \n",
    "                                                    padding=self.padding,\n",
    "                                                   truncating=self.padding)\n",
    "\n",
    "        return ([np.array(tokens_data_padded), np.array(categ_data), np.array(sparse_data),\n",
    "#                  np.array(bert_ids_data), np.array(bert_masks_data), np.array(bert_segments_data),\n",
    "                ],\n",
    "                np.array(labels),\n",
    "                np.array(subjects),\n",
    "                )\n",
    "    \n",
    "    def __data_generation_hierarchical(self, users, post_indexes):\n",
    "        'Generates data containing batch_size samples' # X : (n_samples, *dim, n_channels)\n",
    "        user_tokens = []\n",
    "        user_categ_data = []\n",
    "        user_sparse_data = []\n",
    "#         user_bert_ids_data = []\n",
    "#         user_bert_masks_data = []\n",
    "#         user_bert_segments_data = []\n",
    "        \n",
    "        labels = []\n",
    "        for subject in users:\n",
    "            tokens_data = []\n",
    "            categ_data = []\n",
    "            sparse_data = []\n",
    "            subject_ids = []\n",
    "#             bert_ids_data = []\n",
    "#             bert_masks_data = []\n",
    "#             bert_segments_data = []\n",
    "            \n",
    "            texts = self.data[subject]['texts']\n",
    "            raw_texts = self.data[subject]['raw']\n",
    "            label = self.data[subject]['label']\n",
    "            liwc_scores = self.data[subject]['liwc']\n",
    "            \n",
    "#             if len(texts) < self.max_posts_per_user:\n",
    "#                 # TODO: pad with zeros\n",
    "#                 pass\n",
    "\n",
    "            for i in post_indexes[subject]:\n",
    "                raw_text = raw_texts[i]\n",
    "                words = texts[i]\n",
    "                liwc = liwc_scores[i]\n",
    "#                     bert_ids, bert_masks, bert_segments \n",
    "                encoded_tokens, encoded_emotions, encoded_pronouns, encoded_stopwords, \\\n",
    "                                        = self.__encode_text(words, raw_text)\n",
    "                try:\n",
    "                    subject_id = int(re.findall('[0-9]+', subject)[0])\n",
    "                except IndexError:\n",
    "                    subject_id = subject\n",
    "                tokens_data.append(encoded_tokens)\n",
    "                # using zeros for padding\n",
    "                # TODO: there is something wrong with this\n",
    "                categ_data.append(encoded_emotions + [encoded_pronouns] + liwc)\n",
    "                sparse_data.append(encoded_stopwords)\n",
    "#                 bert_ids_data.append(bert_ids)\n",
    "#                 bert_masks_data.append(bert_masks)\n",
    "#                 bert_segments_data.append(bert_segments)\n",
    "            tokens_data_padded = np.array(sequence.pad_sequences(tokens_data, maxlen=self.seq_len,\n",
    "                                          padding=self.padding,\n",
    "                                        truncating=self.padding))\n",
    "            user_tokens.append(tokens_data_padded)\n",
    "\n",
    "            user_categ_data.append(categ_data)\n",
    "            user_sparse_data.append(sparse_data)\n",
    "            \n",
    "#             user_bert_ids_data.append(bert_ids_data)\n",
    "#             user_bert_masks_data.append(bert_masks_data)\n",
    "#             user_bert_segments_data.append(bert_segments_data)\n",
    "\n",
    "            labels.append(label)\n",
    "            subject_ids.append(subject_id)\n",
    "    \n",
    "\n",
    "        user_tokens = sequence.pad_sequences(user_tokens, \n",
    "                                             maxlen=self.posts_per_group, \n",
    "                                             value=self.pad_value)\n",
    "        user_tokens = np.rollaxis(np.dstack(user_tokens), -1)\n",
    "        \n",
    "        user_categ_data = sequence.pad_sequences(user_categ_data,  \n",
    "                                                 maxlen=self.posts_per_group, \n",
    "                                                 value=self.pad_value)\n",
    "        user_categ_data = np.rollaxis(np.dstack(user_categ_data), -1)\n",
    "        \n",
    "        user_sparse_data = sequence.pad_sequences(user_sparse_data, \n",
    "                                                  maxlen=self.posts_per_group, \n",
    "                                                  value=self.pad_value)\n",
    "        user_sparse_data = np.rollaxis(np.dstack(user_sparse_data), -1)\n",
    "        \n",
    "#         user_bert_ids_data = sequence.pad_sequences(user_bert_ids_data, \n",
    "#                                                     maxlen=self.posts_per_group, \n",
    "#                                                     value=self.pad_value)\n",
    "#         user_bert_ids_data = np.rollaxis(np.dstack(user_bert_ids_data), -1)\n",
    "        \n",
    "#         user_bert_masks_data = sequence.pad_sequences(user_bert_masks_data, \n",
    "#                                                       maxlen=self.posts_per_group, \n",
    "#                                                       value=self.pad_value)\n",
    "#         user_bert_masks_data = np.rollaxis(np.dstack(user_bert_masks_data), -1)\n",
    "        \n",
    "#         user_bert_segments_data = sequence.pad_sequences(user_bert_segments_data, \n",
    "#                                                          maxlen=self.posts_per_group, \n",
    "#                                                          value=self.pad_value)\n",
    "#         user_bert_segments_data = np.rollaxis(np.dstack(user_bert_segments_data), -1)\n",
    "        \n",
    "        return ((user_tokens, user_categ_data, user_sparse_data,\n",
    "                )\n",
    "                ,\n",
    "#                  user_bert_ids_data, user_bert_masks_data, user_bert_segments_data),\n",
    "                np.array(labels), np.array(subject_ids))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "most_common_words = [k for k,v in \n",
    "                     pickle.load(open(\"all_vocab_clpsyck_erisk.pkl\", \"rb\")).most_common(200)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_extracted_embeddings_nonover = pickle.load(open(\"common_words_uneven_neighbors_overlap.pkl\", \"rb\"))\n",
    "features_extracted_embeddings_over = pickle.load(open(\"common_words_even_neighbors_overlap.pkl\", \"rb\"))\n",
    "features_extracted_embeddings_corr = pickle.load(open(\"common_words_uneven_neighbors_correlated.pkl\", \"rb\"))[:300]\n",
    "features_extracted_embeddings_uncorr = pickle.load(open(\"common_words_uneven_neighbors_anticorrelated2.pkl\", \"rb\"))[:300]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_features = list(pickle.load(open(\"common_best_features_erisk_clpsych.pkl\", \"rb\")))[:300]\n",
    "len(best_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "most_common_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_extracted_embeddings_corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_extracted_embeddings_uncorr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_extracted_embeddings_nonover"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(set_type='train', liwc=True, bow=True):\n",
    "    features = []\n",
    "    labels = []\n",
    "    subjects = []\n",
    "    if not set_type:\n",
    "        set_types = ['train', 'test']\n",
    "    else:\n",
    "        set_types = [set_type]\n",
    "    for set_type in set_types:\n",
    "        for d in DataGenerator(user_level_data, subjects_split, batch_size=1, sample_seqs=False, \n",
    "                               post_groups_per_user=1, posts_per_group=100,\n",
    "                               set_type=set_type, sampling_distr='exp', \n",
    "                               sparse_words=features_extracted_embeddings_corr):\n",
    "            if liwc and bow:\n",
    "                features.append(np.concatenate([d[0][1].flatten(), d[0][2].flatten()]))\n",
    "            elif liwc:\n",
    "                features.append(d[0][1].flatten())\n",
    "            elif bow:\n",
    "                features.append(d[0][2].flatten())\n",
    "                \n",
    "            labels.append(d[1].flatten())\n",
    "            subjects.append(d[2].flatten())\n",
    "    return np.array(features), np.array(labels), np.array(subjects)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, l, g = get_data(set_type='train', bow=True, liwc=False)\n",
    "len(f), f[0].shape, len(l), l[0].shape, len(g), g[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_extracted_embeddings_over"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_class = MultinomialNB\n",
    "model_arguments = {}\n",
    "# model_arguments = {'kernel': 'rbf', 'C': 5}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.model_selection import GroupKFold, LeaveOneGroupOut\n",
    "\n",
    "\n",
    "\n",
    "def cross_validation(features, labels, groups, folds=2):\n",
    "    svmmodels= {}\n",
    "    total_score = 0\n",
    "    for l in range(21):\n",
    "#         print(\"Classifier for label\", l)\n",
    "        label = labels[:,l]\n",
    "        svmmodels[l] = model_class(**model_arguments)\n",
    "#         print(features, label)\n",
    "        validator = GroupKFold(n_splits=folds)\n",
    "#         logo = LeaveOneGroupOut()\n",
    "#         validator = logo.split(features, label, groups)\n",
    "        cvscores = cross_val_score(svmmodels[l], features, label, groups=groups, cv=validator)\n",
    "        score = sum(cvscores)/folds\n",
    "        print(cvscores)\n",
    "        if not np.isnan(score):\n",
    "            total_score += sum(cvscores)/folds\n",
    "    return total_score/21\n",
    "\n",
    "f, l, g = get_data(set_type=None, bow=True, liwc=True)\n",
    "print(\"final score\", cross_validation(f,l,g, folds=5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def results_for_label(train_features, train_labels, test_features, test_labels):\n",
    "    svmmodel=model_class(**model_arguments)\n",
    "    svmmodel.fit(train_features, train_labels)\n",
    "    predictions = svmmodel.predict(test_features)\n",
    "    # for regression, round to the nearest integer\n",
    "    predictions = [round(n) for n in predictions]\n",
    "    print(l, predictions, test_labels, train_labels)\n",
    "    return test_labels==predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Is this right?\n",
    "# TODO: I should do a majority vote or smth. This is not precisely AHR, unless I have 1 group per user\n",
    "\n",
    "trainf, trainl, trainu = get_data(set_type='train', bow=True, liwc=True)\n",
    "testf, testl, testu = get_data(set_type='test', bow=True, liwc=True)\n",
    "cumresults = []\n",
    "for l in range(21):\n",
    "    results = results_for_label(trainf, trainl[:,l], testf, testl[:,l])\n",
    "    cumresults.append(results)\n",
    "\n",
    "nrques = 21\n",
    "correct_per_user = {u: 0 for u in set(testu.flatten())}\n",
    "total_per_user = {u: 0 for u in set(testu.flatten())}\n",
    "for q, ques in enumerate(cumresults):\n",
    "    s = 0\n",
    "    for u, answ in enumerate(cumresults[q]):\n",
    "        if answ:\n",
    "            correct_per_user[testu[s].item()] += 1\n",
    "        total_per_user[testu[s].item()] += 1\n",
    "        s+=1\n",
    "\n",
    "for u in correct_per_user:\n",
    "    print(\"u\", u, correct_per_user[u]/total_per_user[u], \"correct\", correct_per_user[u], \"total\", total_per_user[u])\n",
    "# print(\"AHR\", sum(correct_per_user.values())/len(set(testu.flatten()))/nrques)\n",
    "print(\"AHR\", sum(correct_per_user.values())/sum(total_per_user.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "writings_df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts_positive = pickle.load(open(\"all_texts_clpsych_erisk_positive.pkl\", \"rb\")).split(\"\\n\")\n",
    "texts_negative = pickle.load(open(\"all_texts_clpsych_erisk_negative.pkl\", \"rb\")).split(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tt = TweetTokenizer()\n",
    "sw = stopwords.words(\"english\")\n",
    "def tokenize_tweets(t, tokenizer=tt, stop=True):\n",
    "    tokens = tokenizer.tokenize(t.lower())\n",
    "    tokens_clean = [token for token in tokens if \n",
    "                            re.match(\"^[a-z]*$\", token)]\n",
    "    if not stop:\n",
    "        tokens_clean = [token for token in tokens_clean \n",
    "                        if token not in sw]\n",
    "    return tokens_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocabulary_kbest = list(pickle.load(open(\"all_vocab_clpsyck_erisk.pkl\", \"rb\")).keys())[:100000]\n",
    "pipe = Pipeline([('count', CountVectorizer(vocabulary=vocabulary_kbest, tokenizer=tt.tokenize)),\n",
    "                    ('tfid', TfidfTransformer())]).fit(texts_positive + texts_negative)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_X = pipe['count'].transform([\"\\n\".join(texts_positive)]).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "negative_X = pipe['count'].transform([\"\\n\".join(texts_negative)]).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_X.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "negative_X.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectKBest, chi2, mutual_info_classif, f_classif, SelectPercentile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_features = {'kbest': None, 'percentile': None}\n",
    "selectors = {'kbest': None, 'percentile': None}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# KBest\n",
    "kbest = SelectKBest(chi2, k=200)\n",
    "kbest.fit_transform([positive_X.flatten(), negative_X.flatten()], [1,0])\n",
    "selectors['kbest'] = kbest\n",
    "\n",
    "# Percentile\n",
    "percent = SelectPercentile(chi2, percentile=0.4)\n",
    "percent.fit_transform([positive_X.flatten(), negative_X.flatten()], [1,0])\n",
    "selectors['percentile'] = percent\n",
    "        \n",
    "def get_features(selector, vocabulary):\n",
    "    features = []\n",
    "    support = selector.get_support()\n",
    "    for i,w in enumerate(vocabulary):\n",
    "        if support[i]:\n",
    "            features.append(w)\n",
    "    return features\n",
    "\n",
    "for key, selector in selectors.items():\n",
    "    best_features[key] = get_features(selector, vocabulary_kbest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(common_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(best_features['kbest'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "common_features = set(best_features['kbest']).intersection(set(best_features['percentile']))\n",
    "len(common_features)\n",
    "pickle.dump(common_features, open(\"common_best_features_erisk_clpsych.pkl\", \"wb+\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(best_features['kbest'], open(\"kbest_features_erisk_clpsych200.pkl\", \"wb+\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extra analysis\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract LIWC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_tokens(row):\n",
    "    tokens = []\n",
    "    if row.tokenized_text:\n",
    "        tokens += row.tokenized_text\n",
    "    if row.tokenized_title:\n",
    "        tokens += row.tokenized_title\n",
    "    return tokens\n",
    "writings_df['all_tokens'] = writings_df.apply (lambda row: merge_tokens(row), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: include the title\n",
    "def extract_emotions(tokens, emotion, relative=True):\n",
    "    if not tokens:\n",
    "        return None\n",
    "    emotion_words = [t for t in tokens \n",
    "                     if t in nrc_lexicon[emotion]]\n",
    "    if relative:\n",
    "        return len(emotion_words) / len(tokens)\n",
    "    else:\n",
    "        return len(emotion_words)\n",
    "    \n",
    "    return encoded_emotions\n",
    "\n",
    "from functools import partial\n",
    "for emotion in emotions:\n",
    "    writings_df[emotion] = writings_df['all_tokens'].apply(partial(extract_emotions, emotion=emotion, \n",
    "                                                                   relative=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "writings_df['pronouns'] = writings_df['all_tokens'].apply(partial(encode_pronouns, relative=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# writings_df[['label%i'%i for i in range(21)] + ['text', 'pronouns', 'text_len'] + emotions].corr('spearman')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# writings_df['label15'] = writings_df['label15'].apply(lambda l: encode_labels([l])[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# writings_df['label17'] = writings_df['label17'].apply(lambda l: encode_labels([l])[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "writings_df.groupby('subject').mean()[\n",
    "    ['label%i'%i for i in range(21)] + ['pronouns', 'text_len'] + emotions].corr(\n",
    "    'spearman')[['pronouns', 'text_len'] + emotions]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "writings_df.corrwith?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from liwc_readDict import readDict\n",
    "\n",
    "liwc = readDict('/home/anasab/resources/liwc.dic')\n",
    "categories = [c for (w,c) in liwc]\n",
    "set(categories)\n",
    "liwc_dict = {}\n",
    "for (w, c) in liwc:\n",
    "    if c not in liwc_dict:\n",
    "        liwc_dict[c] = []\n",
    "    liwc_dict[c].append(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "writings_per_user_df['all_tokens'] = writings_per_user_df.apply (lambda row: merge_tokens(row), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_liwc_categories(tokens, category_words, relative=True):\n",
    "    category_cnt = 0\n",
    "    if not tokens:\n",
    "        return None\n",
    "    text_len = len(tokens)\n",
    "    for t in tokens:\n",
    "        for word in category_words:\n",
    "            if t==word or (word[-1]=='*' and t.startswith(word[:-1])) \\\n",
    "            or (t==word.split(\"'\")[0]):\n",
    "                category_cnt += 1\n",
    "                break # one token cannot belong to more than one word in the category\n",
    "    if relative:\n",
    "        return category_cnt/text_len\n",
    "    else:\n",
    "        return category_cnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "from functools import partial\n",
    "# for categ in ['negemo', 'posemo', 'affect', 'sad', 'anx', 'pronoun']:#liwc_dict.keys():\n",
    "for categ in liwc_dict.keys():\n",
    "    if categ in writings_df.columns:\n",
    "        continue\n",
    "    print(\"Encoding for category %s...\" % categ)\n",
    "    writings_df[categ] = writings_df['all_tokens'].apply(partial(encode_liwc_categories, \n",
    "                                                                   category_words=liwc_dict[categ], \n",
    "                                                                   relative=True))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pickle.dump(writings_per_user_df, open(\"writings_df_t2_test_liwc.pkl\", \"wb+\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "relevant_categs = ['posemo', 'negemo', 'anx', 'sad', 'affect', 'feel', 'social', 'health', \n",
    "                   'sexual', 'present', 'cogmech', 'inhib']\n",
    "writings_df.groupby('subject').mean()[\n",
    "    ['label%i'%i for i in range(21)] + relevant_categs].corr(\n",
    "    'spearman')[relevant_categs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(writings_df.groupby('subject').min()[\n",
    "    ['label%i'%i for i in range(21)] + list(liwc_dict.keys())].corr()[list(liwc_dict.keys())].mean().sort_values().index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(writings_df, open('writings_df_T2_liwc.pkl', 'wb+'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature extraction / analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Correlations with means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_liwc_correlations_df = writings_df.groupby('subject').mean().corr(method='spearman')[\n",
    "    ['label%d'%d for d in range(21)]]\n",
    "label_liwc_correlations_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_correlated_categs_overall_cnt = Counter()\n",
    "for d in range(21):\n",
    "    top_correlated_categs = list(label_liwc_correlations_df['label%d'%d][list(categories)].sort_values(ascending=False)[:5].index)\n",
    "    print(d, top_correlated_categs)\n",
    "    top_correlated_categs_overall_cnt.update(top_correlated_categs)\n",
    "top_correlated_categs_overall_cnt.most_common(10)\n",
    "top_correlated_categs_overall = [k for k, v in top_correlated_categs_overall_cnt.most_common(10)]\n",
    "top_correlated_categs_overall_cnt.most_common(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "writings_df.groupby('subject').mean()[top_correlated_categs_overall]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_categs_values = {}\n",
    "for subject in set(writings_df.subject):\n",
    "    sorted_categs_values[subject] = writings_df[writings_df['subject']==subject][top_correlated_categs_overall + ['date']].sort_values('date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for categ in top_correlated_categs_overall:\n",
    "    sorted_categs_values['subject2827'][categ].rolling(50).mean().plot(legend=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for categ in top_correlated_categs_overall:\n",
    "    sorted_categs_values['subject9798'][categ].rolling(50).mean().plot(legend=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for categ in top_correlated_categs_overall:\n",
    "    sorted_categs_values['subject9218'][categ].rolling(50).mean().plot(legend=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Correlations with deviations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_functions = {'text': lambda t: \" \".join(t), \n",
    "                                        'title': lambda t: \" \".join(t),\n",
    "                                        'text_len': 'sum',\n",
    "                                        'title_len': 'sum'}\n",
    "column_functions.update({'label%i'%i: 'min' for i in range(21)})\n",
    "column_functions.update({categ: 'std' for categ in categories})\n",
    "writings_df_categs_devs = writings_df.groupby('subject').aggregate(column_functions)[\n",
    "    ['label%i'%i for i in range(21)] + list(categories)\n",
    "]\n",
    "#                                          'subset': 'min'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "writings_df_categs_devs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_liwc_dev_correlations_df = writings_df_categs_devs.corr(method='spearman')[\n",
    "    ['label%d'%d for d in range(21)]]\n",
    "label_liwc_dev_correlations_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_correlated_categs_overall_devs_cnt = Counter()\n",
    "for d in range(21):\n",
    "    top_correlated_categs = list(label_liwc_dev_correlations_df['label%d'%d][list(categories)].sort_values(ascending=False)[:5].index)\n",
    "    print(d, top_correlated_categs)\n",
    "    top_correlated_categs_overall_devs_cnt.update(top_correlated_categs)\n",
    "top_correlated_categs_overall_devs_cnt.most_common(10)\n",
    "top_correlated_categs_overall_devs = [k for k, v in top_correlated_categs_overall_devs_cnt.most_common(10)]\n",
    "top_correlated_categs_overall_devs_cnt.most_common(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "writings_df.groupby('subject').std()[top_correlated_categs_overall_devs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_categs_devs_values = {}\n",
    "for subject in set(writings_df.subject):\n",
    "    sorted_categs_devs_values[subject] = writings_df[writings_df['subject']==subject][top_correlated_categs_overall_devs + ['date']].sort_values('date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for categ in top_correlated_categs_overall_devs:\n",
    "    sorted_categs_devs_values['subject2827'][categ].rolling(50).mean().plot(legend=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for categ in top_correlated_categs_overall_devs[:2]:\n",
    "    sorted_categs_devs_values['subject9694'][categ].rolling(50).mean().plot(legend=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for categ in top_correlated_categs_overall_devs[:2]:\n",
    "    sorted_categs_devs_values['subject1272'][categ].rolling(50).mean().plot(legend=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "writings_df.groupby('subject')[['label%d'%d for d in range(21)]].mean().sum(axis=1).sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "for categ in top_correlated_categs_overall_devs[:3]:\n",
    "    sorted_categs_devs_values['subject3993'][categ].rolling(50).mean().plot(legend=True)    \n",
    "plt.show()\n",
    "for categ in top_correlated_categs_overall_devs[:3]:\n",
    "    sorted_categs_devs_values['subject9454'][categ].rolling(50).mean().plot(legend=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "low_subjects = ['subject9694', 'subject2903']\n",
    "high_subjects = ['subject5897', 'subject436', 'subject9454']\n",
    "all_subjects = list(set(writings_df.subject))[:10]\n",
    "for subject in low_subjects+high_subjects:\n",
    "#     color='k'\n",
    "#     if subject in high_subjects:\n",
    "#         color='b'\n",
    "#     else:\n",
    "#         color='y'\n",
    "    plt.plot(sorted_categs_values[subject]['ipron'][:500].rolling(50).mean().values)#, color)\n",
    "    \n",
    "plt.legend(low_subjects+high_subjects)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tfenv",
   "language": "python",
   "name": "tfenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
